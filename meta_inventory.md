# Meta-Inventory – generated on 2025-09-15T08:55:06Z

## 1. Meta-Folders
| Folder | Depth | File Count | Human Description |
|---|---:|---:|---|
| .agent | 1 | 3 | Files: bashrc_telemetry.sh |
| .cache/research | 2 | 0 | Files:  |
| .devcontainer | 1 | 1 | Files: devcontainer.json |
| .git/objects/c4 | 3 | 6 | Files: 70accd417fe7a556d0da5062cca8ac3946dacb |
| agent | 1 | 7 | Files: outcomes |
| agent/memory | 2 | 1 | Files: memory_log.jsonl |
| agent/outcomes | 2 | 3 | Files: research_report.md |
| docs/agents | 2 | 9 | Files: PLANNING_PREFERENCES.md |
| docs/audit | 2 | 24 | Files: size_baseline.json |
| docs/llm | 2 | 1 | Files: RUNTIME_LAYER.md |
| docs/ops | 2 | 2 | Files: memory_privacy_dsr.md |
| docs/rag | 2 | 1 | Files: PINECONE_RAG.md |
| docs/research | 2 | 14 | Files: q13_polars_vs_pandas |
| docs/research/q06_esg_models | 3 | 2 | Files: poc_protocol.md |
| docs/research/q11_orjson_determinism | 3 | 3 | Files: results.md |
| docs/research/q12_compiled_validators | 3 | 3 | Files: results.md |
| docs/research/q13_polars_vs_pandas | 3 | 2 | Files: poc_protocol.md |
| docs/research/q21_xdist_stability | 3 | 2 | Files: poc_protocol.md |
| infra/rag | 2 | 8 | Files: __init__.py |
| infra/rag/ingest | 3 | 3 | Files: __init__.py |
| infra/rag/tests | 3 | 3 | Files: test_perf_splitter_bench.py |
| llm_runtime | 1 | 2 | Files: __init__.py |
| orchestrator | 1 | 2 | Files: __init__.py |
| scripts/research | 2 | 20 | Files: tests |
| scripts/research/connectors | 3 | 4 | Files: federal_register_live.py |
| scripts/research/tests | 3 | 9 | Files: test_research_offline.py |
| src/agent_core | 2 | 34 | Files: tests |
| src/agent_core/.pytest_cache | 3 | 5 | Files: v |
| src/agent_core/__pycache__ | 3 | 1 | Files: __init__.cpython-313.pyc |
| src/agent_core/agent_core | 3 | 17 | Files: __init__.py |
| src/agent_core/agents | 3 | 3 | Files: researcher.py |
| src/agent_core/memory | 3 | 2 | Files: __pycache__ |
| src/agent_core/tests | 3 | 2 | Files: test_rag_memory_schema.py |
| src/llm | 2 | 7 | Files: src |
| src/llm/src | 3 | 2 | Files: llm_runtime |
| src/llm/tests | 3 | 2 | Files: test_parity.py |
| src/orchestrator | 2 | 19 | Files: tests |
| src/orchestrator/.pytest_cache | 3 | 4 | Files: v |
| src/orchestrator/src | 3 | 4 | Files: orchestrator |
| src/orchestrator/tests | 3 | 6 | Files: test_agent_core_adapter.py |
| storage | 1 | 2 | Files: index.json |
| storage/vector_store | 2 | 1 | Files: research_db |
| storage/vector_store/research_db | 3 | 1 | Files: chroma.sqlite3 |

## 2. Meta-Files
| File | SHA256 | Lines | Keyword Hits | Excerpt Proving Implementation |
|---|---|---:|---:|---|
| meta_inventory.md | 3a9f78a0bb14924e59282658e506b3770d66f1a0213738a375d4a0fe9d27af05 | 5152 | 7563 | # Meta-Inventory – generated on 2025-09-11T13:13:51Z  ## 1. Meta-Folders |
| coherence_graph.json | 3f58d71494af45ef45dad64518d5d8cfe41b329d5c12d96a32c27edb433f6ed1 | 11674 | 545 |     },     {       "path": "memory.json",       "type": "other",       "mtime": 1757349262.4704006 |
| bandit-report.json | ba4ee2feb1cb9f595df7e689533db54d7e83f543a98ad52f66c438985c790875 | 1494 | 82 |       "skipped_tests": 0     },     "isa_superapp/core/agent_system.py": {       "CONFIDENCE.HIGH": 0,       "CONFIDENCE.LOW": 0, |
| MAINTENANCE_SUMMARY.md | 30d9e34930480b42664671bc496a6d96437cb60c3714be4f1aef93d65b01b075 | 25 | 7 |  Changed - Memory system hardened (router/logs/drift/nap-time, privacy delete APIs, adapter flags) - CI extended (memory coherence gate, nightly/weekly schedules) - Docs expanded (orchestration, RAG,  |
| .pre-commit-config.yaml | 9c999c817f47c76aa291698c09dd3d8b583649d51334fec558448b91e14ba857 | 192 | 2 |         args: [--ignore-missing-imports]         files: ^(src\|scripts\|isa_superapp)/.*\.py$         exclude: ^scripts/research/\|^scripts/tests/\|^src/orchestrator/src/\|^src/docs_provider/src/docs_provi |
| docker-compose.monitoring.yml | 1a2e0a828fe3d1c92f1d9e12d61fa8d72412849685038162c92436a6f2c20f50 | 344 | 1 |       start_period: 30s    # Promtail - Log collection agent   promtail:     image: grafana/promtail:2.9.0 |
| pyproject.toml | a1b160f4aec584f0b8a33a2529450b7d25a5d626d63855d6fc1e360f2c2d6d8c | 257 | 2 |     "I",  # isort     "B",  # flake8-bugbear     "C4", # flake8-comprehensions     "UP", # pyupgrade     "ARG001", # unused-function-args |
| deployment-config.yaml | 6c8900e0bb912a64ceebd8aad7958565a045b66a8f405e13e459551960bc4506 | 503 | 8 |       replicas: 1       cpu: "500m"       memory: "512Mi"     scaling:       min_replicas: 1 |
| MAINTENANCE_LOG.md | f5b028adcb8eb76837845f2f8b0a5af633cfb51d505cd3996405605b90e8f6cd | 17 | 1 | - Phase 7 (Documentation Integrity): Completed. MkDocs site builds, docs lint clean, cross-links updated. - Phase 7.5 (Coherence & Interconnection Audit): New artifacts generated (graph, orphans, term |
| QUALITY_SCORECARD.md | bfedfd39ec1e1803e7044e02760836b86d0b7a1d66212e7808aac874ea782d31 | 16 | 1 | - Performance: 70 — Perf benches exist (Q11/Q12); broader profiling pending. - Security: 70 — Bandit/pip-audit advisory; SBOM/Trivy weekly workflows configured. - Maintainability: 80 — Type-check clea |
| orphans_and_dead_ends.md | 4c4a2b836b797d6bf77cd5cbfe054727b4512a058fec7035edbd52860d880581 | 408 | 60 | - ISA_SuperApp/cli.py - ISA_SuperApp/core/__init__.py - ISA_SuperApp/core/agent_system.py - ISA_SuperApp/core/app.py - ISA_SuperApp/core/base_agent.py |
| run_research_crew.py | e4094b5db0f3dbc7b97c24965f8a411507be40ee9434808689e541a0bf04317c | 67 | 27 | sys.path.insert(0, str(project_root))  from src.agent_core.agents.planner import PlannerAgent from src.agent_core.agents.researcher import ResearcherAgent from src.agent_core.agents.synthesizer import |
| alert_rules.yml | 1b9dce6a7a5a5595a39755a2a3954f05d5e220f0d92708bbb87d9ecd7af74130 | 493 | 32 |           description: "Redis has been down for more than 1 minute. Instance: {{ $labels.instance }}"        - alert: RedisHighMemoryUsage         expr: redis_memory_used_bytes / redis_memory_max_byte |
| setup.py | 9271036b72bb2c64a6dfa7e1c365836edfb08592028dc7d950d586cf24cca6f6 | 125 | 4 |     author="ISA SuperApp Team",     author_email="team@isa-superapp.com",     description="Intelligent System Architecture SuperApp - A comprehensive AI-powered research and analysis platform",     lo |
| CONTRIBUTING.md | fe47bc844075837de97ccffce0aa94e06e5509dc48eabe95b59d844bdbcc52d8 | 37 | 2 | - Docs references: `make docs-lint` (inspect `docs/audit/docs_ref_report.md`) - Healthcheck (consolidated): `make healthcheck` (see `docs/audit/healthcheck.md`) - PR Notes: `make pr-notes` (attach `ag |
| ruff.toml | 27c78098578e70feb2e3ef338a60a9127ad0c39b417238713e6860161b0f9929 | 50 | 1 |     "I",  # isort     "B",  # flake8-bugbear     "C4", # flake8-comprehensions     "UP", # pyupgrade     "ARG001", # unused-function-args |
| loki-config.yml | 6eb16f69547be51d3b79aaaa7012bca8dc38152d53344d6a3c7fe21bf95df28f | 50 | 1 |     instance_addr: 127.0.0.1     kvstore:       store: inmemory  query_range: |
| TERMS.md | 00c7aeffb983cb068d38fa43c0656577a69655e86f503826427fdf98d578c319 | 363 | 20 | Env/Identifiers (frequency) - ISA: 75 - LLM: 54 - API: 49 - ROOT: 49 |
| gemini.md | 997c2360ffece54720f1a4762ef7395ce346b5ba6abab43f311772153a1b23a0 | 37 | 13 | ### Persona  You are Gemini Code Assist, a world-class software engineering partner for the ISA_D project. Your primary directive is to leverage your deep understanding of the entire codebase and docu |
| meta_risk_xray.md | 2c4eb3f9e9ce27847789139241d3482ff0fb263bdf29ab9ecc9c4a4ff230d189 | 13 | 18 | \| Concept \| Risk Score \| Evidence Snippet (≤ 120 chars) \| Recommended Owner \| Max Acceptable Age (days) \| \|---\|---:\|---\|---\|---:\| \| Agent \| 10 \| Agent: folders=11, files=452, Risk=DUPLICATE; max_age=9 |
| prometheus.yml | 3f1f2892af16c6e9eca663e8a4984d692c2f058b72df3ae6dfbf8f0e235da6c5 | 196 | 1 | enable_feature:   - exemplar-storage   - memory-snapshot-on-shutdown   - promql-at-modifier   - promql-negative-offset |
| ISA_SuperApp/__init__.py | df88330a854c26c6303b1d6b85a3ad1e6f64fcc9b5a8ce52eebd956506c4f23f | 128 | 4 | try:     from .ai import (         ISAAgent,         ISAEmbedding,         ISAModel, |
| ISA_SuperApp/cli.py | 9db603e0bd751f85c685c204846fdb9459950ffb106d0ed9a387f7f63e0417d6 | 475 | 6 |     timeout: Optional[int], ):     """Execute a task using the agent system."""     config_path = ctx.obj.get("config_path")  |
| ISA_SuperApp/core/rerank.py | 0e6f8a14e8d92be02657e49ae06303a464768f2eee90ebe8a6607bab6fc72cfe | 501 | 4 |                 if score >= self.config.similarity_threshold:                     reranked_result = SearchResult(                         vector=result.vector,                         score=float(scor |
| ISA_SuperApp/core/config.py | 9e41abf08e7265b33752408f056cf7228f4339f6f9ba75aa4aedc2c021db6559 | 738 | 75 |  @dataclass class VectorStoreConfig:     """Vector store configuration."""  |
| ISA_SuperApp/core/models.py | 56d184e6540d47c422c7f8dd8a2207c9bc45d8c5232abba671632eeae3853117 | 662 | 26 |  This module defines the core data models used throughout the application for representing documents, vectors, metadata, and other entities. """  |
| ISA_SuperApp/core/embedding.py | 847293aa443be3e44da93ba65cfedc483b8a9e07ef060fa1df5e7df4420b95b5 | 637 | 193 | """ Embedding service for ISA SuperApp.  This module provides text embedding capabilities using various |
| ISA_SuperApp/core/vector_store.py | 7fc3205257b04924d6ecb73172a5cfd5b6b3d765ecc828b0d830959b1e060ec1 | 754 | 381 | """ Vector store for ISA SuperApp.  This module provides vector storage and similarity search capabilities |
| ISA_SuperApp/core/base_agent.py | 4ef682310d352a919155a5a05fb778fac571f36aff5dc240745db07b3c758c32 | 640 | 225 | """ Base agent class for ISA SuperApp.  This module provides the foundational agent infrastructure with common functionality |
| ISA_SuperApp/core/agent_system.py | 241a73103f519533ccfcdeb5546bcae2c4958b56cd7408f312a795eae29a5f98 | 893 | 303 | """ Agent system for ISA SuperApp.  This module provides the core agent system functionality including |
| ISA_SuperApp/core/__init__.py | 9486502fd755cda25ca0889c6f66355aadb35da647caf5d82f3abb05f174cb2e | 78 | 26 | - Retrieval systems with dense and hybrid search capabilities - Reranking functionality for improved search result quality - Vector store integrations - Embedding providers - Configuration management |
| ISA_SuperApp/core/logger.py | ad87ba0f6802ddd75802f321a1c31739aaaeaca545344e262f5a6ff7b04cae8f | 361 | 6 |         status_code: int,         duration_ms: float,         user_agent: Optional[str] = None,         client_ip: Optional[str] = None,         **kwargs: Any, |
| ISA_SuperApp/core/retrieval.py | 1fb0a1e7b7792f6bb8c544aef8df16b3cf2ad4d099401e8e14426d068c20bbfe | 791 | 153 | Retrieval system for ISA SuperApp.  This module provides document retrieval capabilities using vector search and hybrid retrieval strategies. """ |
| ISA_SuperApp/core/app.py | b8105c09534a83c85e867a4dd0b3d2fa958755ee8a86ebe063747b55c6ba3acb | 490 | 103 | Main ISA SuperApp application module.  This module provides the core application class that orchestrates all components of the ISA SuperApp system. """ |
| ISA_SuperApp/core/exceptions.py | c8acbfada7c49815ff455ecbedf749d31607555b4dc1280d7ac154fd65c3d908 | 306 | 1 |  class ISAResourceError(ISAException):     """Exception raised for resource-related errors (memory, disk, etc.)."""      def __init__( |
| ISA_SuperApp/core/workflow.py | e4e76fbed9223df0a7a282ff50737d965553d030c8a2488b6698975aa8be6386 | 1002 | 96 | from typing import Any, Callable, Dict, List, Optional, Set, Union  from .agent_system import AgentOrchestrator, BaseAgent, ResearchAgent from .exceptions import ISAConfigurationError, ISANotFoundErro |
| infra/feature_flags/local_flags.json | 0952e6f9862805e36f1fcc5a8571b953dfa8ccec2493483141d06176d928d7e2 | 30 | 2 |       "created_at": 1757242946.951872     },     "ISA_REF_LLM_RUNTIME_20250906": {       "enabled": false,       "traffic": 0, |
| config/deployment-config.yml | 7e16ae15db39b791eea003ec2270b43fd02ada16be67e3a5779df434f2a3a3c7 | 160 | 1 |       - response_time       - cpu_usage       - memory_usage        recreate: |
| config/deployment-config.yaml | 23fb8374adf311da4b876d2a8589081f9616281b1a8d73c305a359279285ba23 | 356 | 4 |     resources:       cpu: "100m"       memory: "256Mi"     health_check:       endpoint: "/health" |
| k8s/deployment.yaml | b476e5cab98ba785aaf5246124bf1913e74e8af6e0708b32ef3a237f68d4a66a | 147 | 2 |           requests:             cpu: 100m             memory: 256Mi           limits:             cpu: 500m |
| k8s/vpa.yaml | bfd75315c16eaa6c4e81331dcdc85db69c9e0395abb5948023626c280f792b34 | 27 | 3 |       minAllowed:         cpu: 100m         memory: 128Mi       maxAllowed:         cpu: 2 |
| k8s/kustomization.yaml | 959fc8a160f271b527065240b67344f4616f6b23e74ec463150de4453e42a3b5 | 76 | 2 |             requests:               cpu: 200m               memory: 256Mi             limits:               cpu: 1 |
| k8s/hpa.yaml | 9d805a40b4ba791bbf277d2adff22d0df12ea1a0735b74f905c5e69b4ed466be | 53 | 1 |   - type: Resource     resource:       name: memory       target:         type: Utilization |
| k8s/README.md | 80a23ccebf0e70e51673785bf21207ead513b29b03aff1f587fe4061d11575fb | 206 | 4 | Default resource allocations: - **CPU**: 200m requests, 1 core limits - **Memory**: 256Mi requests, 1Gi limits - **Replicas**: 3 minimum, 10 maximum  |
| k8s/overlays/staging/deployment-patch.yaml | 43ab23ea2b346041b937f379a33a32065b75187ac40d2d24334016f532e5519f | 33 | 2 |           requests:             cpu: 50m             memory: 64Mi           limits:             cpu: 200m |
| k8s/overlays/development/deployment-patch.yaml | 54ed991c0f6976285f9a935a6b8983bff516f85c312cba98f30bde8ced7bf132 | 45 | 2 |           requests:             cpu: 100m             memory: 128Mi           limits:             cpu: 500m |
| k8s/overlays/production/hpa.yaml | 18340674fe61e875a86fa2c0e6bd942943da01c67467d1a9d70f113ca658a00b | 37 | 1 |   - type: Resource     resource:       name: memory       target:         type: Utilization |
| k8s/overlays/production/deployment-patch.yaml | 39b9b7b0cd224025cd2a5b7a8443129e3ced410529af84840124c5b5d57d6980 | 33 | 2 |           requests:             cpu: 100m             memory: 128Mi           limits:             cpu: 500m |
| k8s/base/hpa.yaml | 0d2aa21b5c034e729c841f77f3582768d5e21c1dc867cb70a140ca88a200ea09 | 41 | 1 |   - type: Resource     resource:       name: memory       target:         type: Utilization |
| experiments/isa_docs_v1_20250908/manifest_copy.yaml | 891944d6c5688866393a2fad852a8c84857239b84033ae7441c218bef3cf8e97 | 27 | 4 | # Ingestion manifest example for isa_docs_v1 # Connects canonical doc sources to the vector store schema.  id: isa_docs_v1_manifest |
| experiments/isa_docs_v1_20250908/processed/processed.yaml | 43c1117fa77745580f250e95e831d408b0581e87565d6572383ed0764453c533 | 10 | 3 |   chunk_size: 500   method: token embedding_model: text-embedding-3-small items_processed: 0 manifest_id: isa_docs_v1_manifest |
| tests/conftest.py | 80e3530e0c68ab2f29741c2f565783a965597cccfe17edbb6c893fd543b5eb2d | 471 | 34 |         "ENVIRONMENT": "test",         "LOG_LEVEL": "DEBUG",         "DATABASE_URL": "sqlite:///:memory:",         "REDIS_URL": "redis://localhost:6379/15",  # Use database 15 for tests         "CHROM |
| tests/test_retrieval.py | f2d8340ce7e698a87a5af1deccedc0ee7566a41c0aafa3fc251ff847f8938d65 | 893 | 71 | from isa_superapp.retrieval.rag_retriever import RAGRetriever from isa_superapp.retrieval.re_ranking import ReRanker from isa_superapp.vector_store.base import SearchResult, VectorDocument   |
| tests/test_core.py | 1e58ea88a13f37f4cc1fbae86c4b35e924087bf43a1536ef1d78652084833e3d | 490 | 24 |     ConfigurationError,     ISAError,     OrchestrationError,     ValidationError,     VectorStoreError, |
| tests/test_vector_stores.py | 157fb6f31c5db3953c4da21d7cb65af1bd658f6628c85d3e6e130be20e94d192 | 869 | 244 | """ Tests for vector store functionality. """  |
| tests/test_llm_providers.py | 73c9a788db5ae3bde444023abb4ed27dfc3f79bed5fe596d4b6739dfcc683640 | 583 | 120 | """ Tests for LLM provider functionality. """  |
| tests/README.md | 3d1779a3cb71ea7590cf7d3981aeebe1cb9291e9a305fb2a8493aaf723eb0c78 | 277 | 22 | │   ├── test_config.py │   ├── test_exceptions.py │   ├── test_vector_store.py │   ├── test_orchestrator.py │   └── test_retrieval.py |
| tests/utils.py | 74cadc4a22b4263cc5e7d336b138e0be0a0974d901ccd916e0e1d0749a99cce5 | 494 | 36 |      @staticmethod     def generate_embeddings(         count: int = 10,         dimension: int = 1536, |
| tests/test_main.py | e92eaa40f1aae48ac2980f787b489761356f4b2ea7b28ee782f4e9d3051f85cf | 469 | 54 | from isa_superapp.core.exceptions import ConfigurationError, ISAError from isa_superapp.main import ISASuperApp, create_app, main from isa_superapp.orchestrator.base import TaskDefinition, TaskPriorit |
| tests/test_vector_store.py | 3c9cab384203426f2c2133ab23523c78b5662993c752c9ce4975ba9d09646801 | 836 | 246 | """ Tests for vector store components. """  |
| tests/test_core_app.py | a1744c8d4a72f84282f17f17dc22b05e74614201fa1d206fa14ce21bafee5cdd | 301 | 24 |         """Create a test app instance."""         config = Config(             vector_store={"provider": "memory", "collection_name": "test_collection"},             llm={"provider": "mock", "model":  |
| tests/test_agents.py | 45e5297cab06bc290bb648e1fbdcbbc9755317d0b53290755f1743a870d8c73e | 920 | 479 | """ Tests for agent components. """  |
| tests/unit/test_retrieval.py | a085de5d3026d1ded4cb840bf95c817ec4002f823a1e1f2861ae818981bb0d6f | 536 | 42 |      @pytest.fixture     def mock_vector_store(self):         """Provide a mock vector store."""         return MagicMock() |
| tests/unit/test_llm.py | 1a0308ff60c575595673e7620a94187a31d64c6f9d305e4ebbe324c6d13b10f2 | 649 | 145 | """ Unit Tests for LLM Components ============================  |
| tests/unit/test_memory.py | 66a47e442769698ff12d98fdf2f7f12e86c4637b39d631f25736dc261466cbc6 | 781 | 175 | """ Unit Tests for Memory System Components ======================================  |
| tests/unit/test_vector_store.py | 18fbe6d2d80e7c4c55638c093ccdf14201179fb065654b4741168b6abef81964 | 583 | 243 | """ Unit Tests for Vector Store Components =====================================  |
| agent/check.py | 4eedc6dbeca7739a01f96f362f29794f30ddfca8bee42e4ed173c552b35c0c7c | 61 | 1 | def main() -> int:     run_id = os.environ.get("GITHUB_RUN_ID") or str(int(time.time()))     out_dir = Path("agent/outcomes")     out_dir.mkdir(parents=True, exist_ok=True)     result = { |
| agent/policy.py | e6f9f77796347dc3d32f5f31f397db6372edda2e99ed9021b858a9f0514cf3f4 | 59 | 2 | import yaml  # type: ignore  POLICY_PATH = Path(".agent/policy.yaml")   |
| agent/outcomes/PR_NOTES.md | ad59ca13da3ea6ccd2946a5676998821b498a9f6a300e2086c5a5196e30bdd95 | 16 | 1 |  ## Plan Propagate agentic docs + local automation; add outcomes+router  ## Diff Summary |
| docs/RESEARCH_KNOWLEDGE_GAPS.md | 8a0a25a0ec8524d3dccacdef686520c94eb02889ce62fa06900f1595db3f64c2 | 254 | 29 | Last updated: 2025-09-02  Purpose: Identify knowledge gaps and external capabilities that would most improve delivery quality, velocity, and safety. Drive high‑ROI, low‑bloat integrations.  Rubric (sc |
| docs/VECTOR_STORE_SCHEMA.md | 461e9cfa08875b51c34c1e4c104d453b9441a42eab9c03c268fc8ddec2160086 | 85 | 24 | # Vector Store Schema  This document defines the canonical schema, chunking strategy, and metadata fields for vector store entries used by the ISA project. |
| docs/RESEARCH_OPERATIONS.md | 161d879cb7e23abb89025c2a4def6ee1141c9136326cfd5bfab1c8ba7d72f5bd | 73 | 4 | Last updated: 2025-09-02  Goal: Convert research into high‑impact, low‑bloat improvements via a repeatable Research‑to‑Production (R2P) pipeline with strong evidence standards and measurable ROI.  R2P |
| docs/AI_AGENT_ONBOARDING.md | 89901ba3cf07a420dda345607ffd3211f9f97e133725edeb157a3d11f11314e0 | 54 | 26 | # AI Agent Onboarding Guide  This document serves as the central onboarding guide for any AI agent (e.g., Gemini Code Assist, ChatGPT, etc.) working on the ISA_D project. Its purpose is to ensure cons |
| docs/unified-workflow-architecture.md | 53d9b747677cb4b11263b32a56cd01535a6a92baae39f43b4fc15f8faba95db1 | 307 | 3 | │       └── action.yml                # Reusable rollback action └── scripts/     └── deploy_orchestrator.py        # Deployment orchestration script ```  |
| docs/AGENTIC_ARCHITECTURE.md | a4e9d95ee35cb376513aefc77550e6013a30862310fa5e2be4a4a1892c2b75bf | 146 | 97 | # Agentic Architecture — Roles, Loops, Safety, Rewards Last updated: 2025-09-02  |
| docs/ULTIMATE_PLAN.md | 5414810dc601bcb7b3017fa6b1d8b6eae042bc21e98fac3bf43a98a971bcf9a8 | 151 | 16 | # Ultimate Agentic Development Plan — Checklists and Acceptance Criteria Last updated: 2025-09-02  |
| docs/AI_PROJECT_CHARTER.md | ceecb59769c276692cff86e14c1bbd9ef7f3fe38ace0a0a1dea92cd60b0f678f | 215 | 37 | ## Project Overview  The ISA (Intelligent Systems Architecture) project is designed to create a robust, scalable, and governable AI system that integrates multiple AI agents, memory management, vector |
| docs/RESEARCH_CAPABILITIES.md | 0ed395e3372cd0e73a80796d818a2b834486b47955302b293a101aa8ca20f6f6 | 54 | 16 | - Extractor (`scripts/research/extract.py`): bs4+lxml extraction, boilerplate removal, whitespace normalization. - Offline tests: `scripts/research/tests/` ensures deterministic behavior without netwo |
| docs/TODO_NeSy.md | e646f81bcdd3ce337ca03a887ff267910b93b08d7f6ece28fc3713d17d109edd | 99 | 2 | Status Legend: [ ] pending  [~] in-progress  [x] done  [!] blocked  Scope: All NeSy integrations for GS1 ESG gap-analysis. Keep adapters modular, feature-flagged, and evaluated via A/B before promotio |
| docs/ISA_VISION_OUTCOMES.md | e060d45737e717d017938bc6bed4ca7cde44da7575df847a33e0df3014bcc4be | 49 | 7 |  ## Vision (Purpose) Build an Intelligent Standards Architect for GS1: an AI‑augmented expert system that anticipates regulatory and market change, codifies knowledge into standards‑native data and on |
| docs/TODO.md | 524fcf37fca3e768d00ce9b63839ff622c8715e0d857deb2bb4500aca442d0e6 | 574 | 113 | # Master TODO — Agentic Monorepo Program (All Plans)  Last updated: 2025-09-09 |
| docs/github-environments-setup.md | 5f1778769a8abb179cbfac59e647f4dd872ff62ff0f88c21572f08a7a1a6707e | 195 | 1 |    aws iam create-open-id-connect-provider \      --url https://token.actions.githubusercontent.com \      --thumbprint a031c46782e6b6c2c2bb7b8b0b8b0b8b0b8b0b8b0 \      --client-id-list sts.amazonaws. |
| docs/AGENTIC_SCORECARD.md | 5a2636970f4d467302c01f452e54444d9eac5ca932eb9f3525b4bbfdf43bdaf4 | 36 | 7 | # Agentic Scorecard — Dimensions, Rubric, and Status Last updated: 2025-09-02  |
| docs/README.md | 1a3ae4ca9113a4b496e9bd630579c7ab956e763b1f8b1fee70adba3974fbc98c | 39 | 15 | ## Quick Links - Roadmap: docs/ROADMAP.md - Agentic Architecture: docs/AGENTIC_ARCHITECTURE.md - CLI Quickstart: README.md (Run the Research Crew) - Orchestration & Interop: docs/agents/ORCHESTRATION_ |
| docs/DEFINITION_OF_DONE.md | 1cf2ea897f7c9a37dc74fefd6acddf9ff5dc48c32da49d514a40aa6945fc9d5b | 41 | 2 | Last updated: 2025-09-02  Purpose: Ensure every change ships with quality, performance, safety, and documentation, aligned with the agentic, evidence-first philosophy.  Applies To: All PRs and changes |
| docs/ROADMAP.md | 1bc6621ae7ad4652998142d8426dcaf7a44045607e465343f9076da451e32c6b | 404 | 93 | Last updated: 2025-09-10  Purpose: Provide a holistic roadmap for building a self-improving, production-grade agentic platform and ESG/ISA_C data system. Organized by tracks and phased milestones with |
| docs/CI_WORKFLOWS.md | b22e560bd67e00335ca60bd53eb842f3b68eab13ee1afa3ce131a56ca81e3f82 | 100 | 38 | - Artifacts/signals (advisory):   - Combined Coverage: `coverage-total.xml`; no‑regression check.   - Memory coherence: drift check (advisory) + memory log snapshot (artifact).   - Latency Histogram:  |
| docs/CI_CD_ARCHITECTURE.md | a60b4e5bbf1f5a9ab40f9dd1b8154b87357e98f9b43813c52a3ff5c74f35711e | 320 | 2 | ### 1. Unified CI/CD Pipeline ([`unified-cicd.yml`](.github/workflows/unified-cicd.yml))  The main entry point that orchestrates the entire CI/CD process:  - **Triggers**: Push to main/develop, PRs, r |
| docs/unified-cicd-architecture.md | d0e908329b068e5715a991c51878688ddb11f5f457e61bde02bd63ec7ca3b186 | 645 | 13 |  #### 1. Unified Workflow Engine The central orchestrator that manages the entire CI/CD pipeline execution. It handles: - Event processing and workflow triggering - Configuration loading and validatio |
| docs/QUALITY_GATES.md | ebe72d53241251a83ca7939f0350b0a77143ff805e6982bde283e7ed31b1a64f | 82 | 10 | - Determinism: enforced (deterministic, offline test). Cross‑OS matrix runs daily (advisory). - Typecheck (mypy): advisory → enforced after 7 clean runs on target modules. - Tests + coverage: core cov |
| docs/DATA_FLOW.md | 5ded052be07fc6319d144bfce3f111a55fc76a84c4ef16dccd0d9b2cdd001b77 | 29 | 18 | # Research Data Flow — CLI, Agents, Tools, Memory Last updated: 2025-09-06  |
| docs/QUALITY_METHODS.md | 83c95fbb6f5a5c0520067dbe06d98ad23ae8a030408243aa29d87b9156144b1f | 26 | 14 | Core Methods - Determinism: Canonical JSON writer + snapshot tests; cross‑OS matrix for parity. - Gates: Lint (enforced), Types/Tests/Security (advisory → enforced after 7 green days), Memory Coherenc |
| docs/COST_TELEMETRY.md | 5f214fbe4b5b88d838b563ce21c6d73d3ad710a0a833e2be936fa640e6cad452 | 19 | 3 | Last updated: 2025-09-02  Goal: Track and reduce spend for APIs/LLMs/storage/compute with minimal overhead.  Principles |
| docs/AGENTIC_GOALS.md | 37aa10c07b97f742078e6fc86719a1e87d56fb5c6bf8c761337e6520f9d97a9c | 68 | 12 | # Agentic Goals, Behaviors, and Strategy — 12–18 Month Plan Last updated: 2025-09-02  |
| docs/ADOPTION_PLAN.md | 7e0a62734af40a7ff390f98c0aef5e333a94165c9cb0c7315703b7e2d927626e | 42 | 7 | # Adoption Plan — Agentic Enhancements (Step-by-Step, With Acceptance) Last updated: 2025-09-02  |
| docs/IMPLEMENTATION_PLAN.md | 27c936c6f4eca8bdaf17717d44c53da3360d6b9dbe090d7fba580fcc918b8223 | 78 | 8 | - [ ] Deliver AI Project Charter ({doc}`AI_PROJECT_CHARTER`) — owner: eng-lead — Acceptance: charter reviewed by core team, linked from README  - [ ] Deliver Vector Store Schema ({doc}`VECTOR_STORE_SC |
| docs/CI_CD_MIGRATION_GUIDE.md | 92f3fe5b723edff8a12e390ae4d915cda4c9f09e82f4a447540593a11177acae | 509 | 1 | aws iam create-open-id-connect-provider \   --url https://token.actions.githubusercontent.com \   --thumbprint a031c46782e6e6c662c2c87c76da9aa62ccabd8e \   --client-id-list sts.amazonaws.com  |
| docs/research/q13_polars_vs_pandas/search_ledger.md | 04edc87d15502aa011858ba578f4c30cbec411328f473870fc16a5419f7d0d19 | 13 | 1 | Question: Q13 — Dataframes: performance and rewrite cost for our transforms Date Range: Queries & Keywords: polars pandas benchmark join groupby memory Sources Searched: docs/RESEARCH_SOURCES.md; Pola |
| docs/research/q13_polars_vs_pandas/poc_protocol.md | 61f188b95ae35b4f938ab7233b276d20404785aaa5523b526235fa322a70a1c7 | 14 | 2 | Last updated: 2025-09-02  Question/Hypothesis: Polars (or hybrid) reduces runtime and memory for heavy joins/aggregations by ≥30%. Success Metrics: ≥30% speedup; reduced peak RSS; acceptable rewrite c |
| docs/ADR/0001-tooling-choice.md | 6138bab278eece90a479d5d8724a74d82b66a5684ba4ace6486a95afe00332c7 | 20 | 2 |  Context - Aim to maximize signal, minimize bloat. - Prefer single tools that cover multiple concerns where quality is high.  |
| docs/ADR/0002-agent-safety-and-autonomy.md | 6b26a2ec0d85a0bb28124be38c1ae28b3d91346732fab6ac61bd1468989d2b02 | 25 | 7 | # ADR 0002 — Agent Safety, Policies, and Autonomy Tiers Last updated: 2025-09-02  |
| docs/llm/RUNTIME_LAYER.md | 6087d804a1671752a34123f96b7f718a8911e49cada7b584f2d887a21744f60d | 13 | 3 | # LLM Runtime Layer — OpenAI Responses API and Bedrock Agents Last updated: 2025-09-02  |
| docs/interop/MCP.md | d3cabacafbb2a68bacd1e94c85d0bb5600f92ad253cdb6775087c660524f866b | 15 | 1 |  Client - Minimal MCP client with session/permissions; adapters for orchestrator.  CI Smoke |
| docs/agents/INTEGRATION_PROMPTS.md | 3bfb270139be98cdd6f582f7247a6b923073edc3ea581ca6e2cc0c89fcdb82aa | 25 | 14 | # Integration Prompts — Orchestration, RAG, Interop Last updated: 2025-09-02  |
| docs/agents/RESEARCH_AGENT.md | 3f786a17df6d68e3893681ad76b10dca3e06e4ec50832cab154f5a0e20069b0a | 71 | 36 |  # Agentic System: Autonomous Research Agent  **Owner**: `eng-lead` |
| docs/agents/ORCHESTRATION_ARCHITECTURE.md | f1a0eae3d975a01970f16b1c41de8207ecabc62bb265149968cc5decf549ca37 | 77 | 38 | # Agent Orchestration & Interoperability — LangGraph, AutoGen, LLM Runtimes, RAG, MCP Last updated: 2025-09-02  |
| docs/agents/AGENTS.md | 3588f387e24a5f3f5fd1975c7308f7ee570d4b3c0badea5e997c7e809b31267e | 100 | 19 | # Agent Operating Guide (System Prompt & Policies) Last updated: 2025-09-05  |
| docs/agents/ISA_D_REFACTOR_PACK.md | 9433d7caac05a4e4f2f063dc1c05a69479a0f109152ceb9859456ba5a4ec86db | 176 | 2 | # ISA_D Refactor Pack (Zero-Regression Playbook)  Below is a ready-to-paste “ISA_D Refactor Pack” that folds the zero-regression playbook into the ISA_D agent loop. Each block is ISA_D-native and alig |
| docs/agents/CODEGENESIS.md | 1faa125f2198487874dfbeee7ba84f83070732ae8f0ed37a772ddc18c21525f4 | 66 | 24 | # CodeGenesis — Autonomous, Self‑Improving Software Agent (Operating Manual) Last updated: 2025-09-02  |
| docs/agents/MEMORY_ARCHITECTURE.md | f10a31f0f4401f6fb81815cc855b4a7b421f52c2ad31ec317e4c635f6a491209 | 51 | 19 | # ISA Memory Architecture — Modular, Multi-Backend, CI-Gated Last updated: 2025-09-02  |
| docs/rag/PINECONE_RAG.md | 21b783715f8c2406731fcec7c3ab49a0b33cb2004cf334cce8659459cbb5ef5c | 17 | 5 |  Scope - Build ingestion (splitters), embeddings, Pinecone indexing, and retrieval utilities with eval harness.  Plan |
| docs/model_cards/TEMPLATE.md | 4b61f86b3995cb67f99100d627624de42a02c68e878bbbee483e6529b3bd8bae | 230 | 1 | **Model Name**: *[Your model name]*   **Model Version**: *[Version number]*   **Model Type**: *[e.g., Language Model, Embedding Model, Classification Model]*   **Architecture**: *[e.g., Transformer, C |
| docs/model_cards/EXAMPLE.md | 36033420fa90724b7ac96a7bfd8288a23ed27d3ffe866ccdb45649642f16049e | 250 | 33 | # Model Card: text-embedding-3-large  ## Model Details |
| docs/audit/docs_ref_report.md | 8ade83f2615746f96375ebba2b8414ab4ed29f5f9cba1e0a700202af4b47091f | 11 | 2 |  ## link — 3 - docs/AI_PROJECT_CHARTER.md: broken link -> docs/AGENTIC_ARCHITECTURE.md - docs/AI_PROJECT_CHARTER.md: broken link -> docs/AGENTIC_GOALS.md - docs/AI_PROJECT_CHARTER.md: broken link -> d |
| docs/audit/QUALITY_SCORECARD.md | 443c3a74c464fb7505ec7ce79d0fd7f9367345946d00a6f15294491a0ab59328 | 295 | 19 |  **Current State:** - Agentic architecture: Well documented - Repository structure: Monorepo approach implemented - Design patterns: Established and documented |
| docs/audit/remediation_plan.md | ff080e4779a9aeb502592a99837f185115c85e79779ac827762c0cef86068440 | 13 | 1 | - [ ] Reduce completeness gaps by referencing key docs in ROADMAP/TODO/DoD (2 pts)  Owner: Project (You + Agent) — single-owner model |
| docs/audit/completeness_gap.yaml | fc95398dfe200a40500ba448ae4c94114c52c3f965f7242c1e07bf920603ccef | 650 | 79 | gaps: - path: .agent/policy.yaml   reason: Artefact not linked to any rule   suggestion: Add appropriate governance in docs and CI |
| docs/audit/audit_report.md | 78465d324b7f11e2cf324b64e946143d0e03dcaa67b96b6e5f1fc6690de13210 | 17 | 1 | - Lint/Type/Tests/Sec: present (promotion pending for some gates) - Observability: /metrics and histograms present (api_server.py sha=) - Container: non-root + healthcheck present (Dockerfile sha=9ddd |
| docs/audit/agent_outcomes_summary.md | 2a823bf8dbd5e480f819ff6858ff4ca2f0c799d4918cded5ed8577f732800e19 | 7 | 1 | # Agent Outcomes Summary Last updated: 2025-09-02  |
| docs/audit/healthcheck.md | a32dd3c22022445bcd49e16d83321831792a85a905b2b2d4152be0e8ecef3581 | 11993 | 1554 |  99 \| \|     "ISAValidationError", 100 \| \|     # AI/ML 101 \| \|     "ISAAgent", 102 \| \|     "ISAModel", 103 \| \|     "ISAEmbedding", |
| docs/audit/scenario_simulation.md | 5473656d75982583742d716db01cb9ed4dd6f348ee799a002d41c40b727c5f17 | 47 | 3 |   - ISA_SuperApp/src/api_server.py:112 (sha256=9e8ca6db32717b42a053880777bcf24018f0ab7eb2a57940b9fd334d982e0fd9) `@app.get("/metrics")`   - ISA_SuperApp/src/api_server.py:75,79–84,92,105–106 (metrics  |
| docs/deployment/UNIFIED_DEPLOYMENT_SYSTEM.md | 9f036e21c8ae162fee998a6454399f693ccd3312fa7ce1503b7d31aa208879b8 | 392 | 5 |    - Provides automated rollback capabilities  2. **Deployment Orchestrator** (`scripts/deploy-orchestrator.sh`)    - Central deployment coordination script    - Handles environment protection rules |
| docs/templates/retrospective_template.md | 08c8297d7f5426e440c6424e8b7de08d36cfd3172b91f6bb187063e7fd748cad | 12 | 1 | Top Risks & Mitigations: Improvements to R2P/Process: Updates to Agent Reward Priors: Next Experiments: |
| docs/ops/memory_privacy_dsr.md | e9eeed684db1e6ed110874734c8a2458683b8bb2f60ec9ed498da0dfef99e94f | 26 | 19 | # Memory Privacy — DSR (Access/Delete/Export) Runbook Last updated: 2025-09-02  |
| docs/guilds/DIPLOMACY_STANDARDS_GUILDS.md | 6ca3a1bef121abb7fb978e89b3859a0ccd8e2e2b58436790c17e8b459953b339 | 56 | 1 |  Executive Summary The global supply chain is shifting under simultaneous pressures: rapid digitalization and rising regulatory complexity. GS1 Netherlands should evolve from reactive standards admini |
| docs/issues/0001_high_priority_items.md | 3afa5c7653dcad4c9ab828315e2629bacb4c45493505f51105901a8aaaa1504b | 19 | 2 | Deliverables: - docs/AI_PROJECT_CHARTER.md — owner: eng-lead - docs/VECTOR_STORE_SCHEMA.md — owner: data-engineer - docs/model_cards/TEMPLATE.md + docs/model_cards/EXAMPLE.md — owner: data-science - d |
| context7-master/README.md | 1ec148a15fa3f6e584984e7045710224644511e662263ed0f0f5949a99e7a9f2 | 1171 | 17 | ## ❌ Without Context7  LLMs rely on outdated or generic information about the libraries you use. You get:  - ❌ Code examples are outdated and based on year-old training data |
| context7-master/docs/README.uk.md | 026a63028b5943d13d597c62738388da9f5c683de59eeadc1da6cb6924ceeb55 | 889 | 6 | ```  Після збереження введіть у чаті `get-library-docs`, а потім ваш ідентифікатор документації Context7 (наприклад, `get-library-docs /nuxt/ui`). Додаткова інформація доступна на [сайті документації  |
| context7-master/docs/README.fr.md | 652c92d64c6980db47066f94241045d57d1c23e2bbfb3684e18c58a34478dbdf | 408 | 11 | ## ❌ Sans Context7  Les LLMs s’appuient sur des informations obsolètes ou génériques concernant les bibliothèques que vous utilisez. Vous obtenez :  - ❌ Des exemples de code obsolètes, basés sur des d |
| context7-master/docs/README.id-ID.md | 871b54f0d70d94950f0ca671a10f7c948db5e407d963764b2081507ef702dcb3 | 885 | 16 | ## ❌ Tanpa Context7  LLM bergantung pada informasi yang sudah usang atau generik tentang pustaka yang Anda gunakan. Anda mendapatkan:  - ❌ Contoh kode yang sudah usang dan berdasarkan data pelatihan d |
| context7-master/docs/README.it.md | 4e92e0f775af5e279d6882db42a206835f42a848695d1a51a124edda75c3f1c7 | 357 | 10 | ## ❌ Senza Context7  LLMs si affidano a informazioni obsolete o generiche sulle librerie che utilizzi. Ottieni:  - ❌ Gli esempi di codice sono obsoleti e basati su dati di formazione vecchi di anni |
| context7-master/docs/README.es.md | 9dc272ba68ea0601df77c7f8539465fe10889cadb50fec58d3cd8bc64fac55f6 | 259 | 10 | ## ❌ Sin Context7  Los LLMs dependen de información desactualizada o genérica sobre las bibliotecas que utilizas. Obtienes:  - ❌ Ejemplos de código desactualizados y basados en datos de entrenamiento  |
| context7-master/docs/README.ar.md | 6880054ab4e21e3804acd2c996c8c2c312dff37e0a3b2f5e72f0516643d6d5cd | 339 | 6 | ```  ### التثبيت في Copilot Coding Agent  أضف التكوين التالي إلى قسم `mcp` في ملف إعدادات Copilot Coding Agent الخاص بك Repository->Settings->Copilot->Coding agent->MCP configuration: |
| context7-master/docs/README.tr.md | 852e543f978130e4ed2703030d9584455ed0d1a780dc4e187bda662286e5a1eb | 379 | 9 | ## ❌ Context7 Olmadan  LLM'ler, kullandığınız kütüphaneler hakkında güncel olmayan veya genel bilgilere güvenir. Karşılaştığınız sorunlar:  - ❌ Kod örnekleri eskidir ve bir yıllık eğitim verilerine da |
| context7-master/docs/adding-projects.md | 1db81469bbbb26bd028b1969f9abf70cae507be03f878cf77b172057fba498e4 | 119 | 7 | - **`projectTitle`** (string): The display name for your project in Context7. This overrides the default repository name.  - **`description`** (string): A brief description of what your library does.  |
| context7-master/docs/README.de.md | aac175bb865caeeb7d1fec27980f9ee31484e413fae6aef86952abb958d78011 | 355 | 10 | ## ❌ Ohne Context7  KI-Sprachmodelle (LLMs) greifen auf veraltete oder allgemeine Informationen über die von dir verwendeten Bibliotheken zurück. Das Ergebnis:  - ❌ Codebeispiele sind veraltet und bas |
| context7-master/docs/README.ja.md | 25fe4513cf260c2839d6c8ad39af7e04db20f29265d1ed200e1ddaa045f6acaa | 715 | 13 | ## ❌ Context7 を使わないと  LLM は使用しているライブラリに関する古い情報や一般的な情報に依存しています。その結果：  - ❌ コード例が古く、1 年前のトレーニングデータに基づいている |
| context7-master/docs/README.pt-BR.md | 867e3957327f8007d217a7511d262eb6fa662ad0a81225a4957cb88c46c5652d | 1160 | 17 | ## ❌ Sem o Context7  Os LLMs dependem de informações desatualizadas ou genéricas sobre as bibliotecas que você usa. Você obtém:  - ❌ Exemplos de código desatualizados e baseados em dados de treinament |
| context7-master/docs/README.zh-TW.md | 05b8852199a2a436dd68de184f9e75ad2ba6a84b685a9096ae5a2408235c5a28 | 954 | 16 | ## ❌ 沒有 Context7  大型語言模型（LLM）依賴過時或通用的函式庫資訊。你會遇到：  - ❌ 程式碼範例過時，僅根據一年前的訓練資料 |
| context7-master/docs/README.zh-CN.md | b3b61138bacbd20e52c78b1aad7e444ff78ad4650ca4509e276a5985864232dd | 1189 | 15 | ## ❌ 不使用Context7  大语言模型(LLM)可能依赖过时或通用的库信息。你可能会遇到：  - ❌ 代码示例已过时，或基于一年前的训练数据 |
| context7-master/docs/README.vi.md | 90bfba27cc0a36b3238e16ca37f9545e5d206856257588626ae4605b7a817da2 | 1007 | 17 | ## ❌ Không có Context7  Các LLM dựa vào thông tin lỗi thời hoặc chung chung về các thư viện bạn sử dụng. Bạn sẽ gặp phải:  - ❌ Các ví dụ code lỗi thời và dựa trên dữ liệu huấn luyện cũ |
| context7-master/docs/README.ko.md | c6a8e2a525ec2520e165067d01c09606b7e04e65ac56e670bd23768f8d7bd49c | 973 | 14 | ## ❌ Context7 없이  LLM은 사용하는 라이브러리에 대한 오래되거나 일반적인 정보에 의존하면 다음과 같은 문제가 발생할 수 있습니다:  - ❌ 1년 전 학습 데이터를 기반으로 한 오래된 코드 예제 |
| context7-master/docs/README.ru.md | b93d6207620ff38663e3861514179e8ae5f7969c2d2cc6b80e78b8ef5245f26c | 436 | 9 | ## ❌ Без Context7  LLMs полагаются на устаревшую или обобщённую информацию о библиотеках, с которыми вы работаете. В результате этого вы получаете:  - ❌ Устаревшие примеры кода многолетней давности |
| context7-master/schema/context7.json | 8653fbee58e456dfd2af8c1225e0380c4c50ccd5f05e89d3c56e10fa1a3186fc | 131 | 2 |     "description": {       "type": "string",       "description": "A brief description of what your library does. This helps coding agents understand the purpose of your project.",       "minLength":  |
| llm_runtime/__init__.py | 72a074240bd3b42aae6ba86817531b0db3a2dc6a2bcc8dec850e5ffc901dc624 | 11 | 7 | """Compatibility shim for tests importing `llm_runtime`.  Delegates to the canonical implementation under `src.llm.src.llm_runtime`. |
| .venv/lib/python3.13/site-packages/lizard.py | 1f41201ac534a2ee0895163d03123263f3b8fd63bcb6b65d6b818633b6b890d4 | 1123 | 1 |      Args:         argv: Arguments vector; if None, sys.argv by default.     """     options = parse_args(argv or sys.argv) |
| .venv/lib/python3.13/site-packages/piplicenses.py | 60b61d3b48593aa450fba84638203286091784980fbd9c57e1fad5c8f99fc71c | 1170 | 2 |         def esc_quotes(val: bytes \| str) -> str:             """             Meta-escaping double quotes             https://tools.ietf.org/html/rfc4180             """ |
| .venv/lib/python3.13/site-packages/README.md | c8b266045239bff2ed092b4029703869fa62eccf37cee6a239d75cc3613a3b6a | 321 | 2 |   [b-section]   date = "2018"   name = "Richard Stallman"  [[a-section.hello]] |
| .venv/lib/python3.13/site-packages/__editable___isa_superapp_0_1_0_finder.py | 78e6c9a35c38723542257fb2dc36f177aff3a49443c87e60e3bc3ea49b9f146f | 86 | 4 | from pathlib import Path  MAPPING: dict[str, str] = {'ISA_SuperApp': '/Users/frisowempe/ISA_D/ISA_SuperApp', 'dspy_modules': '/Users/frisowempe/ISA_D/dspy_modules', 'infra': '/Users/frisowempe/ISA_D/i |
| .venv/lib/python3.13/site-packages/nodeenv.py | 5469c29b3f50047d6ec6d76fa1fb7347ec46e100db89a4cc0b50085b29a4a6a6 | 1549 | 1 | def urlopen(url):     home_url = "https://github.com/ekalinin/nodeenv/"     headers = {'User-Agent': 'nodeenv/%s (%s)' % (nodeenv_version, home_url)}     req = urllib2.Request(url, None, headers)      |
| .venv/lib/python3.13/site-packages/typing_extensions.py | 433d11d170d3a24d2eb065ebc1bfe848cea7e3d7ce68567ab52bea2d4c2f7ed8 | 4318 | 2 |          The buffer protocol allows Python objects to expose a low-level         memory buffer interface. Before Python 3.12, it is not possible         to implement the buffer protocol in pure Python |
| .venv/lib/python3.13/site-packages/imagesize.py | 3c0b5b01873825343a07e6a1f03108880c7eed4a3eaf8c2da7df58988464bf54 | 384 | 1 |                 size = 2                 ftype = 0                 while not 0xc0 <= ftype <= 0xcf or ftype in [0xc4, 0xc8, 0xcc]:                     fhandle.seek(size, 1)                     byte =  |
| .venv/lib/python3.13/site-packages/astroid/manager.py | 8330d859f253e725e1f6408091b1971b5d612232110dc212bdb09c9acd9f56f1 | 487 | 2 |                     "Failed to import module {modname} with error:\n{error}.",                     modname=modname,                     # we remove the traceback here to save on memory usage (since th |
| .venv/lib/python3.13/site-packages/astroid/brain/brain_ssl.py | 20e1aedb18dcbb7bb1c1f577b30dab314995631005453856dae78de7a6e6ac41 | 165 | 1 |      from _ssl import OPENSSL_VERSION_NUMBER, OPENSSL_VERSION_INFO, OPENSSL_VERSION     from _ssl import _SSLContext, MemoryBIO     from _ssl import (         SSLError, SSLZeroReturnError, SSLWantRead |
| .venv/lib/python3.13/site-packages/astroid/brain/brain_numpy_core_multiarray.py | ec9503c5f23990c4aa56bdc2436cde70f104ed9fbf050f91370a89b75be1373a | 106 | 4 |     "lexsort": """def lexsort(keys, axis=-1):             return numpy.ndarray([0, 0])""",     "may_share_memory": """def may_share_memory(a, b, max_work=None):             return True""",     # Not y |
| .venv/lib/python3.13/site-packages/astroid/brain/brain_curses.py | 4ed67b17df7bc915a8ed56c2786f50de08fe1cce0e908e40efaff4da04dcb9ac | 185 | 1 |     COLOR_CYAN = 1     COLOR_GREEN = 1     COLOR_MAGENTA = 1     COLOR_RED = 1     COLOR_WHITE = 1 |
| .venv/lib/python3.13/site-packages/astroid/brain/brain_numpy_core_numerictypes.py | 8c6e9bb64754a46f1fb38abac106796d5d596c227f1a678c7cb1db55a72db263 | 265 | 1 |     class int64(signedinteger): pass      buffer_type = memoryview     bool8 = bool_     byte = int8 |
| .venv/lib/python3.13/site-packages/marshmallow/fields.py | a141238da89b881d5e26936e1f406ace5d0675102d1019864469d55e851e11b2 | 2083 | 2 |     :param kwargs: The same keyword arguments that :class:`Field` receives.      .. versionadded:: 3.0.0rc4     """  |
| .venv/lib/python3.13/site-packages/marshmallow/schema.py | acfbac82a909a4e0d62f46def0264f7a3658a919a722ded5f23526031596114f | 1248 | 1 |         """Whether to register the `Schema <marshmallow.Schema>` with marshmallow's internal         class registry. Must be `True` if you intend to refer to this `Schema <marshmallow.Schema>`         |
| .venv/lib/python3.13/site-packages/sentence_transformers/similarity_functions.py | a8db581109cf508448bce5e65fd200ce8c9dc0657df1149da6bbb58f754bccba | 130 | 5 |         Example:             >>> similarity_fn = SimilarityFunction.to_similarity_fn("cosine")             >>> similarity_scores = similarity_fn(embeddings1, embeddings2)             >>> similarity_sc |
| .venv/lib/python3.13/site-packages/sentence_transformers/model_card_templates.py | 1fc12483d605365f19902f3a87650bc36d62011ecbef7c225708973b05767663 | 192 | 21 | # {MODEL_NAME}  This is a [sentence-transformers](https://www.SBERT.net) model: It maps sentences & paragraphs to a {NUM_DIMENSIONS} dimensional dense vector space and can be used for tasks like clust |
| .venv/lib/python3.13/site-packages/sentence_transformers/quantization.py | cdfc38380e4cbd258fb8053a409bc64aeeec70cb31f746fac3e35cbe08c56404 | 443 | 180 |  def semantic_search_faiss(     query_embeddings: np.ndarray,     corpus_embeddings: np.ndarray \| None = None,     corpus_index: faiss.Index \| None = None, |
| .venv/lib/python3.13/site-packages/sentence_transformers/__init__.py | 8f9426e73ae34972727added0fd222c0dc19bd3c2e7ffdf9aee4d9ef32ea44e9 | 73 | 2 | from sentence_transformers.LoggingHandler import LoggingHandler from sentence_transformers.model_card import SentenceTransformerModelCardData from sentence_transformers.quantization import quantize_em |
| .venv/lib/python3.13/site-packages/sentence_transformers/training_args.py | 858aae62058b154ad236dad6ffb8f2a70ec48ca7c4a0863d9d823d4d8e994361 | 310 | 4 |         learning_rate_mapping (`Dict[str, float] \| None`, *optional*):             A mapping of parameter name regular expressions to learning rates. This allows you to set different             learn |
| .venv/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py | 5b6e574401710c771a1477990c46e6c3a9de3728fa4945ac177436a4fad74cc9 | 2463 | 287 | from .models import Pooling, Transformer from .peft_mixin import PeftAdapterMixin from .quantization import quantize_embeddings from .util import (     batch_to_device, |
| .venv/lib/python3.13/site-packages/sentence_transformers/data_collator.py | 15d5e572ae83839009f2c468616791d011d7488b046b590a79952a4d58badf2e | 178 | 1 |              # If a prompt is provided, we prepend it to the column values. Some Pooling setups require removing the             # prompt tokens from the pooled embeddings, so we also store the prompt |
| .venv/lib/python3.13/site-packages/sentence_transformers/trainer.py | 661917eccc7bb866b7e93aba252d9e2b4bbe505065dbab5ddec237499503c200 | 1303 | 9 |             True         """         # All inputs ending with `_input_ids` (Transformers), `_sentence_embedding` (BoW), `_pixel_values` (CLIPModel)         # are considered to correspond to a feature  |
| .venv/lib/python3.13/site-packages/sentence_transformers/fit_mixin.py | b442ab2154b0c1b6bf2bf90be271145e69f39bb464e9307c90aceee7274f3246 | 729 | 1 |         batch_sampler = BatchSamplers.BATCH_SAMPLER         # Convert dataloaders into a DatasetDict         # TODO: This is rather inefficient, as we load all data into memory. We might benefit from  |
| .venv/lib/python3.13/site-packages/sentence_transformers/model_card.py | cc04c55f00df1a2897cd2ac58949dff68a8c4eb276345acc438f44487a895a5e | 1191 | 11 |  from sentence_transformers import __version__ as sentence_transformers_version from sentence_transformers.models import Router, StaticEmbedding from sentence_transformers.training_args import Sentenc |
| .venv/lib/python3.13/site-packages/sentence_transformers/model_card_template.md | 73bfb402509752637ba6132177b10a271b439a62d93d5972cee77bdcabd92526 | 277 | 13 | # {{ model_name if model_name else "Sentence Transformer model" }}  This is a [sentence-transformers](https://www.SBERT.net) model{% if base_model %} finetuned from [{{ base_model }}](https://huggingf |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/DistillKLDivLoss.py | d2bef0ae022175ebacc06108b0c2cbba0a1aac78bcb78f1987f5adace6bf3e87 | 174 | 12 |      def forward(self, sentence_features: Iterable[dict[str, Tensor]], labels: Tensor) -> Tensor:         embeddings = [self.model(sentence_feature)["sentence_embedding"] for sentence_feature in sente |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/CachedMultipleNegativesSymmetricRankingLoss.py | 94cd68256ea5a6f9f6815011f5b96627063284867156ac8534901e4632cf9cc8 | 289 | 21 | from sentence_transformers import SentenceTransformer, util from sentence_transformers.losses.CachedMultipleNegativesRankingLoss import RandContext from sentence_transformers.models import StaticEmbed |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/ContrastiveLoss.py | 98eb3aa1aca8e79b86181e1b9513afc6b4bc82bf6abc46fbd905b61582b66eef | 120 | 4 |         """         Contrastive loss. Expects as input two texts and a label of either 0 or 1. If the label == 1, then the distance between the         two embeddings is reduced. If the label == 0, th |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/SoftmaxLoss.py | b51afc3934d35bfe62db6d010a795dc94c4d3d506e8adc7a0ed07495d4886635 | 156 | 23 |         self,         model: SentenceTransformer,         sentence_embedding_dimension: int,         num_labels: int,         concatenation_sent_rep: bool = True, |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/MultipleNegativesSymmetricRankingLoss.py | 3689f0b89776eb2e4cd2403186c064564b12a87fd0fdaa521a1f47c131d17777 | 144 | 20 |                 is referred to as temperature, which is the inverse of the scale. In short: scale = 1 / temperature, so                 scale=20.0 is equivalent to temperature=0.05.             simila |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py | f2fbdf382b03c44f05c90a50d09bfac1d320e59016afc0b3abf04a6a80cc9f3b | 177 | 24 |         this, a higher batch size results in more in-batch negatives, which then increases performance (to a point).          This loss function works great to train embeddings for retrieval setups wh |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/CoSENTLoss.py | f8cd994707b002d9d582cc81be095683ebdf16243d1e67c735a76e0bd99deaac | 129 | 13 |             model: SentenceTransformerModel             similarity_fct: Function to compute the PAIRWISE similarity                 between embeddings. Default is                 ``util.pairwise_cos_s |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/BatchHardSoftMarginTripletLoss.py | b2695492b40e699c3ce4a233d0a95e2be9d9f067b7ae5132210c928a15114153 | 153 | 6 |             model: SentenceTransformer model             distance_metric: Function that returns a distance between                 two embeddings. The class SiameseDistanceMetric contains              |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/MarginMSELoss.py | e076e2e9e7e9318ac0ddc36a78da01e998facda515d951e1259d07dc2f53a6cc | 226 | 23 |      def forward(self, sentence_features: Iterable[dict[str, Tensor]], labels: Tensor) -> Tensor:         embeddings = [self.model(sentence_feature)["sentence_embedding"] for sentence_feature in sente |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/MatryoshkaLoss.py | e9ebea3d0516670bd6b23ad715dc41e59957c8aa6d04bcc6871f0fc5b67c4881 | 253 | 17 |     if dim > tensor_dim:         raise ValueError(             f"Dimension {dim} in matryoshka_dims cannot be greater than the model's embedding dimension: {tensor_dim}"         )     tensor = tensor[ |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/Matryoshka2dLoss.py | 51ccacddc11cfab2bf78ba0140d3c0dc6eb82a93a7bf07b0727a4fcc2ea9afb1 | 152 | 6 |         """         The Matryoshka2dLoss can be seen as a loss *modifier* that combines the :class:`AdaptiveLayerLoss` and the         :class:`MatryoshkaLoss`. This allows you to train an embedding mo |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/DenoisingAutoEncoderLoss.py | 98f027b6be2e577601298ce5f30ccd0e89ab88d4acfae1293b4ffbeaf69699b3 | 203 | 11 |  from torch import Tensor, nn from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, PreTrainedModel  from sentence_transformers import SentenceTransformer |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/CachedGISTEmbedLoss.py | cc7fa857ccc244a0a16aa4f709de98745acadd22494bbc34787cea2657684d16 | 435 | 31 |  from sentence_transformers import SentenceTransformer from sentence_transformers.models import StaticEmbedding from sentence_transformers.util import all_gather_with_grad  |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/AdaptiveLayerLoss.py | 40bce4cbd21b629577623eeb7f7980b9b73ed0094646e3d24ddd765a5ed92723 | 274 | 46 | class TransformerDecorator:     """     Decorator that caches the embeddings of all layers of the transformer.     When `layer_idx` is set, it returns the cached embeddings of that layer instead.  |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/OnlineContrastiveLoss.py | 77c831ebd6b70a948d922fd80773959074c9d73d2a5e282769523b50870931e6 | 89 | 5 |             model: SentenceTransformer model             distance_metric: Function that returns a distance between                 two embeddings. The class SiameseDistanceMetric contains              |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/MSELoss.py | 787f57d5a6218ea09a9c1e412b6260e57315593667a7b88c22fd9e034d35cb4e | 98 | 14 |     def __init__(self, model: SentenceTransformer) -> None:         """         Computes the MSE loss between the computed sentence embedding and a target sentence embedding. This loss         is used |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/CosineSimilarityLoss.py | 635bedc8614bfa7af2d3e69b2e4aa1ddced250ae8a9cfd0e7a046974610954d5 | 99 | 12 |         """         CosineSimilarityLoss expects that the InputExamples consists of two texts and a float label. It computes the         vectors ``u = model(sentence_A)`` and ``v = model(sentence_B)`` |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/ContrastiveTensionLoss.py | 318a8ad1744f1eef0d855763e03b3eed11a3b846f84f68a7c26ed5078970cce7 | 240 | 10 |     such that a positive pair consists of two identical sentences and a negative pair consists of two different sentences. An independent     copy of the encoder model is created, which is used for en |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/MegaBatchMarginLoss.py | 6494c0e195648928b513930f94d4529b37974c179c3c7d685e1484bf28d384f6 | 181 | 12 |                 should be < negative_margin             use_mini_batched_version: As large batch sizes require a lot                 of memory, we can use a mini-batched version. We break              |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/BatchAllTripletLoss.py | abb6f307393749cc1a46be0e3b7cf1c81b622b9fced5d3576ab31b5fb6b3fce0 | 151 | 6 |             model: SentenceTransformer model             distance_metric: Function that returns a distance between                 two embeddings. The class SiameseDistanceMetric contains              |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/GISTEmbedLoss.py | 0d6182130a570f77921e446957b4bedde707512c0708d0e5d8f278a9ae385805 | 265 | 23 | from transformers import PreTrainedTokenizerBase  from sentence_transformers.models import StaticEmbedding from sentence_transformers.SentenceTransformer import SentenceTransformer from sentence_trans |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/TripletLoss.py | a61a80f24628f0bb30874566bc6895b64d0949d83004d1ba317812c2b7d8e43f | 125 | 11 |             model: SentenceTransformerModel             distance_metric: Function to compute distance between two                 embeddings. The class TripletDistanceMetric contains                 c |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/CachedMultipleNegativesRankingLoss.py | 708efcbfd878da0c00d25db7781b57dfc8d74e33e12acb00f2b63ccac1924329 | 327 | 38 |  from sentence_transformers import SentenceTransformer, util from sentence_transformers.models import StaticEmbedding from sentence_transformers.util import all_gather_with_grad  |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/BatchSemiHardTripletLoss.py | 58e6bfbd71d029ac504dd0561f16645078a7adb116bd793b01bc885290af0ff7 | 188 | 7 |             model: SentenceTransformer model             distance_metric: Function that returns a distance between                 two embeddings. The class SiameseDistanceMetric contains              |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/AnglELoss.py | 19b234ab51e39be2e5e7bbe8ce98ba77fd06e0b918de50f2e06c4185b7f701bd | 82 | 1 |         return """ @misc{li2023angleoptimized,     title={AnglE-optimized Text Embeddings},     author={Xianming Li and Jing Li},     year={2023}, |
| .venv/lib/python3.13/site-packages/sentence_transformers/losses/BatchHardTripletLoss.py | c37952f1f684c73909e251189d5cd0b42d33fd509caea03571ba31f03867fb35 | 267 | 16 |      @staticmethod     def cosine_distance(embeddings: Tensor) -> Tensor:         """Compute the 2D matrix of cosine distances (1-cosine_similarity) between all embeddings."""         return 1 - pytor |
| .venv/lib/python3.13/site-packages/sentence_transformers/util/hard_negatives.py | 98f7d3e46ae5b4e67de1413594071d251f4d5dcb0dadb35dc65b15ffd054ba1c | 770 | 49 |     Args:         dataset (Dataset): A dataset containing (anchor, positive) pairs.         model (SentenceTransformer): A SentenceTransformer model to use for embedding the sentences.         anchor_ |
| .venv/lib/python3.13/site-packages/sentence_transformers/util/similarity.py | 48689766a695f1c838e5f2a736b49a84719445ba679b07508a28bdd09fcb23bd | 233 | 12 | from transformers.utils import logging  from .tensor import _convert_to_batch_tensor, _convert_to_tensor, normalize_embeddings, to_scipy_coo  # NOTE: transformers wraps the regular logging module for  |
| .venv/lib/python3.13/site-packages/sentence_transformers/util/__init__.py | ea7887713790887b18edc05b0cdf94668157d9dffb658882693b9c0535e93f76 | 98 | 6 |     information_retrieval,     paraphrase_mining,     paraphrase_mining_embeddings,     semantic_search, ) |
| .venv/lib/python3.13/site-packages/sentence_transformers/util/tensor.py | d7d30d070ae5ef4fe14e8af3edae68de4f4fdc3262bcb2abf55ff07286921eb8 | 193 | 56 |   def normalize_embeddings(embeddings: Tensor) -> Tensor:     """     Normalizes the embeddings matrix, so that each sentence embedding has unit length. |
| .venv/lib/python3.13/site-packages/sentence_transformers/util/retrieval.py | cac6b9df93bdbcc74ea12970949b4a32edbb78f6d30e87132ef38e93ba8215b2 | 357 | 88 |  from .similarity import cos_sim from .tensor import normalize_embeddings  logger = logging.getLogger(__name__) |
| .venv/lib/python3.13/site-packages/sentence_transformers/datasets/ParallelSentencesDataset.py | 86d72707673d5bef09b249c0c0240f2201453543ef426b0e3dd20c99af584261 | 205 | 28 |     second sentence zweiter satz    segunda oración      The sentence in the first column will be mapped to a sentence embedding using the given the embedder. For example,     embedder is a mono-lingu |
| .venv/lib/python3.13/site-packages/sentence_transformers/backend/utils.py | bfaa8aeb95d8d2b3879f9ff65745145e77b7bf3e2f867d504eff79ba7f64d27b | 326 | 8 |  # Verify that everything works as expected embeddings = model.encode(["The weather is lovely today.", "It's so sunny outside!", "He drove to the stadium."]) print(embeddings.shape)  |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/LayerNorm.py | d905e4654960e4fbf7a2ecdc1d9eda2b5379ce9432328ae5d872939e22bda002 | 54 | 3 |      def forward(self, features: dict[str, Tensor]):         features["sentence_embedding"] = self.norm(features["sentence_embedding"])         return features  |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/Dense.py | 8ab3d4434ec8b7e1bccebd75fb1e3de587917762874b30c4fa6277830fdf647e | 106 | 5 |     Feed-forward function with activation function.      This layer takes a fixed-sized sentence embedding and passes it through a feed-forward layer. Can be used to generate deep averaging networks ( |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/WordWeights.py | e195c9c0b1ff51816d9918edcd5702aae8497563803b484118b36680eca93be9 | 71 | 11 |  class WordWeights(Module):     """This model can weight word embeddings, for example, with idf-values."""      config_keys: list[str] = ["vocab", "word_weights", "unknown_word_weight"] |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/CLIPModel.py | b23ff7ea3140ebebbbf2ec1dd5fffc61a1884e7fa4a397502d31beb0d9fe113c | 122 | 5 |             text_embeds = self.model.text_projection(text_outputs[1])          sentence_embedding = []         image_features = iter(image_embeds)         text_features = iter(text_embeds) |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/Normalize.py | 01159e990eded27413fba16e16b172cfc467cf541f5bd315d7d03881a5019016 | 30 | 3 |  class Normalize(Module):     """This layer normalizes embeddings to unit length"""      def __init__(self) -> None: |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/Pooling.py | 84f618855fa68b87907ceefa1452bfbffb5984d4e1d19e7d187a18e2d2e6bb52 | 248 | 64 | class Pooling(Module):     """     Performs pooling (max or mean) on the token embeddings.      Using pooling, it generates from a variable sized sentence a fixed sized sentence embedding. This layer  |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/__init__.py | 3ac670e213869a9bd599a5be140a2d4527f664499a4a372f5bf623c488a0b716 | 45 | 6 | from .Pooling import Pooling from .Router import Asym, Router from .StaticEmbedding import StaticEmbedding from .Transformer import Transformer from .WeightedLayerPooling import WeightedLayerPooling |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/CNN.py | ab42e55ee36c5743b28e1107517ea193fb6342b0fe9ec4661040a876299232d8 | 89 | 17 |  class CNN(Module):     """CNN-layer with multiple kernel-sizes over the word embeddings"""      config_keys: list[str] = ["in_word_embedding_dimension", "out_channels", "kernel_sizes"] |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/BoW.py | 1cbbc594f1242abdbaa089ea5988249c87dc67a7a814307db437cd295fc71aa7 | 88 | 16 |  class BoW(InputModule):     """Implements a Bag-of-Words (BoW) model to derive sentence embeddings.      A weighting can be added to allow the generation of tf-idf vectors. The output vector has the  |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/Transformer.py | 933ece9f62abff026054a75404ef491b3996105dae643d7f911c136b101b3c2e | 443 | 10 |  class Transformer(InputModule):     """Hugging Face AutoModel to generate token embeddings.     Loads the correct class, e.g. BERT / RoBERTa etc.  |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/WeightedLayerPooling.py | ebbfa39363cb2bd448d34b3ba1248f038726afefcb60f53ad856ee8d47fec9b3 | 73 | 14 |  class WeightedLayerPooling(Module):     """Token embeddings are weighted mean of their different hidden layer representations"""      config_keys: list[str] = ["word_embedding_dimension", "layer_star |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/WordEmbeddings.py | ddb5cc32bd43a36dbcdd983a5afca6c50075a5f444c6c8347fe275a52e8644e7 | 194 | 68 |   class WordEmbeddings(Module):     config_keys: list[str] = ["tokenizer_class", "update_embeddings", "max_seq_length"]     config_file_name: str = "wordembedding_config.json" |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/Module.py | 5ab7acca5f3494d8b973eefeb07a10fb30caf4804b40b40aa5fcb85eca307c48 | 403 | 5 |             - ``attention_mask``: The attention mask for the input tokens.             - ``token_type_ids``: The token type IDs for the input tokens.             - ``token_embeddings``: The token embe |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/Dropout.py | 5b1ef6a25eec6d088c69a9046ff910500226f43013e3e9b0eb1378f0303ad4f3 | 28 | 2 |      def forward(self, features: dict[str, Tensor]):         features.update({"sentence_embedding": self.dropout_layer(features["sentence_embedding"])})         return features  |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/Router.py | d1c224a25054aaf2145cae308b727cfa00bbc12c687e9debf171e200126af005 | 418 | 15 |             use the ``learning_rate_mapping`` argument in the :class:`~sentence_transformers.training_args.SentenceTransformerTrainingArguments`             or :class:`~sentence_transformers.sparse_en |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/StaticEmbedding.py | dcd55770de38ca077e2f8466c32fc948a5518ee486ca231055752eb92fa4799e | 269 | 84 |   class StaticEmbedding(InputModule):     def __init__(         self, |
| .venv/lib/python3.13/site-packages/sentence_transformers/models/LSTM.py | 051cbf54c00304227f13f48cd4fc9b1aebef402480e2a8721eaf9e75fad911c4 | 95 | 14 |  class LSTM(Module):     """Bidirectional LSTM running over word embeddings."""      config_keys: list[str] = ["word_embedding_dimension", "hidden_dim", "num_layers", "dropout", "bidirectional"] |
| .venv/lib/python3.13/site-packages/sentence_transformers/evaluation/NanoBEIREvaluator.py | 31ff047c1f319b51fcb9d613cfa6eb70f8f53c17c3f320ac4ddbd27596b887c5 | 482 | 1 |         batch_size (int): The batch size for evaluation. Defaults to 32.         write_csv (bool): Whether to write the evaluation results to a CSV file. Defaults to True.         truncate_dim (int, o |
| .venv/lib/python3.13/site-packages/sentence_transformers/evaluation/TripletEvaluator.py | 2e3e5be77e573996b3e31d2f5eb7c57f756a9d6570b2d692f558e36255313c66 | 271 | 8 |             the anchor than the positive sample. Defaults to None.         name (str): Name for the output. Defaults to "".         batch_size (int): Batch size used to compute embeddings. Defaults to |
| .venv/lib/python3.13/site-packages/sentence_transformers/evaluation/ParaphraseMiningEvaluator.py | 698675286e8741d762bc63f630ac3f46293140e37284a262652730c23df376c9 | 279 | 5 |             i.e. if dup[a][b] and dup[b][c], then dup[a][c]. Defaults to False.         query_chunk_size (int, optional): To identify the paraphrases, the cosine-similarity between             all sen |
| .venv/lib/python3.13/site-packages/sentence_transformers/evaluation/BinaryClassificationEvaluator.py | a75e50c083f4dc3fa9fa1894b758d81eada67a8528007cd11820588a9cb00f57 | 379 | 12 | class BinaryClassificationEvaluator(SentenceEvaluator):     """     Evaluate a model based on the similarity of the embeddings by calculating the accuracy of identifying similar and     dissimilar sen |
| .venv/lib/python3.13/site-packages/sentence_transformers/evaluation/__init__.py | 26e8312b116e6bf0c6017146f0d174060c1f15f2a5517a3483c4a2a505c5eaba | 34 | 3 |  from .BinaryClassificationEvaluator import BinaryClassificationEvaluator from .EmbeddingSimilarityEvaluator import EmbeddingSimilarityEvaluator from .InformationRetrievalEvaluator import InformationR |
| .venv/lib/python3.13/site-packages/sentence_transformers/evaluation/MSEEvaluatorFromDataFrame.py | 425dc92a8ab47688027062968497aa8eea3af8cc90c56fa5b7563d3db83fae80 | 139 | 14 | class MSEEvaluatorFromDataFrame(SentenceEvaluator):     """     Computes the mean squared error (x100) between the computed sentence embedding and some target sentence embedding.      Args: |
| .venv/lib/python3.13/site-packages/sentence_transformers/evaluation/MSEEvaluator.py | c9fa0a9d468d48c757d2e8b88c28bd4e262ac7bce965598d453c13bdf1f03ae2 | 158 | 10 | class MSEEvaluator(SentenceEvaluator):     """     Computes the mean squared error (x100) between the computed sentence embedding     and some target sentence embedding.  |
| .venv/lib/python3.13/site-packages/sentence_transformers/evaluation/SentenceEvaluator.py | 9878b972f33fe6cf8277feb92155458afdf9455928fc5da746045430ce7e5e04 | 121 | 2 |         Args:             model (SentenceTransformer): Model we are evaluating             sentences (str \| list[str] \| np.ndarray): Text that we are embedding          Returns: |
| .venv/lib/python3.13/site-packages/sentence_transformers/evaluation/TranslationEvaluator.py | 6f68f5dc07f27c07546f6f3f292096ef66fa4b1b67a354f98924834aa9ec017b | 192 | 7 |         source_sentences (List[str]): List of sentences in the source language.         target_sentences (List[str]): List of sentences in the target language.         show_progress_bar (bool): Whethe |
| .venv/lib/python3.13/site-packages/sentence_transformers/evaluation/InformationRetrievalEvaluator.py | 27af2c6449a4e957b1fc71345622a4db5aba23b2609e6f589a3eb68b8d71ea18 | 568 | 12 |         name (str): A name for the evaluation. Defaults to "".         write_csv (bool): Whether to write the evaluation results to a CSV file. Defaults to True.         truncate_dim (int, optional):  |
| .venv/lib/python3.13/site-packages/sentence_transformers/evaluation/EmbeddingSimilarityEvaluator.py | d090f3733a7e841ab790f52d478bc9a81237faf9bdc8b6c6c647e83e428eb1d0 | 272 | 22 |   class EmbeddingSimilarityEvaluator(SentenceEvaluator):     """     Evaluate a model based on the similarity of the embeddings by calculating the Spearman and Pearson rank correlation |
| .venv/lib/python3.13/site-packages/sentence_transformers/evaluation/RerankingEvaluator.py | 50975b9be234a96b95c4b3c0a531b5287021e7f58afe5bf81aee3a93fc41eca5 | 372 | 6 |         name (str, optional): Name of the evaluator. Defaults to "".         write_csv (bool, optional): Write results to CSV file. Defaults to True.         similarity_fct (Callable[[torch.Tensor, to |
| .venv/lib/python3.13/site-packages/sentence_transformers/cross_encoder/training_args.py | 0f75b35e1aa82b61328587b350b8aacde8f08ca9aaf247f1e54eed1f748b3cfd | 40 | 2 |         learning_rate_mapping (`Dict[str, float] \| None`, *optional*):             A mapping of parameter name regular expressions to learning rates. This allows you to set different             learn |
| .venv/lib/python3.13/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py | 84181165c4abe69df1a1dc7498a9a04dbc150ef0ba4f932f62fbb7adffc6991f | 766 | 4 |     on a scale of 0 ... 1.      It does not yield a sentence embedding and does not work for individual sentences.      Args: |
| .venv/lib/python3.13/site-packages/sentence_transformers/cross_encoder/trainer.py | eeee3cad117ea38615f132cc730d51c4c6e30ab339f72b09f72209940e2575a6 | 348 | 2 |     ) -> tuple[list[dict[str, torch.Tensor]], torch.Tensor \| None]:         """Turn the inputs from the dataloader into the separate model inputs & the labels."""         # All inputs ending with `_in |
| .venv/lib/python3.13/site-packages/sentence_transformers/cross_encoder/losses/MultipleNegativesRankingLoss.py | fbedbc2e25a8b032df46efecd4d87f9ac19c6dbf5d18ad3ec2c12a724943f400 | 192 | 2 |         this, a higher batch size results in more in-batch negatives, which then increases performance (to a point).          This loss function works great to train embeddings for retrieval setups wh |
| .venv/lib/python3.13/site-packages/sentence_transformers/cross_encoder/losses/LambdaLoss.py | dd3492a666fea1eaad34501ddd24c2448080d1f4c71faec20e63c66ad79c73b0 | 361 | 1 |                 loss. Defaults to :class:`~torch.nn.Identity`.             mini_batch_size (int, optional): Number of samples to process in each forward pass. This has a significant                 im |
| .venv/lib/python3.13/site-packages/sentence_transformers/cross_encoder/losses/ListMLELoss.py | b5d2470ddc3cf645a35633aa0afdd4c7cc3826637eba551950bb21dc108097c1 | 127 | 1 |                 loss. Defaults to :class:`~torch.nn.Identity`.             mini_batch_size (int, optional): Number of samples to process in each forward pass. This has a significant                 im |
| .venv/lib/python3.13/site-packages/sentence_transformers/cross_encoder/losses/PListMLELoss.py | be265798843b51307789de8a17d2d5243ed96582bb6aa2a4764dfe58da8a7afb | 295 | 1 |                 loss. Defaults to :class:`~torch.nn.Identity`.             mini_batch_size (int, optional): Number of samples to process in each forward pass. This has a significant                 im |
| .venv/lib/python3.13/site-packages/sentence_transformers/cross_encoder/losses/CachedMultipleNegativesRankingLoss.py | 099e7ba970e310756f8e8f81630b95e592f5857c33a55a0a103a0bd1e46efd83 | 282 | 14 |         Boosted version of :class:`~sentence_transformers.cross_encoder.losses.MultipleNegativesRankingLoss` that         caches the gradients of the logits wrt. the loss. This allows for much higher  |
| .venv/lib/python3.13/site-packages/sentence_transformers/cross_encoder/losses/RankNetLoss.py | 221e340eadacfce93e18d7ca12a3bacc727b1918dcce0dc70d3413477e9c7041 | 124 | 1 |                 loss. Defaults to :class:`~torch.nn.Identity`.             mini_batch_size (int, optional): Number of samples to process in each forward pass. This has a significant                 im |
| .venv/lib/python3.13/site-packages/sentence_transformers/cross_encoder/losses/ListNetLoss.py | bc0067274cbc0a5307b098a3491dfe9f61d73f4e0c11abd040686eca1fb360c5 | 198 | 1 |                 loss. Defaults to :class:`~torch.nn.Identity`.             mini_batch_size (int, optional): Number of samples to process in each forward pass. This has a significant                 im |
| .venv/lib/python3.13/site-packages/sentence_transformers/cross_encoder/evaluation/reranking.py | 815b8eb61e1b2665ab1e712d77af409453c96e5189b9db2c85297e41e8b6b5d4 | 302 | 2 |             signal, but setting it to False will result in a more realistic evaluation. Defaults to True.         name (str, optional): Name of the evaluator, used for logging, saving in a CSV, and th |
| .venv/lib/python3.13/site-packages/sentence_transformers/cross_encoder/evaluation/nano_beir.py | f4bfb79a000aee60ab626f975b5d012e8a068884d286e7d2216252464909452b | 347 | 2 |             instead of ``documents``. When using ``documents``, setting this to True will result in a more useful evaluation             signal, but setting it to False will result in a more realistic |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/training_args.py | 81f8c7245a0ce07c2edbc257075c6a0a5aa33920bcae11dc2e7c44d5e29a7721 | 50 | 2 |         learning_rate_mapping (`Dict[str, float] \| None`, *optional*):             A mapping of parameter name regular expressions to learning rates. This allows you to set different             learn |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/SparseEncoder.py | 6bb3d7d94f6753e1200d90cf6938fd6b0c10b510302e298539c31375c2f25d9c | 1416 | 181 | class SparseEncoder(SentenceTransformer):     """     Loads or creates a SparseEncoder model that can be used to map sentences / text to sparse embeddings.      Args: |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/model_card.py | 94799e9891c725e3f35378cdd95eb9d08d396382c74e03961f5d51776d4a2d9e | 132 | 3 | from sentence_transformers.model_card import SentenceTransformerModelCardCallback, SentenceTransformerModelCardData from sentence_transformers.models import Asym, Module, Router from sentence_transfor |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/search_engines.py | 7dea3962879fbd5def13e5b71fb18e3befc530da7583853510b1408c053bef9c | 556 | 121 |  def semantic_search_qdrant(     query_embeddings: torch.Tensor,     corpus_embeddings: torch.Tensor \| None = None,     corpus_index: tuple[QdrantClient, str] \| None = None, |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/model_card_template.md | 68ef2067010c66b8b72c01d2eb8fc9e73767492e4e27a6d964f9411500879a16 | 276 | 13 | # {{ model_name if model_name else ((model_type or "Sparse Encoder") + " model") }}  This is a [{{ model_type or "Sparse Encoder" }}](https://www.sbert.net/docs/sparse_encoder/usage/usage.html) model{ |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/losses/SparseCosineSimilarityLoss.py | a5f574807009c40723e26f01b44741646f34b2d7c0dd83b8660495498dc390cb | 77 | 1 |         """         SparseCosineSimilarityLoss expects that the InputExamples consists of two texts and a float label. It computes the         vectors ``u = model(sentence_A)`` and ``v = model(sentenc |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/losses/SparseMSELoss.py | f57bf002ada6f3a991aaf2adc378de028a3da42e7c16754648e28ca5eeddf21c | 60 | 6 |     def __init__(self, model: SparseEncoder) -> None:         """         Computes the MSE loss between the computed sentence embedding and a target sentence embedding. This loss         is used when  |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/losses/SparseCoSENTLoss.py | d584dee81fa25b7164380d20a6ecf294d140c662e767865443428e3e35123dc9 | 77 | 1 |             model: SparseEncoder             similarity_fct: Function to compute the PAIRWISE similarity                 between embeddings. Default is                 ``util.pairwise_cos_sim``.       |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/losses/SparseTripletLoss.py | 247bdaecefc5d1c43ea6077e71a0acbd88fc2b7934f39e72fdceaacd2faba264 | 72 | 1 |             model: SparseEncoder             distance_metric: Function to compute distance between two                 embeddings. The class TripletDistanceMetric contains                 common dista |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/losses/FlopsLoss.py | 1ef93c9e17ec5080ca92f72258e8315b097fbacdf6a127795b8d72f77a20d671 | 65 | 14 |         """         FlopsLoss implements a regularization technique to promote sparsity in sparse encoder models.         It calculates the squared L2 norm of the mean embedding vector, which helps re |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/losses/SpladeLoss.py | 612688e22b6ea912492f563abe109b13672c6e90186a8ced0d9b055eadfcf93c | 204 | 22 |             model: SparseEncoder model             loss: The principal loss function to use can be any of the SparseEncoder losses except CSR related losses and flops loss.             document_regula |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/losses/CSRLoss.py | 8560e8fd3ded54b217170642a8aaa61dfdad5438fc0ba5dc5238887056ab940f | 229 | 17 |         CSRReconstructionLoss implements the reconstruction loss component for Contrastive Sparse Representation (CSR) models.          This loss ensures that the sparse encoding can accurately recons |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/losses/SparseMultipleNegativesRankingLoss.py | dd70ae10d96676a347822a4dbc18b14e67df3b41eceb953342bd764968190e33 | 103 | 5 |         this, a higher batch size results in more in-batch negatives, which then increases performance (to a point).          This loss function works great to train embeddings for retrieval setups wh |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/models/SparseStaticEmbedding.py | 398a8dc92c098188339fea65f4eb7c11ec2c969a5ab5c85470e6bcce298b29d4 | 229 | 24 |   class SparseStaticEmbedding(InputModule):     """     SparseStaticEmbedding module for efficient sparse representations. |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/models/__init__.py | 69551a706132732d0bda95d19d3e44ce9b2bfe1a33546acb253297724465e85c | 9 | 3 | from .MLMTransformer import MLMTransformer from .SparseAutoEncoder import SparseAutoEncoder from .SparseStaticEmbedding import SparseStaticEmbedding from .SpladePooling import SpladePooling  |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/models/SpladePooling.py | 2ea5ab2a56101f699c4701e8328d973ff73fe0de97628298948cb16e93d95fdc | 148 | 23 | class SpladePooling(Module):     """     SPLADE Pooling module for creating the sparse embeddings.      This module implements the SPLADE pooling mechanism that: |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/models/MLMTransformer.py | dd228fd15eb7ce13f93ae77d9ac60e4929bd0097426ec5625181a1d60d9a5126 | 399 | 6 |         self.max_seq_length = max_seq_length         if max_seq_length is None:             if hasattr(self.config, "max_position_embeddings") and hasattr(self.tokenizer, "model_max_length"):          |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/models/SparseAutoEncoder.py | ba659ed9161f76b41e7b4b4631cd867723b119dd0685a3246b33bc2aaa9390a2 | 237 | 19 |     Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation, https://arxiv.org/abs/2503.01776      This module transforms dense embeddings into sparse representations by:      1. Apply |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/evaluation/SparseMSEEvaluator.py | 07f7e39c8493c59c9c0ce0845d7d16efa488e755b6f8afa01346238c9822114b | 171 | 10 |     This evaluator extends :class:`~sentence_transformers.evaluation.MSEEvaluator` but is specifically designed for sparse encoder models.      Note that this evaluator doesn't take benefit of the spa |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/evaluation/SparseTripletEvaluator.py | ab420a647d6146d7f2a0c8fc132a511f01cf5fa1b8d8b20caad587b676b5497f | 192 | 4 |             the anchor than the positive sample. Defaults to None.         name (str): Name for the output. Defaults to "".         batch_size (int): Batch size used to compute embeddings. Defaults to |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/evaluation/__init__.py | 95e4d59312c9b902db7f0c265f41f6e13ba3a597fc5db3cef1dcb08557a9a8d4 | 42 | 3 |     SparseBinaryClassificationEvaluator, ) from sentence_transformers.sparse_encoder.evaluation.SparseEmbeddingSimilarityEvaluator import (     SparseEmbeddingSimilarityEvaluator, ) |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/evaluation/SparseEmbeddingSimilarityEvaluator.py | ae905e7d92ae201b62127b4660ba48b56163aa671eafe48023685c1207fe37b2 | 169 | 11 | from typing import TYPE_CHECKING, Any, Literal  from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator from sentence_transformers.util import append_to_last_row  |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/evaluation/SparseTranslationEvaluator.py | 36390c15ab509bba1775240c2a02bc4b4a4f2e8dfa3e468ad3aa8693206b1322 | 159 | 5 |         source_sentences (List[str]): List of sentences in the source language.         target_sentences (List[str]): List of sentences in the target language.         show_progress_bar (bool): Whethe |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/evaluation/SparseBinaryClassificationEvaluator.py | 678eb3f38dbef3f6c774e31e4b93d7cd90c5f05ba538117f49c8d3804d6d90a3 | 194 | 5 |     This evaluator extends :class:`~sentence_transformers.evaluation.BinaryClassificationEvaluator` but is specifically designed for sparse encoder models.      Evaluate a model based on the similarit |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/evaluation/SparseInformationRetrievalEvaluator.py | 8ddf01dc8d114c61ec3d80df7f73c8a10f42a41da7f25f39e79901a1f2335e6d | 281 | 6 |         model: SparseEncoder,         corpus_model=None,         corpus_embeddings: torch.Tensor \| None = None,         output_path: str \| None = None,     ) -> dict[str, float]: |
| .venv/lib/python3.13/site-packages/sentence_transformers/sparse_encoder/evaluation/SparseRerankingEvaluator.py | 8d63d993487d47de52575f079086159fddb7eb98fc1cb88eaba9f91b6e445356 | 212 | 7 |         name (str, optional): Name of the evaluator. Defaults to "".         write_csv (bool, optional): Write results to CSV file. Defaults to True.         similarity_fct (Callable[[torch.Tensor, to |
| .venv/lib/python3.13/site-packages/execnet/script/shell.py | 250cf1fe311be0cd77a347ed1f64fa6bcad05928e7060874901548d4d9bb721a | 91 | 3 |   class promptagent(Thread):     def __init__(self, clientsock) -> None:         print("server side starting") |
| .venv/lib/python3.13/site-packages/packaging/version.py | a257f2ba4fc33db7e5364278c0159eb57435edcef8c770c1e74d5d7a052fec36 | 583 | 1 | A string containing the regular expression used to match a valid version.  The pattern is not anchored at either end, and is intended for embedding in larger expressions (for example, matching a versi |
| .venv/lib/python3.13/site-packages/packaging/licenses/_spdx.py | a009b5ced3c5c25b2608a7bb94002cbff38839f4b57160eef5b34191ebbeda7b | 760 | 2 |     'adobe-glyph': {'id': 'Adobe-Glyph', 'deprecated': False},     'adobe-utopia': {'id': 'Adobe-Utopia', 'deprecated': False},     'adsl': {'id': 'ADSL', 'deprecated': False},     'afl-1.1': {'id': ' |
| .venv/lib/python3.13/site-packages/aiohttp/web_ws.py | 948b609b26ad91787433a118ec9a199d2664525e91d30bfc07cf17e082ea41b5 | 632 | 1 |         if self._writer is None:             raise RuntimeError("Call .prepare() first")         if not isinstance(data, (bytes, bytearray, memoryview)):             raise TypeError("data argument mus |
| .venv/lib/python3.13/site-packages/aiohttp/multipart.py | bcd205120654755cd8614d30b28c1cc7b0afb144e4a8fa3e2d6833ba9b0f9cbf | 1142 | 3 |         This is intentional: BodyPartReader payloads are designed for streaming         large data (potentially gigabytes) and must be consumed only once via         the write() method to avoid memory |
| .venv/lib/python3.13/site-packages/aiohttp/web_response.py | 3ca73388d5382e67ed5ea295be844cac06ce7950a5a5237e8b39c7b2259ece65 | 857 | 4 |         elif quoted_value == ETAG_ANY:             return ETag(value=ETAG_ANY)         match = QUOTED_ETAG_RE.fullmatch(quoted_value)         if not match:             return None |
| .venv/lib/python3.13/site-packages/aiohttp/client_ws.py | d42223217c32cce308630e808d4112e3ea94c1bc951d6d6c7892907e0fd1b5af | 429 | 1 |      async def send_bytes(self, data: bytes, compress: Optional[int] = None) -> None:         if not isinstance(data, (bytes, bytearray, memoryview)):             raise TypeError("data argument must b |
| .venv/lib/python3.13/site-packages/aiohttp/test_utils.py | 6494b36568c2efa2926edc1d75329c3fabc7a5497fa337c07f717dddec261d15 | 775 | 2 |         After that point, the TestClient is no longer usable.          This is an idempotent function: running close multiple times         will not have any additional effects.  |
| .venv/lib/python3.13/site-packages/aiohttp/web_exceptions.py | ee722e8b0859dfdbc927d2ab5aa02b03941c59b51daa4cf608bc04a496a978df | 453 | 1 | #  server SHOULD include an entity containing an explanation of the error #  situation, and whether it is a temporary or permanent condition. User #  agents SHOULD display any included entity to the u |
| .venv/lib/python3.13/site-packages/aiohttp/streams.py | 53ea9392e02a21fa490a1b8a132faf627f2743f675315716d163b60c7889cffa | 728 | 1 |          chunk_splits = self._http_chunk_splits         # Prevent memory leak: drop useless chunk splits         while chunk_splits and chunk_splits[0] < self._cursor:             chunk_splits.pop(0) |
| .venv/lib/python3.13/site-packages/aiohttp/web_protocol.py | 73c6b43ca1aa7e12008aad916e832ccb5351cdae1d9e3ea09d7216bc951e085d | 793 | 1 |             # Important don't hold a reference to the current task             # as on traceback it will prevent the task from being             # collected and will cause a memory leak.             r |
| .venv/lib/python3.13/site-packages/aiohttp/compression_utils.py | 2c35157c388284735bfe88cc1084c9ba84846ce010e10ce7bb4eef4c72fefe96 | 279 | 2 |     from typing import Union      Buffer = Union[bytes, bytearray, "memoryview[int]", "memoryview[bytes]"]  try: |
| .venv/lib/python3.13/site-packages/aiohttp/client.py | 526c30a03bab9830efc53c1ae1ed55125928e2673cfd29ecbecdc203a484fa47 | 1614 | 4 |  # https://www.rfc-editor.org/rfc/rfc9110#section-9.2.2 IDEMPOTENT_METHODS = frozenset({"GET", "HEAD", "OPTIONS", "TRACE", "PUT", "DELETE"})  _RetType = TypeVar("_RetType", ClientResponse, ClientWebSo |
| .venv/lib/python3.13/site-packages/aiohttp/web_urldispatcher.py | b0591cb1af2a2c5903a78effa16ed9edf8aaec37155e27dfd44b67d1037c0c90 | 1304 | 5 |         formatter = ""         for part in ROUTE_RE.split(path):             match = self.DYN.fullmatch(part)             if match:                 pattern += "(?P<{}>{})".format(match.group("var"), s |
| .venv/lib/python3.13/site-packages/aiohttp/payload.py | 3ba9ec60d50b2fb01e33673227a4d85fbde77159cbe71270b7901e831c0c2aac | 1121 | 9 |     _value: bytes     # _consumed = False (inherited) - Bytes are immutable and can be reused     _autoclose = True  # No file handle, just bytes in memory      def __init__( |
| .venv/lib/python3.13/site-packages/aiohttp/client_reqrep.py | e48648842d35e8f33098483513219d3f66f229c63c9f6f0373f4cb0335367b5a | 1534 | 3 |                 self.headers[hdr] = val          if hdrs.USER_AGENT not in used_headers:             self.headers[hdrs.USER_AGENT] = SERVER_SOFTWARE  |
| .venv/lib/python3.13/site-packages/aiohttp/web_log.py | ad7e43ef12ce5f607a04c76267e72199efca7c97d6e485c4a05c0b7e47e46a3b | 217 | 2 |     Usage:         log = logging.getLogger("spam")         log_format = "%a %{User-Agent}i"         access_logger = AccessLogger(log, log_format)         access_logger.log(request, response, time) |
| .venv/lib/python3.13/site-packages/aiohttp/formdata.py | 75199063c2c0e964a3e47cea17db54ceefd235eea6cd9d43a975e4ca0e206b6d | 180 | 1 |         if isinstance(value, io.IOBase):             self._is_multipart = True         elif isinstance(value, (bytes, bytearray, memoryview)):             msg = (                 "In v4, passing bytes |
| .venv/lib/python3.13/site-packages/aiohttp/connector.py | 5907ad2a8496ed79c703daf8a3d396c0edfe9fbca63b005dd9383fc47370d01b | 1835 | 3 |     from collections.abc import Buffer else:     Buffer = Union[bytes, bytearray, "memoryview[int]", "memoryview[bytes]"]  if TYPE_CHECKING: |
| .venv/lib/python3.13/site-packages/aiohttp/typedefs.py | c1496ac1ef4cc3d5bc8d3dc7b1825c624d34a8fdc430fcf79d39185e678d378f | 70 | 1 |     _MultiDictProxy = MultiDictProxy  Byteish = Union[bytes, bytearray, memoryview] JSONEncoder = Callable[[Any], str] JSONDecoder = Callable[[str], Any] |
| .venv/lib/python3.13/site-packages/aiohttp/hdrs.py | dab8f933203eeb245d60f856e542a45b888d5a110094620e4811f90f816628d1 | 122 | 2 | UPGRADE: Final[istr] = istr("Upgrade") URI: Final[istr] = istr("URI") USER_AGENT: Final[istr] = istr("User-Agent") VARY: Final[istr] = istr("Vary") VIA: Final[istr] = istr("Via") |
| .venv/lib/python3.13/site-packages/aiohttp/web_fileresponse.py | 12d0eec39985eee1a48ebaf0481683424e85d45256e299f0136a591afdd3d502 | 419 | 1 |         self, writer: AbstractStreamWriter, fobj: IO[Any], offset: int, count: int     ) -> AbstractStreamWriter:         # To keep memory usage low,fobj is transferred in chunks         # controlled  |
| .venv/lib/python3.13/site-packages/aiohttp/http_writer.py | 7db46d28f612a916ed01daff82aa63176fb8b08d4448bf1d3c317ec58fe600c6 | 379 | 7 |         self._compress = ZLibCompressor(encoding=encoding, strategy=strategy)      def _write(self, chunk: Union[bytes, bytearray, memoryview]) -> None:         size = len(chunk)         self.buffer_s |
| .venv/lib/python3.13/site-packages/aiohttp/helpers.py | 6db94d121a788458a6126c4c74f371125b81635ecbe58500ac762fa31ce811ee | 959 | 1 |  def validate_etag_value(value: str) -> None:     if value != ETAG_ANY and not _ETAGC_RE.fullmatch(value):         raise ValueError(             f"Value {value!r} is not a valid etag. Maybe it contain |
| .venv/lib/python3.13/site-packages/aiohttp/http_parser.py | 4910032a3814b58271520bef613c89034c01f16a4a8d370aa73213f1fb04d5a1 | 1051 | 8 |                 )             name = bname.decode("utf-8", "surrogateescape")             if not TOKENRE.fullmatch(name):                 raise InvalidHeader(bname)  |
| .venv/lib/python3.13/site-packages/aiohttp/cookiejar.py | 7b6f19310c09e4fd2f6cf5f5397e127bbfa4df3786be870512acc6870a46e779 | 523 | 1 |         # If the expiration heap grows larger than the number expirations         # times two, we clean it up to avoid keeping expired entries in         # the heap and consuming memory. We guard this |
| .venv/lib/python3.13/site-packages/aiohttp/abc.py | 8c0da3458031736d7b80ef7a0bec035dc00f7035a3549a6a5eb4c67daeeec2a3 | 269 | 1 |      @abstractmethod     async def write(self, chunk: Union[bytes, bytearray, memoryview]) -> None:         """Write chunk into stream."""  |
| .venv/lib/python3.13/site-packages/aiohttp/_websocket/models.py | 5c0ce3b3ff0962ccd65c8819e91dd946b17eb57f50ffa2e20f8f56458a23a293 | 85 | 1 | # the lambda and arg processing since NamedTuples are constructed # with a run time built lambda # https://github.com/python/cpython/blob/d83fcf8371f2f33c7797bc8f5423a8bca8c46e5c/Lib/collections/__ini |
| .venv/lib/python3.13/site-packages/aiohttp/_websocket/reader_py.py | 812b04fe2481afbf8e46f3a6824093ec9a63e3f8f7f39e22fc2a7cf127b5ffa1 | 477 | 2 |      # data can be bytearray on Windows because proactor event loop uses bytearray     # and asyncio types this to Union[bytes, bytearray, memoryview] so we need     # coerce data to bytes if it is no |
| .venv/lib/python3.13/site-packages/aiohttp/_websocket/reader_c.py | 812b04fe2481afbf8e46f3a6824093ec9a63e3f8f7f39e22fc2a7cf127b5ffa1 | 477 | 2 |      # data can be bytearray on Windows because proactor event loop uses bytearray     # and asyncio types this to Union[bytes, bytearray, memoryview] so we need     # coerce data to bytes if it is no |
| .venv/lib/python3.13/site-packages/commitizen/tags.py | 6e99cc1008c95785fa17833eb02a4f4f3ded911631ed8384c7b91e5d26e4b523 | 266 | 2 |         """         tag = tag.name if isinstance(tag, GitTag) else tag         is_legit = any(regex.fullmatch(tag) for regex in self.version_regexes)         if warn and not is_legit and not self.is_i |
| .venv/lib/python3.13/site-packages/commitizen/out.py | fefb0175859d29875b383080abb0baa31efb09a4447c0e2e08e2f79ed34a26da | 44 | 1 |  def warn(value: str) -> None:     message = colored(value, "magenta")     line(message, file=sys.stderr) |
| .venv/lib/python3.13/site-packages/pyasn1/type/opentype.py | 8e3a926d3800682c6548749feba61c2dbaf1b5f87ff7c9c0c76bfcc335b7e4c5 | 105 | 1 |         )      For untyped `SET OF` or `SEQUENCE OF` vectors:      .. code-block:: python |
| .venv/lib/python3.13/site-packages/tokenizers/implementations/byte_level_bpe.py | 8817a933fcf5b392b2ef314356b60b7372f96f262b228ba4efe934246b85d74b | 123 | 1 |     """ByteLevelBPETokenizer      Represents a Byte-level BPE as introduced by OpenAI with their GPT-2 model     """  |
| .venv/lib/python3.13/site-packages/tokenizers/implementations/char_level_bpe.py | 35a83f1c5abc46f72e72a8bc321575fb4c6da11d02ec58c739e70555444beecb | 151 | 1 |     (https://arxiv.org/abs/1508.07909)      The defaults settings corresponds to OpenAI GPT BPE tokenizers and differs from the original     Sennrich subword-nmt implementation by the following option |
| .venv/lib/python3.13/site-packages/httpcore/_backends/sync.py | 6e113877d88af549b176c76c826d847ca9d76819acd9682019853eee3994ba35 | 242 | 2 |     ):         self._sock = sock         self._incoming = ssl.MemoryBIO()         self._outgoing = ssl.MemoryBIO()  |
| .venv/lib/python3.13/site-packages/paho/mqtt/properties.py | 244b8abc726d9621ef37ba72fa230b59d4348ecc698966da20e9027ef53a8724 | 422 | 7 |             # id:  type, packets             # payload format indicator             1: (self.types.index("Byte"), [PacketTypes.PUBLISH, PacketTypes.WILLMESSAGE]),             2: (self.types.index("Fou |
| .venv/lib/python3.13/site-packages/paho/mqtt/client.py | 5a3f0f73b344541828586a90f79a6beecb8e4396d8b81064bc2920c1a853618a | 5005 | 2 |         return "No error."     elif mqtt_errno == MQTT_ERR_NOMEM:         return "Out of memory."     elif mqtt_errno == MQTT_ERR_PROTOCOL:         return "A network protocol error occurred when commu |
| .venv/lib/python3.13/site-packages/paho/mqtt/packettypes.py | 08d48d0f21c6b0f1a10ab93d081527a4d5f10349c49f311a560e0aadbe91a0e4 | 44 | 1 |      # Dummy packet type for properties use - will delay only applies to will     WILLMESSAGE = 99      Names = ( "reserved", \ |
| .venv/lib/python3.13/site-packages/msgpack/fallback.py | d20d4fce9d2fb66044989e70f45decffe24c55444ff114b81b571ce5345a02c2 | 930 | 9 |          def write(self, s):             if isinstance(s, memoryview):                 s = s.tobytes()             elif isinstance(s, bytearray): |
| .venv/lib/python3.13/site-packages/networkx/conftest.py | 41e7075cb3e6111f9fe9bbdcfcba4a4acd6069003b8c727b209573c0db8dd338 | 258 | 1 |     "algorithms/centrality/current_flow_betweenness.py",     "algorithms/centrality/current_flow_betweenness_subset.py",     "algorithms/centrality/eigenvector.py",     "algorithms/centrality/katz.py" |
| .venv/lib/python3.13/site-packages/networkx/convert_matrix.py | f415d2117cc2108b5ed67c7c7f7e5c5a15e8f845588ce92e5b81f726eb6afa81 | 1315 | 1 |     order : {'C', 'F'}, optional         Whether to store multidimensional data in C- or Fortran-contiguous         (row- or column-wise) order in memory. If None, then the NumPy default         is us |
| .venv/lib/python3.13/site-packages/networkx/drawing/layout.py | c570074b4d056d073dd3ed4939240bde12b1456773be7f29cc6a10b9a7d4064d | 2029 | 17 |  def spectral_layout(G, weight="weight", scale=1, center=None, dim=2, store_pos_as=None):     """Position nodes using the eigenvectors of the graph Laplacian.      Using the unnormalized Laplacian, th |
| .venv/lib/python3.13/site-packages/networkx/drawing/tests/test_layout.py | dbfc097c1702707c019b5251ad088b31c9cd5a8694457e85e0b15c9f938fba5e | 632 | 5 |         pytest.raises(nx.NetworkXException, nx.planar_layout, G)      def test_smoke_planar_layout_embedding_input(self):         embedding = nx.PlanarEmbedding()         embedding.set_data({0: [1, 2] |
| .venv/lib/python3.13/site-packages/networkx/linalg/algebraicconnectivity.py | 3ac81ccec37bb7e3fad0744434dd467bb54e114136ee2d5d971b4253e04e1b73 | 656 | 26 | """ Algebraic connectivity and Fiedler vectors of undirected graphs. """  |
| .venv/lib/python3.13/site-packages/networkx/linalg/laplacianmatrix.py | 09a57416ab9955355b03b98b29fded3cf734a8685d33a1cff88f6077814eb0a1 | 521 | 2 |      where `I` is the identity matrix, `P` is the transition matrix of the     graph, and `\Phi` a matrix with the Perron vector of `P` in the diagonal and     zeros elsewhere [1]_.  |
| .venv/lib/python3.13/site-packages/networkx/linalg/attrmatrix.py | 806d9c6599b837b3d0857baae67c59ab54bf3a65bad7ae35add467ac3897ff0b | 467 | 1 |     order : {'C', 'F'}, optional         Whether to store multidimensional data in C- or Fortran-contiguous         (row- or column-wise) order in memory. This parameter is passed to         numpy.zer |
| .venv/lib/python3.13/site-packages/networkx/linalg/tests/test_algebraic_connectivity.py | b97abb8757c29af714c89861dc3ba3c99bc91f6486960a3e25174b6df7f76ca2 | 401 | 26 |   def test_fiedler_vector_tracemin_chol():     """Test that "tracemin_chol" raises an exception."""     pytest.importorskip("scipy") |
| .venv/lib/python3.13/site-packages/networkx/classes/graph.py | b90894c252baa70f4687262aef9517e0d2b1f59964320d89db0318dd00bbfe7a | 2072 | 5 |      Simple graph information is obtained using object-attributes and methods.     Reporting typically provides views instead of containers to reduce memory     usage. The views update as the graph is |
| .venv/lib/python3.13/site-packages/networkx/classes/multigraph.py | 3d2651ed0832b3394ee4fab387123de782f24aa2c7abee7cf4e42b08eb42f69c | 1284 | 5 |      Simple graph information is obtained using methods and object-attributes.     Reporting usually provides views instead of containers to reduce memory     usage. The views update as the graph is u |
| .venv/lib/python3.13/site-packages/networkx/classes/multidigraph.py | 68eaa37d227a2f1f65fb5cf008830d6115b4996d703c39e211c45643c80a9986 | 967 | 3 |      Simple graph information is obtained using methods and object-attributes.     Reporting usually provides views instead of containers to reduce memory     usage. The views update as the graph is u |
| .venv/lib/python3.13/site-packages/networkx/classes/digraph.py | 16ea7519b0030a95ca2c0d7633aed16e1034726e811a2ff8708c412ec8c712d7 | 1353 | 3 |      Simple graph information is obtained using object-attributes and methods.     Reporting usually provides views instead of containers to reduce memory     usage. The views update as the graph is u |
| .venv/lib/python3.13/site-packages/networkx/classes/tests/dispatch_interface.py | 380e2dd57417ed0aa6de91a14d960a9e8e1cff36c872fa525acb4efcb5c8551a | 186 | 8 |  import networkx as nx from networkx import DiGraph, Graph, MultiDiGraph, MultiGraph, PlanarEmbedding from networkx.classes.reportviews import NodeView  |
| .venv/lib/python3.13/site-packages/networkx/classes/tests/test_graph.py | 320f521dbb52dd123ff46e04edd9437f58e9be224e9b0e072309c5b883ee405c | 928 | 1 |         platform.python_implementation() == "PyPy", reason="PyPy gc is different"     )     def test_memory_leak(self):         G = self.Graph()  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/planarity.py | 84fac86f2e527edb5c7515e8fb54a18b4cff3c49e5bfe1d7b1556302a871af76 | 1464 | 90 | import networkx as nx  __all__ = ["check_planarity", "is_planar", "PlanarEmbedding"]   |
| .venv/lib/python3.13/site-packages/networkx/algorithms/clique.py | fa7b8fc23a06309aa01d98d7e5d26ec74997e74f1b0cd12e88e898eee3d5b91e | 758 | 9 |     worst-case, the length of this list can be exponential in the number     of nodes in the graph (for example, when the graph is the complete     graph). This function avoids storing all cliques in  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/communicability_alg.py | d2d66f64a63efc651407b1ac4482f169b4b68c4a48e7551d83900323d003199c | 164 | 1 |      where `\phi_{j}(u)` is the `u\rm{th}` element of the `j\rm{th}` orthonormal     eigenvector of the adjacency matrix associated with the eigenvalue     `\lambda_{j}`.  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/hybrid.py | cf7b0814c3a98dad70963fa523c608e8e21b48b6561ebebab92ab25444995976 | 197 | 8 |  @nx._dispatchable(returns_graph=True) def kl_connected_subgraph(G, k, l, low_memory=False, same_as_graph=False):     """Returns the maximum locally `(k, l)`-connected subgraph of `G`.  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/dag.py | bd67790b9545125d3e7b7b1dab0ce00ab2dc169d306107bbbb86a428294150d9 | 1469 | 1 |     Notes     -----     This function is not idempotent in the sense that the node labels in     the returned branching may be uniquely generated each time the     function is invoked. In fact, the no |
| .venv/lib/python3.13/site-packages/networkx/algorithms/threshold.py | 3fcc55d29f69ccad267514c6b3f19a3883d1e7a84a3b016261a4df25b5f2660a | 1036 | 10 |   def eigenvectors(creation_sequence):     """     Return a 2-tuple of Laplacian eigenvalues and eigenvectors |
| .venv/lib/python3.13/site-packages/networkx/algorithms/cycles.py | 0cfca9c44ede8040bd588572665fa3fbb85b827c662ce83982d383a7fb660c4f | 1235 | 3 |     chords = G.edges - tree_edges - {(v, u) for u, v in tree_edges}      # We maintain a set of vectors orthogonal to sofar found cycles     set_orth = [{edge} for edge in chords]     while set_orth: |
| .venv/lib/python3.13/site-packages/networkx/algorithms/cluster.py | 2117f16251e55adae347c4118e2f828471d7bdcdbd5a6f1cdd68f04f7a65e12a | 659 | 2 |     Returns     -------     c4 : dictionary        A dictionary keyed by node with the square clustering coefficient value.  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/graph_hashing.py | fa04087e1d96a0f880c6096067d9f1fb5d79ff31c2a35d2c2cfe98a5dc83f7b5 | 436 | 2 |      >>> g1_hashes[1]     ['f6fc42039fba3776', 'a93b64973cfc8897', 'db1b43ae35a1878f', '57872a7d2059c1c0']     >>> g2_hashes[5]     ['f6fc42039fba3776', 'a93b64973cfc8897', 'db1b43ae35a1878f', '1716d2 |
| .venv/lib/python3.13/site-packages/networkx/algorithms/planar_drawing.py | 017ba84f7685804b4278c9c0694b11aa3c4200174d619f0ea3db0638a050b68d | 465 | 66 | import networkx as nx  __all__ = ["combinatorial_embedding_to_pos"]   |
| .venv/lib/python3.13/site-packages/networkx/algorithms/isomorphism/tree_isomorphism.py | 8b9c7b4fd70ba3d30b6a625b05c5ec8c6de7aa55d04aeb39be6c681047c5961f | 265 | 1 | This implements an algorithm from: The Design and Analysis of Computer Algorithms by Aho, Hopcroft, and Ullman Addison-Wesley Publishing 1974 Example 3.2 pp. 84-86. |
| .venv/lib/python3.13/site-packages/networkx/algorithms/isomorphism/isomorphvf2.py | 35373db829b646747d471b8ab004bfef44560f5cc960224d3e179f7096548b95 | 1263 | 23 |         # (Di)GraphMatcher classes make use of cyclic references, garbage         # collection will never happen when we define __del__() to         # restore the recursion level. The result is a memo |
| .venv/lib/python3.13/site-packages/networkx/algorithms/isomorphism/temporalisomorphvf2.py | fb5356f3597c90cf68ad0da78bdb5c362cd0cc484e504f416812578d45aa8622 | 309 | 3 | a semantic check, via the semantic_feasibility() function.  As well as including G1 (the graph in which to seek embeddings) and G2 (the subgraph structure of interest), the name of the temporal attrib |
| .venv/lib/python3.13/site-packages/networkx/algorithms/isomorphism/tests/test_temporalisomorphvf2.py | 93cd37d89e08b59e1a14778eada3a9885f32e1a3e6d8ed60e3852f51fad02608 | 213 | 6 |         assert not gm.subgraph_is_isomorphic()      def test_timdelta_one_config0_returns_no_embeddings(self):         G1 = self.provide_g1_topology()         temporal_name = "date" |
| .venv/lib/python3.13/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py | b458d9d198458c91754b2d339e2053ac74dc6eafc634cacf55e135c9b7a1c8cd | 500 | 25 |      personalization: dict, optional       The "personalization vector" consisting of a dictionary with a       key some subset of graph nodes and personalization value each of those.       At least o |
| .venv/lib/python3.13/site-packages/networkx/algorithms/link_analysis/hits_alg.py | 389d833ca9ffa860c1896ed3967f3fbcbb491af064cd66cec7295b1e7f799dee | 338 | 15 |     Notes     -----     The eigenvector calculation is done by the power iteration method     and has no guarantee of convergence.  The iteration will stop     after max_iter iterations or an error to |
| .venv/lib/python3.13/site-packages/networkx/algorithms/link_analysis/tests/test_pagerank.py | ad424d6bfda72834a4ef9160d72ca030f02a83f05d93480658c0d1298f20d659 | 214 | 2 |  # Example from # A. Langville and C. Meyer, "A survey of eigenvector methods of web # information retrieval."  http://citeseer.ist.psu.edu/713792.html  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/link_analysis/tests/test_hits.py | c0e7a86e2940c4725b2c351ab5de0ec22482b7ee1c9f21625f85bc52f2552419 | 78 | 1 |  # Example from # A. Langville and C. Meyer, "A survey of eigenvector methods of web # information retrieval."  http://citeseer.ist.psu.edu/713792.html  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/connectivity/edge_augmentation.py | 70af52ea9467b0a2f26ffe7b82e29fac06cb8972fab0c00b1c27fba51e2dcc53 | 1271 | 12 |     component, so we ignore self edges.  We also are only interested in the     minimum weight edge bridging each k-edge-connected component so, we group     the edges by meta-edge and take the lighte |
| .venv/lib/python3.13/site-packages/networkx/algorithms/approximation/kcomponents.py | bcd5d0db049262035a7c30f76870ac931be466be64eab12c2a6c6d4d9383239b | 368 | 2 |     bicomponent actually are part of a component of level k, the auxiliary     graph needed for the algorithm is likely to be very dense. Thus, we use     a complement graph data structure (see `AntiG |
| .venv/lib/python3.13/site-packages/networkx/algorithms/approximation/traveling_salesman.py | 1d953a75b3e8dc78b3dbe6774072c59b991d1814309173de7e4554b96f880b60 | 1509 | 1 |            pp.1138-1162         """         # 1. Set d equal to the zero n-vector.         d = {}         for n in G: |
| .venv/lib/python3.13/site-packages/networkx/algorithms/approximation/density.py | 849dba3b8ae6c972ddb1d6de9282950e15d22f53105880b4394e1ba6a2cd9ec2 | 397 | 4 |         )      loads = dict.fromkeys(G.nodes, 0)  # Load vector for Greedy++.     best_density = 0.0  # Highest density encountered.     best_subgraph = set()  # Nodes of the best subgraph found. |
| .venv/lib/python3.13/site-packages/networkx/algorithms/approximation/treewidth.py | 85f2e23e585e40c37b306e82191e70ec0b1c29b2eede94cb358452d7748ed17a | 256 | 1 |     possible. This algorithm chooses the nodes using the Minimum Fill-In     heuristic. The running time of the algorithm is :math:`O(V^3)` and it uses     additional constant memory.     """  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/current_flow_closeness.py | 22f79c23c0591384a029ac845e12a8c08270ed2d9f0ff74dfff37e7fd4d6f8c1 | 97 | 3 |     dtype: data type (default=float)       Default data type for internal matrices.       Set to np.float32 for lower memory consumption.      solver: string (default='lu') |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/eigenvector.py | 10aff1ae0f9e39b8350aeb056cbdf9222b4b543e8e4d02a030e543b2aaa16c9b | 358 | 58 | """Functions for computing eigenvector centrality."""  import math |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/current_flow_betweenness_subset.py | daab4b81fff77ede6a743bc716b7d852deb37908b8d8dc3b5c1a526516e82480 | 228 | 6 |     dtype: data type (float)       Default data type for internal matrices.       Set to np.float32 for lower memory consumption.      solver: string (default='lu') |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/__init__.py | 12bdd8a18a23efa51f6383fa2342fed1f09090eee6314d1bdcd2ec4d3d911962 | 21 | 1 | from .degree_alg import * from .dispersion import * from .eigenvector import * from .group import * from .harmonic import * |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/closeness.py | 7a1927b46fa00294fdba15898c6684650fad110fa17710d3ee5b9ffae54f3401 | 283 | 2 |     See Also     --------     betweenness_centrality, load_centrality, eigenvector_centrality,     degree_centrality, incremental_closeness_centrality  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/current_flow_betweenness.py | cd946a82b074eae0f3830589fc52d41770d2ae0904475b6f6a46191d7f036d26 | 343 | 9 |     dtype : data type (float)       Default data type for internal matrices.       Set to np.float32 for lower memory consumption.      solver : string (default='full') |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/katz.py | be77059c72b5b86a1a36d19a1c47b270dc1c551a3908483aaab65047fcb81b00 | 332 | 13 |      Katz centrality computes the centrality for a node based on the centrality     of its neighbors. It is a generalization of the eigenvector centrality. The     Katz centrality for node $i$ is  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/harmonic.py | 8e28f3116bd3e4f3c00f4428b3e2004eb3c98e70bbc95fd51d657026fa540dc5 | 90 | 1 |     See Also     --------     betweenness_centrality, load_centrality, eigenvector_centrality,     degree_centrality, closeness_centrality  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/degree_alg.py | e34282029ab810cdd43601c7feff3557e8bf9a9ccc5559ff5f07fecd48d2fc87 | 151 | 1 |     See Also     --------     betweenness_centrality, load_centrality, eigenvector_centrality      Notes |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/trophic.py | ee6a45ae98108703f701dd6996926ed56cd3191d585ab229fd25213340fc670c | 182 | 1 |         self_loops = list(nx.selfloop_edges(G))         if self_loops:             # Make a copy so we do not change G's edges in memory             G_2 = G.copy()             G_2.remove_edges_from(se |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/subgraph_alg.py | 4bc4cadbaff28ac5b7872c8b2becfc187c466516515fc234efee141c9095c3af | 343 | 3 |     Notes     -----     This version of the algorithm computes eigenvalues and eigenvectors     of the adjacency matrix.  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/tests/test_katz_centrality.py | 7b45d61c80f0d39e925798b63c5887cdf3c5d8315ab96d744b5ed3baf235504b | 346 | 5 |         for n in sorted(G):             assert b[n] == pytest.approx(b_answer[n], abs=1e-7)         b = nx.eigenvector_centrality_numpy(G)         for n in sorted(G):             assert b[n] == pytest |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/tests/test_betweenness_centrality.py | 176d18aa0c1d6ad4e6f5deb63c9066a81db92357756c0affd63c662ec9adf9f1 | 904 | 4 |             assert b[n] == pytest.approx(b_answer[n], abs=1e-7)      def test_C4(self):         """Edge betweenness centrality: C4"""         G = nx.cycle_graph(4) |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/tests/test_harmonic_centrality.py | c08ee74ad5ff908149a19418fe2f035d795904e27356741f38ff3289d5f43c05 | 123 | 9 |         cls.K5 = nx.complete_graph(5)          cls.C4 = nx.cycle_graph(4)         cls.C4_directed = nx.cycle_graph(4, create_using=nx.DiGraph)  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/tests/test_current_flow_betweenness_centrality_subset.py | 25f44680fba217ebc9bb97dcdbfa5c25844411ba3170afdd9b2fa7a77f5ce00c | 148 | 2 |             assert v1 == pytest.approx(v2, abs=1e-7)      def test_C4(self):         """Edge betweenness centrality: C4"""         G = nx.cycle_graph(4) |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/tests/test_eigenvector_centrality.py | 0a1cc7d125379d09d47a7bf3446af704827367d70d97c39f3d5f44554336cf27 | 187 | 28 |   class TestEigenvectorCentrality:     def test_K5(self):         """Eigenvector centrality: K5""" |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/tests/test_load_centrality.py | 56fdf3496f3d8842cdfbc28d6d47259a484e7b52f329d17b53fc37e27628bc8a | 345 | 3 |         cls.P2 = nx.path_graph(2)          cls.C4 = nx.cycle_graph(4)         cls.T = nx.balanced_tree(r=2, h=2)         cls.Gb = nx.Graph() |
| .venv/lib/python3.13/site-packages/networkx/algorithms/centrality/tests/test_current_flow_betweenness_centrality.py | 54ec71d40ee2486b5d11bcc961e6bfb16fc7bf44bbd7ea28d42557ed1a9de516 | 198 | 2 |             assert v1 == pytest.approx(v2, abs=1e-7)      def test_C4(self):         """Edge flow betweenness centrality: C4"""         G = nx.cycle_graph(4) |
| .venv/lib/python3.13/site-packages/networkx/algorithms/tests/test_cycles.py | 081110fe43651e0e4f1dbf6f28c4bda2dfa5a94bafb3f70081a3ed9c4427efa8 | 985 | 1 |         #   0  D   F  6   cyc2=234E   -- top         #   \  \|   \|  /   cyc3=45678F -- right         #    B-A-9-8-7    cyc4=89AC   -- bottom         #       \ /       cyc5=234F89AD -- middle         #  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/tests/test_threshold.py | 0faddeba5eecfcbdd86b37cb2e508c8fb92f7d299792790e503acb918cd5feaf | 267 | 2 |         s1 = nxt.swap_d(s, 1.0, 1.0, seed=1)      def test_eigenvectors(self):         np = pytest.importorskip("numpy")         eigenval = np.linalg.eigvals |
| .venv/lib/python3.13/site-packages/networkx/algorithms/tests/test_planar_drawing.py | 7c14ddf49cc3913a8d433ec6050092f654a15353f7956450ecbf84e568527650 | 275 | 119 |  import networkx as nx from networkx.algorithms.planar_drawing import triangulate_embedding   |
| .venv/lib/python3.13/site-packages/networkx/algorithms/tests/test_swap.py | 589b4632449b01dd42bf4e95694783547a2c34eb5d8a0b2a12ca72bb1d04c42b | 180 | 1 |   def test_degree_seq_c4():     G = nx.cycle_graph(4)     degrees = sorted(d for n, d in G.degree()) |
| .venv/lib/python3.13/site-packages/networkx/algorithms/tests/test_planarity.py | da2cb6d87e003c1d8ad0388f7285a689057d05342527d25239ec6e6cdd78b14d | 557 | 91 |         (returns planar if and only if the graph is actually planar)     2. In case a counter example is returned: Check if it is correct     3. In case an embedding is returned: Check if its actually |
| .venv/lib/python3.13/site-packages/networkx/algorithms/tests/test_cluster.py | dacdb7f9d469dcd7a62b896992760c26837763fed46fc565bb31f8177b987a89 | 585 | 1 |      def test_lind_square_clustering(self):         """Test C4 for figure 1 Lind et al (2005)"""         G = nx.Graph(             [ |
| .venv/lib/python3.13/site-packages/networkx/algorithms/tests/test_hybrid.py | 9102f368ca2a65c285689dc3ecf29b6363be157e7d5c3675a4de6e9fc332fad9 | 25 | 1 |     H = nx.kl_connected_subgraph(G, 2, 2)     (H, graphOK) = nx.kl_connected_subgraph(         G, 2, 2, low_memory=True, same_as_graph=True     )     assert graphOK |
| .venv/lib/python3.13/site-packages/networkx/algorithms/bipartite/link_analysis.py | 795451420c3331c50f3eee9c72c90f93bdb273f9669c5e441aa3487577be3310 | 317 | 9 |     * $p_j^0$ and $u_i^0$ are personalization values that can encode a priori       weights for the nodes $j \in P$ and $i \in U$, respectively. Akin to the       personalization vector used by PageRa |
| .venv/lib/python3.13/site-packages/networkx/algorithms/bipartite/tests/test_centrality.py | 3c004f6eb232a00ce210440a5ec64b9768d3dfa37c0d9a4d47310efa37aef3d6 | 193 | 4 |         cls.P4 = nx.path_graph(4)         cls.K3 = nx.complete_bipartite_graph(3, 3)         cls.C4 = nx.cycle_graph(4)         cls.davis = nx.davis_southern_women_graph()         cls.top_nodes = [ |
| .venv/lib/python3.13/site-packages/networkx/algorithms/bipartite/tests/test_cluster.py | 3b456c3d5b7cbdc63f1351638cb257db16946e1555888e4c3fafe02d36c4a68b | 85 | 2 | def test_ra_clustering_davis():     G = nx.davis_southern_women_graph()     cc4 = round(bipartite.robins_alexander_clustering(G), 3)     assert cc4 == 0.468  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/bipartite/tests/test_matching.py | dfed83325ded17e838ff1347bc4b98e1f656ed2e5ca8c4cefc6529733d6091e4 | 328 | 1 |   class TestMinimumWeightFullMatching:     @classmethod     def setup_class(cls): |
| .venv/lib/python3.13/site-packages/networkx/algorithms/traversal/beamsearch.py | 567d14e16724f08092848006820bf7b55b505955b4001133fe1701b06aea97aa | 91 | 1 |      >>> G = nx.karate_club_graph()     >>> centrality = nx.eigenvector_centrality(G)     >>> list(nx.bfs_beam_edges(G, source=0, value=centrality.get, width=3))     [(0, 2), (0, 1), (0, 8), (2, 32),  |
| .venv/lib/python3.13/site-packages/networkx/algorithms/minors/contraction.py | a412f61ae72c5db5212c3d8b5cc0752139be9d026d1be1cad52141ef1b1a51c1 | 667 | 2 |      >>> C5 = nx.cycle_graph(5)     >>> C4 = nx.cycle_graph(4)     >>> M = nx.contracted_edge(C5, (0, 1), self_loops=False)     >>> nx.is_isomorphic(M, C4) |
| .venv/lib/python3.13/site-packages/networkx/algorithms/shortest_paths/weighted.py | 2053f1fd0425979940da9e1b8c0223a7a9f7accec9cb7135129bbcf9bcd1d65d | 2517 | 69 |     "all_pairs_dijkstra_path_length",     "dijkstra_predecessor_and_distance",     "bellman_ford_path",     "bellman_ford_path_length",     "single_source_bellman_ford", |
| .venv/lib/python3.13/site-packages/networkx/algorithms/shortest_paths/dense.py | e58f33894f91b166514f3c44133839801edfe23f72c5b361a654db2da325886f | 265 | 1 |     all_pairs_shortest_path_length     """     # could make this its own function to reduce memory costs     return floyd_warshall_predecessor_and_distance(G, weight=weight)[1] |
| .venv/lib/python3.13/site-packages/networkx/algorithms/shortest_paths/generic.py | ce3d1a770d77db833cecb87e0874788644b59f25c69c21daf1d76fd12a72076f | 714 | 36 |     method : string, optional (default = 'dijkstra')         The algorithm to use to compute the path.         Supported options: 'dijkstra', 'bellman-ford'.         Other inputs produce a ValueError. |
| .venv/lib/python3.13/site-packages/networkx/algorithms/shortest_paths/unweighted.py | aaa3045520470887a80f375f1ea4398ab99558df1538a2ef55feb509caf0ccff | 563 | 2 |     :any:`single_source_dijkstra_path_length` :        Shortest weighted path length from source with Dijkstra algorithm.     :any:`single_source_bellman_ford_path_length` :        Shortest weighted p |
| .venv/lib/python3.13/site-packages/networkx/algorithms/shortest_paths/tests/test_weighted.py | d5b9a6b4bdacd89b062a59cb73b502e5bdcb3dd2f58ca096932eca7cdf5d668f | 973 | 77 |         vlp(G, s, t, length, nx.bidirectional_dijkstra, weight)         vlp(G, s, t, length, nx.single_source_dijkstra, weight)         vlp(G, s, t, length, nx.single_source_bellman_ford, weight)      |
| .venv/lib/python3.13/site-packages/networkx/algorithms/shortest_paths/tests/test_generic.py | d8a535cea524b7c645decb3215d67513ef8f7329a1bc4408e651d4cba5b1540b | 451 | 20 |         ) == [0, 1, 2, 3]         assert nx.shortest_path(             self.directed_cycle, 0, 3, weight="weight", method="bellman-ford"         ) == [0, 1, 2, 3]         # when Dijkstra's will probab |
| .venv/lib/python3.13/site-packages/networkx/algorithms/community/quality.py | a04c3e45905eeb68da9c54d3b3e6a4eb600f0621761694280621efd75ff86106 | 348 | 2 |      Implementation note: this function creates an intermediate graph     that may require the same amount of memory as that of `G`.      """ |
| .venv/lib/python3.13/site-packages/networkx/algorithms/community/tests/test_asyn_fluid.py | 53300cc49ce137be2a5229de851ec1d6b854fefb22809efe711bdc13a8dd2b27 | 137 | 1 |     test.add_edge("3c", "3d")      # c4     test.add_edge("4a", "4b")     test.add_edge("4a", "4c") |
| .venv/lib/python3.13/site-packages/networkx/tests/test_all_random_functions.py | 25cdad10e104a931f0b75029b07d7708fc6d8a7dd7e8707ae788402e722e0723 | 251 | 1 |     t(nx.fruchterman_reingold_layout, G, seed=seed)     t(nx.algebraic_connectivity, G, seed=seed)     t(nx.fiedler_vector, G, seed=seed)     t(nx.spectral_ordering, G, seed=seed)     # print('startin |
| .venv/lib/python3.13/site-packages/networkx/utils/configs.py | 0797652c65bf52f515afb522e5e33715b936a9e0a6cd9e27503abfda5582f9d3 | 392 | 1 |         conversion may occur when automatically using a backend from `backend_priority`         or when using the `backend=` keyword argument to a function call. Caching can         improve performanc |
| .venv/lib/python3.13/site-packages/networkx/utils/decorators.py | ad1800670ea097138160dea7e6491b43b452e37107dde55b27917dd7eba4d083 | 1234 | 1 |         -----         It was observed in NetworkX issue #4732 [1] that the import time of         NetworkX was significantly bloated by the use of decorators: over half         of the import time was  |
| .venv/lib/python3.13/site-packages/networkx/generators/geometric.py | eac9604b4beb6b1aa5ebb00e3fd956cc1ae935bc7f381642a01c18b929104178 | 1038 | 8 |     #     G = nx.empty_graph(n)     # If no positions are provided, choose uniformly random vectors in     # Euclidean space of the specified dimension.     if pos is None: |
| .venv/lib/python3.13/site-packages/networkx/generators/stochastic.py | 420f6f5a6f443ae8363905481cbfdd6791eb5dcd7a9719d6cb35f9d8a58d10f2 | 55 | 1 |         G = MultiDiGraph(G) if G.is_multigraph() else DiGraph(G)     # There is a tradeoff here: the dictionary of node degrees may     # require a lot of memory, whereas making a call to `G.out_degre |
| .venv/lib/python3.13/site-packages/networkx/generators/internet_as_graphs.py | 63fa5068685ed7cdd7e9d5c7e2872a20adc3cd7473d285c4f802b0b0bd720879 | 442 | 3 | """Generates graphs resembling the Internet Autonomous System network"""  import networkx as nx |
| .venv/lib/python3.13/site-packages/networkx/generators/lattice.py | 9150af4da8563d018d6e893a99a5df6aa1b39bcf14bb184fec3f4190a8465b5a | 368 | 1 |      Positions of nodes are computed by default or `with_positions is True`.     Node positions creating the standard embedding in the plane     with sidelength 1 and are stored in the node attribute  |
| .venv/lib/python3.13/site-packages/networkx/generators/expanders.py | e10d694108ef2c99b4d25da560d7b7af54bfd4df4733fc343460e6507dcf719f | 477 | 1 |      A = nx.adjacency_matrix(G, dtype=float)     lams = sp.sparse.linalg.eigsh(A, which="LM", k=2, return_eigenvectors=False)      # lambda2 is the second biggest eigenvalue |
| .venv/lib/python3.13/site-packages/networkx/generators/spectral_graph_forge.py | f6be9df5fe58d3728f5f5dfcb104ca586dff4637a26105542495b0087a86e0c0 | 121 | 6 | """Generates graphs with a given eigenvector structure"""  import networkx as nx |
| .venv/lib/python3.13/site-packages/networkx/generators/joint_degree_seq.py | 9f2a7ce8d0bfe17bf3bf0a70c332abac24b3d62ff86c44920ed5635afa645858 | 665 | 5 |     References     ----------     .. [1] M. Gjoka, B. Tillman, A. Markopoulou, "Construction of Simple        Graphs with a Target Joint Degree Matrix and Beyond", IEEE Infocom, '15     """ |
| .venv/lib/python3.13/site-packages/networkx/generators/tests/test_spectral_graph_forge.py | c788f24e2422c9d6943d661a1ac345b08078ecf033492c1060235719ad81e125 | 50 | 1 |     assert not is_isomorphic(I, H)      # with all the eigenvectors, output graph is identical to the input one     H = spectral_graph_forge(G, 1, transformation="modularity", seed=seed)     assert no |
| .venv/lib/python3.13/site-packages/wcwidth/table_zero.py | e197a284b6431fca1b82bc00e9cb7ebeeda5c5ce2dfc3b1fca207da7d3afc5ba | 4844 | 160 |         (0x005bf, 0x005bf,),  # Hebrew Point Rafe         (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot         (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark L |
| .venv/lib/python3.13/site-packages/wcwidth/table_vs16.py | 84f6eea05c66c6b19fb8169ea2178c4c01a6801d9ae04b9d87162c62890b7faa | 126 | 1 |         (0x1f5b1, 0x1f5b2,),  # Three Button Mouse      ..Trackball         (0x1f5bc, 0x1f5bc,),  # Frame With Picture         (0x1f5c2, 0x1f5c4,),  # Card Index Dividers     ..File Cabinet         (0 |
| .venv/lib/python3.13/site-packages/wcwidth/table_wide.py | bd41e310eb91c35586c94708c362fd1b2999b18bc2d88ddd73ce7c9a56324d83 | 1494 | 9 |         (0x026aa, 0x026ab,),  # Medium White Circle     ..Medium Black Circle         (0x026bd, 0x026be,),  # Soccer Ball             ..Baseball         (0x026c4, 0x026c5,),  # Snowman Without Snow    |
| .venv/lib/python3.13/site-packages/pip_audit/_state.py | ddcc6970aaf5e49a76a433f368d4f3512ab7f1d0b542b520880c4bc48825680f | 275 | 4 | from abc import ABC, abstractmethod from collections.abc import Sequence from logging.handlers import MemoryHandler from typing import Any  |
| .venv/lib/python3.13/site-packages/websocket/_core.py | 3fe95873093e2ca254283a8195e26c9914882635f6bffa381689e074961b867f | 648 | 2 |         >>> ws = WebSocket()         >>> ws.connect("ws://echo.websocket.events",                 ...     header=["User-Agent: MyProgram",                 ...             "x-custom: header"])  |
| .venv/lib/python3.13/site-packages/websocket/tests/test_websocket.py | 1795ed3b06bfbf6247504fb13a90967615205187cd6c7184ac724a4346c4b132 | 498 | 3 |         s.add_packet(b"\x01\x89abcd5\r\x0cD\x0c\x17\x00\x0cA")         # OPCODE=PING, FIN=1, MSG="Please PONG this"         s.add_packet(b"\x89\x90abcd1\x0e\x06\x05\x12\x07C4.,$D\x15\n\n\x17")         |
| .venv/lib/python3.13/site-packages/h11/_writers.py | a052a6e8fb637877db8f844b5fb541eca0dcd60218e778171b7fc747d96d9930 | 146 | 1 | def write_headers(headers: Headers, write: Writer) -> None:     # "Since the Host field-value is critical information for handling a     # request, a user agent SHOULD generate Host as the first heade |
| .venv/lib/python3.13/site-packages/h11/_abnf.py | c9b8b1af4c6cba99e403a18503232e6ee5c5e9373595bfe117cf743600ac7cd7 | 133 | 1 | #   https://github.com/python-hyper/h11/issues/57 # We still don't allow NUL or whitespace, because those are often treated as # meta-characters and letting them through can lead to nasty issues like  |
| .venv/lib/python3.13/site-packages/h11/_util.py | 2d69248d7c89685940cba2eddfdc3bdd44ad925153e68bdcbe8d13918ed162e9 | 136 | 3 |     regex: Pattern[bytes], data: bytes, msg: str = "malformed data", *format_args: Any ) -> Dict[str, bytes]:     match = regex.fullmatch(data)     if not match:         if format_args: |
| .venv/lib/python3.13/site-packages/mypyc/build.py | 117d834b0fa0b36acec505542eb9b9c07f3ce5477a6d684ff563656fe581de35 | 641 | 2 |          multi_file: Should each Python module be compiled into its own C source file.                     This can reduce compile time and memory requirements at the likely                     cost o |
| .venv/lib/python3.13/site-packages/mypyc/annotate.py | b289aa059a97b75a7d95852de0bc827444a3f1756f81352b2eabd5108aa65ef1 | 472 | 2 |                     else:                         ann = "Dynamic attribute set."                 elif name == "PyObject_VectorcallMethod":                     method_name = get_str_literal(op.args[0]) |
| .venv/lib/python3.13/site-packages/mypyc/irbuild/ll_builder.py | 3f9b63af273af2ac61268e7fe61656a37dd4cab655e9e2a2a2bf0cdd9108a8dc | 2439 | 20 |     py_getattr_op,     py_method_call_op,     py_vectorcall_method_op,     py_vectorcall_op, ) |
| .venv/lib/python3.13/site-packages/mypyc/test/test_irbuild.py | f5b94c3688fca123b81bd08a588ff4f26c040c9c3f81dda980393b255cecb1a7 | 89 | 1 |     "irbuild-i16.test",     "irbuild-u8.test",     "irbuild-vectorcall.test",     "irbuild-unreachable.test",     "irbuild-isinstance.test", |
| .venv/lib/python3.13/site-packages/mypyc/ir/ops.py | f92ee82adec4f408551efeb881e12e27d9ba7a270c5ee3b519781055c88f022b | 1879 | 7 |      This is used to initialize RArray values. It's provided to avoid     very verbose IR for common vectorcall operations.      Note that this interacts atypically with reference counting. We |
| .venv/lib/python3.13/site-packages/mypyc/ir/class_ir.py | a3495f09993d0fde59caf40e5eefe3974551c8f4d8d34b0da1e0b37ad90d6013 | 516 | 1 | # # To keep down the number of indirections necessary, we store the # array of trait vtables in the memory *before* the class vtable, and # search it backwards.  (This is a trick we can only do once-- |
| .venv/lib/python3.13/site-packages/mypyc/codegen/emitclass.py | b40ebc48f09738f534c92b190e487c4df9c104a787db5fb66dec45ac287884ec | 1102 | 9 |  def generate_call_wrapper(cl: ClassIR, fn: FuncIR, emitter: Emitter) -> str:     return "PyVectorcall_Call"   |
| .venv/lib/python3.13/site-packages/mypyc/codegen/emitmodule.py | a72ae6faa7849dc63b80b1ba1f0863f217549290eddcf0125ea44a42dcf8440f | 1221 | 1 |     if fn.class_name is not None:         if fn.name == "__call__":             # We can use vectorcalls (PEP 590) when supported             return True         # TODO: Support fastcall for __init__. |
| .venv/lib/python3.13/site-packages/mypyc/codegen/emit.py | 34b8d9cc7cab67b2ee64c8259da784baf99c55fdeb2fb97255585b9b2d56c596 | 1201 | 1 |             self.emit_line(f"{declaration}{dest} = PyTuple_New({len(typ.types)});")             self.emit_line(f"if (unlikely({dest} == NULL))")             self.emit_line("    CPyError_OutOfMemory(); |
| .venv/lib/python3.13/site-packages/mypyc/codegen/emitwrapper.py | cdec2ee962664aa4790e52b12a7caf395b0a9436f0dd05d5712e8fb2b04663fc | 980 | 9 | from mypyc.namegen import NameGenerator  # Generic vectorcall wrapper functions (Python 3.7+) # # A wrapper function has a signature like this: |
| .venv/lib/python3.13/site-packages/mypyc/primitives/misc_ops.py | 17e3d6ec7ac883e1a0a9376bbe3b49c048ec7116d28943e6d23446ad67be6de4 | 294 | 1 |   # Initialize a PyObject * item in a memory buffer (steal the value) buf_init_item = custom_primitive_op(     name="buf_init_item", |
| .venv/lib/python3.13/site-packages/mypyc/primitives/generic_ops.py | 2759b592e3bda9061f2b81f5d49f6111f3935c29d66c92e60740c98f1d2767df | 385 | 6 |  # Call callable object using positional and/or keyword arguments (Python 3.8+) py_vectorcall_op = custom_op(     arg_types=[         object_rprimitive,  # Callable |
| .venv/lib/python3.13/site-packages/mypyc/transform/refcount.py | 07ad76368194d9d7a91aa9dfc6f85bf6512a2a2a25628274c5107ab3626a54e6 | 295 | 1 |  The approach is to decrement reference counts soon after a value is no longer live, to quickly free memory (and call __del__ methods), though there are no strict guarantees -- other than that local v |
| .venv/lib/python3.13/site-packages/pylint/lint/base_options.py | 7ed165aca444d507d53bdfe05d07b5439276809a827a1e94d4f238df7b0d40b7 | 609 | 1 |                 "type": "yn",                 "metavar": "<y or n>",                 "help": "Clear in-memory caches upon conclusion of linting. "                 "Useful if running pylint in a server |
| .venv/lib/python3.13/site-packages/pylint/checkers/spelling.py | 2bd92c3a12c0897dbb27663036388fbf633ed174d28769b2978b2c0fd4adb984 | 475 | 2 |   class ForwardSlashChunker(Chunker):  # type: ignore[misc]     """This chunker allows splitting words like 'before/after' into 'before' and     'after'. |
| .venv/lib/python3.13/site-packages/pylint/checkers/symilar.py | e87abaf2ddcbaa1de65205538694b06a2e1311918894085f2f4b2cfa15729866 | 935 | 2 |          In this case we are returning this instance's Linesets, that is all file         information that will later be used for vectorisation.         """         return self.linesets |
| .venv/lib/python3.13/site-packages/pylint/checkers/typecheck.py | 36ff5cd446082ee91daec8697251740c808963e0ac1a1279814d9811cabf7ff3 | 2353 | 1 |     "range",     "bytes",     "memoryview", }  |
| .venv/lib/python3.13/site-packages/pylint/checkers/unicode.py | 0f2ba8dba4d918f62b6eb050ffb75d7cf0930e52cc889715dfa95fb8c9c4809b | 538 | 3 | # We use '\u' because it doesn't require a map lookup and is therefore faster BIDI_UNICODE = [     "\u202A",  # \N{LEFT-TO-RIGHT EMBEDDING}     "\u202B",  # \N{RIGHT-TO-LEFT EMBEDDING}     "\u202C",   |
| .venv/lib/python3.13/site-packages/pylint/checkers/stdlib.py | 0f5d50a94f1a0e4e0928f23eee2ff2011e4893bc6fe38495a451459ee335dd57 | 976 | 1 |         "contextlib.AsyncExitStack.push_async_callback": ((None, "callback"),),         "multiprocessing.managers.Server.create": ((None, "c"), (None, "typeid")),         "multiprocessing.managers.Sha |
| .venv/lib/python3.13/site-packages/pylint/checkers/classes/class_checker.py | f37ffc8d736b9db68ce49154abd1a79d3a6290f60b16fb674df04e6715a3ff23 | 2451 | 1 | _AccessNodes = Union[nodes.Attribute, nodes.AssignAttr]  INVALID_BASE_CLASSES = {"bool", "range", "slice", "memoryview"} ALLOWED_PROPERTIES = {"bultins.property", "functools.cached_property"} BUILTIN_ |
| .venv/lib/python3.13/site-packages/pylint/checkers/refactoring/refactoring_checker.py | e86d1b152601b6f99c26c0ab457839657d9d566f2ad23c8df9d66100cb315db9 | 2470 | 1 |             "strings from an iterable",             "consider-using-join",             "Using str.join(sequence) is faster, uses less memory "             "and increases readability compared to for-lo |
| .venv/lib/python3.13/site-packages/pylint/message/message_definition_store.py | 6fbb854c3cfd9e3f0a326b3605f7e389666d5896c3e8173299acd7d83911ab93 | 119 | 1 |     # Since MessageDefinitionStore is only initialized once     # and the arguments are relatively small we do not run the     # risk of creating a large memory leak.     # See discussion in: https:// |
| .venv/lib/python3.13/site-packages/pylint/reporters/text.py | bec66ff2dfa56ec92b5abbefcfb7f454f56e41f0ed70daad5eee81575e1c651d | 290 | 3 |     "yellow": "33",     "blue": "34",     "magenta": "35",     "cyan": "36",     "white": "37", |
| .venv/lib/python3.13/site-packages/huggingface_hub/repocard_data.py | 86be11785a4440c35d87ff43c7e2fe209a08d44947ca4fa1fbc651ab055860e1 | 771 | 6 |             A JSON Web Token that is used to verify whether the metrics originate from Hugging Face's [evaluation service](https://huggingface.co/spaces/autoevaluate/model-evaluator) or not.         s |
| .venv/lib/python3.13/site-packages/huggingface_hub/_space_api.py | 8dbeab17ca8bb6368d535d83fbcca000f336eb10e21c2bbc0875c7a308464e68 | 169 | 1 |         raw (`dict`):             Raw response from the server. Contains more information about the Space             runtime like number of replicas, number of cpu, memory size,...     """  |
| .venv/lib/python3.13/site-packages/huggingface_hub/constants.py | 9c82ec780a78aea2eefca413643a4f18e85ea5500f6a70fb6b36e8980be8be3d | 295 | 3 | HF_HUB_DOWNLOAD_TIMEOUT: int = _as_int(os.environ.get("HF_HUB_DOWNLOAD_TIMEOUT")) or DEFAULT_DOWNLOAD_TIMEOUT  # Allows to add information about the requester in the user-agent (eg. partner name) HF_H |
| .venv/lib/python3.13/site-packages/huggingface_hub/_commit_scheduler.py | b5f2283b5c561e34c9eaacba552e87228ca60f27053e0d1dea9052669aeb5365 | 354 | 1 |             useful to avoid degraded performances on the repo when it grows too large.         hf_api (`HfApi`, *optional*):             The [`HfApi`] client to use to commit to the Hub. Can be set wi |
| .venv/lib/python3.13/site-packages/huggingface_hub/__init__.py | 32c52a4dce43733af03b0b4486433d63bb64180947bc3b4d4c36d641c104a930 | 1531 | 14 |         "FeatureExtractionInput",         "FeatureExtractionInputTruncationDirection",         "FillMaskInput",         "FillMaskOutputElement",         "FillMaskParameters", |
| .venv/lib/python3.13/site-packages/huggingface_hub/lfs.py | 9fe4c88caec9eda5c6df38bfff49e477a68d904e1d8ce7fd083e9d610390e4ff | 461 | 1 |             more details.         headers (`dict`, *optional*):             Headers to include in the request, including authentication and user agent headers.      Raises: |
| .venv/lib/python3.13/site-packages/huggingface_hub/file_download.py | 13e35638dd35a69adb02cc3b2b3e3bec95fa7fc1d35ac76911d400b40dfbb797 | 1817 | 10 |     cache_dir: Union[str, Path, None] = None,     local_dir: Union[str, Path, None] = None,     user_agent: Union[Dict, str, None] = None,     force_download: bool = False,     proxies: Optional[Dict] |
| .venv/lib/python3.13/site-packages/huggingface_hub/_inference_endpoints.py | 6a199b3dc117b09fc970c6fd4c381d903f19db3f6ecad9051b7ff5a3a7539bc8 | 414 | 1 |              repository (`str`, *optional*):                 The name of the model repository associated with the Inference Endpoint (e.g. `"gpt2"`).             framework (`str`, *optional*):         |
| .venv/lib/python3.13/site-packages/huggingface_hub/hf_api.py | 6b5db2c0de8b738dc0d76077eb1c4ae1d2735ec82d9a341366a6000b88234f36 | 10620 | 57 |     Example:     ```py     >>> RepoUrl('https://huggingface.co/gpt2')     RepoUrl('https://huggingface.co/gpt2', endpoint='https://huggingface.co', repo_type='model', repo_id='gpt2')  |
| .venv/lib/python3.13/site-packages/huggingface_hub/_snapshot_download.py | 6fe37361072f92db008ab21f1902a0cd0c2ef30d12ea58414ef9c9e52eac6b0f | 344 | 7 |     library_name: Optional[str] = None,     library_version: Optional[str] = None,     user_agent: Optional[Union[Dict, str]] = None,     proxies: Optional[Dict] = None,     etag_timeout: float = cons |
| .venv/lib/python3.13/site-packages/huggingface_hub/repository.py | 2deaeade4afbb42fa851d664e62d42761000f3866f622aa368647bee3da23b29 | 1478 | 2 |                         "Parsing a large file to check if binary or not. Tracking large"                         " files using `repository.auto_track_large_files` is"                         " recomme |
| .venv/lib/python3.13/site-packages/huggingface_hub/hf_file_system.py | 9eb34ea0d1d1c1fd6cc1e6ed42f644c526e5463420f6b1cac4bec2b2593bdaec | 1135 | 3 |             return super().get_file(rpath, lpath, callback=callback, outfile=outfile, **kwargs)          # Taken from https://github.com/fsspec/filesystem_spec/blob/47b445ae4c284a82dd15e0287b1ffc410e8 |
| .venv/lib/python3.13/site-packages/huggingface_hub/fastai_utils.py | 0e9787f5dfbabadda4fe7080030825339d579919a07db45ed923e27e954be589 | 426 | 3 |             Specific directory in which you want to save the fastai learner.         config (`dict`, *optional*):             Configuration object. Will be uploaded as a .json file. Example: 'https:// |
| .venv/lib/python3.13/site-packages/huggingface_hub/_commit_api.py | ebc1f1167244dacf909866511d06afe6438c4ec79857f6508b4e000da4266549 | 909 | 4 |             by a `/`.         headers (`Dict[str, str]`):             Headers to use for the request, including authorization headers and user agent.         num_threads (`int`, *optional*):           |
| .venv/lib/python3.13/site-packages/huggingface_hub/serialization/_dduf.py | b38db6dfdacb887c1a244dfa4031264b9187ec34a643ffc17df88724ee518c88 | 388 | 3 |     @contextmanager     def as_mmap(self) -> Generator[bytes, None, None]:         """Open the file as a memory-mapped file.          Useful to load safetensors directly from the file. |
| .venv/lib/python3.13/site-packages/huggingface_hub/serialization/_torch.py | 8e9066b92649ca6329bcb70370c68dc43bbf7c4e55918fe90151fc7bcb2d608a | 1034 | 16 |             indicates the location where all tensors should be loaded.         mmap (`bool`, *optional*, defaults to `False`):             Whether to use memory-mapped file loading. Memory mapping can |
| .venv/lib/python3.13/site-packages/huggingface_hub/utils/_telemetry.py | e782d7788254e691068213c0874ea0a8d011f94a313a354bbcaa8042c730a99b | 127 | 11 |     library_name: Optional[str] = None,     library_version: Optional[str] = None,     user_agent: Union[Dict, str, None] = None, ) -> None:     """ |
| .venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py | 85eafb519d0a468f5660302ba6a545c845d3bac3865040a3e47352f046a1aa6f | 638 | 3 |     `huggingface_hub` creates 1 Session instance per thread. They are all instantiated using the same `backend_factory`     set in [`configure_http_backend`]. A LRU cache is used to cache the created  |
| .venv/lib/python3.13/site-packages/huggingface_hub/utils/_xet.py | 7fca9f93c60a78f01e1942fa950890d70ff76dcb3bf285b06de00261d51e8399 | 193 | 3 |             The file data needed to refresh the xet connection information.         headers (`Dict[str, str]`):             Headers to use for the request, including authorization headers and user age |
| .venv/lib/python3.13/site-packages/huggingface_hub/utils/_dotenv.py | 4731ea0bc1e0cd5c44f8de031417277a6bd7d0d1e65dc574332d8048ad14d4e4 | 56 | 2 | # AI-generated module (ChatGPT) import re from typing import Dict, Optional |
| .venv/lib/python3.13/site-packages/huggingface_hub/utils/_headers.py | c386b2ab884b19a67707b9f07448b966edb74a6983b8ec2fe7c22defcc246a49 | 229 | 31 |     library_name: Optional[str] = None,     library_version: Optional[str] = None,     user_agent: Union[Dict, str, None] = None,     headers: Optional[Dict[str, str]] = None,     is_write_action: boo |
| .venv/lib/python3.13/site-packages/huggingface_hub/utils/_cache_manager.py | a2ca95e20339331dbddcac353ceb89e6e288728206e7b818d24e8153abdd8cf0 | 897 | 2 |         suno/bark                                           model     70a8a7d34168586dc5d028fa9666aceade177992         8.8K        1 1 week ago    main ~/.cache/huggingface/hub/models--suno--bark/snap |
| .venv/lib/python3.13/site-packages/huggingface_hub/cli/download.py | 3d4a56fa76eee9900fe8ff43a558658802924a5c6f5d6915874536299a2e9214 | 182 | 5 |      # Download file     hf download gpt2 config.json      # Download entire repo |
| .venv/lib/python3.13/site-packages/huggingface_hub/cli/lfs.py | 27d32428e1945ba1a306b2acdb365408e6801b1a5ab71b04a126c18ee843255f | 199 | 4 | """ Implementation of a custom transfer agent for the transfer type "multipart" for git-lfs.  |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_common.py | eaa0086aeba0ca5d5e1e4d0585676304d11704d177dff5570bc95cd4647cb7bb | 458 | 2 |     """Make sure `numpy` is installed on the machine."""     if not is_numpy_available():         raise ImportError("Please install numpy to use deal with embeddings (`pip install numpy`).")     impor |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_client.py | 82063779b83fc630bdcee1d44e9cc6feb82116beb9bc3b7b06d837a404df2631 | 3553 | 50 |     ChatCompletionStreamOutput,     DocumentQuestionAnsweringOutputElement,     FillMaskOutputElement,     ImageClassificationOutputElement,     ImageClassificationOutputTransform, |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_providers/sambanova.py | 527b771f78ebfe4808f6fcd18e6996d43172a04b8f90a09c808225a223a3de3f | 43 | 6 |      def _prepare_route(self, mapped_model: str, api_key: str) -> str:         return "/v1/embeddings"      def _prepare_payload_as_dict( |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_providers/openai.py | 18255878d763588829410ec4fd7bfc21e6e67614e2d12e967c5a2ccf79cbb69b | 26 | 1 |     def _prepare_mapping_info(self, model: Optional[str]) -> InferenceProviderMapping:         if model is None:             raise ValueError("Please provide an OpenAI model ID, e.g. `gpt-4o` or `o1`. |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_providers/nebius.py | 549a53176259e7caf39dcf70c5d93ee7bbf017cb15daf112c3f5a45e35ea0a1a | 84 | 6 |      def _prepare_route(self, mapped_model: str, api_key: str) -> str:         return "/v1/embeddings"      def _prepare_payload_as_dict( |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_mcp/_cli_hacks.py | 70c662ad515ee0dd0433d373cecf5a126cd4054101611e28619a41c935a56423 | 89 | 2 |     import anyio      if getattr(anyio, "_tiny_agents_patched", False):         return     anyio._tiny_agents_patched = True |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_mcp/constants.py | 0273a9fe847956dcb47792770329c618d2bd8b523d2a01a109df673e865c0f53 | 83 | 5 |   FILENAME_CONFIG = "agent.json" FILENAME_PROMPT = "PROMPT.md"  |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_mcp/types.py | 89cf15491f4963577ebcf5ac0555d8b57b4853aebdf876c64379b5d92cecec14 | 43 | 2 |   # AgentConfig root object class AgentConfig(TypedDict):     model: str |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_mcp/cli.py | 518e0adb4ce9e72746c7b1b3a788285575480d5da00766ab28578658ad40cf01 | 248 | 29 |  from ._cli_hacks import _async_prompt, _patch_anyio_open_process from .agent import Agent from .utils import _load_agent_config  |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_mcp/utils.py | 56c4569747ee4990d2d33353f67ec538c4a5cc0d1405b3fca7cc562960edd8f7 | 125 | 19 | """ Utility functions for MCPClient and Tiny Agents.  Formatting utilities taken from the JS SDK: https://github.com/huggingface/huggingface.js/blob/main/packages/mcp-client/src/ResultFormatter.ts. |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_mcp/agent.py | 55a86f4aa95d882d51ef60851f84f4e65f34b845e5e4e8cbc1ba164055096ecc | 104 | 9 |   class Agent(MCPClient):     """     Implementation of a Simple Agent, which is a simple while loop built right on top of an [`MCPClient`]. |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_mcp/mcp_client.py | 9dd69371964f6d4d594cd51e07df9675a3b1edb1c3de5b2b5e72b109e8b0a548 | 370 | 2 |     Args:         model (`str`, `optional`):             The model to run inference with. Can be a model id hosted on the Hugging Face Hub, e.g. `meta-llama/Meta-Llama-3-8B-Instruct`             or a  |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py | a249593e9ed30660a4501e41dd4a6e8af1174161a05315c9c00f99b386050ec3 | 3666 | 50 |     ChatCompletionStreamOutput,     DocumentQuestionAnsweringOutputElement,     FillMaskOutputElement,     ImageClassificationOutputElement,     ImageClassificationOutputTransform, |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_generated/types/fill_mask.py | 3ab4e043b35d9f4fdd58ae6d850859c133876d09e2f23d2225cc7d965ca145db | 48 | 4 |  @dataclass_with_extra class FillMaskParameters(BaseInferenceType):     """Additional inference parameters for Fill Mask"""  |
| .venv/lib/python3.13/site-packages/huggingface_hub/inference/_generated/types/__init__.py | f56beb190f1a4e1b4a48dcd9174ea3f82204d99b88b677bc1459de6b5a75bb7f | 193 | 3 | ) from .feature_extraction import FeatureExtractionInput, FeatureExtractionInputTruncationDirection from .fill_mask import FillMaskInput, FillMaskOutputElement, FillMaskParameters from .image_classifi |
| .venv/lib/python3.13/site-packages/huggingface_hub/commands/scan_cache.py | 12be72d29691bf47de5e7c317be780c2e240eb1959f8e74443515b07cd01a8d5 | 184 | 2 |     suno/bark                                           model     70a8a7d34168586dc5d028fa9666aceade177992         8.8K        1 1 week ago    main C:\\Users\\admin\\.cache\\huggingface\\hub\\models-- |
| .venv/lib/python3.13/site-packages/huggingface_hub/commands/download.py | d1063d868ede8803ef1677413edb46b47eaf5cd937afd022a25b4dc1cf21d59e | 205 | 5 |      # Download file     huggingface-cli download gpt2 config.json      # Download entire repo |
| .venv/lib/python3.13/site-packages/huggingface_hub/commands/lfs.py | c5d6e73513b4e14b907a61215064fcd3d8c58109fd463f929f24ffd0f87e5588 | 201 | 4 | """ Implementation of a custom transfer agent for the transfer type "multipart" for git-lfs.  |
| .venv/lib/python3.13/site-packages/requests_oauthlib/oauth2_session.py | 2b85ed769353894e83abc26f12c8fc694a4c75abd6482640b9339cff1859701c | 588 | 1 |      Note that the only time you will be using Implicit Grant from python is if     you are driving a user agent able to obtain URL fragments.     """  |
| .venv/lib/python3.13/site-packages/structlog/dev.py | 5315ea6845dedea1c339c91db3d2aeca7a49f7bde54e972c8e0e48bd451652ab | 804 | 4 |     BLUE = colorama.Fore.BLUE     CYAN = colorama.Fore.CYAN     MAGENTA = colorama.Fore.MAGENTA     YELLOW = colorama.Fore.YELLOW     GREEN = colorama.Fore.GREEN |
| .venv/lib/python3.13/site-packages/sympy/__init__.py | 4e9476348ba105feab28d82f5bcf6cdba2e3e84de6e059bbfe7a13728c0a4ab0 | 546 | 6 |         trailing, Mul, prod, Add, Mod, Rel, Eq, Ne, Lt, Le, Gt, Ge, Equality,         GreaterThan, LessThan, Unequality, StrictGreaterThan, StrictLessThan,         vectorize, Lambda, WildFunction, Der |
| .venv/lib/python3.13/site-packages/sympy/series/tests/test_limits.py | 62ec1c072f00b5ff9418ff0b8b6b0553482e57f66c8c7ab1f8874fc08e8cdc40 | 1441 | 1 |   def test_basic4():     assert limit(2*x + y*x, x, 0) == 0     assert limit(2*x + y*x, x, 1) == 2 + y |
| .venv/lib/python3.13/site-packages/sympy/crypto/crypto.py | 88011153941ff468b3114314cb14e04d4048d14f50a5291b462af69ef2882940 | 3369 | 6 | This file contains some classical ciphers and routines implementing a linear-feedback shift register (LFSR) and the Diffie-Hellman key exchange.  .. warning:: |
| .venv/lib/python3.13/site-packages/sympy/core/kind.py | f6442fb43c66f924911a2fb5e795ec065febb3ea0dffb770edf34d4f7983bb64 | 389 | 1 |     UndefinedKind      Since matrix forms a vector space over scalar field, multiplication     between matrix with numeric element and number returns matrix with     numeric element. |
| .venv/lib/python3.13/site-packages/sympy/core/add.py | 4dd770b22719151e3212d5539199a4cc5b67f677409617da77bbc98840abea8e | 1281 | 1 |                     # so we can simply put c in slot0 and go the fast way.                     #                     # XXX: This breaks VectorMul unless it overrides                     # _new_rawargs |
| .venv/lib/python3.13/site-packages/sympy/core/__init__.py | d0bef64c69e0ac88362649d6dde95a3d22039a4a4f8d618d55f364df7c0a5c9d | 104 | 2 |     Equality, GreaterThan, LessThan, Unequality, StrictGreaterThan,     StrictLessThan ) from .multidimensional import vectorize from .function import Lambda, WildFunction, Derivative, diff, FunctionC |
| .venv/lib/python3.13/site-packages/sympy/core/numbers.py | 584912d4927da2ffa7e215efc70ac7d4d3e290d9720428cb379bfe8ce671becc | 4483 | 2 |     $\alpha \in \mathbb{Q}(\theta) \hookrightarrow \mathbb{C}$. That is, the     algebraic number $\alpha$ is represented as an element of a particular     number field $\mathbb{Q}(\theta)$, with a pa |
| .venv/lib/python3.13/site-packages/sympy/core/mul.py | ae30a2c8eab1320513591f2c01c9a29517d02eea7dc2ff088fbb3b2487d49153 | 2215 | 1 |         ``Mul(y, x, 2)`` -> ``Mul(2, x, y)``      Since multiplication can be vector space operation, arguments may     have the different :obj:`sympy.core.kind.Kind()`. Kind of the     resulting obje |
| .venv/lib/python3.13/site-packages/sympy/core/operations.py | ff08e1317f8c0fa73250d28273d2bf431cb1a5e1b85907a1772a68d05a7be863 | 742 | 1 |      These binary operations are associative (op(op(a, b), c) = op(a, op(b, c))),     commutative (op(a, b) = op(b, a)) and idempotent (op(a, a) = op(a) = a).     Common examples are AND, OR, Union, I |
| .venv/lib/python3.13/site-packages/sympy/core/basic.py | 23366fb3b88870cbd5f3f6ad85d3819c8bc1609837f2486e3b67c026d77bb931 | 2356 | 1 |     is_Not = False     is_Matrix = False     is_Vector = False     is_Point = False     is_MatAdd = False |
| .venv/lib/python3.13/site-packages/sympy/core/singleton.py | d947a36bc189fb4f9cbc1ce5a8fc0bf6107d78eb63ac915757a9a40d93b5069e | 200 | 5 |     ``S.Zero``.      Singletonization offers two advantages: it saves memory, and it allows     fast comparison. It saves memory because no matter how many times the     singletonized objects appear i |
| .venv/lib/python3.13/site-packages/sympy/core/multidimensional.py | 3565f5a24c9b3bf9d90a5f48848384f1061a958d56a02d33973b2f060fc4d5e1 | 132 | 5 | Provides functionality for multidimensional usage of scalar-functions.  Read the vectorize docstring for more details. """  |
| .venv/lib/python3.13/site-packages/sympy/core/power.py | 14949845fd12de9935246915cb791d5964043619a95667be3dff524b645ce921 | 1848 | 1 |          2. For very large powers, use totient reduction if $e \ge \log(m)$.         Bound on m, is for safe factorization memory wise i.e. $m^{1/4}$.         For pollard-rho to be faster than built-i |
| .venv/lib/python3.13/site-packages/sympy/core/function.py | cb4bc47576940fcb613f75dab1956492882a5ce181d1cb362677c711ae033634 | 3424 | 7 |         if not cls._valid_nargs(n):             # XXX: exception message must be in exactly this format to             # make it work with NumPy's functions like vectorize(). See,             # for ex |
| .venv/lib/python3.13/site-packages/sympy/core/tests/test_singleton.py | c4b249817c2691b2a1b28b7fa93b3ea3876788c8c7521dffbdad31b00e61f8a0 | 77 | 1 |     # if they are used often enough that code can benefit either from the     # performance benefit of being able to use 'is' (this only matters in very     # tight loops), or from the memory savings  |
| .venv/lib/python3.13/site-packages/sympy/core/tests/test_multidimensional.py | 16bfa56a099ede5c0bac1a5d6963fb3bba0f7b38486ad9f95fc7d862cfbc6cdf | 25 | 4 | from sympy.core.symbol import symbols from sympy.functions.elementary.trigonometric import sin from sympy.core.multidimensional import vectorize x, y, z = symbols('x y z') f, g, h = list(map(Function, |
| .venv/lib/python3.13/site-packages/sympy/core/tests/test_numbers.py | 4af4d5654a4c59f786bdaab2254a787bd15820ef251492dc6d172604d58ef26d | 2336 | 2 |     raises(TypeError, lambda: Number(cos))     a = Rational(3, 5)     assert Number(a) is a  # Check idempotence on Numbers     u = ['inf', '-inf', 'nan', 'iNF', '+inf']     v = [oo, -oo, nan, oo, oo] |
| .venv/lib/python3.13/site-packages/sympy/core/tests/test_args.py | 82cbd8905a2a4963341bcb23c01930c0da53ffd8dcfa2a354b20dc7212377c0e | 5518 | 140 | def test_sympy__codegen__cxxnodes__using():     from sympy.codegen.cxxnodes import using     assert _test_args(using('std::vector'))     assert _test_args(using('std::vector', 'vec'))  |
| .venv/lib/python3.13/site-packages/sympy/polys/polytools.py | 054c0af30240a5acd678a437b76ef283e1d3327c22bfd49c3e26af9369f4d919 | 7961 | 1 |                 exponents *= monomial          # If any element of the exponents vector is zero, then there's         # a variable for which there's no degree bound and the ideal         # generated b |
| .venv/lib/python3.13/site-packages/sympy/polys/groebnertools.py | 3612be5dc151f5ee1c8430c927e7625dbed762ec3dcdc8b1140feb8a899384f3 | 863 | 2 |     For performance sake, a critical pair is represented as a tuple     (Sign(um * f), um, f, Sign(vm * g), vm, g), since um * f creates     a new, relatively expensive object in memory, whereas Sign( |
| .venv/lib/python3.13/site-packages/sympy/polys/distributedmodules.py | b7ca4b2200d0b3f74c79c197c326d56282dabe87c4cb60d78454bc379823e525 | 740 | 8 | # Conversion  def sdm_from_vector(vec, O, K, **opts):     """     Create an sdm from an iterable of expressions. |
| .venv/lib/python3.13/site-packages/sympy/polys/monomials.py | e9c0c24d534d3c379e7b96edd114271ae627b0efdf79f8a81c0e661032874ae0 | 629 | 1 |     a total degree $N = 50$ and $M = 0$, which is the worst case, in 5     variables, assuming that exponents and all of coefficients are 32-bit long     and stored in an array we would need almost 80 |
| .venv/lib/python3.13/site-packages/sympy/polys/domains/old_polynomialring.py | 290707e7ca079c7ccea43756a236622e51c3aab02251de0e01a04866282aa727 | 491 | 12 |         return self.dtype(self.dom.factorial(a))      def _vector_to_sdm(self, v, order):         """         For internal use by the modules class. |
| .venv/lib/python3.13/site-packages/sympy/polys/domains/tests/test_polynomialring.py | f273452ae41e89cc22064ea99ea3cb364d1c9c8eb588af03a65f936627ef3917 | 94 | 4 |     assert R.from_FractionField(Qxy.convert(x/y), Qxy) is None      assert R._sdm_to_vector(R._vector_to_sdm([X, Y], R.order), 2) == [X, Y]   |
| .venv/lib/python3.13/site-packages/sympy/polys/tests/test_distributedmodules.py | 7579a3868cd7e58cdbec3b2bb5b7454ea0318bd675519349bc6c63faf1ccedc3 | 209 | 18 |     sdm_LC, sdm_from_dict,     sdm_spoly, sdm_ecart, sdm_nf_mora, sdm_groebner,     sdm_from_vector, sdm_to_vector, sdm_monomial_lcm )  |
| .venv/lib/python3.13/site-packages/sympy/polys/tests/test_groebnertools.py | 6561c170208e54dc03c6e25683558fa3492b4c7c759b5c133e2d9c3983ec013e | 534 | 2 |  def test_critical_pair():     # from cyclic4 with grlex     R, x,y,z,t = ring("x,y,z,t", QQ, grlex)  |
| .venv/lib/python3.13/site-packages/sympy/polys/numberfields/primes.py | 5173a4b8c7676a656f1cf419c708a509b85dc0d34d4bbcd0e1bc1215ce711a09 | 785 | 2 |         $p/\mathfrak{p} = p \mathbb{Z}_K + \beta \mathbb{Z}_K$.          Essentially, this is the same as the number $\Psi$ (or the "reagent")         from Kummer's 1847 paper (*Ueber die Zerlegung... |
| .venv/lib/python3.13/site-packages/sympy/polys/numberfields/subfield.py | 1ee87d8aad820d037ca747ecd9b49efb212807f575395afcac7e7cac94f872b9 | 517 | 1 | def field_isomorphism(a, b, *, fast=True):     r"""     Find an embedding of one number field into another.      Explanation |
| .venv/lib/python3.13/site-packages/sympy/polys/numberfields/galoisgroups.py | 738b3acff984524a1629ecc5adf8ca894dad667127c51e26d4b61a6a089c567a | 624 | 5 |                     else (S4TransitiveSubgroups.S4, False))          # Gal(T) is conjugate to a subgroup of H = D4, so it is either V, C4         # or D4 itself.  |
| .venv/lib/python3.13/site-packages/sympy/polys/numberfields/modules.py | e0c272913ea0b53fcb0b4df72d6b074ff08cee713274b21201d434c80fdb8644 | 2115 | 14 | needed.  A :py:class:`~.ModuleElement` can be constructed from an integer column vector and a denominator:  |
| .venv/lib/python3.13/site-packages/sympy/polys/numberfields/utilities.py | 2072a67da7c4f6d3066a699f76d932478fc81dbd2638df8e0708ad1344acd51d | 475 | 1 |     subspace, to give a basis for the whole space.      To be precise, suppose you have an $n$-dimensional vector space $V$, with     basis $\{v_1, v_2, \ldots, v_n\}$, and an $r$-dimensional subspace |
| .venv/lib/python3.13/site-packages/sympy/polys/numberfields/tests/test_galoisgroups.py | dcb16e31b57dd9504596aa84aa3877ee842f986f1c819d291710c25d4a1844be | 144 | 1 |     # Degree 4     4: [         (x**4 + x**3 + x**2 + x + 1, S4TransitiveSubgroups.C4, False),         (x**4 + 1, S4TransitiveSubgroups.V, True),         (x**4 - 2, S4TransitiveSubgroups.D4, False), |
| .venv/lib/python3.13/site-packages/sympy/polys/numberfields/tests/test_utilities.py | ad018425672d71fce352d33046ec821dead2a84b283f90b7cf56e775d240d7ba | 114 | 2 |     assert B[:, :2] == M     # When we work mod 7, first col of M goes to [1, 0, 0],     # so the supplementary vector cannot equal this, as it did     # when we worked over QQ. Instead, we get the se |
| .venv/lib/python3.13/site-packages/sympy/polys/agca/modules.py | 3de035dfc147b027d49fcbe476b8cf6bddb19b3abb42a9343eb758c15a0da9fd | 1489 | 12 |         will return a triple ``(res, rela, relb)``, where ``res`` is the         intersection module, and ``rela`` and ``relb`` are lists of coefficient         vectors, expressing the generators of ` |
| .venv/lib/python3.13/site-packages/sympy/polys/agca/homomorphisms.py | 81a30d57dea9294b981d9f0177b40eb36ec9d486db2609048f259c4cb7bc1852 | 692 | 1 |     generated by finitely many elements `e_1, \ldots, e_n`, so that the     homomorphism is determined uniquely by its action on the `e_i`. It     can thus be represented as a vector of elements of th |
| .venv/lib/python3.13/site-packages/sympy/polys/matrices/domainmatrix.py | 32f8d647343894acd7dab0a5f2646da6221749eeb8d7fc7a38cad3afc8ac70f0 | 3984 | 8 |         Traceback (most recent call last):         ...         DMNotAField: Cannot normalize vectors over a non-field          Over a ring with ``gcd`` defined the nullspace can potentially be |
| .venv/lib/python3.13/site-packages/sympy/polys/matrices/eigen.py | 82502bc6cf7fad3ac4fecb33d9f77680a093b20b92c841f0a1e40ff36b6621c3 | 91 | 1 | """  Routines for computing eigenvectors with DomainMatrix.  """ |
| .venv/lib/python3.13/site-packages/sympy/polys/matrices/tests/test_nullspace.py | 7801033e59d590a7c533d8e7d60ced394413a2cd529bdab01f5d02fadf6e2d41 | 210 | 2 | # The nullspace as returned by DomainMatrix and related classes is the # transpose of the nullspace as returned by Matrix. Matrix returns a list of # of column vectors whereas DomainMatrix returns a m |
| .venv/lib/python3.13/site-packages/sympy/concrete/guess.py | e847a3761360aa330aee55535e6b3cfbfc469a6a48defb6588b5bbf8bd9e6833 | 474 | 7 |  @public def find_simple_recurrence_vector(l):     """     This function is used internally by other functions from the |
| .venv/lib/python3.13/site-packages/sympy/concrete/tests/test_guess.py | 4cf5ba1f2d753e8e952d91bf771f79c77b0c05897991c407f308c9e933adbbe9 | 83 | 3 | from sympy.concrete.guess import (             find_simple_recurrence_vector,             find_simple_recurrence,             rationalize, |
| .venv/lib/python3.13/site-packages/sympy/holonomic/holonomic.py | bcfe5769b5487b3b005116caeb9a7c3ff41f3c8350c21a25d1deb607b06bdecd | 2766 | 4 |     integral and derivative is also a Holonomic Function.      For ordinary points initial condition should be a vector of values of     the derivatives i.e. :math:`[y(x_0), y'(x_0), y''(x_0) ... ]`.  |
| .venv/lib/python3.13/site-packages/sympy/holonomic/numerical.py | 3253fcc5306a8d542a335fa3c2f892ff23c808a8fab4456c6bd7fac3230249fa | 99 | 1 |     """     Euler's method for numerical integration.     From x0 to x1 with initial values given at x0 as vector y0.     """  |
| .venv/lib/python3.13/site-packages/sympy/ntheory/elliptic_curve.py | 653ebbec41e2dba06465d4532ecd537f8552c8cc43cc9af0935c440a8313ed08 | 398 | 4 |         if char == 3:             return EllipticCurve(self._b4/2, self._b6/4, a2=self._b2/4, modulus=self.modulus)         c4 = self._b2**2 - 24*self._b4         c6 = -self._b2**3 + 36*self._b2*self. |
| .venv/lib/python3.13/site-packages/sympy/ntheory/egyptian_fraction.py | 856f3cea13d626d011aa0648ac7d568d9142d2ebdff421f13089f45fd31666ba | 224 | 1 |           terms is seldom more than a handful.         b) Uses minimal memory.         c) The terms can blow up (standard examples of this are 5/121 and |
| .venv/lib/python3.13/site-packages/sympy/ntheory/residue_ntheory.py | 74305aa204aaae82479725d1aa72e6bb3355c977f2e2b581fe19613823501e99 | 1964 | 12 |      Use ``all_roots`` only when it is expected that all the roots fit     in memory; otherwise use ``sqrt_mod_iter``.      Examples |
| .venv/lib/python3.13/site-packages/sympy/ntheory/generate.py | 07a2d590aeb6ef15b3435504e57a1e33134ced0d4ef04c1c3fb7f02ace6f9199 | 1158 | 3 | from itertools import count # Using arrays for sieving instead of lists greatly reduces # memory consumption from array import array as _array  |
| .venv/lib/python3.13/site-packages/sympy/ntheory/multinomial.py | adb9b74938e07d16cd55b70f787ebdaad5a4b6d8520a4d2c0b7ef736e0cce9f5 | 189 | 1 |     zeros, their coefficient is the same as that of the monomial tuples from     ``multinomial_coefficients(n, n)``. Therefore, the latter coefficients are     precomputed to save memory and time.     |
| .venv/lib/python3.13/site-packages/sympy/ntheory/qs.py | f192b1bea73ea063ea64d6c41fe5dc3ec8d72f2e7ee5aca0541e6b47506448ef | 452 | 2 | def _check_smoothness(num, factor_base):     r""" Check if `num` is smooth with respect to the given `factor_base`     and compute its factorization vector.      Parameters |
| .venv/lib/python3.13/site-packages/sympy/ntheory/tests/test_bbp_pi.py | 4e036964eb4a01f53e215cceeb62a8ececb72cb35f773128f6058c4d30d92fa7 | 135 | 21 | # below dig=''.join(''' 3243f6a8885a308d313198a2e03707344a4093822299f31d0082efa98ec4e6c89452821e638d013 77be5466cf34e90c6cc0ac29b7c97c50dd3f84d5b5b54709179216d5d98979fb1bd1310ba698dfb5 ac2ffd72dbd01ad |
| .venv/lib/python3.13/site-packages/sympy/ntheory/tests/test_residue.py | ed5197b2c95959577747bb40b4870b8d8ca1d138d9a5be41b46d8641e8650146 | 350 | 5 |     _primitive_root_prime_power_iter, _primitive_root_prime_power2_iter, \     _nthroot_mod_prime_power, _discrete_log_trial_mul, _discrete_log_shanks_steps, \     _discrete_log_pollard_rho, _discrete |
| .venv/lib/python3.13/site-packages/sympy/printing/glsl.py | c2c8cf729cb393dda6e08dbfaded1c9f72701233e64659a55565fda30873339c | 549 | 2 |         mat_separator = self._settings['mat_separator']         mat_transpose = self._settings['mat_transpose']         column_vector = (mat.rows == 1) if mat_transpose else (mat.cols == 1)         A  |
| .venv/lib/python3.13/site-packages/sympy/printing/str.py | 7532bf09d4fe326ff346838bf8cc1be2870103ffe1db004500083a56f02279b4 | 1022 | 2 |                 strslice(expr.colslice, expr.parent.cols) + ']')      def _print_DeferredVector(self, expr):         return expr.name  |
| .venv/lib/python3.13/site-packages/sympy/printing/mathml.py | 513ee0e39a0b4eabe7ac2d485197aacb01d357af8b50295fb8e17f53800c95a2 | 2158 | 6 |      def _print_BasisDependent(self, expr):         from sympy.vector import Vector          if expr == expr.zero: |
| .venv/lib/python3.13/site-packages/sympy/printing/codeprinter.py | 41401633a1f8e5806477b7d7ea35d73b78feb5f55a1e1cf16d79fb3a74a6d04b | 1040 | 1 |     _print_Limit = _print_not_supported     _print_MatrixBase = _print_not_supported     _print_DeferredVector = _print_not_supported     _print_NaN = _print_not_supported     _print_NegativeInfinity  |
| .venv/lib/python3.13/site-packages/sympy/printing/numpy.py | 2a9abec929104912980b1b60419122ff8963dc498aec582f6c3253cef07bed37 | 542 | 4 | class NumPyPrinter(ArrayPrinter, PythonCodePrinter):     """     Numpy printer which handles vectorized piecewise functions,     logical operators, etc.     """ |
| .venv/lib/python3.13/site-packages/sympy/printing/llvmjitcode.py | 3638c76e085e1f88fa49ba052037ebac8a2091cac94645bf92397333c0e90e64 | 491 | 4 |      def _compile_function(self, strmod):         llmod = llvm.parse_assembly(strmod)          pmb = llvm.create_pass_manager_builder() |
| .venv/lib/python3.13/site-packages/sympy/printing/tensorflow.py | 4265a82d42a979f058259f89d048b43471eb53b2e2be9f13778b6b5930c5cf2f | 225 | 1 | class TensorflowPrinter(ArrayPrinter, AbstractPythonCodePrinter):     """     Tensorflow printer which handles vectorized piecewise functions,     logical operators, max/min, and relational operators. |
| .venv/lib/python3.13/site-packages/sympy/printing/latex.py | 8c2a977b55ce58b354711373b07398dc232f6e43c12a37fcb43e228ba3d52b15 | 3319 | 10 | if TYPE_CHECKING:     from sympy.tensor.array import NDimArray     from sympy.vector.basisdependent import BasisDependent  # Hand-picked functions which can be used directly in both LaTeX and MathJax |
| .venv/lib/python3.13/site-packages/sympy/printing/julia.py | 57f41b95dd0c39e6c8913e159e6c8fe957486e0acf6aa96582392fede4aaf1b9 | 653 | 2 |         from sympy.matrices import Matrix         L = A.col_list()         # make row vectors of the indices and entries         I = Matrix([k[0] + 1 for k in L])         J = Matrix([k[1] + 1 for k in |
| .venv/lib/python3.13/site-packages/sympy/printing/octave.py | d687de05a21ca097e0cc899ecdf3de77d678759e939398156c441baf4d9370b2 | 712 | 3 |         PREC = precedence(expr)         return "%s \\ %s" % (self.parenthesize(expr.matrix, PREC),                              self.parenthesize(expr.vector, PREC))      def _print_Pi(self, expr): |
| .venv/lib/python3.13/site-packages/sympy/printing/tests/test_c.py | 7ad204809c25196c6d1fa551620dd9923cb0fe4b584588fffa6bc43107a19a32 | 889 | 1 |   def test_ccode_loops_matrix_vector():     n, m = symbols('n m', integer=True)     A = IndexedBase('A') |
| .venv/lib/python3.13/site-packages/sympy/printing/tests/test_glsl.py | 71fa20f5fa7f10e166fe9889c2a51c4af00827bf1b4709058de730af7a1c09a9 | 999 | 6 |  def test_glsl_code_list_tuple_Tuple():     assert glsl_code([1,2,3,4]) == 'vec4(1, 2, 3, 4)'     assert glsl_code([1,2,3],glsl_types=False) == 'float[3](1, 2, 3)'     assert glsl_code([1,2,3]) == gls |
| .venv/lib/python3.13/site-packages/sympy/printing/tests/test_latex.py | c471bf812944b03f9090e2221d4c96138cdbd1bac9c708301acd63241bef380d | 3165 | 4 | from sympy.tensor.indexed import (Idx, Indexed, IndexedBase) from sympy.tensor.toperators import PartialDerivative from sympy.vector import CoordSys3D, Cross, Curl, Dot, Divergence, Gradient, Laplacia |
| .venv/lib/python3.13/site-packages/sympy/printing/tests/test_julia.py | eca4a66cf8bfd09d9948bd9f23fc4b5aaa11f46cbbdcb7cdb731403474bc1223 | 391 | 2 |   def test_vector_entries_hadamard():     # For a row or column, user might to use the other dimension     A = Matrix([[1, sin(2/x), 3*pi/x/5]]) |
| .venv/lib/python3.13/site-packages/sympy/printing/tests/test_octave.py | 58e269b2e1a13182f0da2923c1d4d5ea455a73af88df192367baaf51585e15b5 | 516 | 2 |   def test_vector_entries_hadamard():     # For a row or column, user might to use the other dimension     A = Matrix([[1, sin(2/x), 3*pi/x/5]]) |
| .venv/lib/python3.13/site-packages/sympy/printing/tests/test_maple.py | 761733d9ba9aa41fea33204b320b209ef55121c1d0f879b1bc0c42fd8d19deaf | 382 | 2 |   def test_vector_entries_hadamard():     # For a row or column, user might to use the other dimension     A = Matrix([[1, sin(2 / x), 3 * pi / x / 5]]) |
| .venv/lib/python3.13/site-packages/sympy/printing/tests/test_mathml.py | c9520960794534b6edd6ab5b2abaa3c41d8ff3c76c0fa02d4bd115b038bfbc4c | 2049 | 3 | from sympy.stats.rv import RandomSymbol from sympy.tensor.indexed import IndexedBase from sympy.vector import (Divergence, CoordSys3D, Cross, Curl, Dot,     Laplacian, Gradient) from sympy.testing.pyt |
| .venv/lib/python3.13/site-packages/sympy/printing/tests/test_jscode.py | 39b6a16677bd9506c1897c8964ba218d019d1ec1b60a758214e07c29b14e02a4 | 397 | 1 |   def test_jscode_loops_matrix_vector():     n, m = symbols('n m', integer=True)     A = IndexedBase('A') |
| .venv/lib/python3.13/site-packages/sympy/printing/tests/test_rcode.py | 4d7ca5e38f5e08ee09f8fdc341bdf0f455af32a39d5e67ee897832060fe29d04 | 477 | 1 |   def test_rcode_loops_matrix_vector():     n, m = symbols('n m', integer=True)     A = IndexedBase('A') |
| .venv/lib/python3.13/site-packages/sympy/printing/pretty/pretty.py | 2a611745be9712d239b62418b2cb9e89b28aac9545d45d66c2b175b871b19a93 | 2938 | 12 |      def _print_BasisDependent(self, expr):         from sympy.vector import Vector          if not self._use_unicode: |
| .venv/lib/python3.13/site-packages/sympy/printing/pretty/tests/test_pretty.py | 2b65edfbea6d77158bb949ad6099eeca1f3566b1880d1a8d33f88e5000c07630 | 7973 | 2 | from sympy.testing.pytest import raises, _both_exp_pow, warns_deprecated_sympy  from sympy.vector import CoordSys3D, Gradient, Curl, Divergence, Dot, Cross, Laplacian   |
| .venv/lib/python3.13/site-packages/sympy/algebras/quaternion.py | 8b6164be38f5e2f03a1ad5e07129290f056621873b4f9cd3d61c38f6c6fffed3 | 1667 | 65 |         r"""Returns 4 x 4 Matrix equivalent to a Hamilton product from the         left. This can be useful when treating quaternion elements as column         vectors. Given a quaternion $q = a + bi  |
| .venv/lib/python3.13/site-packages/sympy/algebras/tests/test_quaternion.py | ba7e08e88284dafe9811f52c141498e4deaa699d1a827d69b97d0b1256f59381 | 438 | 10 |     q_vect = Quaternion.from_Matrix(q.to_Matrix(True))     assert (q - q_full).is_zero_quaternion()     assert (q.vector_part() - q_vect).is_zero_quaternion()   |
| .venv/lib/python3.13/site-packages/sympy/solvers/recurr.py | 0f2b2c66e3b27a6a02e89d5c5aaeb7e4eef3920d562c7ad1eca1a833e80dcb48 | 844 | 8 |             a = S.Zero          def _zero_vector(k):             return [S.Zero] * k  |
| .venv/lib/python3.13/site-packages/sympy/solvers/solvers.py | c6c4a541a8f45daba77b19a17d065923fba24571c44e669469bf61819ae699b5 | 3675 | 3 |     ===========      ``f`` is a vector function of symbolic expressions representing the system.     *args* are the variables. If there is only one variable, this argument can     be omitted. ``x0`` i |
| .venv/lib/python3.13/site-packages/sympy/solvers/pde.py | 5768f182699ea67836a1f1450d53ac0475aa7fe214402808cf8957ce10547b28 | 967 | 3 |          Aside from the various solving methods, there are also some         meta-hints that you can pass to pdsolve():          "default": |
| .venv/lib/python3.13/site-packages/sympy/solvers/simplex.py | a5e46fe38683337d14ff4c24f3166fdede8cfdca66fdaf610402e2cabef39dd6 | 1105 | 2 |     """     A linear programming problem is considered infeasible if its     constraint set is empty. That is, if the set of all vectors     satisfying the constraints is empty, then the problem is in |
| .venv/lib/python3.13/site-packages/sympy/solvers/diophantine/diophantine.py | 9fbe17acc216e99c2b01f695564b3b9f0074d460a523449876f4dee4af742677 | 3981 | 6 |     ===========      The Gaussian reduction can find the shortest vector for any norm.     So we define the special norm for the vectors `u = (u_1, u_2)` and `v = (v_1, v_2)` as follows.  |
| .venv/lib/python3.13/site-packages/sympy/solvers/tests/test_solvers.py | 79733a013daea719510bb4b69756315124ba8c934ce363f1cd8093cf80b8be67 | 2726 | 5 |  def test_issue_20747():     THT, HT, DBH, dib, c0, c1, c2, c3, c4  = symbols('THT HT DBH dib c0 c1 c2 c3 c4')     f = DBH*c3 + THT*c4 + c2     rhs = 1 - ((HT - 1)/(THT - 1))**c1*(1 - exp(c0/f)) |
| .venv/lib/python3.13/site-packages/sympy/solvers/ode/systems.py | 2a893600c3b8604297dfc7e2d8baf12e6e73a5370d5f3dfdf1bece06fad47b35 | 2136 | 42 |      The matrix exponential $\exp(A*t)$ appears in the solution of linear     differential equations. For example if $x$ is a vector and $A$ is a matrix     then the initial value problem  |
| .venv/lib/python3.13/site-packages/sympy/solvers/ode/single.py | c81a4f5452b72ec09fd3b7436fdff1eadce1a79778967ff1229319a4fd91cab7 | 2978 | 18 |      @cached_property     def is_autonomous(self):         u = Dummy('u')         x = self.sym |
| .venv/lib/python3.13/site-packages/sympy/solvers/ode/ode.py | f544346ea72b14eb06b92c467d12697760a594859f8946193c2dbe03b0ab79fa | 3573 | 17 | to solve the ODE, you find that you cannot, raise ``NotImplementedError``. :py:meth:`~sympy.solvers.ode.dsolve` will catch this error with the ``all`` meta-hint, rather than causing the whole routine  |
| .venv/lib/python3.13/site-packages/sympy/solvers/ode/riccati.py | dd9ae40b2dee7d70b20b1f2025f02ec7208e81b38b107b6f4e1d95809840ecc9 | 894 | 14 | `\chi_1, \chi_2, \dots, \chi_m` are movable poles of `a(x)`, and the values of `N, n, r_1, r_2, \dots, r_n` can be determined from `a(x)`. The coefficient vectors `(d_0, d_1, \dots, d_N)` and `(c_{i1} |
| .venv/lib/python3.13/site-packages/sympy/solvers/ode/lie_group.py | 0b61e8395b436c84f6af2c784f312f414e3a62a73c2eead3041b63bf99b6f814 | 1097 | 4 |     symbols = numbered_symbols("c", cls=Dummy)     symlist = [next(symbols) for _ in islice(symbols, 6)]     C0, C1, C2, C3, C4, C5 = symlist     pde = C3 + (C4 - C0)*h - (C0*x + C1*y + C2)*hx - (C3*x |
| .venv/lib/python3.13/site-packages/sympy/solvers/ode/tests/test_systems.py | 3de2041cec7cf9e65036ea8e7e18d3bc611e15256b88b9474a13e6cbce2675ee | 2545 | 92 |   C0, C1, C2, C3, C4, C5, C6, C7, C8, C9, C10 = symbols('C0:11') x = symbols('x') f = Function('f') |
| .venv/lib/python3.13/site-packages/sympy/solvers/ode/tests/test_ode.py | 6c47138bdcc0e53a2828e13d76e16d77a4c0551bcb3eb3bdd9aad7edf17ce7e4 | 1106 | 5 |   C0, C1, C2, C3, C4, C5, C6, C7, C8, C9, C10 = symbols('C0:11') u, x, y, z = symbols('u,x:z', real=True) f = Function('f') |
| .venv/lib/python3.13/site-packages/sympy/solvers/ode/tests/test_subscheck.py | 1b3c1cf61f67eb394d3a127c421e9f403781f2085a46682fde4b4101f3c9c7e5 | 204 | 8 |   C0, C1, C2, C3, C4 = symbols('C0:5') u, x, y, z = symbols('u,x:z', real=True) f = Function('f') |
| .venv/lib/python3.13/site-packages/sympy/solvers/ode/tests/test_riccati.py | 6b6fe95f30856fd583b53fe47716247cb77e3c6e71bece2b427fefa4593e3bdb | 878 | 13 |     """     This function tests the Case 1 in the step     to calculate coefficients of c-vectors.      Each test case has 4 values - |
| .venv/lib/python3.13/site-packages/sympy/solvers/ode/tests/test_single.py | b04be15f0b3ddb439efc8baf98121833988f56247a2379e364d80995cf2c302e | 2903 | 48 | f = Function('f') g = Function('g') C1, C2, C3, C4, C5, C6, C7, C8, C9, C10  = symbols('C1:11') a, b, c = symbols('a b c')  |
| .venv/lib/python3.13/site-packages/sympy/codegen/matrix_nodes.py | d1ddea5f2db36aade2b32925138f253fb34fe4b4c5ed290b5cc1cc6f07951975 | 72 | 6 |     >>> with assuming(Q.fullrank(A)):     ...     optimize(expr, [matinv_opt])     MatrixSolve(A, vector=x) """  |
| .venv/lib/python3.13/site-packages/sympy/codegen/ast.py | 47f2610bebabcb1f4da09d4849053a7dbdda5786912f548ca1d995fc3736cf65 | 1907 | 1 |          Number of decimal digits needed to guarantee that two consecutive conversions         (float -> text -> float) to be idempotent. This is useful when one do not want         to loose precision |
| .venv/lib/python3.13/site-packages/sympy/codegen/tests/test_cxxnodes.py | e4ec0df03fd9b4a37dcf9b8d794c1b524c801b334bad380829495c45698e4a91 | 15 | 3 |  def test_using():     v = Type('std::vector')     u1 = using(v)     assert cxxcode(u1) == 'using std::vector' |
| .venv/lib/python3.13/site-packages/sympy/liealgebras/type_d.py | 09a827e065eb62e50fdf65ba8dab883e712ff08703dc7f3cb1b9f47ca4bba665 | 174 | 1 |      def dimension(self):         """Dmension of the vector space V underlying the Lie algebra          Examples |
| .venv/lib/python3.13/site-packages/sympy/liealgebras/type_e.py | 291f386e9e066bb77d8ad2910ac0f7018adaad57b01a234d7bb00758d51f4c03 | 276 | 1 |      def dimension(self):         """Dimension of the vector space V underlying the Lie algebra          Examples |
| .venv/lib/python3.13/site-packages/sympy/liealgebras/type_a.py | 12d9ff69ec84e45758ad45eb1a78cd8932f9938af9f8efc2cac68efbf50a0120 | 165 | 1 |      def dimension(self):         """Dimension of the vector space V underlying the Lie algebra          Examples |
| .venv/lib/python3.13/site-packages/sympy/liealgebras/type_f.py | 808ca4e33034e2e229c22cdc61dbcab19ff191ca4f2c877a2c81d1eada77f1d9 | 163 | 1 |      def dimension(self):         """Dimension of the vector space V underlying the Lie algebra          Examples |
| .venv/lib/python3.13/site-packages/sympy/liealgebras/type_b.py | 1111f568cdfc787654b9325846c58b2850e6ef81b8cb5310b707927e40c54187 | 171 | 1 |      def dimension(self):         """Dimension of the vector space V underlying the Lie algebra          Examples |
| .venv/lib/python3.13/site-packages/sympy/liealgebras/root_system.py | 9f54ca019c960cf4a55039a30206bd49ad829bda9e45775d60f6e5d972b216ae | 197 | 5 |     abelian subalgebra, and consider the adjoint action of g on this     subalgebra.  There is a root system associated with this action. Now, a     root system over a vector space V is a set of finit |
| .venv/lib/python3.13/site-packages/sympy/liealgebras/type_c.py | 025d69039730e482a3bc1cf1f4b74c391779f89657800d2468cbfc687867609d | 170 | 2 |      def dimension(self):         """Dimension of the vector space V underlying the Lie algebra          Examples |
| .venv/lib/python3.13/site-packages/sympy/liealgebras/type_g.py | 21f7bdf1d18fb5aac677e8a2f2125b5dd07448cb1cb78a240e4497db02cdf172 | 112 | 1 |      def dimension(self):         """Dimension of the vector space V underlying the Lie algebra          Examples |
| .venv/lib/python3.13/site-packages/sympy/liealgebras/tests/test_type_C.py | cac4b2fafcc4f65370cc0ba7ae6be71642c1a09c05ed6d8e9fb429a92e91235b | 23 | 1 |  def test_type_C():     c = CartanType("C4")     m = Matrix(4, 4, [2, -1, 0, 0, -1, 2, -1, 0, 0, -1, 2, -1, 0, 0, -2, 2])     assert c.cartan_matrix() == m |
| .venv/lib/python3.13/site-packages/sympy/utilities/lambdify.py | 95ea62784c48d7d42f6583eb1a5fd665a170b5af18641a3a020c439f0ab4d68c | 1593 | 8 |     """     # Transforming everything to strings.     from sympy.matrices import DeferredVector     from sympy.core.basic import Basic     from sympy.core.function import (Derivative, Function) |
| .venv/lib/python3.13/site-packages/sympy/utilities/autowrap.py | 97c9e85912a603e07cd784bdd912b73bae1858090046731fa98d4042a8b64bc8 | 1179 | 1 | When is this module NOT the best approach?      1) If you are really concerned about speed or memory optimizations,        you will probably get better results by working directly with the        wrap |
| .venv/lib/python3.13/site-packages/sympy/utilities/enumerative.py | 6a1e137792a1a8674f47b1101dc5033ac60b0c7eb84a1db3eb19b9803a494858 | 1156 | 12 |  The submultisets, aaabc and bccc of the partition are called *parts*, or sometimes *vectors*.  (Knuth notes that multiset partitions can be thought of as partitions of vectors of integers, where the  |
| .venv/lib/python3.13/site-packages/sympy/utilities/iterables.py | 9e820c45099d48f7db8352e8ad13c7adea334b6eb9bb82075260e43af301da9a | 3180 | 10 |   def _partition(seq, vector, m=None):     """     Return the partition of seq as specified by the partition vector. |
| .venv/lib/python3.13/site-packages/sympy/utilities/tests/test_lambdify.py | 7a64d20f01dd1a9ac434edee80af3a9352fa9bc63721a98f8f5a1434829a62b4 | 2264 | 9 | from sympy.utilities.lambdify import lambdify from sympy.utilities.iterables import numbered_symbols from sympy.vector import CoordSys3D from sympy.core.expr import UnevaluatedExpr from sympy.codegen. |
| .venv/lib/python3.13/site-packages/sympy/utilities/tests/test_codegen_octave.py | 1944088fa623b0cb23f192e65678166bda2fa32a9fc2f8a459775e4bb9bf73b2 | 590 | 3 |  def test_m_loops():     # Note: an Octave programmer would probably vectorize this across one or     # more dimensions.  Also, size(A) would be used rather than passing in m     # and n.  Perhaps use |
| .venv/lib/python3.13/site-packages/sympy/utilities/tests/test_pickling.py | 6571b307f810f63bb0b3f37f9f6bdfe903d5a2375f3f831b97bbaa76d90f6f41 | 724 | 3 |     WildFunction from sympy.sets.sets import Interval from sympy.core.multidimensional import vectorize  from sympy.external.gmpy import gmpy as _gmpy |
| .venv/lib/python3.13/site-packages/sympy/utilities/tests/test_wester.py | 4bbf5436c1a1116e73ea10eb89007c398fd585acf58f443bcafdf51f29f20df9 | 3105 | 15 | # Base conversions; not really implemented by SymPy # Whatever. Take credit! def test_C4():     assert 0xABC == 2748  |
| .venv/lib/python3.13/site-packages/sympy/utilities/tests/test_enumerative.py | 9f0fb5af4320c5bcd8912726c6fec7500200432720f29515387fec94344b83b1 | 180 | 1 |     Multiset partitions can be created as equivalence classes of set     partitions, and this function does just that.  This approach is     slow and memory intensive compared to the more advanced alg |
| .venv/lib/python3.13/site-packages/sympy/utilities/tests/test_codegen_julia.py | 418a9296e5619b1abf0406a010a05be9e248b1e14503078c8e9b8b80d3cc5162 | 621 | 3 |  def test_jl_loops():     # Note: an Julia programmer would probably vectorize this across one or     # more dimensions.  Also, size(A) would be used rather than passing in m     # and n.  Perhaps use |
| .venv/lib/python3.13/site-packages/sympy/utilities/tests/test_codegen.py | a637e16536b92c8f6076b6a40df2ed041ac8c605a358e451fcd0435bd27c0aaf | 1633 | 14 |      (f1, code), (f2, interface) = codegen(         ('matrix_vector', Eq(y[i], A[i, j]*x[j])), "C99", "file", header=False, empty=False)      assert f1 == 'file.c' |
| .venv/lib/python3.13/site-packages/sympy/testing/quality_unicode.py | aae2855291143dfb5518da6c8fbd56a51a1e29953373cb202e33834661cf7fec | 103 | 2 |     # output.     r'*/sympy/testing/tests/test_code_quality.py',     r'*/sympy/physics/vector/tests/test_printing.py',     r'*/physics/quantum/tests/test_printing.py',     r'*/sympy/vector/tests/test_ |
| .venv/lib/python3.13/site-packages/sympy/testing/runtests.py | 743f7fd31b6f1b4c0c810b5dbf10e2ede3dcd822f6c9b351a872a01e32689b31 | 2410 | 1 |      Modified from doctest's version to look harder for code that     appears comes from a different module. For example, the @vectorize     decorator makes it look like functions come from multidimen |
| .venv/lib/python3.13/site-packages/sympy/testing/tests/test_code_quality.py | 6336f50802001933b6f40cb67ec3e7d3e3aab2d028cbd14c88030879dea25591 | 511 | 1 |         # these __init__.py should be fixed:         # XXX: not really, they use useful import pattern (DRY)         "%(sep)svector%(sep)s__init__.py" % sepd,         "%(sep)smechanics%(sep)s__init__. |
| .venv/lib/python3.13/site-packages/sympy/integrals/meijerint.py | c8eb2b1c903b768a35b83b26b224ea2b64e5cb8245df4b00e511254fdda57de7 | 2192 | 6 |     c2 = And(*[re(1 + i + j) > 0 for i in g1.bm for j in g2.bm])     c3 = And(*[re(1 + i + j) < 1 + 1 for i in g1.an for j in g2.an])     c4 = And(*[(p - q)*re(1 + i - 1) - re(mu) > Rational(-3, 2) fo |
| .venv/lib/python3.13/site-packages/sympy/integrals/prde.py | dd5a8140e5fb499bff9444e68685606fd8118dbd73f21899009eafbf9020344a | 1334 | 5 |      Given a differential field (K, D) with constant field C = Const(K), a Matrix     A, and a vector (Matrix) u with coefficients in K, returns the tuple     (B, v, s), where B is a Matrix with coeff |
| .venv/lib/python3.13/site-packages/sympy/integrals/intpoly.py | 4978ddfdfdbde58ad8b2fa10a73136110339c5a4279e3d33bc77585b9284767d | 1303 | 9 |     x1, x2 = line_seg     rev_normal = [-1 * S(i)/norm(A) for i in A]     vector = [x2[i] - x1[i] for i in range(0, 3)]     vector = [vector[i]/norm(vector) for i in range(0, 3)]  |
| .venv/lib/python3.13/site-packages/sympy/integrals/heurisch.py | 1eeab77412445ef606ce405ba179c6eb11421a8adce547ed7f9b2c6e296dc88b | 782 | 1 | # NB @cacheit is not convenient here def _symbols(name, n):     """get vector of symbols local to this module"""     try:         lsyms = _symbols_cache[name] |
| .venv/lib/python3.13/site-packages/sympy/integrals/risch.py | e14b131e2cd9b4031edd5526447ba074eb8f322970f2c2a254e95250c5a3f681 | 1852 | 1 |     """     # __slots__ is defined mainly so we can iterate over all the attributes     # of the class easily (the memory use doesn't matter too much, since we     # only create one DifferentialExtens |
| .venv/lib/python3.13/site-packages/sympy/integrals/tests/test_integrals.py | f1b548378ced4f03afa4bae50c893549445032d88d5e8aaef8b2cc919a7e5ab9 | 2188 | 1 |  def test_issue_15509():     from sympy.vector import CoordSys3D     N = CoordSys3D('N')     x = N.x |
| .venv/lib/python3.13/site-packages/sympy/assumptions/predicates/matrices.py | 5f7bdb9047f7cf024bc9a9c48dfea28d85ee45f15f4affb26ad975b49db9c039 | 512 | 1 |     If $M$ is a :math:`n \times n` symmetric real matrix, it is said     to be positive definite if :math:`Z^TMZ` is positive for     every non-zero column vector $Z$ of $n$ real numbers.      Example |
| .venv/lib/python3.13/site-packages/sympy/plotting/plot.py | ba6bc6e3b788a8e744528e6a922de30e44ba2d82a74d6153679ab3c59641800c | 1235 | 1 |     # NOTE: if this import would be at the top-module level, it would trigger     # SymPy's optional-dependencies tests to fail.     from sympy.vector import BaseScalar      args = _plot_sympify(args) |
| .venv/lib/python3.13/site-packages/sympy/plotting/series.py | 84f90c89c022dbd463a09905a4c0add42467d31741558535c0b9e28a01e009a3 | 2592 | 27 |             return complex(np.nan, np.nan)      # NOTE: np.vectorize is much slower than numpy vectorized operations.     # However, this modules must be able to evaluate functions also with     # mpm |
| .venv/lib/python3.13/site-packages/sympy/plotting/utils.py | 0a29a7a3d3101a371b7b8ad0e9337ceabe2b336b7ad8280046a3ed805d26851f | 324 | 3 |             args[i] = Tuple(*_plot_sympify(a), sympify=False)         elif not (isinstance(a, (str, dict)) or callable(a)             # NOTE: check if it is a vector from sympy.physics.vector module   |
| .venv/lib/python3.13/site-packages/sympy/plotting/experimental_lambdify.py | c5c06196f676876d1a23532950deaa004a4ed3be43bf5df60166d027b9775b38 | 642 | 11 |   class vectorized_lambdify:     """ Return a sufficiently smart, vectorized and lambdified function.  |
| .venv/lib/python3.13/site-packages/sympy/plotting/pygletplot/util.py | 9b34108030dba74e01d372b226ba2cb0ba7c62aef6449ce3a7edc0adf8db307f | 189 | 3 |   def get_direction_vectors():     m = get_model_matrix()     return ((m[0], m[4], m[8]), |
| .venv/lib/python3.13/site-packages/sympy/plotting/pygletplot/plot_axes.py | 43d60df16d077753de7e51cbbcebd267e87178b5382aade75052d80c2d31d04f | 252 | 11 | from sympy.plotting.pygletplot.plot_object import PlotObject from sympy.plotting.pygletplot.util import billboard_matrix, dot_product, \         get_direction_vectors, strided_range, vec_mag, vec_sub  |
| .venv/lib/python3.13/site-packages/sympy/plotting/pygletplot/plot_controller.py | 32ba092523c26c10d3f201acfc676aa55fca1ec96530d269c71d0c537bca255f | 219 | 10 | from pyglet.window import key from pyglet.window.mouse import LEFT, RIGHT, MIDDLE from sympy.plotting.pygletplot.util import get_direction_vectors, get_basis_vectors   |
| .venv/lib/python3.13/site-packages/sympy/plotting/tests/test_utils.py | 164718640153f139c74486e4927c7d36f037f8b811d2e6bb585cb34043ec5481 | 111 | 10 | from sympy.plotting.utils import (     _create_ranges, _plot_sympify, extract_solution) from sympy.physics.mechanics import ReferenceFrame, Vector as MechVector from sympy.vector import CoordSys3D, Ve |
| .venv/lib/python3.13/site-packages/sympy/plotting/tests/test_series.py | 3706bafff60ca160a26349984a5bc93cf9e5bed7ce60b0021d1d516e4a2931cd | 1772 | 1 |     # Verify that symbolic expressions and numerical lambda functions are     # evaluated with the same algorithm. In particular, uniform evaluation     # is going to use np.vectorize, which correctly |
| .venv/lib/python3.13/site-packages/sympy/sets/tests/test_fancysets.py | a22baee4f28dac37833be36d82c1380a993041a4bb24d80262e4b2735ca428a1 | 1314 | 14 |     r2 = Interval(0, 3)     theta2 = Interval(pi, 2*pi, left_open=True)     c4 = ComplexRegion(r2*theta2, polar=True)     assert c4.contains(0) == True     assert c4.contains(2 + I) == False |
| .venv/lib/python3.13/site-packages/sympy/benchmarks/bench_discrete_log.py | 08d721209e4714c3e9365559876bce5341a04376ec7ba86acaa0e8be90c794a1 | 84 | 2 | from sympy.ntheory.residue_ntheory import (discrete_log,         _discrete_log_trial_mul, _discrete_log_shanks_steps,         _discrete_log_pollard_rho, _discrete_log_pohlig_hellman)   |
| .venv/lib/python3.13/site-packages/sympy/combinatorics/graycode.py | c5bb6bf0068561be12326c148bb99fefdd7753cee31fe5c4605ff7a4665f8f4a | 431 | 3 |     A Gray code is essentially a Hamiltonian walk on     a n-dimensional cube with edge length of one.     The vertices of the cube are represented by vectors     whose values are binary. The Hamilton |
| .venv/lib/python3.13/site-packages/sympy/combinatorics/permutations.py | 9d0a1ce188137a84fcd1e1e4a9eb53054c70010416e34512d809d1daee3e13f9 | 3115 | 17 |         ========          __sub__, inversion_vector          """ |
| .venv/lib/python3.13/site-packages/sympy/combinatorics/generators.py | 50076fd1bbeab4dea2f5b7c5801f3bde0f80fb3b2c7346688877240ce108d0cd | 302 | 1 |     The result is given as a subgroup of Sn, except for the special cases n=1     (the group S2) and n=2 (the Klein 4-group) where that's not possible     and embeddings in S2 and S4 respectively are  |
| .venv/lib/python3.13/site-packages/sympy/combinatorics/pc_groups.py | e40c0479840231d61cc9b86513292f259a8462d2502e061b47102735079a8df1 | 711 | 15 |         return pc_relators      def exponent_vector(self, element):         r"""         Return the exponent vector of length equal to the |
| .venv/lib/python3.13/site-packages/sympy/combinatorics/perm_groups.py | b1fd057f1989e6e582c25bf3443e66e471ddb86e6aa87ce1dd8d27d436b1e58a | 5460 | 27 |            "Permutation Group Algorithms"      .. [3] https://en.wikipedia.org/wiki/Schreier_vector      .. [4] https://en.wikipedia.org/wiki/Nielsen_transformation#Product_replacement_algorithm |
| .venv/lib/python3.13/site-packages/sympy/combinatorics/galois.py | 7297768876927629b9fb7f9caaf939f183fe02e4ba0af25e09d516a6239d2192 | 612 | 4 |     Names for the transitive subgroups of S4.     """     C4 = "C4"     V = "V"     D4 = "D4" |
| .venv/lib/python3.13/site-packages/sympy/combinatorics/tests/test_pc_groups.py | c1f918fe29691b45d6ae16963152baafbc9631e5df33c58d4f2b62e6813d6dd9 | 88 | 3 |   def test_exponent_vector():      Groups = [SymmetricGroup(3), SymmetricGroup(4), SymmetricGroup(9).sylow_subgroup(3), |
| .venv/lib/python3.13/site-packages/sympy/combinatorics/tests/test_perm_groups.py | ef4fc079d329afe6318980c71e3c3a7e3be6616efe628ce7106c14786b49a341 | 1244 | 4 |   def test_schreier_vector():     G = CyclicGroup(50)     v = [0]*50 |
| .venv/lib/python3.13/site-packages/sympy/combinatorics/tests/test_permutations.py | 13c27e58b096db3f614f24c9726d5db058055e1f1801eb08a6962c5d1bb9a40b | 565 | 7 |     assert q.atoms() == {0, 1, 2, 3, 4, 5, 6}      assert p.inversion_vector() == [2, 4, 1, 3, 1, 0]     assert q.inversion_vector() == [3, 1, 2, 2, 0, 1]  |
| .venv/lib/python3.13/site-packages/sympy/interactive/traversal.py | 5db71c74eea6b0d02fac6e851499769f85e62224484a7bdd6b841f95f10f83b5 | 96 | 2 |     YELLOW, BYELLOW = '\033[0;33m', '\033[1;33m'  # noqa     BLUE, BBLUE = '\033[0;34m', '\033[1;34m'      # noqa     MAGENTA, BMAGENTA = '\033[0;35m', '\033[1;35m'# noqa     CYAN, BCYAN = '\033[0;36m |
| .venv/lib/python3.13/site-packages/sympy/functions/special/hyper.py | a2a78084500b00dfc7e9e4b416cfdac5d7cbf6321843e6911461a0424cb61d89 | 1186 | 8 |     ===========      The hypergeometric function depends on two vectors of parameters, called     the numerator parameters $a_p$, and the denominator parameters     $b_q$. It also has an argument $z$. |
| .venv/lib/python3.13/site-packages/sympy/tensor/tensor.py | 110f6a263b6f8a3e201b5d358c1d5e3ae4ed6929af9b50dadc81d50819f5165a | 5266 | 10 |          Some examples for different values of ``(*args)``:         ``(1)``         vector, equivalent to ``TensorSymmetry.fully_symmetric(1)``         ``(2)``         tensor with 2 symmetric indices, |
| .venv/lib/python3.13/site-packages/sympy/tensor/toperators.py | 7e7893529758cf43afb4d9c582b1c835e757f3a17155cc5f2a3f65fe5d69f51c | 257 | 1 |             array = array.as_mutable()             varindex = var_indices[0]             # Remove coefficients of base vector:             coeff_index = [0] + [slice(None) for i in range(len(indices)) |
| .venv/lib/python3.13/site-packages/sympy/tensor/indexed.py | dea8907a132f5d20dbaff4435e0ea5fda12ee9d1d95c47d7acca170898fb0aaa | 794 | 2 |  Repeated indices in a product implies a summation, so to express a matrix-vector product in terms of Indexed objects:  >>> x = IndexedBase('x') |
| .venv/lib/python3.13/site-packages/sympy/tensor/array/arrayop.py | 2af146616718bc285691386d540a2d95a4ab71f8c7a20031be9c56be9e9d4a0a | 529 | 1 |     =====      This class is an iterator with which the memory cost can be economised.     Optimisation has been considered to ameliorate the performance for some     specific data types like DenseNDi |
| .venv/lib/python3.13/site-packages/sympy/tensor/array/__init__.py | 9534f5130579b5bdd602f9a64bf9888e10925922e207434d3d6e27f7fddfbb49 | 272 | 1 | Four classes are provided to handle N-dim arrays, given by the combinations dense/sparse (i.e. whether to store all elements or only the non-zero ones in memory) and mutable/immutable (immutable class |
| .venv/lib/python3.13/site-packages/sympy/tensor/array/tests/test_immutable_ndim_array.py | f638bfd78b339feaa82fa0d0e66bb320535a5de7d3ee7e793c58a05e8170939d | 453 | 14 |      number5 = 5     vector = ImmutableDenseNDimArray.zeros(number5)     assert len(vector) == number5     assert vector.shape == (number5,) |
| .venv/lib/python3.13/site-packages/sympy/tensor/array/tests/test_mutable_ndim_array.py | ac515ad28d0025880f367a6a8a397dd556fd116da480719073a72ef5fd5f22f6 | 375 | 14 |      number5 = 5     vector = MutableDenseNDimArray.zeros(number5)     assert len(vector) == number5     assert vector.shape == (number5,) |
| .venv/lib/python3.13/site-packages/sympy/tensor/array/expressions/array_expressions.py | dbc4c8f1cc3043843e40223d5ff8fa5fe946d2447a6a68c07bdfa1f4929be445 | 1970 | 27 | from sympy.core.symbol import (Dummy, Symbol) from sympy.matrices.matrixbase import MatrixBase from sympy.matrices.expressions.diagonal import diagonalize_vector from sympy.matrices.expressions.matexp |
| .venv/lib/python3.13/site-packages/sympy/tensor/array/expressions/tests/test_convert_array_to_matrix.py | daf9127a9f423ca62b4104b4bbc0329ffb1cef27a4d73c338e30962b971f61ef | 690 | 1 |   def test_arrayexpr_convert_array_to_diagonalized_vector():      # Check matrix recognition over trivial dimensions: |
| .venv/lib/python3.13/site-packages/sympy/tensor/tests/test_tensor.py | 5d088b90eb722cb14a5ff95612aa42af6957c50e8b2bf852863d2bcfb46b5a99 | 2219 | 2 |   def test_contract_metric4():     R3 = TensorIndexType('R3', dim=3)     p, q, r = tensor_indices("p q r", R3) |
| .venv/lib/python3.13/site-packages/sympy/tensor/tests/test_tensor_operators.py | 9f899de43bfb428552311e1c1db904292143c604d3a44cb1322080aa8ab22729 | 465 | 6 |      # this is only some special expression     # tested: vector derivative     # tested: scalar derivative     # tested: tensor derivative |
| .venv/lib/python3.13/site-packages/sympy/geometry/line.py | 630f27b3fc3cae7e8511a93a3267ec75c72034d8cc4078687438a4d945fb8c93 | 2878 | 9 |     def angle_between(l1, l2):         """Return the non-reflex angle formed by rays emanating from         the origin with directions the same as the direction vectors         of the linear entities. |
| .venv/lib/python3.13/site-packages/sympy/geometry/point.py | bd0078d15d5fbe16737b70ff0f9e0794c492f205de30859eaddda1068ce63c50 | 1379 | 5 |                     %s''' % (s, o)))          # if the vectors p1 and p2 are linearly dependent, then they must         # be scalar multiples of each other         m = Matrix([s.args, o.args]) |
| .venv/lib/python3.13/site-packages/sympy/geometry/plane.py | cf786311fde26ceef7e4357431be03563bed858943ca23df7a409e78f4820cc3 | 879 | 71 |     inputs. They are:     - three non-collinear points     - a point and the plane's normal vector      Attributes |
| .venv/lib/python3.13/site-packages/sympy/geometry/tests/test_plane.py | 41171fa03b09b42b5cbe315bd7c841107ba9c9c2e0013d8ea2117a1a93528724 | 269 | 35 |     p3 = Point3D(1, 2, 3)     pl3 = Plane(p1, p2, p3)     pl4 = Plane(p1, normal_vector=(1, 1, 1))     pl4b = Plane(p1, p2)     pl5 = Plane(p3, normal_vector=(1, 2, 3)) |
| .venv/lib/python3.13/site-packages/sympy/physics/wigner.py | 2f9432cc3e321f84b24e4efe58209dd3b5cad3f3ddf67cfbb07c28db339657b2 | 1214 | 2 |      A matrix representing the corresponding Euler angle rotation( in the basis     of eigenvectors of `J_z`).      .. math :: |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/functions.py | 2ac5f7cf7deb65d30289fc32565c8a20754987416f7befb3b39c1dd6b906325d | 736 | 21 | from sympy.utilities import dict_merge from sympy.utilities.iterables import iterable from sympy.physics.vector import (Dyadic, Vector, ReferenceFrame,                                   Point, dynamic |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/system.py | 56c3cf41f26cd2004b28960d43664b983f7c2562ddd48672d10191c08db5fd33 | 1554 | 26 | from sympy.physics.mechanics.method import _Methods from sympy.physics.mechanics.particle import Particle from sympy.physics.vector import Point, ReferenceFrame, dynamicsymbols from sympy.utilities.it |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/body.py | 67d64e45e11a6fd147103b32bf645f20140ce3fae2a578455e642dbb53a637f6 | 711 | 16 | from sympy import Symbol from sympy.physics.vector import Point, Vector, ReferenceFrame, Dyadic from sympy.physics.mechanics import RigidBody, Particle, Inertia from sympy.physics.mechanics.body_base  |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/pathway.py | d93ef5c74e97f02676d0d5325e43273fcde02acc76c092446cf252fb580c5c50 | 689 | 17 | from sympy.physics.mechanics.loads import Force from sympy.physics.mechanics.wrapping_geometry import WrappingGeometryBase from sympy.physics.vector import Point, dynamicsymbols   |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/rigidbody.py | b396fbca7b1d70cb2af4f3769ccd72a3335c65dd3c440f8c83332372cee39c12 | 315 | 10 | from sympy import Symbol, S from sympy.physics.vector import ReferenceFrame, Dyadic, Point, dot from sympy.physics.mechanics.body_base import BodyBase from sympy.physics.mechanics.inertia import inert |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/loads.py | 8e76a364e83adf502ab5dd3e06995e8688542fdf750b70a38b63996773151dd9 | 178 | 17 | from collections import namedtuple from sympy.physics.mechanics.body_base import BodyBase from sympy.physics.vector import Vector, ReferenceFrame, Point  __all__ = ['LoadBase', 'Force', 'Torque'] |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/wrapping_geometry.py | 5e4237df5a1070199ee230e61f446a4035a1fe9ab8f68dfc9db46c5f04fd3b91 | 642 | 42 | from sympy.functions.elementary.trigonometric import atan2 from sympy.polys.polytools import cancel from sympy.physics.vector import Vector, dot from sympy.simplify.simplify import trigsimp  |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/inertia.py | 14a7046e960fc7fdba2d2f6c4a9f2572c27cdeca6ac12608cb1339abfcf59980 | 200 | 2 | from sympy import sympify from sympy.physics.vector import Point, Dyadic, ReferenceFrame, outer from collections import namedtuple  |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/__init__.py | eeb80f269d5822d00c39cdbd816aa4469ebc00a09d64bbb8b45406f825a08ce4 | 91 | 5 | __all__ = [     'vector',      'CoordinateSym', 'ReferenceFrame', 'Dyadic', 'Vector', 'Point', 'cross', |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/lagrange.py | 51398294e3fe3e463c4be2dc3e570e0149ac867765aba9a99996a295bbf2e04e | 513 | 16 | from sympy import diff, zeros, Matrix, eye, sympify from sympy.core.sorting import default_sort_key from sympy.physics.vector import dynamicsymbols, ReferenceFrame from sympy.physics.mechanics.method  |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/kane.py | 5f2bc40cd174f62e439c77fe62509e7041c374a2bd8f8f3a3763f9603f3f5da3 | 860 | 28 | from sympy import zeros, Matrix, diff, eye, linear_eq_to_matrix from sympy.core.sorting import default_sort_key from sympy.physics.vector import (ReferenceFrame, dynamicsymbols,                        |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/particle.py | 60a8840643cb55123d7e85e511ef1ebbc62ce56d46c903b5a0e05fd13f1f1c58 | 210 | 7 | from sympy import S from sympy.physics.vector import cross, dot from sympy.physics.mechanics.body_base import BodyBase from sympy.physics.mechanics.inertia import inertia_of_point_mass |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/joint.py | a3d49627da570cefac561d2027a5532342e0634d7d805079c3914fd4f37ef942 | 2189 | 144 | from sympy.physics.mechanics.body_base import BodyBase from sympy.physics.mechanics.functions import _validate_coordinates from sympy.physics.vector import (Vector, dynamicsymbols, cross, Point,       |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/body_base.py | 6f03f4e255a60f4898fd3d15b27e8d58c6e75b2cd430516a900a00c8ab28c3f7 | 95 | 1 | from abc import ABC, abstractmethod from sympy import Symbol, sympify from sympy.physics.vector import Point  __all__ = ['BodyBase'] |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/jointsmethod.py | 9ea9176b0b6ec5ec8fd03f031006144422650d84b81246bfbd7c7a5193fbcbbe | 319 | 8 |         Iterable of Body objects in the system.     loads : iterable         Iterable of (Point, vector) or (ReferenceFrame, vector) tuples         describing the forces on the system.     mass_matrix |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/linearize.py | 62d01aa7a4f3b1925defde1c7430840c956530e5ddff014031a09965a707c1b1 | 475 | 3 | from sympy.core.symbol import Dummy from sympy.utilities.iterables import flatten from sympy.physics.vector import dynamicsymbols from sympy.physics.mechanics.functions import msubs, _parse_linear_sol |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/actuator.py | 77b15f6fdbe8d539ab71f8b2ef5fe0d2bd5bb6c71fbef69b13ebf39e4bb702e9 | 1148 | 20 | from sympy.physics.mechanics.pathway import PathwayBase from sympy.physics.mechanics.rigidbody import RigidBody from sympy.physics.vector import ReferenceFrame, Vector   |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/tests/test_pathway.py | a060b19543af8b235cd4604cbe1939b185597eef02e28ee524c6ea6ad0627b70 | 692 | 1 | def _simplify_loads(loads):     return [         load.__class__(load.location, load.vector.simplify())         for load in loads     ] |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/tests/test_body.py | ca01df59e2fafb72d6f60a971dfcddbea421256c60dbe5362902072aa18da8a4 | 341 | 13 | from sympy import (Symbol, symbols, sin, cos, Matrix, zeros,                                 simplify) from sympy.physics.vector import Point, ReferenceFrame, dynamicsymbols, Dyadic from sympy.physics |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/tests/test_lagrange.py | 8ae1e89ae94117c31a7cb7a8aca19a2c750417c0af1615dcc44b4dd219356a43 | 248 | 2 |     # The kinematics are formed by a series of simple rotations. Each simple     # rotation creates a new frame, and the next rotation is defined by the new     # frame's basis vectors. This example u |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/tests/test_joint.py | a23850741b1637a9d1ede804869c3e2c0c8345d1483df484b03a052f56e1ceab | 1241 | 39 |     CylindricalJoint, PlanarJoint, SphericalJoint, WeldJoint, Body) from sympy.physics.mechanics.joint import Joint from sympy.physics.vector import Vector, ReferenceFrame, Point from sympy.testing.py |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/tests/test_jointsmethod.py | f0850eee7b4b3ecc9d0d3e18800d453f23b94d7369a38088582ecefc975683d4 | 250 | 1 |     PinJoint, JointsMethod, RigidBody, Particle, Body, KanesMethod,     PrismaticJoint, LagrangesMethod, inertia) from sympy.physics.vector import dynamicsymbols, ReferenceFrame from sympy.testing.pyt |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/tests/test_kane3.py | fbd31b5cb7d8503840ffd0f6a3836b34b8034ce9ca0cb2ec82bc905b700769cb | 316 | 4 |                 u6: v / PaperRadFront}      # Linearizes the forcing vector; the equations are set up as MM udot =     # forcing, where MM is the mass matrix, udot is the vector representing the     # |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/tests/test_kane.py | 2b51ce9bb72e3f35de3bd6665bba001e0bbe8f13a0d4816ac8a0776217806eeb | 554 | 3 |     # The kinematics are formed by a series of simple rotations. Each simple     # rotation creates a new frame, and the next rotation is defined by the new     # frame's basis vectors. This example u |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/tests/test_functions.py | 0a5d5a4f7a93fb4224eaf2604ba6ade8f51a7964507e9106f3c42f108c73d419 | 263 | 2 |     sol = {y.diff(), x.diff().diff(), z.diff()}     assert find_dynamicsymbols(expr, exclude=exclude_list) == sol     # Test finding all dynamicsymbols in a vector with a given reference frame     d,  |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/tests/test_actuator.py | 5a84e70ff20685ec153b370bef26c95dffe6acad3f13bd600dc9e89fedcc6b28 | 1085 | 10 |     RigidBody,     TorqueActuator,     Vector,     dynamicsymbols,     DuffingSpring, |
| .venv/lib/python3.13/site-packages/sympy/physics/mechanics/tests/test_wrapping_geometry.py | 697c2e11aa6bb2d9d25bb0702ebdce294cb149a8113cee7c2feb5431aab723db | 364 | 26 |     @staticmethod     @pytest.mark.parametrize(         'position_1, position_2, vector_1, vector_2',         [             (r * N.x, r * N.y, N.y, N.x), |
| .venv/lib/python3.13/site-packages/sympy/physics/units/dimensions.py | 18cba8485d6fa8a0ecfdedc927b63496916b9de5cc64b664fea202e5de90e545 | 591 | 10 |         canonical dimension basis.          It corresponds to the matrix where columns are the vector of base         dimensions in canonical basis.  |
| .venv/lib/python3.13/site-packages/sympy/physics/units/__init__.py | 0d5bd6cbda8d466ef8d8d146701a726c5636d192b7054ec358d6cb3135d8885a | 454 | 1 | This module defines dimension/unit systems and physical quantities. It is based on a group-theoretical construction where dimensions are represented as vectors (coefficients being the exponents), and  |
| .venv/lib/python3.13/site-packages/sympy/physics/units/tests/test_dimensionsystem.py | b36ff644027039a3ce4efc888803bd4986a9dfbe32b59a966dab5690b0a76d25 | 96 | 8 |   def test_dim_can_vector():     dimsys = DimensionSystem(         [length, mass, time], |
| .venv/lib/python3.13/site-packages/sympy/physics/biomechanics/musculotendon.py | 2eb630167c244a10d659942d0a0b5252abdcd47e489538ff04d54ac5f14d844d | 1425 | 2 | from sympy.physics.biomechanics._mixin import _NamedMixin from sympy.physics.mechanics.actuator import ForceActuator from sympy.physics.vector.functions import dynamicsymbols   |
| .venv/lib/python3.13/site-packages/sympy/physics/biomechanics/curve.py | 3decca394cad882d79a0b575d460b833abbb9dd5c7a70b5b8a5a9d6c88aabe0c | 1764 | 17 |      with constant values of $c0 = 0.814$, $c1 = 1.06$, $c2 = 0.162$,     $c3 = 0.0633$, $c4 = 0.433$, $c5 = 0.717$, $c6 = -0.0299$, $c7 = 0.2$,     $c8 = 0.1$, $c9 = 1.0$, $c10 = 0.354$, and $c11 = 0 |
| .venv/lib/python3.13/site-packages/sympy/physics/biomechanics/tests/test_curve.py | de36d6107afc89e65809f565c09d4a4c0d5627d75c4c2c90d69debf06da3a752 | 1696 | 10 |         self.c2 = Symbol('c_2')         self.c3 = Symbol('c_3')         self.c4 = Symbol('c_4')         self.c5 = Symbol('c_5')         self.c6 = Symbol('c_6') |
| .venv/lib/python3.13/site-packages/sympy/physics/biomechanics/tests/test_musculotendon.py | 2ece7d9ad250f375b47dda4318518d79382dc4bf32019e8e0d6f7a37d9af16d3 | 838 | 3 | from sympy.physics.mechanics.actuator import ForceActuator from sympy.physics.mechanics.pathway import LinearPathway from sympy.physics.vector.frame import ReferenceFrame from sympy.physics.vector.fun |
| .venv/lib/python3.13/site-packages/sympy/physics/continuum_mechanics/truss.py | 8642cb9d703d691684d98bc0d2876ced3e34cc941751cfe32c8d74f0d8e1b532 | 1109 | 3 |          direction: Sympifyable             The angle, in degrees, that the load vector makes with the horizontal             in the counter-clockwise direction. It takes the values 0 to 360,          |
| .venv/lib/python3.13/site-packages/sympy/physics/continuum_mechanics/arch.py | 4ca6a81e4efe4e834fd27e9918517f716eb1f7ae42f83de210d8aa168ef86495 | 1026 | 1 |              angle: Sympifyable                 The angle in degrees, the load vector makes with the horizontal                 in the counter-clockwise direction.  |
| .venv/lib/python3.13/site-packages/sympy/physics/continuum_mechanics/cable.py | d483a96bf78b6307728b13640e12d72504a0e1f421c0e1fb61b9b58d64786900 | 816 | 1 |              direction : Sympifyable                 The angle, in degrees, that the load vector makes with the horizontal                 in the counter-clockwise direction. It takes the values 0 to  |
| .venv/lib/python3.13/site-packages/sympy/physics/continuum_mechanics/beam.py | 56ad71247ae36ad40452280cb3194093caa8652ca9fd9ff41a2279cb90083088 | 3904 | 35 |         l = self.length         C3 = Symbol('C3')         C4 = Symbol('C4')         rotation_jumps = tuple(self._rotation_hinge_symbols)         deflection_jumps = tuple(self._sliding_hinge_symbols) |
| .venv/lib/python3.13/site-packages/sympy/physics/continuum_mechanics/tests/test_beam.py | 5a68bc0428eedb51f545aa26283a85013bc252ab2b71aff8de8e48c80e6ce289 | 1119 | 7 |     b3.bc_slope.append((0, 2))     C3 = symbols('C3')     C4 = symbols('C4')      p = b3.load |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/functions.py | 6f874764ec5bbd2efb48c71294257619368ecd68f44d0894b4368efdd863dd4c | 651 | 68 | from sympy.integrals.integrals import integrate from sympy.simplify.trigsimp import trigsimp from .vector import Vector, _check_vector from .frame import CoordinateSym, _check_frame from .dyadic impor |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/vector.py | 47b3fadd03d979ed257c71d50d4ed4abdd5926ce5ec2354ae47563f471cd790a | 807 | 117 |   __all__ = ['Vector']   |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/__init__.py | 8d99ab341e997d8ecd38ff27c7c19671f2362316f69afee55ee1879fade4c8ec | 37 | 3 |     'Dyadic',      'Vector',      'Point', |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/point.py | 5b51fa25df990081d8f3228edd85a3faf744a7ba88db2a209739391ee4fecb61 | 636 | 57 | from .vector import Vector, _check_vector from .frame import _check_frame from warnings import warn |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/frame.py | 275b18faa6806a671914a3f6eb1e7843d4d62135c1823984defe4f884685ae2e | 1576 | 119 | from sympy.core.symbol import Symbol from sympy.simplify.trigsimp import trigsimp from sympy.physics.vector.vector import Vector, _check_vector from sympy.utilities.misc import translate  |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/fieldfunctions.py | 1f74bba1e2c76889d99ecf64a34e013ce71248e2b63398412bbd6307cd771316 | 314 | 46 | from sympy.core.singleton import S from sympy.integrals.integrals import integrate from sympy.physics.vector import Vector, express from sympy.physics.vector.frame import _check_frame from sympy.physi |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/dyadic.py | 0ae0244818276ad7e7650da005acd9402d430555db92c885596ab1bb6c370b65 | 546 | 35 |      A more powerful way to represent a rigid body's inertia. While it is more     complex, by choosing Dyadic components to be in body fixed basis vectors,     the resulting matrix is equivalent to t |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/printing.py | 6b537ec338829ede201ed63d96ea9ef820d6f5a02da59d0572f5b043484c104a | 372 | 33 |   class VectorStrPrinter(StrPrinter):     """String Printer for vector expressions. """  |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/tests/test_point.py | e424f34f76be8a0777ddab80adae2ebac9b43d851cff084fb55eca028678839c | 383 | 2 | from sympy.physics.vector import dynamicsymbols, Point, ReferenceFrame from sympy.testing.pytest import raises, ignore_warnings import warnings |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/tests/test_fieldfunctions.py | 1548e1d7c43307a75749abbd887bad6f7ea8dbc7da49aed3f6c07489ca636be3 | 134 | 11 | from sympy.core.symbol import Symbol from sympy.functions.elementary.trigonometric import (cos, sin) from sympy.physics.vector import ReferenceFrame, Vector, Point, \      dynamicsymbols from sympy.ph |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/tests/test_frame.py | 4b9c67e50f5d323fc00884bd7dfec0093052eec145a2f8bd0c8a2ff9cad4b24a | 762 | 29 | from sympy.matrices.immutable import ImmutableDenseMatrix as Matrix from sympy.simplify.simplify import simplify from sympy.physics.vector import (ReferenceFrame, Vector, CoordinateSym,                |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/tests/test_dyadic.py | bc248bc68d29ca7ac7ac20a8ed2e3ddb9960461a129bf32be5884887fd5b61cc | 124 | 2 | from sympy.functions.elementary.trigonometric import (cos, sin) from sympy.matrices.immutable import ImmutableDenseMatrix as Matrix from sympy.physics.vector import ReferenceFrame, dynamicsymbols, out |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/tests/test_output.py | 860aa513eff337f10f13f80867fbf6b97075cb66aea37f6145e5a9bc5526d904 | 76 | 13 | from sympy.core.singleton import S from sympy.physics.vector import Vector, ReferenceFrame, Dyadic from sympy.testing.pytest import raises  |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/tests/test_vector.py | 6ea53596d4ba5066d2a3be0a5ccb6f3f598ea6a290e97495d7d5a3c364283457 | 275 | 20 | from sympy.functions.elementary.trigonometric import (cos, sin) from sympy.matrices.immutable import ImmutableDenseMatrix as Matrix from sympy.physics.vector import ReferenceFrame, Vector, dynamicsymb |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/tests/test_printing.py | a95063cf87f74ed0eb76e5182cd0ebbe5af30553010ea2e8dbb256b051dd5f5f | 354 | 17 | from sympy.functions.elementary.miscellaneous import sqrt from sympy.functions.elementary.trigonometric import (asin, cos, sin) from sympy.physics.vector import ReferenceFrame, dynamicsymbols, Dyadic  |
| .venv/lib/python3.13/site-packages/sympy/physics/vector/tests/test_functions.py | a87193d1147ebe4029d68177d1314d81a7ae386bd77599cad9a299b9182b6478 | 510 | 11 | from sympy.functions.elementary.trigonometric import (cos, sin) from sympy.integrals.integrals import Integral from sympy.physics.vector import Dyadic, Point, ReferenceFrame, Vector from sympy.physics |
| .venv/lib/python3.13/site-packages/sympy/physics/control/lti.py | a3a9fea855eb8817844ebe1a9c280eb985625294170ed05e8dc908758765c71d | 5002 | 15 |         return self.num_outputs, self.num_inputs      def dsolve(self, initial_conditions=None, input_vector=None, var=Symbol('t')):         r"""         Returns `y(t)` or output of StateSpace given b |
| .venv/lib/python3.13/site-packages/sympy/physics/control/tests/test_lti.py | 600bf0035d7348a45c1e680b3ee0898412576c5acf7e350dcad690b2712c12bf | 2274 | 13 |     A4 = Matrix([[a0, a1], [a2, a3]])     B4 = Matrix([[b0, b1], [b2, b3]])     C4 = Matrix([[c0, c1], [c2, c3]])     D4 = Matrix([[d0, d1], [d2, d3]])     ss4 = StateSpace(A4, B4, C4, D4) |
| .venv/lib/python3.13/site-packages/sympy/physics/optics/__init__.py | d149aa22ddbebbc5b036402ab27395b7d565901f4ad024482588906a5b49ef7c | 39 | 4 |     'hyperfocal_distance', 'transverse_magnification',      'jones_vector', 'stokes_vector', 'jones_2_stokes', 'linear_polarizer',     'phase_retarder', 'half_wave_retarder', 'quarter_wave_retarder',  |
| .venv/lib/python3.13/site-packages/sympy/physics/optics/utils.py | 06a7eebedae33b73c47034350de70dcadd9387d629b3ac6e79dd6d118e32b2f9 | 699 | 15 | def refraction_angle(incident, medium1, medium2, normal=None, plane=None):     """     This function calculates transmitted vector after refraction at planar     surface. ``medium1`` and ``medium2`` c |
| .venv/lib/python3.13/site-packages/sympy/physics/optics/polarization.py | 988ad988e5577ad1ad2a42f197c2e569fd99f5ca167a77fa24aac2961e16f325 | 733 | 50 | the fields.  - Jones vectors.  - Stokes vectors. |
| .venv/lib/python3.13/site-packages/sympy/physics/optics/tests/test_utils.py | 4a389c8c0a6d7191b0b97fa26ff2eaecf94638da2dbe8d97278a77240f623552 | 203 | 2 |     n = Matrix([0, 0, 1])     normal_ray = Ray3D(Point3D(0, 0, 0), Point3D(0, 0, 1))     P = Plane(Point3D(0, 0, 0), normal_vector=[0, 0, 1])     assert refraction_angle(r1, 1, 1, n) == Matrix([       |
| .venv/lib/python3.13/site-packages/sympy/physics/optics/tests/test_polarization.py | f35333c80dbd1d972483f4acfbcf3ee68d20f5aba00ea0abfcbc1c248897b80d | 58 | 12 | from sympy.physics.optics.polarization import (jones_vector, stokes_vector,     jones_2_stokes, linear_polarizer, phase_retarder, half_wave_retarder,     quarter_wave_retarder, transmissive_filter, re |
| .venv/lib/python3.13/site-packages/sympy/physics/quantum/qubit.py | 984d3179bcfccea78a11ce31c30f7e22feed673c478e6f4a96caf65a05107153 | 812 | 5 |     else:         raise QuantumError(             'Matrix must be a row/column vector, got %r' % matrix         )     if not isinstance(nqubits, Integer): |
| .venv/lib/python3.13/site-packages/sympy/physics/quantum/spin.py | 97ad7af1f4c46440b815e68c4bc88baa8ddbe1832f5253d366fabd37c892574f | 2151 | 4 |         \|1,-1>/2 - sqrt(2)*\|1,0>/2 + \|1,1>/2      Get the vector representation of a state in terms of the basis elements     of the Jx operator:  |
| .venv/lib/python3.13/site-packages/sympy/physics/quantum/shor.py | 0d5c0fc4b00f4abf2ddc5dda5c920f7b8a395d2b90884e9ae9e03a39899d645c | 174 | 4 |         n = 1         k = 0         # Determine the value stored in high memory.         for i in range(self.t):             k += n*qubits[self.t + i] |
| .venv/lib/python3.13/site-packages/sympy/physics/quantum/sho1d.py | 66ba11fc58f19a33a60dc774166d38bd6293182a6f2da12ee0d8aea652a6ef4f | 680 | 16 |         KroneckerDelta(b, k)      Vector representation of a numerical state ket:          >>> from sympy.physics.quantum.sho1d import SHOKet, NumberOp |
| .venv/lib/python3.13/site-packages/sympy/physics/quantum/represent.py | 74163d44b0f6d55d16b8805b8a06a08da2d25028a5a03ce2b6ff1697a7d4f5d1 | 575 | 4 |     various basis sets. Under this operation the follow transforms happen:      * Ket -> column vector or function     * Bra -> row vector of function     * Operator -> matrix or differential operator |
| .venv/lib/python3.13/site-packages/sympy/physics/quantum/hilbert.py | aab8daf76bc5ec151e4b21ce2ca557f3e5ca70f193ed0690316aea5978d136eb | 654 | 5 |     """An abstract Hilbert space for quantum mechanics.      In short, a Hilbert space is an abstract vector space that is complete     with inner products defined [1]_.  |
| .venv/lib/python3.13/site-packages/sympy/external/tests/test_autowrap.py | 9d4598790775405f8ebb803ade25b2a6c9faa49322d2e30bc9b6bc69108e8673 | 314 | 5 |   def runtest_autowrap_matrix_vector(language, backend):     has_module('numpy')     x, y = symbols('x y', cls=IndexedBase) |
| .venv/lib/python3.13/site-packages/sympy/external/tests/test_numpy.py | b6e1238b997a1aa6cd8efef84fa6b77bc2c3cc8db329468bcef7e5b8d5ce144d | 336 | 3 |  def test_lambdify_matrix_vec_input():     X = sympy.DeferredVector('X')     M = Matrix([         [X[0]**2, X[0]*X[1], X[0]*X[2]], |
| .venv/lib/python3.13/site-packages/sympy/parsing/tests/test_autolev.py | b50b9415af18a9576c1cf39c52103094c281f14934f077a30e10c275af255ecd | 179 | 1 |      # NOTE : The Autolev outputs above were manually transformed into     # equivalent SymPy physics vector expressions. Would be nice to automate     # this transformation.     expected_w_c_f = (l[' |
| .venv/lib/python3.13/site-packages/sympy/parsing/tests/test_c_parser.py | 5589772b889fff6de2212f817bc301486d0e299a3eeb18311e2376da569e032a | 5249 | 71 |             'int c;'         )         c_src4 = (             'int x = 1, y = 6.78;' + '\n' +             'float p = 2, q = 9.67;' |
| .venv/lib/python3.13/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py | 8efd6362f9ab1a6a26e85ddf8584c71b5b2a2cae851423b5fa3aef0d6fa73c43 | 2084 | 26 |             self.type2 = collections.OrderedDict()              # These lists are used to distinguish matrix, numeric and vector expressions.             self.matrix_expr = []             self.numeric |
| .venv/lib/python3.13/site-packages/sympy/parsing/autolev/_antlr/autolevlistener.py | 1036f75e41fd63b08bcf118cfad63e9c6ab13067c11d592a29d5423f10018111 | 422 | 6 |       # Enter a parse tree produced by AutolevParser#VectorOrDyadic.     def enterVectorOrDyadic(self, ctx:AutolevParser.VectorOrDyadicContext):         pass |
| .venv/lib/python3.13/site-packages/sympy/parsing/autolev/_antlr/autolevparser.py | 059609ec892ead19a6e384b9d29629ffd2470a34fc7ebd70e477a4b0010f8ed8 | 3064 | 6 |       class VectorOrDyadicContext(ExprContext):          def __init__(self, parser, ctx:ParserRuleContext): # actually a AutolevParser.ExprContext |
| .venv/lib/python3.13/site-packages/sympy/simplify/cse_main.py | b5c5265d7146219ca85f83ef044999f98626f8204b5e803218b1ef7abc4fdb7a | 946 | 1 |     symbol is no longer needed for subsequent expressions.      Use of such output can reduce the memory footprint of lambdified     expressions that contain large, repeated subexpressions.  |
| .venv/lib/python3.13/site-packages/sympy/simplify/hyperexpand.py | b1359dd7e55e2ebd0d4ebf9c9ba9dfb6398efe054fa9ad4ff6e77faef4994b9e | 2495 | 2 |     def build_invariants(self):         """         Compute the invariant vector.          Explanation |
| .venv/lib/python3.13/site-packages/sympy/simplify/_cse_diff.py | 36ad605e7dbba35bfcdedfff49052e69c9cea21872c1adfdb9c3da4768c3e75f | 292 | 4 |      expr : Matrix         The vector to be differentiated.      wrt : iterable |
| .venv/lib/python3.13/site-packages/sympy/simplify/tests/test_cse_diff.py | 63fcd866995dc235285a24d3a45325c383d792a369f6bf59c2bc38ea09263686 | 207 | 1 |   def test_nonvectorJacobian():     X = Matrix([[exp(x + y + z), exp(x + y + z)],                 [exp(x + y + z), exp(x + y + z)]]) |
| .venv/lib/python3.13/site-packages/sympy/vector/functions.py | ae6101695d17a592e408f7091688c74bd08d1e2ad5e79bf9b03c0da933f0a863 | 514 | 99 | from sympy.vector.coordsysrect import CoordSys3D from sympy.vector.deloperator import Del from sympy.vector.scalar import BaseScalar |
| .venv/lib/python3.13/site-packages/sympy/vector/kind.py | 53aab1722658efe002cc14a918cd22493239b6a7e5a4f06f9b8fc9f6e8f2c721 | 68 | 24 | #sympy.vector.kind  from sympy.core.kind import Kind, _NumberKind, NumberKind |
| .venv/lib/python3.13/site-packages/sympy/vector/parametricregion.py | 8006abba763cab70fc595bebc9911b250e20fa7957a381673be09bc84a555177 | 190 | 3 | from sympy.solvers import solve from sympy.geometry import Point, Segment, Curve, Ellipse, Polygon from sympy.vector import ImplicitRegion   |
| .venv/lib/python3.13/site-packages/sympy/vector/coordsysrect.py | d0129dafc006f015099d2848232c82be4539395763b59b0a701b8681d6ef747c | 1032 | 120 | from sympy.matrices.matrixbase import MatrixBase from sympy.solvers import solve from sympy.vector.scalar import BaseScalar from sympy.core.containers import Tuple from sympy.core.function import diff |
| .venv/lib/python3.13/site-packages/sympy/vector/vector.py | 68e49fc9f46f91ab735875aeba563a9f4fe2a84948e669ed0148cd3e9b690623 | 715 | 159 | from sympy.functions.elementary.miscellaneous import sqrt from sympy.matrices.immutable import ImmutableDenseMatrix as Matrix from sympy.vector.basisdependent import (BasisDependentZero,     BasisDepe |
| .venv/lib/python3.13/site-packages/sympy/vector/basisdependent.py | 3fb2e8814724e8d5a313300e1f7758af803c33940238f6825bbe659a242906a5 | 375 | 16 |  if TYPE_CHECKING:     from sympy.vector.vector import BaseVector   |
| .venv/lib/python3.13/site-packages/sympy/vector/scalar.py | 5806f6e410b44c4399fbf6c4b4bd607724ae33569d2732b8ee42584eb0b8638c | 73 | 1 |      def __new__(cls, index, system, pretty_str=None, latex_str=None):         from sympy.vector.coordsysrect import CoordSys3D         if pretty_str is None:             pretty_str = "x{}".format(ind |
| .venv/lib/python3.13/site-packages/sympy/vector/__init__.py | 6e02aeb55a943d6baf1d60698849ba5d613a8867c03c9c37a6dd7d3519f69f5d | 51 | 30 | from sympy.vector.coordsysrect import CoordSys3D from sympy.vector.vector import (Vector, VectorAdd, VectorMul,                                  BaseVector, VectorZero, Cross, Dot, cross, dot) |
| .venv/lib/python3.13/site-packages/sympy/vector/point.py | f8914e89bb1072538a0b69b6a99462186078a0af62795651776965e60e24ddb1 | 149 | 18 | from sympy.core.basic import Basic from sympy.core.symbol import Str from sympy.vector.vector import Vector from sympy.vector.coordsysrect import CoordSys3D from sympy.vector.functions import _path |
| .venv/lib/python3.13/site-packages/sympy/vector/orienters.py | 12d58d59f3af02ecbfc22a5a9bd480eff9ae292aec3fee3750f4420b3e7ab1bd | 399 | 18 | from sympy.core.cache import cacheit from sympy.core.symbol import Str import sympy.vector   |
| .venv/lib/python3.13/site-packages/sympy/vector/integrals.py | c7c0ebbca5cfce7134e4982767b2372162d6aef165f52120846685987ac1684e | 207 | 28 | from sympy.simplify.simplify import simplify from sympy.utilities.iterables import topological_sort from sympy.vector import (CoordSys3D, Vector, ParametricRegion,                         parametric_r |
| .venv/lib/python3.13/site-packages/sympy/vector/implicitregion.py | e3e33ffac84be0427d9df8c067fc60d3421765542085c099ddbbfc4066e4a292 | 507 | 5 |     >>> from sympy import Eq     >>> from sympy.abc import x, y, z, t     >>> from sympy.vector import ImplicitRegion      >>> ImplicitRegion((x, y), x**2 + y**2 - 4) |
| .venv/lib/python3.13/site-packages/sympy/vector/deloperator.py | e0124d8e6237e361e455199e424a9abaabe26cab1fd873aece49d04df40c9298 | 122 | 14 | from sympy.core import Basic from sympy.vector.operators import gradient, divergence, curl   |
| .venv/lib/python3.13/site-packages/sympy/vector/operators.py | 74d0bb98d5d96f72b15f91b28c53434cb4e4cd29d88cea2166d057b90d647991 | 336 | 49 | from sympy.core.expr import Expr from sympy.core import sympify, S, preorder_traversal from sympy.vector.coordsysrect import CoordSys3D from sympy.vector.vector import Vector, VectorMul, VectorAdd, Cr |
| .venv/lib/python3.13/site-packages/sympy/vector/dyadic.py | 20ecab80e3721831cfb46d1120d70c81eb4054c48e9982396bdf6cf8ec170530 | 286 | 54 | from __future__ import annotations  from sympy.vector.basisdependent import (BasisDependent, BasisDependentAdd,                                          BasisDependentMul, BasisDependentZero) from sym |
| .venv/lib/python3.13/site-packages/sympy/vector/tests/test_implicitregion.py | c158a50f91fe3211e25b9f104fa3f953bb93efd25d2879bd0fb2606688ba044e | 91 | 1 | from sympy.sets import FiniteSet, EmptySet from sympy.geometry import Point from sympy.vector import ImplicitRegion from sympy.testing.pytest import raises  |
| .venv/lib/python3.13/site-packages/sympy/vector/tests/test_operators.py | 29ec545af73f370a761d6ac46e1c623bb31e685c5895c92ba7ffd393083ec265 | 44 | 3 | from sympy.vector import CoordSys3D, Gradient, Divergence, Curl, VectorZero, Laplacian from sympy.printing.repr import srepr  |
| .venv/lib/python3.13/site-packages/sympy/vector/tests/test_dyadic.py | 7f547e04bffadd505b7345e0117fcb63357fdceba961de21a79473464e9d01b2 | 135 | 12 | from sympy.matrices.immutable import ImmutableDenseMatrix as Matrix from sympy.simplify.simplify import simplify from sympy.vector import (CoordSys3D, Vector, Dyadic,                           DyadicA |
| .venv/lib/python3.13/site-packages/sympy/vector/tests/test_integrals.py | 883ab75a9afc23c117006917a8ca40f8ff62d7312757b954f1647ac413a110ad | 107 | 22 | from sympy.functions.elementary.trigonometric import (cos, sin) from sympy.testing.pytest import raises from sympy.vector.coordsysrect import CoordSys3D from sympy.vector.integrals import ParametricIn |
| .venv/lib/python3.13/site-packages/sympy/vector/tests/test_field_functions.py | bfd97c131f0ad8cb0f1b1a803e1a4482ee96028eb04baaaf7562ca40cc601380 | 322 | 46 | from sympy.core.function import Derivative from sympy.vector.vector import Vector from sympy.vector.coordsysrect import CoordSys3D from sympy.simplify import simplify |
| .venv/lib/python3.13/site-packages/sympy/vector/tests/test_vector.py | ac9a4c9545a27b3ad8e9dac750d74973cfc50d83301821b8941cbccd2e174999 | 343 | 105 | from sympy.integrals.integrals import Integral from sympy.matrices.immutable import ImmutableDenseMatrix as Matrix from sympy.vector.vector import Vector, BaseVector, VectorAdd, \      VectorMul, Vect |
| .venv/lib/python3.13/site-packages/sympy/vector/tests/test_printing.py | dc1796e79890e2a5dd7c34c5aa9b44dae7c93c92013b375f218571f389ff1300 | 222 | 5 | from sympy.printing.latex import latex from sympy.printing.pretty import pretty as xpretty from sympy.vector import CoordSys3D, Del, Vector, express from sympy.abc import a, b, c from sympy.testing.py |
| .venv/lib/python3.13/site-packages/sympy/vector/tests/test_functions.py | 06cdac7a4743272c3fc2b5291bbbd94061f4cb44b80b801bc464a9794ffc0b6b | 185 | 18 | from sympy.vector.vector import Vector from sympy.vector.coordsysrect import CoordSys3D from sympy.vector.functions import express, matrix_to_vector, orthogonalize |
| .venv/lib/python3.13/site-packages/sympy/vector/tests/test_parametricregion.py | 39f29aa45f40fe0f57e89c6061cd147f1221c17cd1111cda8fe1228d008938dc | 98 | 2 | from sympy.core.numbers import pi from sympy.functions.elementary.trigonometric import (cos, sin) from sympy.vector.coordsysrect import CoordSys3D from sympy.vector.parametricregion import ParametricR |
| .venv/lib/python3.13/site-packages/sympy/vector/tests/test_coordsysrect.py | abd9fd3881bf0a90f8290376d1dcf0459217a0cbfb552829f1f1e65679197ebd | 465 | 13 | from sympy.testing.pytest import raises from sympy.vector.coordsysrect import CoordSys3D from sympy.vector.scalar import BaseScalar from sympy.core.function import expand |
| .venv/lib/python3.13/site-packages/sympy/diffgeom/diffgeom.py | 0e0c60c4ff41ecd4fe3351dbd7ed40c0760706f5d993f63afcca997063ec98e8 | 2271 | 133 |     coord_functions = base_scalars      def base_vector(self, coord_index):         """Return a basis vector field.         The basis vector field for this coordinate system. It is also an |
| .venv/lib/python3.13/site-packages/sympy/diffgeom/__init__.py | 7168f837b01f360ad87062017b15fe52b5b17ddd5b3fd0d336a5262d6509f670 | 20 | 4 | from .diffgeom import (     BaseCovarDerivativeOp, BaseScalarField, BaseVectorField, Commutator,     contravariant_order, CoordSystem, CoordinateSymbol,     CovarDerivativeOp, covariant_order, Differe |
| .venv/lib/python3.13/site-packages/sympy/diffgeom/rn.py | 92f82d87aacd256b7de24cd5a2ca59c221f9dc2face154a2a2b92d40d98ca1b4 | 144 | 7 | R2.r, R2.theta = R2_origin.r, R2_origin.theta = R2_p.r, R2_p.theta = R2_p.coord_functions()  # Defining the basis vector fields and adding shortcuts for them to the # manifold and the patch. R2.e_x, R |
| .venv/lib/python3.13/site-packages/sympy/diffgeom/tests/test_class_structure.py | 2db472c61869f8d9e77c9da04e7d527658020509f6ae1c81ef10293a071dfeb3 | 34 | 1 | f = Function('f') s1, s2 = cs.coord_functions() v1, v2 = cs.base_vectors() f1, f2 = cs.base_oneforms()  |
| .venv/lib/python3.13/site-packages/sympy/diffgeom/tests/test_diffgeom.py | dc17a90abea779dfb80bfde67b8cd272ed3a1d71bd431fdd041c48a625c0bf2e | 343 | 11 |     t = symbols('t')     start_point = R2_r.point([1, 0])     vector_field = -R2.y*R2.e_x + R2.x*R2.e_y     equations, init_cond = intcurve_diffequ(vector_field, t, start_point)     assert str(equatio |
| .venv/lib/python3.13/site-packages/sympy/stats/symbolic_multivariate_probability.py | 47a0a8ed709cc4ba0eb53a82e994a71aeca564d501ac2e400f40eb26bda31350 | 309 | 2 |          if 1 not in arg.shape:             raise ShapeError("Expression is not a vector")          shape = (arg.shape[0], arg.shape[0]) if arg.shape[1] == 1 else (arg.shape[1], arg.shape[1]) |
| .venv/lib/python3.13/site-packages/sympy/stats/joint_rv_types.py | 3d46ad47859c3c79801da76df22461e71621e4d262833621f84a00311e5b943c | 946 | 8 |     def check(mu, sigma):         _value_check(mu.shape[0] == sigma.shape[0],             "Size of the mean vector and covariance matrix are incorrect.")         #check if covariance matrix is positiv |
| .venv/lib/python3.13/site-packages/sympy/stats/stochastic_process_types.py | 604500fac69387c585e8f9fb19c82b7327254426ff482d77627a60388a6eefe4 | 2384 | 5 |             P = self.transition_probabilities             I = eye(P.shape[0])             w = self.fixed_row_vector()             W = Matrix([list(w) for i in range(0, P.shape[0])])             if (I  |
| .venv/lib/python3.13/site-packages/sympy/stats/stochastic_process.py | a43cf4adb2974e268d98c9a6cfbd1d3f717f2962ff5e1a022851d804db7541e5 | 67 | 1 |     of the process follows any specific distribution, like,     in Bernoulli Process, each random indexed symbol follows     Bernoulli distribution. For processes with memory, this     parameter shoul |
| .venv/lib/python3.13/site-packages/sympy/stats/crv_types.py | a97631b6f24f838391248ec0c489118709c9ea5733dec54159fe2da10cbdbef0 | 4733 | 2 |      mu : Real number or a list/matrix, the location (mean) or the         location vector     b : Real number or a positive definite matrix, representing a scale         or the covariance matrix. |
| .venv/lib/python3.13/site-packages/sympy/stats/tests/test_continuous_rv.py | 05c0648b25fb7b5422c12eb19c3faa2f35e78a3bea6ec79b4f35c49f721f1b21 | 1584 | 1 |     a, b = symbols('a b', positive=True)     # FIXME: simplify(E(X)) seems to hang without extended_positive=True     # On a Linux machine this had a rapid memory leak...     # a, b = symbols('a b', p |
| .venv/lib/python3.13/site-packages/sympy/stats/tests/test_joint_rv.py | 5b6f2b09161ccefe496b1ee4f9b8fb3af793fb2f803f8abe911474f8b35a597d | 437 | 1 |  @XFAIL def test_joint_vector_expectation():     m = Normal('A', [x, y], [[1, 0], [0, 1]])     assert E(m) == (x, y) |
| .venv/lib/python3.13/site-packages/sympy/matrices/determinant.py | a434c36022c1496268bff8ff07e6591dda87dfe590feec2165ac2b5f710313d9 | 1022 | 14 |      # Compute the diagonal entries.     # Because multiplying matrix times vector is so much     # more efficient than matrix times matrix, recursively     # compute -R * A**n * C. |
| .venv/lib/python3.13/site-packages/sympy/matrices/subspaces.py | b8ba38aa73f4c6f15c168e6185fea0ee91d21e245b710d404c32b0181c56ec21 | 175 | 9 |  def _columnspace(M, simplify=False):     """Returns a list of vectors (Matrix objects) that span columnspace of ``M``      Examples |
| .venv/lib/python3.13/site-packages/sympy/matrices/matrices.py | 8aa822ef1edc8e72d3e8eb91a7a4d88e839b26d52d6dc3e97864ce0be12787d4 | 688 | 3 |  class MatrixEigen(MatrixSubspaces):     """Provides basic matrix eigenvalue/vector operations.     Should not be instantiated directly. See ``eigen.py`` for their     implementations.""" |
| .venv/lib/python3.13/site-packages/sympy/matrices/dense.py | 1d33cd30a6e2d8cd16d271c898db4789bf49339542f2c8bdf6574bfc5ca52b04 | 1095 | 7 |     [0, 0, 3]])      >>> diag([1, 2, 3])  # a column vector     Matrix([     [1], |
| .venv/lib/python3.13/site-packages/sympy/matrices/matrixbase.py | b27a6ff990458be091b5f33063d96e9124cfa442d55e6245d7a1a7f313d5df22 | 5429 | 37 |      def vech(self, diagonal=True, check_symmetry=True):         """Reshapes the matrix into a column vector by stacking the         elements in the lower triangle.  |
| .venv/lib/python3.13/site-packages/sympy/matrices/__init__.py | 8b66b7ed695c0a3f3e00a1bf632f0105d38716002e5a88acff621c0ff221d34b | 73 | 4 |     symarray, wronskian, zeros) from .dense import MutableDenseMatrix from .matrixbase import DeferredVector, MatrixBase  MutableMatrix = MutableDenseMatrix |
| .venv/lib/python3.13/site-packages/sympy/matrices/solvers.py | 916914772d17a166e7ed16384b5374a8d831280714ac789396271bdb9ad1f73e | 943 | 7 |     """Solve the linear system ``Ax = b``.      ``M`` is the matrix ``A``, the method argument is the vector     ``b``.  The method returns the solution vector ``x``.  If ``b`` is a     matrix, the sy |
| .venv/lib/python3.13/site-packages/sympy/matrices/common.py | bff8cc8c7f6dea6ac797b679425ba13be1b4ed051a2527628a8176602d719616 | 3259 | 6 |      def vech(self, diagonal=True, check_symmetry=True):         """Reshapes the matrix into a column vector by stacking the         elements in the lower triangle.  |
| .venv/lib/python3.13/site-packages/sympy/matrices/eigen.py | bf4f66a9bda16741ea19b1b362910b39ab481e71933f95c00c4fb544672e6be8 | 1347 | 31 |      # The nullspace for a real eigenvalue should be non-trivial.     # If we didn't find an eigenvector, try once more a little harder     if len(ret) == 0 and simplify:         ret = m.nullspace(isz |
| .venv/lib/python3.13/site-packages/sympy/matrices/tests/test_interactions.py | e93eb0907c935b9bf67f0834af3d8750ba031257c0fcdb6d029536b7ea5914a2 | 78 | 1 |   def test_matrix_symbol_vector_matrix_multiplication():     A = MM * SV     B = IM * SV |
| .venv/lib/python3.13/site-packages/sympy/matrices/tests/test_sparse.py | 1af5cdea405595d8eaa11f1637c23f3e36e52a1466c915af56e2d4819120ba06 | 746 | 1 |                           [0, 0, 0, 0, 0, 1, R(1)/3],                           [0, 0, 0, 0, 0, 0, 0]])     # now check the vectors     basis = M.nullspace()     assert basis[0] == Matrix([-3, 1, 0, 0 |
| .venv/lib/python3.13/site-packages/sympy/matrices/tests/test_eigen.py | 5e6f977bba860022e9ab03b1e56da60e3bded8ac897feabc3f2122e348cc8009 | 713 | 1 |     )      # XXX We skip test for some parts of eigenvectors which are very     # complicated and fragile under expression tree changes     A = DFT(5).as_explicit().expand(complex=True) |
| .venv/lib/python3.13/site-packages/sympy/matrices/tests/test_matrices.py | 62bc2b73356c4ee2e83c00248787656586df51c54451ef3cc32339ddf9943adc | 3488 | 24 | from sympy.matrices.exceptions import (ShapeError, MatrixError,     NonSquareMatrixError) from sympy.matrices.matrixbase import DeferredVector from sympy.matrices.determinant import _find_reasonable_p |
| .venv/lib/python3.13/site-packages/sympy/matrices/tests/test_matrixbase.py | d84528cf40e5de13c536f594fbe96ce913c67e595925b56f652b0303d0fa8cfa | 3796 | 24 |  from sympy import (     Abs, Add, Array, DeferredVector, E, Expr, FiniteSet, Float, Function,     GramSchmidt, I, ImmutableDenseMatrix, ImmutableMatrix,     ImmutableSparseMatrix, Integer, KroneckerD |
| .venv/lib/python3.13/site-packages/sympy/matrices/tests/test_subspaces.py | a6863a93a9762d22fb3828b140d1b3adab8b64861bae30ee97b27ec84134d92f | 110 | 2 |                           [0, 0, 0, 0, 0, 0, 0]])      # now check the vectors     basis = M.nullspace()     assert basis[0] == Matrix([-3, 1, 0, 0, 0, 0, 0]) |
| .venv/lib/python3.13/site-packages/sympy/matrices/tests/test_commonmatrix.py | 0846186b97eb18318f015cfbf2e6154c10b7207a102c6d7c5519eadbcf57b414 | 1267 | 2 |  def test_col_insert():     c4 = Matrix([4, 4, 4])     for i in range(-4, 5):         l = [0, 0, 0] |
| .venv/lib/python3.13/site-packages/sympy/matrices/expressions/companion.py | 95750945b8d047a7b599d1d0749c0d2095cc5bcd1798a6ce56a36f5178c1e7b5 | 57 | 4 |     >>> from sympy.matrices.expressions import CompanionMatrix     >>> x = Symbol('x')     >>> c0, c1, c2, c3, c4 = symbols('c0:5')     >>> p = Poly(c0 + c1*x + c2*x**2 + c3*x**3 + c4*x**4 + x**5, x)  |
| .venv/lib/python3.13/site-packages/sympy/matrices/expressions/applyfunc.py | f2c7295a3669ef2ceebd436bd26c4dd372a0c93ccb45ae4d90697db3cd583e06 | 205 | 1 |         ewdiff = ElementwiseApplyFunction(fdiff, self.expr)         if 1 in x.shape:             # Vector:             iscolumn = self.shape[1] == 1             for i in lr: |
| .venv/lib/python3.13/site-packages/sympy/matrices/expressions/factorizations.py | cc5363301b09aa1b087030fc31ee16f3e43e4d5f3d5a9b5f1b70ddf722bfb4f1 | 63 | 2 |         return (Q.upper_triangular,)  class EigenVectors(Factorization):     @property     def predicates(self): |
| .venv/lib/python3.13/site-packages/sympy/matrices/expressions/__init__.py | 20ca97092b0f874569fcc0bd1d94ee740e4318ce1606aff207e06cb746b3c8cf | 63 | 2 | from .adjoint import Adjoint from .hadamard import hadamard_product, HadamardProduct, hadamard_power, HadamardPower from .diagonal import DiagonalMatrix, DiagonalOf, DiagMatrix, diagonalize_vector fro |
| .venv/lib/python3.13/site-packages/sympy/matrices/expressions/diagonal.py | 5c75a84fe26fe50c0956c18d6dfc479cd1b6b3280fcb509e47fb7acebf285283 | 221 | 31 |     (2, 1)      The diagonal can be addressed like a matrix or vector and will     return the corresponding element of the original matrix:  |
| .venv/lib/python3.13/site-packages/sympy/matrices/expressions/dotproduct.py | b0a75487054a4c1dcb12f77cc4cc020dec4da10d43cf8dc3098b269b7530156c | 56 | 7 | class DotProduct(Expr):     """     Dot product of vector matrices      The input should be two 1 x n or n x 1 matrices. The output represents the |
| .venv/lib/python3.13/site-packages/sympy/matrices/expressions/matexpr.py | 9df57d3210cd051f4790e3fbce85ceb6ff70591e0e17135cce9ae29384b7521f | 889 | 1 |         if _get_shape(self.first)[1] != _get_shape(self.second)[1]:             # Remove one-dimensional identity matrices:             # (this is needed by `a.diff(a)` where `a` is a vector)          |
| .venv/lib/python3.13/site-packages/sympy/matrices/expressions/tests/test_diagonal.py | dcbe95b3f62bdfa6bc76022a01e21c3447f4c5c5727b21a100d36ed1d948a702 | 157 | 4 | from sympy.matrices.expressions import MatrixSymbol from sympy.matrices.expressions.diagonal import DiagonalMatrix, DiagonalOf, DiagMatrix, diagonalize_vector from sympy.assumptions.ask import (Q, ask |
| .venv/lib/python3.13/site-packages/sympy/matrices/expressions/tests/test_derivatives.py | f6605e6806435fbf896d8b3ab4c0a536e183ca011354dfdd0974a51e6c808708 | 478 | 1 |   def test_matrix_derivative_vectors_and_scalars():      assert x.diff(x) == Identity(k) |
| .venv/lib/python3.13/site-packages/oauthlib/oauth2/rfc8628/endpoints/device_authorization.py | b5bc9e419f370e966570245281bb498904fccb0aaf906037f38af42a6682dfda | 233 | 2 |         """The end-user verification URI on the authorization         server.  The URI should be short and easy to remember as end users         will be asked to manually type it into their user agent |
| .venv/lib/python3.13/site-packages/oauthlib/oauth2/rfc6749/parameters.py | 82d64e886e9f4f62b70a8cbc4479dcbbd2b8d5aa3a01dc00863bc378b037ac1c | 529 | 5 |     :param state: An opaque value used by the client to maintain                   state between the request and callback.  The authorization                   server includes this value when redirect |
| .venv/lib/python3.13/site-packages/oauthlib/oauth2/rfc6749/errors.py | 04fd0dde54bcff65f1d86ad2193e6555100714c35f914d604efe55188d7dc28e | 400 | 1 |     redirection URI, or if the client identifier is missing or invalid,     the authorization server SHOULD inform the resource owner of the     error and MUST NOT automatically redirect the user-agen |
| .venv/lib/python3.13/site-packages/oauthlib/oauth2/rfc6749/clients/web_application.py | f62a7300a8a1138cbf45c103ad30cd1f412720aa059f61ea751fcd3aa4274a59 | 223 | 3 |     A web application is a confidential client running on a web     server.  Resource owners access the client via an HTML user     interface rendered in a user-agent on the device used by the     res |
| .venv/lib/python3.13/site-packages/oauthlib/oauth2/rfc6749/clients/mobile_application.py | e5e040ffd19c8af330422baad2b38cdd32807265a7bcb6e919f826679d6bf5f7 | 175 | 6 |     """A public client utilizing the implicit code grant workflow.      A user-agent-based application is a public client in which the     client code is downloaded from a web server and executes with |
| .venv/lib/python3.13/site-packages/oauthlib/oauth2/rfc6749/endpoints/introspect.py | 02645b6b38a81658c209a71aea9a564a2dfc928661625cff3eb8072e031c0070 | 121 | 1 |    This endpoint defines a method to query an OAuth 2.0 authorization    server to determine the active state of an OAuth 2.0 token and to    determine meta-information about this token. OAuth 2.0 dep |
| .venv/lib/python3.13/site-packages/oauthlib/oauth2/rfc6749/endpoints/authorization.py | d8dd826ff4d0b6950f72a0c8725b099d9111b5a30a987f6e4a01a83192c59d42 | 115 | 1 |      """Authorization endpoint - used by the client to obtain authorization     from the resource owner via user-agent redirection.      The authorization endpoint is used to interact with the resourc |
| .venv/lib/python3.13/site-packages/oauthlib/oauth2/rfc6749/grant_types/implicit.py | a0bb9f481117e66d7f904e0d0a3d5d99a48b8f228c65db2f06b4a7d398a4d07e | 374 | 14 |         \|         -+----(A)-- & Redirection URI --->\|               \|         \|  User-   \|                                \| Authorization \|         \|  Agent  -\|----(B)-- User authenticates -->\|     Se |
| .venv/lib/python3.13/site-packages/oauthlib/oauth2/rfc6749/grant_types/authorization_code.py | 0d6931601c4e88a078fb3ccf5f052c035ad6a4bb2171efb9c218e088a7272dc6 | 548 | 11 |     tokens and refresh tokens and is optimized for confidential clients.     Since this is a redirection-based flow, the client must be capable of     interacting with the resource owner's user-agent  |
| .venv/lib/python3.13/site-packages/oauthlib/openid/connect/core/endpoints/userinfo.py | 91cd50dc337cc41ca4dd07bf4b42c0966251d8c9179c29cd16a2ea56bf32df35 | 107 | 1 |         Response as defined in `Section 3`_ of OAuth 2.0 Bearer Token Usage         [RFC6750]. (HTTP errors unrelated to RFC 6750 are returned to the User         Agent using the appropriate HTTP stat |
| .venv/lib/python3.13/site-packages/oauthlib/openid/connect/core/grant_types/base.py | 272ec813d3fdefbc8bb9f28bf3d87a361cc8e2fd725b2e135e86059dc2c541b3 | 331 | 4 |                     page - The Authorization Server SHOULD display the                     authentication and consent UI consistent with a full User                     Agent page view. If the display |
| .venv/lib/python3.13/site-packages/oauthlib/oauth1/rfc5849/signature.py | 4498d1037d42d2e0adc31fe97afbd7c772b22b0244bb035e5319c5e6e576cdfe | 853 | 3 |      The "HMAC-SHA256" signature method uses the HMAC-SHA256 signature     algorithm as defined in `RFC4634`_::          digest = HMAC-SHA256 (key, text) |
| .venv/lib/python3.13/site-packages/pygments/console.py | 01a8035aac1e6b6c8159fd74282f69b4180ca4c8f12a9f3200102687e3503959 | 71 | 2 |  dark_colors = ["black", "red", "green", "yellow", "blue",                "magenta", "cyan", "gray"] light_colors = ["brightblack", "brightred", "brightgreen", "brightyellow", "brightblue",            |
| .venv/lib/python3.13/site-packages/pygments/style.py | 0a9c3d7420325b7fc90301515ce2579ad29be59c0edbfe4a4a696aeaae1f670e | 204 | 4 |     'ansiyellow': '7f7fe0',     'ansiblue': '00007f',     'ansimagenta': '7f007f',     'ansicyan': '007f7f',     'ansigray': 'e5e5e5', |
| .venv/lib/python3.13/site-packages/pygments/unistring.py | 6a5fbfac17a646e1af8a7b2b33a6ad36c1d3989e8351bc36e2ad8ed91bb57017 | 154 | 68 | Cf = '\xad\u0600-\u0605\u061c\u06dd\u070f\u08e2\u180e\u200b-\u200f\u202a-\u202e\u2060-\u2064\u2066-\u206f\ufeff\ufff9-\ufffb\U000110bd\U000110cd\U0001bca0-\U0001bca3\U0001d173-\U0001d17a\U000e0001\U00 |
| .venv/lib/python3.13/site-packages/pygments/filters/__init__.py | 074d0aa8f0908791345e1cda0caef841ad44e1f0d24e50fa6f43efaf5bfebc44 | 941 | 4 |         '\\varrho'               : '\U000003c1',         '\\sigma'                : '\U000003c3',         '\\tau'                  : '\U000003c4',         '\\upsilon'              : '\U000003c5',      |
| .venv/lib/python3.13/site-packages/pygments/lexers/c_like.py | 1531a9d7b76ce97dab0d9387ba9da11fa0449f780a2b89cb9bda7274d1219b41 | 739 | 3 |     variable_qualifiers = {'__device__', '__constant__', '__shared__',                            '__restrict__'}     vector_types = {'char1', 'uchar1', 'char2', 'uchar2', 'char3', 'uchar3',           |
| .venv/lib/python3.13/site-packages/pygments/lexers/graphics.py | b6617d34d00b9ef3e76b1f32c180b7a4b3a56b8e585eda7d500d07fb91224d06 | 795 | 22 |                 # Precise qualifiers                 'precise',                 # Memory qualifiers                 'coherent', 'volatile', 'restrict', 'readonly', 'writeonly',                 # State |
| .venv/lib/python3.13/site-packages/pygments/lexers/hdl.py | 30e5b186602e138122d02283aaa68e37b4fcb65e3781e6a772b358335dfa6745 | 467 | 11 |                 'small', 'specify', 'specparam', 'strength', 'string', 'strong0',                 'strong1', 'struct', 'table', 'task', 'tran', 'tranif0', 'tranif1',                 'type', 'typedef', |
| .venv/lib/python3.13/site-packages/pygments/lexers/_postgres_builtins.py | 3ea878cf444145b9d6eab090b5651dcd6089c4dcaaa49effd073a4b711c3c64e | 740 | 1 |     'timetz',     'tsquery',     'tsvector',     'txid_snapshot',     'uuid', |
| .venv/lib/python3.13/site-packages/pygments/lexers/_qlik_builtins.py | c6e272f5cf6e6435efea1f33e7cd8fe4faf1aa4c5367f9d2f203e5f4e0fd54df | 667 | 2 |     "lightgray",     "lightgreen",     "lightmagenta",     "lightred",     "magenta", |
| .venv/lib/python3.13/site-packages/pygments/lexers/phix.py | 859ab2721aa8e6c14c043112cc33d78350d81d07bff6c9f6f7851f6e38a16859 | 364 | 12 |         'cdCanvasGetImageRGB', 'cdCanvasGetSize', 'cdCanvasGetTextAlignment',         'cdCanvasGetTextSize', 'cdCanvasLine', 'cdCanvasMark',         'cdCanvasMarkSize', 'cdCanvasMultiLineVectorText',  |
| .venv/lib/python3.13/site-packages/pygments/lexers/_sourcemod_builtins.py | 1fc0052ec343744a7298858ea43c1b0c91823f5c3ec7ed604a5ccf0e2a0c178a | 1152 | 34 |     'TE_WriteFloat',     'TE_ReadFloat',     'TE_WriteVector',     'TE_ReadVector',     'TE_WriteAngles', |
| .venv/lib/python3.13/site-packages/pygments/lexers/erlang.py | 6d4d757951efa282f0995927ccde9791bd83324ec76de9ea74d9584b38538433 | 527 | 1 |         'list_to_float', 'list_to_integer', 'list_to_pid', 'list_to_tuple',         'load_module', 'localtime_to_universaltime', 'make_tuple', 'md5',         'md5_final', 'md5_update', 'memory', 'modu |
| .venv/lib/python3.13/site-packages/pygments/lexers/apdlexer.py | 66be7e8e08f10bc3cacd194479c95a9195cf1dc8bb14705982143ac308ae4fb0 | 594 | 1 |                "BFKDELE", "BFKLIST", "BFL", "BFLDELE", "BFLIST",                "BFLLIST", "BFSCALE", "BFTRAN", "BFUNIF", "BFV",                "BFVDELE", "BFVLIST", "BIOOPT", "BIOT", "BLC4", "BLC5",  |
| .venv/lib/python3.13/site-packages/pygments/lexers/configs.py | c16f2963449ae5ad74a6701e4cb19fe3c1e18b141355a81e2321c47f56983027 | 1434 | 5 |         "deny_info", "dns_children", "dns_defnames", "dns_nameservers",         "dns_testnames", "emulate_httpd_log", "err_html_text",         "fake_user_agent", "firewall_ip", "forwarded_for", "forwa |
| .venv/lib/python3.13/site-packages/pygments/lexers/mojo.py | f09455a1fb4dd44f96db0a06d0afb89fc3d05d350cf6263a4a5e6c59bdae18d8 | 708 | 1 |                         "map",                         "max",                         "memoryview",                         "min",                         "next", |
| .venv/lib/python3.13/site-packages/pygments/lexers/tablegen.py | d498de757618d7c04d898f49b4d18b3ad19f8b076e34366940b0464de43a8c0c | 178 | 1 |     ~~~~~~~~~~~~~~~~~~~~~~~~      Lexer for LLVM's TableGen DSL.      :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS. |
| .venv/lib/python3.13/site-packages/pygments/lexers/idl.py | adc8a15001a17ee1846925baa6016ae8dce9953fe9bf40da814a1e7e0e330269 | 285 | 4 |         'irotate', 'ir_filter', 'isa', 'isave', 'iscale',         'isetcurrent', 'isetproperty', 'ishft', 'isocontour',         'isosurface', 'isurface', 'itext', 'itranslate', 'ivector',         'ivo |
| .venv/lib/python3.13/site-packages/pygments/lexers/dsls.py | 1a71ca8462f91b1b11167a82efeeb93533d92ce65d9a796536b18ff3ac7f7d01 | 971 | 4 | """     pygments.lexers.dsls     ~~~~~~~~~~~~~~~~~~~~  |
| .venv/lib/python3.13/site-packages/pygments/lexers/solidity.py | 4e2c5f9f092ee187b38fa9cd9bcc556b0ec4755d6a80081dc1a85d4c53f44adf | 88 | 1 |                 'contract', 'do', 'else', 'external', 'false', 'for',                 'function', 'if', 'import', 'inherited', 'internal', 'is',                 'library', 'mapping', 'memory', 'modifi |
| .venv/lib/python3.13/site-packages/pygments/lexers/_scilab_builtins.py | a1960f0755cf748133de9208d75a450dee9ec6d451c96180ee9634e97f0a67cc | 3094 | 4 |     'getlookandfeel',     'getmd5',     'getmemory',     'getmodules',     'getos', |
| .venv/lib/python3.13/site-packages/pygments/lexers/_lilypond_builtins.py | 5d36c62f5cf5a0a328a962c492d1b7de3c7919d19323d0a978ee4d85e122e18d | 4933 | 6 |   "blackmensural-c2",   "blackmensural-c3",   "blackmensural-c4",   "blackmensural-c5",   "french", |
| .venv/lib/python3.13/site-packages/pygments/lexers/lisp.py | 107532d60e29cc4b183c4fb31a3dab0179b76004c4d63f5d0903abe7e24f4a45 | 3147 | 106 |             (r"#\\" + symbol, String.Char),              # vector             (r'#\(', Operator, 'body'),  |
| .venv/lib/python3.13/site-packages/pygments/lexers/mosel.py | 82345d79d840d634e3a18a0cd46a5aa2883f23da3b4d16d830793decdd535f08 | 448 | 1 |     'makesos2',     'maxlist',     'memoryuse',     'minlist',     'newmuid', |
| .venv/lib/python3.13/site-packages/pygments/lexers/_googlesql_builtins.py | 224ace93e4f6bf5cb36c6cd4104421e7f09fe2e0bf7262ffbae8700e96654ee8 | 919 | 1 |     'VALUE',     'VALUES',     'VECTOR',     'VIEW',     'VIEWS', |
| .venv/lib/python3.13/site-packages/pygments/lexers/_vbscript_builtins.py | 32a276001cb00f6d5a491b56619446eb80826c6b2d0b591fb221c6266673c62c | 280 | 1 |     'vbLongDate',     'vbLongTime',     'vbMagenta',     'vbMonday',     'vbMsgBoxHelpButton', |
| .venv/lib/python3.13/site-packages/pygments/lexers/_openedge_builtins.py | 4b3e23f7e08f5886b131afb67d9818eba8fb8a072ed686f5191d94b48f330248 | 2601 | 1 |     'DROP-TARGET',     'DS-CLOSE-CURSOR',     'DSLOG-MANAGER',     'DUMP',     'DYNAMIC', |
| .venv/lib/python3.13/site-packages/pygments/lexers/_luau_builtins.py | f880eb534e245157e35f0490ccc3295e631884db10c59555664f1cb800342e8d | 62 | 4 | 	'UDim', 	'UDim2', 	'Vector2', 	'Vector2int16', 	'Vector3', |
| .venv/lib/python3.13/site-packages/pygments/lexers/c_cpp.py | 0fb648b30687012946060a139709d2a934077fcfc9cafbd2b762f6ab55be17a8 | 415 | 1 |             (words(('inline', '_inline', '__inline', 'naked', 'restrict',                     'thread'), suffix=r'\b'), Keyword.Reserved),             # Vector intrinsics             (r'(__m(128i\|128d |
| .venv/lib/python3.13/site-packages/pygments/lexers/perl.py | f415e7dedc87300e3d36fcdb33d1367334821e3794edbbda3cb51ca19ae1cfee | 734 | 3 |         '\u23b4': '\u23b5', '\u2768': '\u2769', '\u276a': '\u276b',         '\u276c': '\u276d', '\u276e': '\u276f', '\u2770': '\u2771',         '\u2772': '\u2773', '\u2774': '\u2775', '\u27c3': '\u27c |
| .venv/lib/python3.13/site-packages/pygments/lexers/_julia_builtins.py | 37659d4b0e73808d9f8436adfe2e18795aaead14c2fcff31ef57b3d3448237a5 | 412 | 7 |     'AbstractUnitRange',     'AbstractVecOrMat',     'AbstractVector',     'Any',     'ArgumentError', |
| .venv/lib/python3.13/site-packages/pygments/lexers/typoscript.py | 981b9e3e255952800e44f2ac1f0af1e9f0568b2ddf008a86fb63baed098c8852 | 217 | 1 |              r'device\|ELSE\|END\|GLOBAL\|globalString\|globalVar\|hostname\|hour\|IP\|'              r'language\|loginUser\|loginuser\|minute\|month\|page\|PIDinRootline\|'              r'PIDupinRootline\|system\|tree |
| .venv/lib/python3.13/site-packages/pygments/lexers/automation.py | 43ad6aa27f04c297da90c87fd8c4b6136cd4513d7aac6dd434828f623213793b | 380 | 2 |              r'#Hotstring\|#IfWinActive\|#IfWinExist\|#IfWinNotActive\|'              r'#IfWinNotExist\|#IncludeAgain\|#Include\|#InstallKeybdHook\|'              r'#InstallMouseHook\|#KeyHistory\|#LTrim\|#MaxHo |
| .venv/lib/python3.13/site-packages/pygments/lexers/_php_builtins.py | 25de016698cc0c42cf8b8115a12c4ad7ef0115373adc753061f9b5acbac68f43 | 3326 | 6 |                       'ini_restore',                       'ini_set',                       'memory_get_peak_usage',                       'memory_get_usage',                       'php_ini_loaded_fil |
| .venv/lib/python3.13/site-packages/pygments/lexers/scripting.py | 79a6259032befdc0304dc0811cfe905c10b3f27e8ecdb87376445ed2e574c566 | 1617 | 21 |      lsl_keywords = r'\b(?:do\|else\|for\|if\|jump\|return\|while)\b'     lsl_types = r'\b(?:float\|integer\|key\|list\|quaternion\|rotation\|string\|vector)\b'     lsl_states = r'\b(?:(?:state)\s+\w+\|default)\b'  |
| .venv/lib/python3.13/site-packages/pygments/lexers/gdscript.py | 5acec92b1cb433423267fd6231f46f24fae2cc4c2678234b0e878c20568cf825 | 190 | 4 |             (r"((?<!\.)(self\|false\|true)\|(PI\|TAU\|NAN\|INF)" r")\b",              Name.Builtin.Pseudo),             (words(("bool", "int", "float", "String", "NodePath", "Vector2",                     " |
| .venv/lib/python3.13/site-packages/pygments/lexers/_stata_builtins.py | 1eaaebea3efbcd65377061a904fa21c1ec59722e37600e3fb15604e04d6c368c | 458 | 4 |     "mat_capp", "mat_order", "mat_put_rr", "mat_rapp", "mata",     "mata_clear", "mata_describe", "mata_drop", "mata_matdescribe",     "mata_matsave", "mata_matuse", "mata_memory", "mata_mlib",     "m |
| .venv/lib/python3.13/site-packages/pygments/lexers/resource.py | 8a813381692c0791c28e8cfce5736440f49dee7e642f44998ae3e424fd61ba74 | 84 | 1 |     version_added = '2.0'      _types = (':table', ':array', ':string', ':bin', ':import', ':intvector',               ':int', ':alias')  |
| .venv/lib/python3.13/site-packages/pygments/lexers/d.py | a623b2d0425e880c0f1ee822337815bf4cfb1cd877bb68194280944804916d8e | 260 | 1 |                 'template', 'this', 'throw', 'try', 'typeid', 'typeof',                 'union', 'unittest', 'version', 'volatile', 'while', 'with',                 '__gshared', '__traits', '__vector' |
| .venv/lib/python3.13/site-packages/pygments/lexers/other.py | 58b572a8fb2f9bda125c86d9c1b7f2265a12e871a0a055b99d54da535b90a53c | 42 | 1 |     GoodDataCLLexer, MaqlLexer from pygments.lexers.automation import AutoItLexer, AutohotkeyLexer from pygments.lexers.dsls import ProtoBufLexer, BroLexer, PuppetLexer, \     MscgenLexer, VGLLexer fr |
| .venv/lib/python3.13/site-packages/pygments/lexers/matlab.py | 17d28ee2aa302217cff2856109147313fd6caa0e339906ec0763591f5f773e23 | 3308 | 11 |                         "FunctionTestCase",                         "GetCharArray",                         "GetFullMatrix",                         "GetVariable",                         "GetWorkspac |
| .venv/lib/python3.13/site-packages/pygments/lexers/_vim_builtins.py | 6c0e261fcb7598f3d07c489408a12a44ed4ed2b2f60d41b4531d41b7c652bb41 | 1939 | 2 |         ('mh','mh'),         ('mis','mis'),         ('mkspellmem','mkspellmem'),         ('ml','ml'),         ('mls','mls'), |
| .venv/lib/python3.13/site-packages/pygments/lexers/freefem.py | 2c505093e9b5fa734282b97e5431f74309d55aeaef6fb5b6f62d3a2e84f6d3b0 | 894 | 3 |                 'meditff',                 'mem',                 'memory',                 'metric',                 'mode', |
| .venv/lib/python3.13/site-packages/pygments/lexers/teraterm.py | 722c33b5a816e43ae0da0af5ed0ca4ae1e86c0cb0acbb7b8c5d42c857f791b24 | 326 | 1 |                 r'bringupbox\|'                 # 'call' is handled separately.                 r'callmenu\|'                 r'changedir\|'                 r'checksum16\|' |
| .venv/lib/python3.13/site-packages/pygments/lexers/_cocoa_builtins.py | 29ad652c97bb25f5ad761a38205201f365fdc81beb6df1c20a6106fa97975e14 | 76 | 24 | """  COCOA_INTERFACES = {'AAAttribution', 'ABNewPersonViewController', 'ABPeoplePickerNavigationController', 'ABPersonViewController', 'ABUnknownPersonViewController', 'ACAccount', 'ACAccountCredentia |
| .venv/lib/python3.13/site-packages/pygments/lexers/ncl.py | cc9e9a8658ad8ade12d2905773b5aef7a3c1ef13a7e7d3307d1d87758e7f0bad | 895 | 20 |                 'wrf_user_intrp3d', 'wrf_user_latlon_to_ij', 'wrf_user_list_times',                 'wrf_user_ll_to_ij', 'wrf_user_unstagger', 'wrf_user_vert_interp',                 'wrf_vector', 'gs |
| .venv/lib/python3.13/site-packages/pygments/lexers/pddl.py | 324e3f07395138909dd3147828a4514ab6e3d05ecb2d07014639ac9ad5a6ac28 | 83 | 2 |             (words((                 ':requirements', ':types', ':constants',                 ':predicates', ':functions', ':action', ':agent',                 ':parameters', ':precondition', ':effect |
| .venv/lib/python3.13/site-packages/pygments/lexers/_asy_builtins.py | 71df4cd34607d7dc3964bedaaae7260b79f0a491934b4e14fb4d4d2f2e44dbfe | 1645 | 11 |     'variancebiased',     'vbox',     'vector',     'vectorfield',     'verbatim', |
| .venv/lib/python3.13/site-packages/pygments/lexers/igor.py | c1579f6d48dbddfb5a5b72c2286b57d4980b822638126468af98153a7f2f400f | 436 | 4 |         'FTPDownload', 'FTPUpload', 'FuncFit', 'FuncFitMD', 'GBLoadWave', 'GetAxis',         'GetCamera', 'GetFileFolderInfo', 'GetGizmo', 'GetLastUserMenuInfo',         'GetMarquee', 'GetMouse', 'Get |
| .venv/lib/python3.13/site-packages/pygments/lexers/forth.py | 64cb6c1dd35b9d2ff421d49895f0257d348f12bd0c12c468f9866b89036e7934 | 179 | 1 |              # *** Wordset LOCAL-EXT              r'locals\\|\|'              # *** Wordset MEMORY              r'allocate\|free\|resize\|'              # *** Wordset SEARCH |
| .venv/lib/python3.13/site-packages/pygments/lexers/css.py | 24dd51058b1e7be8eba475ab4a684ddd329ce1390e067fbf0441a98130b372a1 | 603 | 2 |     'cornflowerblue', 'cornsilk', 'crimson', 'cyan', 'darkblue', 'darkcyan',     'darkgoldenrod', 'darkgray', 'darkgreen', 'darkgrey', 'darkkhaki',     'darkmagenta', 'darkolivegreen', 'darkorange', ' |
| .venv/lib/python3.13/site-packages/pygments/lexers/asm.py | c66d98e66713fac177a10bda8abe125acf44593ca7768694a12b03cb9bfab212 | 1052 | 13 |     alignQual = r'(align\(\d+\))'     widthQual = r'(width\((\d+\|all)\))'     allocQual = r'(alloc\(agent\))'     # Instruction Modifiers     roundingMod = (r'((_ftz)?(_up\|_down\|_zero\|_near))') |
| .venv/lib/python3.13/site-packages/pygments/lexers/roboconf.py | 1db62e2b90aa99075deb74916369e57b4d6befea7b9a29744a7a1ab980e610e6 | 82 | 1 |     ~~~~~~~~~~~~~~~~~~~~~~~~      Lexers for Roboconf DSL.      :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS. |
| .venv/lib/python3.13/site-packages/pygments/lexers/_lasso_builtins.py | f2ad606ecacc25e69e521c4860a85a3b10bd8ff07e341a6afd7163d997b8d57d | 5327 | 26 |         'map',         'memberstream',         'memory_session_driver_impl_entry',         'memory_session_driver_impl',         'memory_session_driver', |
| .venv/lib/python3.13/site-packages/pygments/lexers/pascal.py | 376b510239579d3c60800cf3936b4e380573782d8c073ad7cbdeff1d09799f8e | 645 | 4 |             'findresourcehinstance', 'flush', 'frac', 'freemem',             'get8087cw', 'getdir', 'getlasterror', 'getmem',             'getmemorymanager', 'getmodulefilename', 'getvariantmanager',  |
| .venv/lib/python3.13/site-packages/pygments/lexers/webassembly.py | ce070ca2eccb6b071b785afac3f48ebc6a1447af19b6a9e7b1b39c58456578b9 | 120 | 3 | keywords = (     'module', 'import', 'func', 'funcref', 'start', 'param', 'local', 'type',     'result', 'export', 'memory', 'global', 'mut', 'data', 'table', 'elem',     'if', 'then', 'else', 'end',  |
| .venv/lib/python3.13/site-packages/pygments/lexers/installers.py | 6479628ade0fc73d6d60a3888ca9035c8e5d8d3929cd850c5483d1d71bd4acbf | 353 | 1 |     ~~~~~~~~~~~~~~~~~~~~~~~~~~      Lexers for installer/packager DSLs and formats.      :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS. |
| .venv/lib/python3.13/site-packages/pygments/lexers/business.py | 951b5e90e25fb0391bd760066eecf5d3e1baece26b54980206d8a14d0f3f6a86 | 626 | 5 |                 'LAST', 'LEADING', 'LEFT', 'LENGTH', 'LIMIT', 'LIMITS', 'LINAGE',                 'LINAGE-COUNTER', 'LINE', 'LINES', 'LOCALE', 'LOCK',                 'LOWLIGHT', 'MANUAL', 'MEMORY', ' |
| .venv/lib/python3.13/site-packages/pygments/lexers/tcl.py | 94af7b8eee278a492dfa818ecc87b214433df32ab8759488f2e12662cab447a7 | 149 | 1 |         'lassign', 'lindex', 'linsert', 'list', 'llength', 'load', 'loadTk',         'lrange', 'lrepeat', 'lreplace', 'lreverse', 'lsearch', 'lset', 'lsort',         'mathfunc', 'mathop', 'memory', 'm |
| .venv/lib/python3.13/site-packages/pygments/lexers/basic.py | aa955ee61f056bb349a3512284dfb847f519a473ba9b2d92b2091bf8192d90ab | 657 | 1 |             (r'\b(Local\|Global\|Const\|Field)\b', Keyword.Declaration),             (words((                 'TNullMethodException', 'TNullFunctionException',                 'TNullObjectException', 'TA |
| .venv/lib/python3.13/site-packages/pygments/lexers/_stan_builtins.py | 7708b586594cfcdb1a0aff9a5c9cbb9448b9ed7e478798120fdeda090c93f4a3 | 649 | 16 |     'positive_ordered',     'real',     'row_vector',     'simplex',     'unit_vector', |
| .venv/lib/python3.13/site-packages/pygments/lexers/eiffel.py | e7275820415c81c328123e0194adf5859d1a25bf0e5f445d02fb8235d971c2ac | 69 | 1 |              bygroups(Operator.Word, Whitespace, Operator.Word)),             (words((                 'across', 'agent', 'alias', 'all', 'as', 'assign', 'attached',                 'attribute', 'chec |
| .venv/lib/python3.13/site-packages/pygments/lexers/modula2.py | 36da57051a1409e1df7e5801dfd2e49d2902c2104704abf612bfe98a78d5b0d1 | 1580 | 2 |       Embedding a Dialect Option within a source file      A dialect option may be embedded in a source file in form of a dialect |
| .venv/lib/python3.13/site-packages/pygments/lexers/actionscript.py | 2419e009ee548584ffd1d2c3da3ecf9cf3b4c51449866ca912e43e0b98a7f296 | 244 | 1 |                 'IOError', 'IOErrorEvent', 'JointStyle', 'Key', 'Keyboard', 'KeyboardEvent', 'KeyLocation',                 'LineScaleMode', 'Loader', 'LoaderContext', 'LoaderInfo', 'LoadVars', 'Local |
| .venv/lib/python3.13/site-packages/pygments/lexers/_cl_builtins.py | 9107942326633f8917d1fae42020dc2b10584022eacc80d76b9595e5c7af843a | 232 | 12 |     'assoc-if-not', 'atan', 'atanh', 'atom', 'bit', 'bit-and', 'bit-andc1',     'bit-andc2', 'bit-eqv', 'bit-ior', 'bit-nand', 'bit-nor', 'bit-not',     'bit-orc1', 'bit-orc2', 'bit-vector-p', 'bit-xo |
| .venv/lib/python3.13/site-packages/pygments/lexers/_mql_builtins.py | c9b4508e56fb0ae974b03b2d9f3c49977874a92e887aab2bf35d5faabc72ba65 | 1172 | 6 |     'WindowsTotal',     'Year',     'ZeroMemory',     'iAC',     'iADX', |
| .venv/lib/python3.13/site-packages/pygments/lexers/rego.py | 471e46a616e4b6bf688e0e436ea972c47790aaab45ee0f16fa8174ae69680cd6 | 58 | 2 |     """     name = 'Rego'     url = 'https://www.openpolicyagent.org/docs/latest/policy-language/'     filenames = ['*.rego']     aliases = ['rego'] |
| .venv/lib/python3.13/site-packages/pygments/lexers/python.py | 5997bb7c1007299fc1c4f83ca88536e941a193cab0518c84349dc8c8f5bae267 | 1202 | 7 |                 'hasattr', 'hash', 'hex', 'id', 'input', 'int', 'isinstance',                 'issubclass', 'iter', 'len', 'list', 'locals', 'map', 'max',                 'memoryview', 'min', 'next',  |
| .venv/lib/python3.13/site-packages/pygments/lexers/factor.py | bab678127e2e28508b5dd1245cb5a0f446141461d04d30c2c0d5edcaafa78289 | 364 | 7 |         'string?'), suffix=r'(\s+)')      builtin_vectors = words((         '1vector', '<vector>', '>vector', '?push', 'vector', 'vector?'),         suffix=r'(\s+)') |
| .venv/lib/python3.13/site-packages/pygments/lexers/_usd_builtins.py | 73d85b535730a8150214884d7eefc3a1bf32c2fd6b94f862f70d8e4e3de447cb | 113 | 3 |     "uint4",     "usdaType",     "vector3d",     "vector3f",     "vector3h", |
| .venv/lib/python3.13/site-packages/pygments/lexers/dylan.py | ef367511b1d65de547a930f7e80ab290aaa8ddf86e221e2c33ec2173151a1ff6 | 280 | 1 |         'third-setter', 'truncate', 'truncate/', 'type-error-expected-type',         'type-error-value', 'type-for-copy', 'type-union', 'union', 'values',         'vector', 'zero?'}      valid_name =  |
| .venv/lib/python3.13/site-packages/pygments/lexers/jvm.py | 62dd62437428757458fb1fc750e19e761cae0411e7e63607f88f0dccecc74e51 | 1803 | 10 |             # DefaultBehaviour Reflection             (r'(asText\|become\!\|derive\|freeze\!\|frozen\?\|in\?\|is\?\|kind\?\|'              r'mimic\!\|mimics\|mimics\?\|prependMimic\!\|removeAllMimics\!\|'          |
| .venv/lib/python3.13/site-packages/pygments/lexers/promql.py | 9fed2fa3ea3cf996aca8fdd56b8ba3b39eb651f6522df645f91cd3ef5c8bd139 | 177 | 1 |                 "time",                 "timestamp",                 "vector",                 "year",             ), |
| .venv/lib/python3.13/site-packages/pygments/lexers/sql.py | 5921babceb11f3b10413049079f3ff67b4dab941bf063a8c1d41663da48e563e | 1110 | 3 |              # Misc keywords             (words(('actual', 'Memory Usage', 'Disk Usage', 'Memory', 'Buckets', 'Batches',                     'originally', 'row', 'rows', 'Hits', 'Misses',              |
| .venv/lib/python3.13/site-packages/pygments/lexers/_mapping.py | f5fbfbc5839400eafa2f37dd152e0c0db3eeefca38390407fb69ec2356cd65fe | 603 | 12 |     'AgdaLexer': ('pygments.lexers.haskell', 'Agda', ('agda',), ('*.agda',), ('text/x-agda',)),     'AheuiLexer': ('pygments.lexers.esoteric', 'Aheui', ('aheui',), ('*.aheui',), ()),     'AlloyLexer': |
| .venv/lib/python3.13/site-packages/pygments/lexers/praat.py | e1414afa76c2e96919061260710a841aaabd0a8709916ec0993fce2506e35b39 | 304 | 2 |         'DurationTier', 'EEG', 'ERP', 'ERPTier', 'EditCostsTable', 'EditDistanceTable',         'Eigen', 'Excitation', 'Excitations', 'ExperimentMFC', 'FFNet', 'FeatureWeights',         'FileInMemory' |
| .venv/lib/python3.13/site-packages/pygments/lexers/q.py | 59015487726ba4ada3f95196fd8b67dee2797eb50d9902059cbb4c546440f432 | 188 | 1 |             (r"[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}",              Number.Hex),             # Byte Vectors             (r"0x[0-9a-fA-F]+", Number.Hex),             # Floats |
| .venv/lib/python3.13/site-packages/pygments/lexers/_mysql_builtins.py | cb4900599540b34cf6753149255e36399a482e046777c4f7cd294116ffa0fe80 | 1336 | 1 |     'medium',     'member',     'memory',     'merge',     'message_text', |
| .venv/lib/python3.13/site-packages/pygments/lexers/rita.py | 323d50371c75b16019602d36930f298957246a2c3d07432a42d888883147d290 | 43 | 1 |     """     name = 'Rita'     url = 'https://github.com/zaibacu/rita-dsl'     filenames = ['*.rita']     aliases = ['rita'] |
| .venv/lib/python3.13/site-packages/pygments/lexers/haskell.py | 318afbe3e3c00bc9062515fe7599af66c1d373b6b6bbac854b6075f4b7c30fb8 | 867 | 1 |                 'let', 'proof', 'of', 'then', 'static', 'where', '_', 'with',                 'pattern',  'term',  'syntax', 'prefix',                 'postulate', 'parameters', 'record', 'dsl', 'impo |
| .venv/lib/python3.13/site-packages/pygments/lexers/fortran.py | d4f139753c5fe037fa2d479715c98db727975ac0bcb5288ae5d6303c720979e4 | 213 | 2 |                 'FUNCTION', 'GENERIC', 'IF', 'IMAGES', 'IMPLICIT',                 'IMPORT', 'IMPURE', 'INCLUDE', 'INQUIRE', 'INTENT', 'INTERFACE',                 'INTRINSIC', 'IS', 'LOCK', 'MEMORY', |
| .venv/lib/python3.13/site-packages/pygments/lexers/modeling.py | 33b079f1b181f99c1dd4498fc4aaad46f83b4e0342c9e9b7315507bf4fc7d924 | 367 | 2 |              r'smooth\|spatialDistribution\|sqrt\|StateSelect\|String\|subSample\|'              r'sum\|superSample\|symmetric\|tan\|tanh\|terminal\|terminate\|time\|'              r'transpose\|vector\|zeros)\b', Nam |
| .venv/lib/python3.13/site-packages/pygments/lexers/javascript.py | 4c62902d2ac2a6b08a7e12cb180abfd0439dbeabc9297f6939d2a8eed091bab4 | 1592 | 1 |              r'Error_InvalidDatabase\|Error_InvalidPassword\|'              r'Error_InvalidUsername\|Error_ModuleNotFound\|'              r'Error_NoError\|Error_NoPermission\|Error_OutOfMemory\|'             |
| .venv/lib/python3.13/site-packages/pygments/lexers/foxpro.py | 081916eb616e89bcf7c9fc9e95909a10ef0619d1495acb9186ac2db12781c0b3 | 428 | 2 |              r'LENC\|LIKE\|LIKEC\|LINENO\|LOADPICTURE\|LOCFILE\|LOCK\|LOG\|'              r'LOG10\|LOOKUP\|LOWER\|LTRIM\|LUPDATE\|MAKETRANSACTABLE\|MAX\|'              r'MCOL\|MDOWN\|MDX\|MDY\|MEMLINES\|MEMORY\|MENU\|MESSA |
| .venv/lib/python3.13/site-packages/pygments/lexers/fantom.py | 249d77f8dc32903fa22044a7bb309e7c261e4033bde5c1cc240f136ac1788070 | 252 | 1 |             (r'`', Punctuation, 'insideUri'),                # Opening accent             (r'\b(true\|false\|null)\b', Keyword.Constant),    # Bool & null             (r'(?:(\w+)(::))?(\w+)(<\\|)(.*?)(\\| |
| .venv/lib/python3.13/site-packages/pygments/lexers/ride.py | 90259dc6e4773dc9558b8c22034b94c78098105c2e4eaa0cb0a8e1496e17df28 | 139 | 1 |      typesName = (         'Unit', 'Int', 'Boolean', 'ByteVector', 'String', 'Address', 'Alias',         'Transfer', 'AssetPair', 'DataEntry', 'Order', 'Transaction',         'GenesisTransaction', 'Pa |
| .venv/lib/python3.13/site-packages/pygments/lexers/_scheme_builtins.py | da136d24e2663f6d6552c8a4a6a309da00262d3dd1c27fca11eaa15f00a381f9 | 1610 | 118 |     "bit-position",     "bit-set*!",     "bitvector",     "bitvector->list",     "bitvector-bit-clear?", |
| .venv/lib/python3.13/site-packages/pygments/lexers/macaulay2.py | ce457ebf18d061ad098fd4c67c53f588c8294d9e00a50b8000874954659bda2b | 1815 | 14 |     "SheafMap",     "SheafOfRings",     "SparseMonomialVectorExpression",     "SparseVectorExpression",     "String", |
| .venv/lib/python3.13/site-packages/pygments/lexers/urbi.py | 6a334fef4349837da336714366c2efafffb84d3a121aa446905c803c824b7c25 | 146 | 1 |             (r'(true\|false\|nil\|void)\b', Keyword.Constant),             (words((                 'Barrier', 'Binary', 'Boolean', 'CallMessage', 'Channel', 'Code',                 'Comparable', 'Contai |
| .venv/lib/python3.13/site-packages/pygments/lexers/haxe.py | 5870b2fe7ad71e77cb2137db769dc98b796a414e0702c4d4a57b0b0a9dbfe2c9 | 936 | 14 |         'meta': [             include('spaces'),             (r'@', Name.Decorator, ('meta-body', 'meta-ident', 'meta-colon')),         ],  |
| .venv/lib/python3.13/site-packages/pygments/lexers/_tsql_builtins.py | 3e2d918535dc2c4de0948f68c4d87256c38c9fe7caff54d1c49f84b183f92dc2 | 1004 | 1 |     'smalldatetime',     'smallint',     'smallmoney',     'sql_variant',     'table', |
| .venv/lib/python3.13/site-packages/pygments/lexers/wgsl.py | f6281df5dce2c4622035ec2bbaff663e7166b3e73d05a86465c082ad9ca0bfce | 407 | 9 |           vec2           vec3           vec4           """.split(), suffix=r'\b'), Name.Builtin)  |
| .venv/lib/python3.13/site-packages/pygments/formatters/terminal.py | 27f17f7455f047d2c75af6ad2039f0a91609ca35664a8d59c7c2bf5c387a4b23 | 128 | 4 |     Keyword:            ('blue',    'brightblue'),     Keyword.Type:       ('cyan',        'brightcyan'),     Operator.Word:      ('magenta',      'brightmagenta'),     Name.Builtin:       ('cyan',    |
| .venv/lib/python3.13/site-packages/pygments/formatters/html.py | 16b1c9ebd1549621323d8d334df69bd02d603dfecb5ec2a0791961c249e2a88b | 996 | 1 |      def _lookup_ctag(self, token):         entry = ctags.TagEntry()         if self._ctags.find(entry, token.encode(), 0):             return entry['file'].decode(), entry['lineNumber'] |
| .venv/lib/python3.13/site-packages/pygments/formatters/irc.py | 47426cd13616c92948db213db16ead3787785fec7793d666b9db228c63e72e65 | 155 | 5 |     Keyword:            ('blue',    'brightblue'),     Keyword.Type:       ('cyan',        'brightcyan'),     Operator.Word:      ('magenta',      'brightcyan'),     Name.Builtin:       ('cyan',       |
| .venv/lib/python3.13/site-packages/pygments/styles/xcode.py | 3db41dce019a0386bd2c05358b9f1a958f643382059505f98c743039899ffd19 | 54 | 1 |         Comment.Preproc:        '#633820',          String:                 '#C41A16',         String.Char:            '#2300CE',  |
| .venv/lib/python3.13/site-packages/pygments/styles/tango.py | 3b6c1c338847b94d58b74ef533d08aec93ed8a2482ab2c6d4fdb5b890202576f | 144 | 2 |     http://tango.freedesktop.org/Tango_Icon_Theme_Guidelines      Butter:     #fce94f     #edd400     #c4a000     Orange:     #fcaf3e     #f57900     #ce5c00     Chocolate:  #e9b96e     #c17d11     #8 |
| .venv/lib/python3.13/site-packages/pygments/styles/paraiso_dark.py | 264ae0e2750a215345f14e1f3cd57f4a6abf83d3456dbf5e894ae36295604198 | 125 | 2 | RED = "#ef6155" ORANGE = "#f99b15" YELLOW = "#fec418" GREEN = "#48b685" AQUA = "#5bc4bf" |
| .venv/lib/python3.13/site-packages/pygments/styles/solarized.py | aaea482c5667d365aca67005e523d86fe5bc82ea3dc6752d8dbd4778bc375e01 | 145 | 5 |         Comment.Hashbang:    colors['base01'],         Comment.Multiline:   colors['base01'],         Comment.Preproc:     'noitalic ' + colors['magenta'],         Comment.PreprocFile: 'noitalic ' + c |
| .venv/lib/python3.13/site-packages/pygments/styles/lilypond.py | 63a7e9fec10bfb31129b101a331ce3b6b2a4f7472e0c2fc36a535d0bcc23d27c | 63 | 1 |         Token.Comment: "italic #A3AAB2",         Token.String: "#AB0909",         Token.String.Escape: "#C46C6C",         Token.String.Symbol: "noinherit",         Token.Pitch: "", #"#911520", |
| .venv/lib/python3.13/site-packages/pygments/styles/paraiso_light.py | 33137deb8644a737b7c05d2cb3e8a069ad88ec4ebce0c1def99ab4ad63c7df0a | 125 | 2 | RED = "#ef6155" ORANGE = "#f99b15" YELLOW = "#fec418" GREEN = "#48b685" AQUA = "#5bc4bf" |
| .venv/lib/python3.13/site-packages/pygments/styles/lightbulb.py | 63cbb5a9dbe51df06a2368c97b1e794a4bd56ad568fc58c453313a87e5fb9bed | 111 | 4 |     "blue_1": "#73D0FF",     "gray_1": "#7e8aa1",     "gray_2": "#3c4354",     "gray_3": "#6e7681",     "red_1": "#f88f7f", |
| .venv/lib/python3.13/site-packages/mako/cache.py | 900e8528697935e4c19d24dc9e1a0f91269e27425e62917a18cf2acc46464adb | 240 | 1 |        caching strategies.   Mako includes a backend that works with        the Beaker caching system.   Beaker itself then supports        a number of backends (i.e. file, memory, memcached, etc.)    |
| .venv/lib/python3.13/site-packages/mako/template.py | 567e672e8058f98cd24092af44f1466f87e23f266bc80e50fbc996badbf46fd0 | 712 | 5 |     :param uri: string URI or other identifier for this template.      If not provided, the ``uri`` is generated from the filesystem      path, or from the in-memory identity of a non-file-based       |
| .venv/lib/python3.13/site-packages/mako/ext/pygmentplugin.py | 4e7a490f241e5934c61d9ada303a70f050773cdcdb99785a65c8f2201b9dca2d | 151 | 1 |     mako_lexer = MakoLexer()     python_lexer = Python3Lexer()     if filename.startswith("memory:") or language == "mako":         return lambda string: highlight(             string, mako_lexer, pyg |
| .venv/lib/python3.13/site-packages/mako/testing/fixtures.py | 9c4a7bc13bac7fb1349f743e047256dacfedd6fc74281f69a1a750d419882731 | 120 | 2 |         )      def _do_memory_test(         self,         source, |
| .venv/lib/python3.13/site-packages/onnxruntime/__init__.py | 1cc26ff9b30da507b4758d3d191070548979fc9370b3c9d127f9b348ebfaf160 | 346 | 2 |         OrtAllocatorType,  # noqa: F401         OrtArenaCfg,  # noqa: F401         OrtMemoryInfo,  # noqa: F401         OrtMemType,  # noqa: F401         OrtSparseFormat,  # noqa: F401 |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/symbolic_shape_infer.py | 5306c1ba685d285b35acd35e3124c2400bad0b27dd65f312e26bb689dd445f3e | 3094 | 20 |             "RemovePadding": self._infer_RemovePadding,             "RestorePadding": self._infer_RestorePadding,             "RotaryEmbedding": self._infer_RotaryEmbedding,             "SimplifiedLay |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/operator_type_usage_processors.py | 9e33e7d1567e9267aad28b4c6599ba85ee878694e9cb95ab2e3435e67ff4ce4e | 654 | 1 |     # ML Op notes.     #  CastMap: Switch on value type of input map type, and output type     #  DictVectorizer: Templatized on key+value of input so need to handle like OneHot with custom processor  |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/types.py | 65bf1669af8025cf781c95931740f17cdace55559c85b68833090538462d6748 | 86 | 2 |             elem_type = sequence_type.ElemType()  # TypeInfo             elem_type_str = FbsTypeInfo.typeinfo_to_str(elem_type)             # TODO: Decide if we need to wrap the type in a std::vector. |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/RuntimeOptimizationRecord.py | 9383580a2fc1660fcab29d475909c867d14dda8cfc2a7c7c6111998773f79b41 | 106 | 7 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(10))         if o != 0:             a = self._tab.Vector(o)             return self._tab.String(a + flatbuffers.number_types |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/DeprecatedKernelCreateInfos.py | 1152d036336b214a86996fde4aa8f26235d24cd41dd0c0d12d2f43c5b90b3351 | 121 | 14 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))         if o != 0:             a = self._tab.Vector(o)             return self._tab.Get(flatbuffers.number_types.Uint32F |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/NodesToOptimizeIndices.py | 912b540e3b76db7a7f6a40fa6ea436843d09138205247b720dbccc948764982b | 161 | 7 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))         if o != 0:             a = self._tab.Vector(o)             return self._tab.Get(flatbuffers.number_types.Uint32F |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/Attribute.py | 01152d7eb462c7a492727187602ae4846677db8f3495d3567f179004e17edf94 | 338 | 32 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(20))         if o != 0:             a = self._tab.Vector(o)             return self._tab.Get(flatbuffers.number_types.Float3 |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/DeprecatedSessionState.py | e799014012fbe7de1511f6ed99caf2f0c263f2950e8b8836026a8e9ea8366a49 | 97 | 6 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/Checkpoint.py | 097abb2972ca172eda88de8cc9e42b91db4099ba4ec5fd6ed3c2d7c2f9ead0ec | 126 | 6 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(8))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/OptimizerGroup.py | f6711ed86d69b37e763041096ea27c543082608f2e0f20166c84192e7adf9c43 | 118 | 6 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(10))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type( |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/PropertyBag.py | 1b08c5faadfab986afd3d85641d261e6ea22edc5eb6e5bb82f549e6f1dcd1cef | 153 | 18 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/RuntimeOptimizations.py | 18b9673fa41177169dfe3c8a6c4ff79b85157bd380c07dc6cf744ee36ef02858 | 80 | 7 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/OpIdKernelTypeStrArgsEntry.py | 44e854d35c62987fb0c30265e72e539058c06f94d1c8d29b5840e4038d663381 | 92 | 6 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/Graph.py | c1305274847455693a90b9445688c403fd70768fe36e0ffac8277d1f2e8ebc74 | 321 | 42 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/ParameterOptimizerState.py | 8dacfbd095bf019addbc9a3d83f4658b3865283d81c06190528ce596339872b2 | 92 | 6 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/SparseTensor.py | 78b5695691cfdac8d34497f4dcbe97d3994a273ef92c979d7822205aacf7ba91 | 115 | 7 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(8))         if o != 0:             a = self._tab.Vector(o)             return self._tab.Get(flatbuffers.number_types.Int64Fl |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/RuntimeOptimizationRecordContainerEntry.py | d2c0fe10456793f70a19c31c49415464fcd32793703ca08d60cbd02cc1e6d597 | 92 | 7 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/KernelTypeStrResolver.py | 841d1183dd99668aef5287b6335b2d6a0bbdb4ab47be201458736c92faaa22d0 | 79 | 6 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/Model.py | dc81559f18e8f3fd4c910e8f58eb305bcf1df8221036637ae8d7e40e4adaf8ec | 224 | 12 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/Tensor.py | 1b3d0bf9ac30e0e2ad81a2bafadcf1705443ab9fa0cf035f0536036ccf20e5e2 | 204 | 20 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(8))         if o != 0:             a = self._tab.Vector(o)             return self._tab.Get(flatbuffers.number_types.Int64Fl |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/NodeEdge.py | d982bdedc50faf7172750d51ba50c0a38a893007a9640df341b5e50f9f64e253 | 127 | 12 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/Shape.py | ea6e0838faf80ceececa1012d616cc570104ac7077442f7981334746174c6f72 | 79 | 6 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/ModuleState.py | 5e6eeb48c5be4893c71162e8601ee0fc59cff799e7d62d41eca4bd55d6c5eb4e | 142 | 12 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/Node.py | 20a5ddb00fb84a51f23933837adbdef95fed61ed3d2d107a7176f82b5ffb3c48 | 318 | 31 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(20))         if o != 0:             a = self._tab.Vector(o)             return self._tab.String(a + flatbuffers.number_types |
| .venv/lib/python3.13/site-packages/onnxruntime/tools/ort_format_model/ort_flatbuffers_py/fbs/KernelTypeStrArgsEntry.py | 91ecddf655af14f6d6323cbd2e3e0e316d6f72ba2d646a382c307ad3ef61180a | 92 | 6 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py | 46ff5aa2fe2b472840e7a0f64b05b86b88d4e395030bde532316828938c9056d | 1155 | 38 |                 input_dict[n] = v._get_c_value()             result = sess.run_with_ort_values(input_dict, output_names, run_options)             if not isinstance(result, C.OrtValueVector):           |
| .venv/lib/python3.13/site-packages/onnxruntime/quantization/matmul_bnb4_quantizer.py | 56f022568fb3cc009d7fbb546466b2fd937e6bf0c4481c83558924fbf338d519 | 240 | 1 |         if len(fpweight.shape) != 2:             raise ValueError("Current bnb4 block quantization only supports 2D tensors!")         # need to copy since the transposed weight still has the original |
| .venv/lib/python3.13/site-packages/onnxruntime/quantization/onnx_quantizer.py | 1695c08aca76501ade6a6246df85116ce3091262cce9fdef41b1dcd9aed99d70 | 1009 | 1 |                 quantized_input_names.append(quantized_value.q_name)                 continue             # adding this for case embed_layernorm.py has optional segment_embedding             if not no |
| .venv/lib/python3.13/site-packages/onnxruntime/quantization/quantize.py | 3709d571f3a826717e1f4c14043d544ff78bf079743ee24cb8a08e03e9bb7bfc | 944 | 1 |                     Default is None. If set to an integer, during calculation of the min-max range of the tensors                     it will load at max value number of outputs before computing and m |
| .venv/lib/python3.13/site-packages/onnxruntime/quantization/matmul_nbits_quantizer.py | 6868fe2cac8a93af754bd3b5006ee57a4d4b712b713a109afc463b6602143e0f | 1537 | 17 |   class GPTQWeightOnlyQuantConfig(WeightOnlyQuantConfig):     def __init__(         self, |
| .venv/lib/python3.13/site-packages/onnxruntime/quantization/shape_inference.py | f362c34d8eb6364496109d8a0064175681bc479ae4ad202fb04b08e058817678 | 193 | 1 |                     if has_external_data(input_model):                         raise ValueError(                             "ModelProto has external data not loaded into memory, ORT cannot create ses |
| .venv/lib/python3.13/site-packages/onnxruntime/quantization/quant_utils.py | b768055fd059f69a3b2b2972eefb541a37704c2655e7f34d3f50b924eb882e17 | 1022 | 2 |         key_value_list.append(key_value)      TrtTable.TrtTableStartDictVector(builder, len(key_value_list))     for key_value in key_value_list:         builder.PrependUOffsetTRelative(key_value) |
| .venv/lib/python3.13/site-packages/onnxruntime/quantization/operators/embed_layernorm.py | 686ab6cb0e19b63be00b9fed78023f7c09f5f14120af54a126b5d3eedd7c2464 | 122 | 15 |         [0] input_ids (int32)         [1] segment_ids (int32)         [2] word_embedding (float32)         [3] position_embedding (float32)         [4] segment_embedding (float32) |
| .venv/lib/python3.13/site-packages/onnxruntime/quantization/CalTableFlatBuffers/TrtTable.py | ce303e58577f203918948f8f98040099f44278de2dc5323137b01da2a2055ba2 | 91 | 6 |         o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))         if o != 0:             x = self._tab.Vector(o)             x += flatbuffers.number_types.UOffsetTFlags.py_type(j |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/fusion_options.py | b3cde1f0a913b7c578fe5010b7ce58a48967c78e3eea045cb95b746fcbee368e | 341 | 6 |         self.enable_layer_norm = True         self.enable_attention = True         self.enable_rotary_embeddings = True          # Use MultiHeadAttention instead of Attention operator. The difference: |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/fusion_rotary_attention.py | 0752cc5c74d5110bf6d9d8e69b3eac17eae1a7b2a0507cf452323e88ceebe042 | 1592 | 61 | class FusionRotaryAttention(FusionAttention):     """     Fuse Attention subgraph with rotary positional embeddings into one MultiHeadAttention node.     """  |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/onnx_model_bert_tf.py | f705bc910c2399d15a84abf8053be718cd4716084bf1cb5c898587d150db5d61 | 589 | 45 |         return initializers      def find_segment_ids(self, segment_embedding, input_ids):         input_name_to_nodes = self.input_name_to_nodes()         if segment_embedding not in input_name_to_no |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/machine_info.py | 610a983ddaa8d04af3429e4561e215fdc2325d3715b36565afdfb0206e77b231 | 229 | 10 |     nvmlDeviceGetCount,     nvmlDeviceGetHandleByIndex,     nvmlDeviceGetMemoryInfo,     nvmlDeviceGetName,     nvmlInit, |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/metrics.py | f96c28503271887115f5a693ff86581c2c362ad3223d41a0fa7bffe17adb8a8e | 164 | 3 |         latency_ms_mean: float \| None = 0.0,         throughput_qps: float \| None = 0.0,         max_memory_usage_GB: float \| None = 0.0,     ):         super().__init__() |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/fusion_gpt_attention.py | 9a4f942888e8bb3aed90c97703e2dd2ee2dceb094eab101d6c4da0462618c293 | 547 | 9 |   class FusionGptAttentionPastBase(Fusion):     """Base class for GPT Attention Fusion with past state"""  |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/benchmark.py | faace39abbe2b8a15dac6fb99542abd4380d5eacce6f77ec5798beca6c5fab06 | 946 | 3 |                         output_buffer_max_sizes = [max_last_state_size]                         for i in range(len(ort_outputs)):                             if i == 2 and MODELS[model_name][3] == "gp |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/onnx_model_gpt2.py | 5c3187b27ebd767670bcfde48c6dea501e1028350b5867815e0fd8789dacb1a7 | 102 | 10 |  import onnx from fusion_gpt_attention import FusionGptAttention from fusion_gpt_attention_megatron import FusionGptAttentionMegatron from fusion_gpt_attention_no_past import FusionGptAttentionNoPast |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/fusion_gpt_attention_no_past.py | 0e4f25e9a4fbae5e2c83fe7cc8c3beb8536a39d0a703a6c195af1df2de2d48a7 | 261 | 7 |   class FusionGptAttentionNoPast(Fusion):     """     Fuse GPT-2 Attention without past state into one Attention node. |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/fusion_reshape.py | 26bc95ae7564eb6dbe31693c11834b973cfc0230354821d6fd397d4ab7270e68 | 174 | 3 |                     [2, 0, 0, 0, 0],                     output_name_to_node,                 )  # GPT2 exported by PyTorch 1.4 with opset_version=11                 if path2 is None:                  |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/benchmark_helper.py | 642bd98bcb981a9be8bfac2d1171a41f5871ea7c9afe538067a85c3ef9a47e5e | 648 | 47 |  def allocateOutputBuffers(output_buffers, output_buffer_max_sizes, device):  # noqa: N802     # Allocate output tensors with the largest test size needed. So the allocated memory can be reused     #  |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/onnx_model_phi.py | 71b6a69eca1d56a7ae801baf7e8384c029df66a1c52ae42723804b9953216557 | 930 | 23 | class ProcessRotCacheFunc:     def __call__(self, x):         # half rotary embedding         assert len(x.shape) == 2         if x.shape[1] == 32: |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/convert_generation.py | d7c63159504b8f82cbb22fa6453d9e014c9a0d57e26250f6b36a9679cc7ba99d | 3548 | 151 | # ------------------------------------------------------------------------- """ This converts GPT2 or T5 model to onnx with beam search operator.  Example 1: convert gpt2 model with beam search: |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/huggingface_models.py | 7f156fea1f63aeae00029521e23df1efecf6a341abec92f5899d813c73f4b022 | 75 | 2 |     "AutoModelForSequenceClassification",     "AutoModelForQuestionAnswering",     "AutoModelForCausalLM", ]  |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/float16.py | 9dfd1f1ee6c2e2a7ab35e18b617b9396762b52c797e6c0b1f0beff137dbbf7c4 | 502 | 2 |     "CastMap",     "CategoryMapper",     "DictVectorizer",     "FeatureVectorizer",     "Imputer", |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/onnx_model_bert_keras.py | 8d77db7a7110b6246238df74cd3b6aaa2101ecdecc283442a10011017b755b1c | 475 | 26 |      def preprocess(self):         self.process_embedding()         self.fuse_mask()         self.skip_reshape() |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/fusion_base.py | 15b838aed7b2c3f20f0686f91a0657636b0fc35b3dd83d104b939f4ab7ecd014 | 142 | 1 |      def add_nodes_to_remove(self, nodes: list[NodeProto]):         # Some nodes are shared between paths (e.g. rotary embedding nodes in the Q and K paths).         # When path A is fused, its shared |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/fusion_embedlayer.py | 42d1da6196aa2cca6336e5d49b696afc2e731d9feb009ac10d395b8065452a05 | 811 | 165 | class FusionEmbedLayerNoMask(Fusion):     """     Fuse embedding layer into one node (EmbedLayerNormalization).     It supports the following model types: BERT, DistilBert, ALBert.     """ |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/onnx_model_bert.py | 8df6d46d33f736edda0a015e3d87cd99c7a211088dd1140af32e6d2bc295a153 | 489 | 8 | from fusion_quickgelu import FusionQuickGelu from fusion_reshape import FusionReshape from fusion_rotary_attention import FusionRotaryEmbeddings from fusion_shape import FusionShape from fusion_simpli |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/onnx_exporter.py | abcf5378a98324fa54b057c425690539ffd45e0764035b7718bcb562da142c6c | 720 | 16 | from transformers import AutoConfig, AutoFeatureExtractor, AutoTokenizer, LxmertConfig, TransfoXLConfig  from onnxruntime.transformers.models.gpt2.gpt2_helper import (     PRETRAINED_GPT2_MODELS,      |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/optimizer.py | c2a7a51eb352f961cb19d7e7efeb3b9d2fe559a0e183acc5bd40b2b6eec92c52 | 624 | 15 | from onnx_model_clip import ClipOnnxModel from onnx_model_conformer import ConformerOnnxModel from onnx_model_gpt2 import Gpt2OnnxModel from onnx_model_mmdit import MmditOnnxModel from onnx_model_phi  |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/fusion_qordered_layernorm.py | 467d5123c319e18e5c6ad7d5cb98b53aa8a80b128f9b3665e8356e3c98d23cce | 123 | 1 |         upstream_dequantize_node_children = self.model.get_children(upstream_dequantize_node, input_name_to_nodes)          # In GPT2, the DQ node will be feeding a residual downstream Add and hence,  |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/fusion_attention_clip.py | 227a5d57e9d2137d6224b7f982917d62630fb1bd4cd46cf38a8adc151e29fc5d | 336 | 1 |             root_input = node_before_layer_norm.output[0]         else:             # Deal with the first attention after the embedding layer.             for i in [0, 1]:                 node_before_ |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/large_model_exporter.py | ea17befa95bbdf47d7f4dfb845db82e4c5f3a41f402b19d5925fdba5ba45ada5 | 396 | 6 |  """ Export LLM to onnx """  |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/profiler.py | c8255aa2aaa4dfb07481228bf11424a8d3b8619dc74cf44ce6a0f3b51ca9e107 | 435 | 7 |         type=int,         default=1,         help="past sequence length for gpt2",     )  |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/fusion_gpt_attention_megatron.py | 1db0e80d75d886acb8b0415426f69fe4bcb953abbaba90a0f09500d5defc0901 | 356 | 7 |  import numpy as np from fusion_gpt_attention import FusionGptAttentionPastBase from onnx import helper from onnx_model import OnnxModel |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/convert_tf_models_to_pytorch.py | b5847fc2624005183d0501bd6a3de83b78f40014aee328b8fd2836cf1e95785e | 206 | 10 |         "https://storage.googleapis.com/albert_models/albert_large_v1.tar.gz",     ),     "gpt-2-117M": (         "gpt2",         "GPT2Config", |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/onnx_model_t5.py | 5874dcab54ed077c8690e2c3b2ec942b1ed33b611dc570b3c36f71c249389a4d | 986 | 1 |         # The log_max is the value of the following formula:         #   math.log(max_distance / (relative_attention_num_buckets // (4 if is_bidirectional else 2)))         # See https://github.com/hu |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/phi2/convert_to_onnx.py | 2ab6f6d00b9e91390b2b913dfb57c67ee9e4123e454834b31af942a187a1fc37 | 583 | 17 | from onnx_model import OnnxModel from packaging import version from transformers import AutoConfig, AutoModelForCausalLM  from onnxruntime import __version__ as ort_version |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/phi2/inference_example.py | 644567d29fe57b31065d0aa29a91c3fb8f9c2753bf97d0668d3bdef4f46ced5f | 415 | 1 |                 ).to(torch.int32)              # Set logits to zeros for next inference run and re-use memory buffer             if outputs["logits"].shape[1] != 1:                 outputs["logits"] = |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/t5/t5_decoder.py | 1bd3d552645993ba05b79377c6bd21218d259cb96fa9af959906c3a96da48477 | 438 | 8 |             decoder_start_token_id if decoder_start_token_id is not None else self.config.decoder_start_token_id         )         self.tie_word_embeddings = (             self.config.tie_word_embeddi |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/bert/eval_squad.py | 2738696764077e0e4428bd337a7271a73a9c59a1579dafae06ba0ae66150fd81 | 330 | 2 |          print(ort_model.config)         if sequence_length > ort_model.config.max_position_embeddings:             raise RuntimeError("sequence length should not be larger than {ort_model.config.max_ |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/stable_diffusion/diffusion_models.py | 4aa5af1ae65f4af43fe91924c90739bc12b73b9ae5e05a3a89d21e38a67bc921 | 1319 | 42 |         return self.name().split("/")[-1].replace("stable-diffusion", "sd")      def clip_embedding_dim(self):         # TODO: can we read from config instead         if self.version in ("1.4", "1.5") |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/stable_diffusion/engine_builder_torch.py | 363586bb73e814808c745cf54f6dccde1014cd7faca6299959d4eaf692331349 | 109 | 1 |                 compile_config = self.compile_config[model_name]                 if model_name in ["unet", "unetxl"]:                     model.to(memory_format=torch.channels_last)                 en |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/stable_diffusion/engine_builder_tensorrt.py | 1a07461aa64ad7dd37f9f62d4375fc59b0dcc76f02968e900b2a7bcfffd64703 | 396 | 24 |         self.engine = engine_from_bytes(bytes_from_path(self.engine_path))      def activate(self, reuse_device_memory=None):         if reuse_device_memory:             self.context = self.engine.cre |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/stable_diffusion/benchmark.py | 4a8a4ef7e4b34d1278ff9a63e9310b47434c3a63de9bbc1b6b80ddd199ee8d59 | 1524 | 188 | # import torch before onnxruntime so that onnxruntime uses the cuDNN in the torch package. import torch from benchmark_helper import measure_memory  SD_MODELS = { |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/stable_diffusion/pipeline_stable_diffusion.py | d311a66c934b85052d5fae92fe8a9af3a201036e2150c70de5504ce680e24cc2 | 832 | 33 |             if self.engine_type == EngineType.TORCH:                 outputs = self.backend.engines[encoder](text_input_ids)                 text_embeddings = outputs[0]                 if output_hidd |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/stable_diffusion/engine_builder_ort_cuda.py | 31a113189c1ee4cd2f37e1075ba4d38c43bf394c683d467713211057fa31eb9d | 388 | 3 |                  model.rename_graph_output(                     "last_hidden_state" if model_name == "clip" else "text_embeds", "text_embeddings"                 )                 model.prune_graph( |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/stable_diffusion/demo_utils.py | e166dc377e4de53f18ea71e2a989b23b753142853a2f0d2220476adff478a270 | 779 | 7 |      if engine_type == EngineType.TRT:         max_device_memory = max(base.backend.max_device_memory(), (refiner or base).backend.max_device_memory())         _, shared_device_memory = cudart.cudaMal |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/stable_diffusion/benchmark_controlnet.py | 88aebf9e23d035a79c4ca3635a656f6cc830ec38f5ed9a7d76c3ec8f40c72b12 | 427 | 8 | def compile_torch(pipeline, use_nhwc=False):     if use_nhwc:         pipeline.unet.to(memory_format=torch.channels_last)      pipeline.unet = torch.compile(pipeline.unet, mode="reduce-overhead", full |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/longformer/benchmark_longformer.py | 6b961e8dc05ea4bb9e7726fa148acf9e384d9740f1fbd075ae85b113d98c11ee | 822 | 57 | # -------------------------------------------------------------------------- # # This script run benchmark of latency or peak memory usage of Longformer model inference. # Please run convert_to_onnx.p |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/gpt2/convert_to_onnx.py | 0e921157448eafe3ce8f53f5d5df382db299a035c209d5be3bcd7a5935670ad1 | 559 | 24 | # -------------------------------------------------------------------------- """ This converts GPT2 model to onnx. Examples: (1) Convert pretrained model 'gpt2' to ONNX    python convert_to_onnx.py -m |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/gpt2/gpt2_tester.py | c58c02b13dd7fa932f765afbee53b1538494afe89ff40f31c682d5a7413a9997 | 502 | 25 | # license information. # -------------------------------------------------------------------------- # This script helps evaluation of GPT-2 model. import logging import math |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/gpt2/parity_check_helper.py | 14504c2fbc3437c475603fd0b27faf02c79211d734e8f1ad73d012ca22516ec0 | 147 | 12 | import torch from benchmark_helper import create_onnxruntime_session from gpt2_helper import Gpt2Helper from onnx import TensorProto, numpy_helper  |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/gpt2/gpt2_parity.py | d5fc5e1ba1fe4f7760d47af99354c89a810b5dbbdc9cceeba396606f75bb9a40 | 514 | 7 | # --------------------------------------------------------------------------  # This script uses different configurations in mixed precision conversion for GPT-2 model, and # measures the inference la |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/gpt2/benchmark_gpt2.py | 2159c8d1969c55b2d009c2c30248db59a86a3e8829300b970b10dcd9489644ab | 414 | 21 | # license information. # -------------------------------------------------------------------------- # This script benchmarks gpt2 model with past state. # For gpt2 model without past state, use benchm |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/gpt2/gpt2_helper.py | 85b9e214eb772a980b444a0f425ec36c2ba104319cf3e69db91bd44cca90471b | 1032 | 82 | # license information. # -------------------------------------------------------------------------- # This script helps onnx conversion and validation for GPT2 model with past state. import logging im |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/sam2/sam2_utils.py | 0fcd9919c85215e79cdaf848c7cd6e7e19fd326ab594ff63202e8979315ae4d0 | 148 | 2 |         "image_features_0": [batch_size, 32, height // 4, width // 4],         "image_features_1": [batch_size, 64, height // 8, width // 8],         "image_embeddings": [batch_size, 256, height // 16 |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/sam2/benchmark_sam2.py | ee0ad5947692b3a99767ba5d758d0b4d20f17d23b2605ae2ac537cf1d7fa45e1 | 639 | 4 |                 "image_features_0": torch.rand(1, 32, 256, 256, dtype=dtype, device=self.device),                 "image_features_1": torch.rand(1, 64, 128, 128, dtype=dtype, device=self.device),      |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/sam2/sam2_image_onnx_predictor.py | 7feb0499bf8375ac3f1144fbce6338cdb7f750c36eb35685835db257e66c9687 | 280 | 8 |     ) -> None:         """         Uses SAM-2 to compute the image embedding for an image, and then allow mask prediction given prompts.          Arguments: |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/sam2/image_decoder.py | 37811921edc67e122c56d7f3e390e9697ca5211429e25ff63641bf3df53819e1 | 273 | 15 |         image_features_0: torch.Tensor,         image_features_1: torch.Tensor,         image_embeddings: torch.Tensor,         point_coords: torch.Tensor,         point_labels: torch.Tensor, |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/sam2/image_encoder.py | 5249aa77f18bcc1b7e0732070bac567c6cecdea36bad4d906b96b47d2d6d1629 | 237 | 14 |             image_features_0: image features of shape [B, 32, H/4, W/4] - high resolution features of level 0             image_features_1: image features of shape [B, 64, H/8, W/8] - high resolution  |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/sam2/prompt_encoder.py | abcf97fd7f5abbfc5ce6cf41d044d71eaa4fb43845fb41ef37b3d42f46556671 | 190 | 49 |             has_input_masks (torch.Tensor): [L]. 1.0 if input_masks is used, 0.0 otherwise.         Returns:             sparse_embeddings (torch.Tensor): [L, P+1, 256], embedding for points and boxes |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/sam2/mask_decoder.py | a4f969c138d63cea4a4f4f8028d957983ff74fac9377ad217c4b6079586db3fe | 209 | 46 |         image_features_0: torch.Tensor,         image_features_1: torch.Tensor,         image_embeddings: torch.Tensor,         image_pe: torch.Tensor,         sparse_embeddings: torch.Tensor, |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/llama/llama_parity.py | c8c16a2ba8ad7a25aad0ecf155daa58e41153dcc60f173a526bad29aea3f3767 | 343 | 5 | def get_sequence_lengths(args: argparse.Namespace, config: AutoConfig):     past_sequence_length, curr_sequence_length = (8, 1) if args.use_past_kv else (0, 8)     max_sequence_length = config.max_pos |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/llama/convert_to_onnx.py | 99b38bb1b184017558c9c597c9e08d1eb85c674b8215788728a0f0c29e397138 | 1099 | 15 | from optimizer import optimize_model from packaging import version from transformers import AutoConfig, AutoModelForCausalLM  from onnxruntime import __version__ as ort_version |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/llama/benchmark_all.py | a9c3eddeb897f4dc7d97c958824c5423dcd5550ab355033dfc79f7cb6cbdf09f | 489 | 15 |     entries = []     batch_size, sequence_length, step = None, None, None     latency_s, latency_ms, throughput, memory = None, None, None, None      batch_pattern = "Batch Size: " |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/llama/benchmark.py | 892597f3cbac9151c650a612829f3c72dad1ed76c675ce03289fe26e9bc5db5c | 704 | 11 | import psutil import torch from benchmark_helper import measure_memory, setup_logger from dist_settings import get_rank, get_size from llama_inputs import ( |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/llama/llama_torch.py | 7163fcc7518d07631c9cf0d26c0109ba1b8762e5d99cf97c4ab21c732abf6e4e | 48 | 2 | import torch from dist_settings import barrier, get_rank, get_size from transformers import AutoConfig, AutoModelForCausalLM  logger = logging.getLogger("") |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/llama/llama_inputs.py | 79931e42126f61c3882da3991c3ebc1ab31c105aa8ef9d19e45c3fb74dcb386e | 505 | 3 |  # Add IO bindings for execution providers using OrtValue # Use when you need to run inference once or twice to save memory def add_io_bindings_as_ortvalues(     model: InferenceSession, |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/llama/benchmark_e2e.py | 4da543b764f7a8d7e46d382d9c464b3860e512591468d93a1e38230b45a458dc | 609 | 8 | # $ huggingface-cli login # # 3) Accept Meta's license in Hugging Face to access the models at https://huggingface.co/meta-llama/ # # 4) Install the latest ONNX Runtime version |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/whisper/whisper_jump_times.py | 72a9a2ed368175f8e5a6ca35c6aa4e1c748ae3b876485a5afd5c2eb94927e368 | 478 | 3 |     """     Calculate jump times from text_indices and time_indices where     text_indices and time_indices are both 1d vectors     """     TOKENS_PER_SECOND = 50.0  # noqa: N806 |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/whisper/convert_to_onnx.py | 084d6d0268f0447e3f96e447ae536fe3b94ef6f7fc68e911d5c69dc8908353bc | 544 | 5 |      quant_args.add_argument(         "--quantize_embedding_layer",         required=False,         action="store_true", |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/whisper/benchmark_all.py | 2b6ca6e72f93afe3a8f31cdc4318ce7bd3d44e6b8216224bd68bf422ab9f5602 | 527 | 15 |     feat_ext_latency_s, feat_ext_throughput_s = None, None     token_length, latency_s, per_token_latency_s, per_token_latency_ms = None, None, None, None     throughput, memory = None, None      # De |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/whisper/benchmark.py | 0008e582b1b1129a2442bb495e211a5bd8a3b2ae7e8f9923811dc08f0950abbe | 611 | 6 | import torch import whisper from benchmark_helper import measure_memory, setup_logger from onnxruntime_extensions import get_library_path from optimum.onnxruntime import ORTModelForSpeechSeq2Seq |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/whisper/whisper_inputs.py | 06629c906ad3217567b90042b96871de8b99b1465f6c700803890dda0eac679c | 381 | 1 |      ort_inputs = {}     model_inputs = list(map(lambda i: i.name, model.get_inputs()))  # noqa: C417     use_buffer_sharing = "cache_indirection" in model_inputs     for name in model_inputs: |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/whisper/whisper_helper.py | c50b2e2e96cfa39687928c716513970e042eb8937e9183948c118cfd5ae68ea1 | 484 | 1 |             else:                 name_or_path = model_name_or_path             model = whisper.load_model(name_or_path, device, download_root=cache_dir, in_memory=True)          # Set PyTorch model p |
| .venv/lib/python3.13/site-packages/onnxruntime/transformers/models/whisper/whisper_decoder.py | 260ec2b995d0410680e582698f72ba81ef16125814e8524d85648f38faf6137e | 466 | 1 |          # Run forward pass         # NOTE: There is a bug with openai-whisper==20240930 with the introduction of SDPA.         # In the Whisper codebase, the following line         # |
| .venv/lib/python3.13/site-packages/pycparser/ply/yacc.py | 79ab520e444b811afa5f7fa1a0393f49042fd3ae51d0174bd8aedf439e028153 | 3495 | 1 | # This implementation supports both SLR and LALR(1) parsing.  LALR(1) # support was originally implemented by Elias Ioup (ezioup@alumni.uchicago.edu), # using the algorithm found in Aho, Sethi, and Ul |
| .venv/lib/python3.13/site-packages/duckduckgo_search/cli.py | 6836d0d4e46ab1ae74f960350d23572b15adbf285ceef6a7a48fcf22b216ac7b | 372 | 2 |     3: "yellow",     4: "blue",     5: "magenta",     6: "cyan",     7: "bright_black", |
| .venv/lib/python3.13/site-packages/distlib/locators.py | a0178066916e3d0498d3d3203672df4061805d7bd53bde8116967228cb8ae2d3 | 1296 | 1 |     def get_page(self, url):         """         Get the HTML for an URL, possibly from an in-memory cache.          XXX TODO Note: this cache is never actually cleared. It's assumed that |
| .venv/lib/python3.13/site-packages/distlib/scripts.py | 42fa7be84f49737220c98b9b9e9a88f5f4bb7ac78639ee058e97952aa2adf48c | 448 | 1 | # new version. If we try to fetch a wrapper *after* that rename, the finder # machinery will be confused as the package is no longer available at the # location where it was imported from. So we load  |
| .venv/lib/python3.13/site-packages/typer/rich_utils.py | 62814237fc314c92dac51833b3b1cef917ca04f6f5b91f3426daf24812c9cb12 | 747 | 2 | STYLE_OPTION = "bold cyan" STYLE_SWITCH = "bold green" STYLE_NEGATIVE_OPTION = "bold magenta" STYLE_NEGATIVE_SWITCH = "bold red" STYLE_METAVAR = "bold yellow" |
| .venv/lib/python3.13/site-packages/typer/cli.py | c7e9a770ef4c866a0c2324952be88429a9c977b841287d449a914761d311822e | 317 | 1 |             state.file = file_path         else:             if not re.fullmatch(r"[a-zA-Z_]\w*(\.[a-zA-Z_]\w*)*", path_or_module):                 typer.echo(                     f"Not a valid file o |
| .venv/lib/python3.13/site-packages/typer/colors.py | 7b8da3f2e079db484ba57e42ff47e247738ea0814c6e13b700366fbfa865015f | 21 | 4 | YELLOW = "yellow" BLUE = "blue" MAGENTA = "magenta" CYAN = "cyan" WHITE = "white" |
| .venv/lib/python3.13/site-packages/docutils/nodes.py | a6ccb4cc8ae8ef7e06b24ecf188a96ab1d00c7fe400749811c2d09e0a61db87a | 2302 | 3 |         """Return list of nodes following `self`.          For looping, Node.findall() is faster and more memory efficient.         """         # traverse() may be eventually removed: |
| .venv/lib/python3.13/site-packages/docutils/parsers/rst/languages/lt.py | 3c7ceb4003fe64071ba02c9cd63bc723997408c427adb044676f39316255cbdc | 110 | 1 |       'rubrika': 'rubric',       'epigrafas': 'epigraph',       'pagridiniai-momentai': 'highlights',       'atitraukta-citata': 'pull-quote',       'sudėtinis-darinys': 'compound', |
| .venv/lib/python3.13/site-packages/docutils/parsers/rst/languages/sk.py | 1d2745c14ea3f6b6528645f218f05cef8f53ad4501eed052cfe6b0d1fe14033b | 97 | 1 |       'obsah': 'contents',       '\xe8as\x9d': 'sectnum',       '\xe8as\x9d-\xe8\xedslovanie': 'sectnum',       'cie\xbeov\xe9-pozn\xe1mky': 'target-notes',       'header (translation required)': 'hea |
| .venv/lib/python3.13/site-packages/docutils/writers/manpage.py | 444a55cc34445e32c9f0285c069cdb9375aff0c278e50589b8f44b07bb399edf | 1215 | 1 |         if self._line_block == 1:             # TODO: separate inline blocks from previous paragraphs             # see http://hg.intevation.org/mercurial/crew/rev/9c142ed9c405             # self.body |
| .venv/lib/python3.13/site-packages/docutils/writers/_html_base.py | a50a9139cd5b04cc3fa33a93ed3f2336d90787b17b11673165401b2c322f32b6 | 1888 | 1 |      def prepare_svg(self, node, imagedata, size_declaration):         # Edit `imagedata` for embedding as SVG image.         # Use ElementTree to add node attributes.         # ET also removes commen |
| .venv/lib/python3.13/site-packages/docutils/writers/odf_odt/__init__.py | b96fd6e85ff331d6dca849a8e2cc1fa2ed9e964e171be4a166eb2780fd5a712e | 3462 | 1 |         self.write_zip_str(zfile, 'content.xml', content)         s1 = self.create_manifest()         self.write_zip_str(zfile, 'META-INF/manifest.xml', s1)         s1 = self.create_meta()         sel |
| .venv/lib/python3.13/site-packages/docutils/utils/math/latex2mathml.py | 10bc0019a620e24c7613bfc013fad2492645203e1030857cb0f0084363ec7551 | 1253 | 2 |     # name:    fences     'matrix':  ('', ''),     'smallmatrix':  ('', ''),  # smaller, see begin_environment()!     'pmatrix': ('(', ')'),     'bmatrix': ('[', ']'), |
| .venv/lib/python3.13/site-packages/docutils/utils/math/unichar2tex.py | 43582fa94196a6b02331fa467ee8c0bb895d8c97afa051b69a8338e925b2e965 | 809 | 4 | 0x3c2: '\\varsigma ', 0x3c3: '\\sigma ', 0x3c4: '\\tau ', 0x3c5: '\\upsilon ', 0x3c6: '\\varphi ', |
| .venv/lib/python3.13/site-packages/docutils/utils/math/tex2unichar.py | fc0d8aedaa7aa3a71bd4b63da8262db1f3fece4e5e7aefc7bba2c897a8fb2e70 | 731 | 4 |     'rho': '\u03c1',  # ρ GREEK SMALL LETTER RHO     'sigma': '\u03c3',  # σ GREEK SMALL LETTER SIGMA     'tau': '\u03c4',  # τ GREEK SMALL LETTER TAU     'theta': '\u03b8',  # θ GREEK SMALL LETTER TH |
| .venv/lib/python3.13/site-packages/docutils/utils/math/math2html.py | 55f67571e16634abb8caf17bda3e31b201ff723b4e91e09ebcf0b7518c387a74 | 3166 | 1 |         'eqnarray': ['r', 'c', 'l'],         'gathered': ['l', 'l'],         'smallmatrix': ['c', 'c'],     }  |
| .venv/lib/python3.13/site-packages/docutils/utils/math/mathalphabet2unichar.py | 6ec8166c4d3d6c8c977cc13e4f20a6b3ed1f7ac595a315cc12b41555e60ea12a | 893 | 3 |     'α': '\U0001d6c2',  # 𝛂 MATHEMATICAL BOLD SMALL ALPHA     'β': '\U0001d6c3',  # 𝛃 MATHEMATICAL BOLD SMALL BETA     'γ': '\U0001d6c4',  # 𝛄 MATHEMATICAL BOLD SMALL GAMMA     'δ': '\U0001d6c5',  # 𝛅 |
| .venv/lib/python3.13/site-packages/grpc/_channel.py | 0701355e58d0864abd314605803224de32c8ab851cdff1a8012c9fd61d574855 | 2253 | 3 | _LOGGER = logging.getLogger(__name__)  _USER_AGENT = "grpc-python/{}".format(_grpcio_metadata.__version__)  _EMPTY_FLAGS = 0 |
| .venv/lib/python3.13/site-packages/grpc/__init__.py | 45437564829736046a3846946ea2893f6b03a67ec2d7009ca26a4342c4bf5240 | 2349 | 4 |         """Cancels the RPC.          Idempotent and has no effect if the RPC has already terminated.         """         raise NotImplementedError() |
| .venv/lib/python3.13/site-packages/grpc/beta/interfaces.py | 9ad427be6ec1836bb931065fdbf9e6c54c4a14200d0f0ed550e1c7bc4edc0613 | 164 | 2 |          This method may only be called while the server is not serving RPCs (i.e. it         is not idempotent).         """         raise NotImplementedError() |
| .venv/lib/python3.13/site-packages/grpc/framework/interfaces/face/face.py | 386c80a5d8ec67c045f6736afb6b1de965ddf5b3e96ef8f88ef5eb19d26efa76 | 1085 | 1 |         """Cancels the RPC.          Idempotent and has no effect if the RPC has already terminated.         """         raise NotImplementedError() |
| .venv/lib/python3.13/site-packages/grpc/aio/_base_server.py | fdb04d180cba7de070c84e1a22ec23295742cb6c106298813ad160dab5da67ef | 386 | 2 |         """Starts this Server.          This method may only be called once. (i.e. it is not idempotent).         """  |
| .venv/lib/python3.13/site-packages/grpc/aio/_call.py | 37dadbbeef3ed01feb57b46d86d4a5a7e9d96a40e8b211e0a6d3a8cc4b95aad5 | 765 | 1 |         """Signal peer that client is done writing.          This method is idempotent.         """         self._raise_for_different_style(_APIStyle.READER_WRITER) |
| .venv/lib/python3.13/site-packages/grpc/aio/_channel.py | 275a29a6943fce4ca1613aa1d1cc68f39b57d78c1d922dea71ca75045494cddd | 628 | 5 | from ._utils import _timeout_to_deadline  _USER_AGENT = "grpc-python-asyncio/{}".format(_grpcio_metadata.__version__)  if sys.version_info[1] < 7: |
| .venv/lib/python3.13/site-packages/grpc/aio/_base_channel.py | c15c04949ef76df4d39180bd27a3598c2abeab6304bd338b49b3ac78d3f3afc9 | 365 | 1 |         all existing RPCs are cancelled immediately.          This method is idempotent.         """  |
| .venv/lib/python3.13/site-packages/grpc/aio/_interceptor.py | 997cf48afa4e0646c1a4c432c489c79850aa566d47ad85f4191ab8219c160854 | 1179 | 1 |         """Signal peer that client is done writing.          This method is idempotent.         """         # If no queue was created it means that requests |
| .venv/lib/python3.13/site-packages/grpc/aio/_server.py | ffbbf6f96f765b5020d4b20daf10840feeb8ee702ab8615429b8069ca374ebfb | 240 | 2 |         """Starts this Server.          This method may only be called once. (i.e. it is not idempotent).         """         await self._server.start() |
| .venv/lib/python3.13/site-packages/grpc/aio/_base_call.py | 4c71571b4a342129f8d09af0d2c365705cdfa1b0fc52b8e08dd74c5ad83c6490 | 258 | 3 |         """Cancels the RPC.          Idempotent and has no effect if the RPC has already terminated.          Returns: |
| .venv/lib/python3.13/site-packages/mpmath/function_docs.py | 8383cff27e882d798770bc80e74b312ba4e6a7f678fe944dfb00c4ad4f03d62e | 10202 | 10 |         -\frac{1}{3^{1/3}\Gamma\left(\frac{1}{3}\right)}.  Other common ways of defining the Ai-function include integrals such as  |
| .venv/lib/python3.13/site-packages/mpmath/ctx_mp_python.py | de89585a8e259354a743403f21a675f35aaa1bcbb9a7119ab7fbfe2f842d9f76 | 1150 | 1 |         The elements are automatically converted to mpmath numbers.          With ``conjugate=True``, the elements in the second vector         will be conjugated:  |
| .venv/lib/python3.13/site-packages/mpmath/__init__.py | b241584d2c1fc0304b0a1015ea923749d7b0800411dd406dcab7c82bf25d9fe8 | 469 | 2 | lu = mp.lu qr = mp.qr unitvector = mp.unitvector inverse = mp.inverse residual = mp.residual |
| .venv/lib/python3.13/site-packages/mpmath/ctx_mp.py | 777af8b7bc4736a485b66aac03d06dab5369cb759333ea5c336fe3782c840b16 | 1340 | 5 |     def hypot(ctx, x, y):         r"""         Computes the Euclidean norm of the vector `(x, y)`, equal         to `\sqrt{x^2 + y^2}`. Both `x` and `y` must be real."""         x = ctx.convert(x) |
| .venv/lib/python3.13/site-packages/mpmath/identification.py | eda31d9e044069e2ff31a7c350d6e61089464129251c367ca663c5b7e38b824c | 845 | 5 | def pslq(ctx, x, tol=None, maxcoeff=1000, maxsteps=100, verbose=False):     r"""     Given a vector of real numbers `x = [x_0, x_1, ..., x_n]`, ``pslq(x)``     uses the PSLQ algorithm to find a list o |
| .venv/lib/python3.13/site-packages/mpmath/libmp/libelefun.py | 8e80593f814e7713df89e5aca352cfb52afa747c9da46fcb42217f6d841858c8 | 1429 | 1 |     mag_cancelled = cancelled[2]+cancelled[3]     # Just redo the sum exactly if necessary (could be smarter     # and avoid memory allocation when a or b is precisely 1     # and the other is tiny... |
| .venv/lib/python3.13/site-packages/mpmath/libmp/libmpf.py | be93f490d56449c6c2568668809e166ad97823b09ed1de1dcc75637d57b9eeca | 1415 | 1 |     With prec=0, no rounding is performed. Note that this can     produce a very large mantissa (potentially too large to fit     in memory) if exponents are far apart.     """     ssign, sman, sexp,  |
| .venv/lib/python3.13/site-packages/mpmath/tests/test_eigen_symmetric.py | bf456298289c214da8c0048330168ffadfb7d2eabea5772c825b7de4a06d34ee | 358 | 2 |     if verbose:         print("eigenvalues:\n", D)         print("eigenvectors:\n", Q)      NC = mp.mnorm(C) |
| .venv/lib/python3.13/site-packages/mpmath/tests/test_matrices.py | ab2038325d82bcdbd6d37e25cc1d351bac1580dafb52b819aa1db090c5eda733 | 254 | 2 |     assert mnorm(A,inf) == 4     assert mnorm(A,'F') == sqrt(20)     # vector norms     assert norm(-3) == 3     x = [1, -2, 7, -12] |
| .venv/lib/python3.13/site-packages/mpmath/functions/rszeta.py | cae515a788a52320e65f21375930710c38f07c424dca92676cf4bec4f1f91e8c | 1404 | 6 |     c1 = ctx.mag(40*(L+2))     xc2 = ctx.mag(68*(L+2)*xA)     xc4 = ctx.mag(xB1*a*math.sqrt(ctx.pi))-1     for k in range(0,L):         xc3 = xc2 - k*xc4+ctx.mag(ctx.fac(k+0.5))/2. |
| .venv/lib/python3.13/site-packages/mpmath/calculus/inverselaplace.py | e7ea67f0dfedd0fb600535e2c6c5d9e31c6b8a12b6279818b157d329f0f1e200 | 974 | 4 |     def calc_laplace_parameter(self, t, **kwargs):         r"""         Determine the vector of Laplace parameter values needed for an         algorithm, this will depend on the choice of algorithm (d |
| .venv/lib/python3.13/site-packages/mpmath/calculus/optimization.py | 6ca9d285712504e9953883a515e92c0ec602a7d7d84a66302a65c3b74cf6e8c3 | 1103 | 5 |     Calculate the Jacobian matrix of a function at the point x0.      This is the first derivative of a vectorial function:          f : R^m -> R^n with m >= n |
| .venv/lib/python3.13/site-packages/mpmath/calculus/odes.py | 81a1e2c3b2098ec38d35301aea2cc53d9a66720f6ec93a7c3142e719dcd3206a | 289 | 11 |         y_n'(x) = F_n(x, [y_0(x), y_1(x), \ldots, y_n(x)])      The derivatives are specified by the vector-valued function     *F* that evaluates     `[y_0', \ldots, y_n'] = F(x, [y_0, \ldots, y_n])` |
| .venv/lib/python3.13/site-packages/mpmath/matrices/matrices.py | a3bf04abad841d09f172c4742c1a160c419110ea0de0bda20ccd6addd42bc34a | 1006 | 19 | import warnings  # TODO: interpret list as vectors (for multiplication)  rowsep = '\n' |
| .venv/lib/python3.13/site-packages/mpmath/matrices/linalg.py | d380b78a3ccc1689bba1be5f5c10837f23cf768dc121ba08784f31d80eafa85d | 791 | 7 | # TODO: # *implement high-level qr() # *test unitvector # *iterative solving  |
| .venv/lib/python3.13/site-packages/mpmath/matrices/eigen_symmetric.py | 14f28f790af5706630e98e9e6b7d9ad587445900cb3fa265407100d967cd2d88 | 1808 | 23 |     """      # note : the vector v of the i-th houshoulder reflector is stored in a[(i+1):,i]     #        whereas v/<v,v> is stored in a[i,(i+1):]  |
| .venv/lib/python3.13/site-packages/mpmath/matrices/eigen.py | 19b0d72370a2c7311d5f1af51bceae5169009e002f77ed39326490f93b2eff99 | 878 | 28 |   hessenberg : reduction of a real or complex square matrix to upper Hessenberg form   schur : reduction of a real or complex square matrix to upper Schur form   eig : eigenvalues and eigenvectors of  |
| .venv/lib/python3.13/site-packages/flake8/formatting/default.py | b9b642050b30773f9cabaeb504ccc7442214e721a9786a3fe642aa9a1a8f557b | 110 | 1 |     "yellow": "\033[33m",     "blue": "\033[34m",     "magenta": "\033[35m",     "cyan": "\033[36m",     "white": "\033[37m", |
| .venv/lib/python3.13/site-packages/pyparsing/unicode.py | 7686a7bfb058401e0475045f7578a06a257f483859cb26814b082f544cfa7977 | 357 | 1 |             (0x1F5F, 0x1F7D),             (0x1F80, 0x1FB4),             (0x1FB6, 0x1FC4),             (0x1FC6, 0x1FD3),             (0x1FD6, 0x1FDB), |
| .venv/lib/python3.13/site-packages/pyparsing/util.py | 9277da17cfe98c72f2ecf2ff61da6c33d55a401ad00eaa382e787486e4f04e5e | 439 | 9 |         self._capacity = capacity         self._active = {}         self._memory = {}      def __getitem__(self, key): |
| .venv/lib/python3.13/site-packages/pyparsing/core.py | 22d6b5ae854ac2acdf6f822f5fcf0bc19825c6e8a2a3b26e5bd7a8ca592165f5 | 6300 | 5 |      def set_results_name(         self, name: str, list_all_matches: bool = False, *, listAllMatches: bool = False     ) -> ParserElement:         """ |
| .venv/lib/python3.13/site-packages/pyparsing/tools/cvt_pyparsing_pep8_names.py | 08abf120188324bbe66e756fde62b4b7235464ddee6f7790e19d5e3b9e31f3f5 | 117 | 1 | }  pre_pep8_arg_names = """parseAll maxMatches listAllMatches callDuringTry includeSeparators fullDump printResults  failureTests postParse matchString identChars maxMismatches initChars bodyChars asK |
| .venv/lib/python3.13/site-packages/chromadb/config.py | 950c2f2ce5c4ef0f47d085e413353ada0807faa8233b1ac06dd1d9374ec652b3 | 504 | 5 |     persist_directory: str = "./chroma"      chroma_memory_limit_bytes: int = 0     chroma_segment_cache_policy: Optional[str] = None  |
| .venv/lib/python3.13/site-packages/chromadb/__init__.py | b43389932dc9089ff65262e2e14a78568ee6cad03e4f95bd4404d2ef09f36e38 | 394 | 5 |     UpdateMetadata,     Documents,     EmbeddingFunction,     Embeddings,     URI, |
| .venv/lib/python3.13/site-packages/chromadb/types.py | 17a0d53e777ca07708fd2a287c992363ceff5bbe494981ea7583e2c3005291ac | 322 | 21 |     Metadata,     UpdateMetadata,     Vector,     PyVector,     LiteralValue, |
| .venv/lib/python3.13/site-packages/chromadb/base_types.py | a416e04d039437edabb130481c6bc2a5e684e0808f8883421bc2bfe4132524b3 | 39 | 3 | Metadata = Mapping[str, Optional[Union[str, int, float, bool]]] UpdateMetadata = Mapping[str, Union[int, float, str, bool, None]] PyVector = Union[Sequence[float], Sequence[int]] Vector = NDArray[Unio |
| .venv/lib/python3.13/site-packages/chromadb/proto/convert.py | c5b6fa94452ae69d80ad4bf89f0912457cd28567294ad6b1a3ebb5b2032f57b0 | 689 | 92 |     collection_configuration_to_json_str, ) from chromadb.api.types import Embedding, Where, WhereDocument from chromadb.execution.expression.operator import (     KNN, |
| .venv/lib/python3.13/site-packages/chromadb/test/conftest.py | b739ea7dbbb8c8886210a3973cea1cafc79ea6fee4b648ca304b58a7340bc3ed | 1117 | 26 | from chromadb.api import ClientAPI, ServerAPI, BaseAPI from chromadb.config import Settings, System from chromadb.db.mixins import embeddings_queue from chromadb.ingest import Producer from chromadb.t |
| .venv/lib/python3.13/site-packages/chromadb/test/test_multithreaded.py | f34d4bebfa1d2a8ae7a09b8fecd5e5f513f847bd22d45cec949052a999f9074c | 230 | 18 |     metadatas: List[Dict[str, int]] = [{f"{i}": i} for i in range(N)]     documents = [f"doc {i}" for i in range(N)]     embeddings = np.random.rand(N, D).tolist()      # Create a normalized record se |
| .venv/lib/python3.13/site-packages/chromadb/test/test_api.py | 5337abd5d4010361dfd8bb654fd69ab284d784a783dc3ebc09bf875d677e5b28 | 1834 | 172 | import chromadb.server.fastapi from chromadb.api.fastapi import FastAPI from chromadb.api.types import Document, EmbeddingFunction, QueryResult from chromadb.config import Settings from chromadb.error |
| .venv/lib/python3.13/site-packages/chromadb/test/test_cli.py | 6a1e6f1e2c9e4d0d4d572e3e5e76001525f88b4e34254e5177e2992216812f56 | 158 | 3 |     def add_records(collection: Collection, num: int) -> None:         ids = [str(i) for i in range(num)]         embeddings = np.random.rand(num, 2)         collection.add(ids=ids, embeddings=embeddi |
| .venv/lib/python3.13/site-packages/chromadb/test/configurations/test_collection_configuration.py | b9819f1b6acd9da81f5e32bf4da3dabde563a99c8a1f21e42832e83cf274b967 | 1619 | 194 | import warnings from chromadb.api.types import (     EmbeddingFunction,     Embeddings,     Space, |
| .venv/lib/python3.13/site-packages/chromadb/test/distributed/test_repair_collection_log_offset.py | 3b83eb9f88d8547792a49e38405d80abb8dea4b766f8237c2e57e3c537346a91 | 74 | 5 |     initial_version = cast(int, collection.get_model()["version"])      # Add RECORDS records, where each embedding has 3 dimensions randomly generated between 0 and 1     for i in range(0, RECORDS, B |
| .venv/lib/python3.13/site-packages/chromadb/test/distributed/test_reroute.py | b478b27293521e7af5728f3de735a02ac936c7fc975b2e41557927ffcfd581cc | 75 | 7 |      ids = [str(i) for i in range(10)]     embeddings: list[Sequence[float]] = [         [float(i), float(i), float(i)] for i in range(10)     ] |
| .venv/lib/python3.13/site-packages/chromadb/test/distributed/test_sanity.py | a55f535420e3f166e765d051f182fd566da63d99793a7fefa6b2cb064073d900 | 103 | 15 |     )      # Add 1000 records, where each embedding has 3 dimensions randomly generated     # between 0 and 1     ids = [] |
| .venv/lib/python3.13/site-packages/chromadb/test/distributed/test_log_backpressure.py | d091e7b45ef50b3d4db8974bcc7b545765a235adf186a5e57f8516881a0ed492 | 55 | 5 |      excepted = False     # Add RECORDS records, where each embedding has 3 dimensions randomly generated between 0 and 1     for i in range(0, RECORDS, BATCH_SIZE):         ids = [] |
| .venv/lib/python3.13/site-packages/chromadb/test/distributed/test_log_failover.py | c648b57b52edbc7ffc1d40aad0872835630a096eecc7bbc49a034fc6de0254a1 | 410 | 103 |     response = log_service_stub.SealLog(request, timeout=60)      # Add RECORDS records, where each embedding has 3 dimensions randomly generated between 0 and 1     ids = []     embeddings = [] |
| .venv/lib/python3.13/site-packages/chromadb/test/property/strategies.py | ae8d22fa79e3cbb0b8785831c4f7e9b845598ca5376f9c1c6924b418728e9737 | 721 | 64 |     Documents,     Embeddable,     EmbeddingFunction,     Embeddings,     Metadata, |
| .venv/lib/python3.13/site-packages/chromadb/test/property/test_embeddings.py | 04181304d87b358f9c2ecd0e1f76e7735b914ed1eeda1b69d067bdce119b6b26 | 1512 | 235 | from chromadb.api.types import (     ID,     Embeddings,     Include,     IDs, |
| .venv/lib/python3.13/site-packages/chromadb/test/property/test_fork.py | 2b1fbcdf44ce8a0a90af8fda7c2c2c9fd6062dca157287a1a2eb9e0b9eb3cc35 | 238 | 22 |             name=collection.name,             metadata=collection.metadata,  # type: ignore[arg-type]             embedding_function=collection.embedding_function,         )         self.collection_na |
| .venv/lib/python3.13/site-packages/chromadb/test/property/test_add.py | dbbe0db44d96a312b0d55903406eefc35a8a567dcea87e10bfebd33f1fd8979d | 372 | 31 | from hypothesis import given, settings from chromadb.api import ClientAPI from chromadb.api.types import Embeddings, Metadatas from chromadb.test.conftest import (     NOT_CLUSTER_ONLY, |
| .venv/lib/python3.13/site-packages/chromadb/test/property/test_persist.py | a48548075fdea5fcce8a261c52fd28fc3075541caab155338a6f3822e8b40636 | 726 | 93 | from chromadb.api import ClientAPI, ServerAPI from chromadb.config import Settings, System from chromadb.segment import VectorReader from chromadb.segment.impl.manager.local import LocalSegmentManager |
| .venv/lib/python3.13/site-packages/chromadb/test/property/test_base64_conversion.py | 4f007323236aa1921feb04fe7882dbb4831ff3eadb18ab62635e435f0a39b3e7 | 64 | 45 | from hypothesis import given, strategies as st from chromadb.api.types import (     optional_embeddings_to_base64_strings,     optional_base64_strings_to_embeddings, ) |
| .venv/lib/python3.13/site-packages/chromadb/test/property/test_cross_version_persist.py | 67ebebd709452c09de122d61decbe85330022f490aa678e0141ce8851909f832 | 351 | 64 | from chromadb.api.configuration import (     ConfigurationParameter,     EmbeddingsQueueConfigurationInternal, ) from chromadb.api.types import Documents, EmbeddingFunction, Embeddings |
| .venv/lib/python3.13/site-packages/chromadb/test/property/test_collections.py | ca784d4e9bb817df0f8b22b7861980203fe852062486cd107b51dc1a0982c908 | 339 | 21 | from typing import Any, Dict, Mapping, Optional import numpy from chromadb.test.property.strategies import hashing_embedding_function   |
| .venv/lib/python3.13/site-packages/chromadb/test/property/test_restart_persist.py | 52752ddfe5721cef37b466effc381e1078311e9e8f7f801b5c2e413fea69f9da | 87 | 14 | )  from chromadb.test.property.test_embeddings import (     EmbeddingStateMachineBase,     EmbeddingStateMachineStates, |
| .venv/lib/python3.13/site-packages/chromadb/test/property/invariants.py | fdb5dd84da6d78e3d79d4b268856dbf4374640f1706f9bf2e368c278a9c94b8f | 585 | 95 |  def wrap_all(record_set: RecordSet) -> NormalizedRecordSet:     """Ensure that an embedding set has lists for all its values"""      embedding_list: Optional[types.Embeddings] |
| .venv/lib/python3.13/site-packages/chromadb/test/property/test_filtering.py | 8accd4c3772b6271a8ffa9e687e4a54159a6abee93eaf3b815bd03b44f77a0c7 | 589 | 70 |     Document,     Documents,     Embedding,     Embeddings,     GetResult, |
| .venv/lib/python3.13/site-packages/chromadb/test/property/test_collections_with_database_tenant_overwrite.py | c7b4801f03738e63b87680c5807d5c08612333db0348e086c31a89aa9f77f752 | 215 | 3 |             name="A00",             metadata=None,             embedding_function=strategies.hashing_embedding_function(                 dim=2, dtype=numpy.float16  # type: ignore             ), |
| .venv/lib/python3.13/site-packages/chromadb/test/utils/test_result_df_transform.py | ec87deeec0709535def4dc18f93847812b2882d8fbe0c1d4994021b7a4b4a739 | 185 | 27 | from typing import List, Dict, Any, cast, Union from chromadb.utils.results import (     _transform_embeddings,     _add_query_fields,     _add_get_fields, |
| .venv/lib/python3.13/site-packages/chromadb/test/utils/test_embedding_function_schemas.py | aac130c66b3983846d21ad0ce5d4ae9a98a6cc2227dc419a23596b34b544e3be | 132 | 20 | from jsonschema import ValidationError from unittest.mock import MagicMock, create_autospec from chromadb.utils.embedding_functions.schemas import (     validate_config_schema,     load_schema, |
| .venv/lib/python3.13/site-packages/chromadb/test/db/test_log_purge.py | 7f8c3c3d4d404dbbfe00a37a9a511b747a60690c2d17c094029da4b51b94e6c4 | 51 | 4 |     # (Does not trigger a purge)     for i in range(5):         first_collection.add(ids=str(i), embeddings=[i, i])      # (Should trigger a purge) |
| .venv/lib/python3.13/site-packages/chromadb/test/api/test_numpy_list_inputs.py | 49be7100320235a9941cb865e377d1377b98a85e3a16154f23867972a4ee01bf | 63 | 12 |     collection: Collection,     ids: List[str],     embeddings: Any,     metadatas: List[Dict[str, Any]],     documents: List[str], |
| .venv/lib/python3.13/site-packages/chromadb/test/api/test_invalid_update.py | 87c1399a8cfa1331717291f0f3ea0771fed4e7976f968b517e402c2840845545 | 18 | 6 |      # Update is invalid because ID does not exist     collection.update(ids=["foo"], embeddings=[[0.0, 0.0, 0.0]])      collection.add(ids=["foo"], embeddings=[[1.0, 1.0, 1.0]]) |
| .venv/lib/python3.13/site-packages/chromadb/test/api/test_limit_offset.py | b2d6cfc8f8813efaa72d26ffd42a2cc42dcb28dabc44da52e2b74cffdd7c8b38 | 67 | 2 |         name=collection.name,         metadata=collection.metadata,  # type: ignore         embedding_function=collection.embedding_function,     )  |
| .venv/lib/python3.13/site-packages/chromadb/test/api/test_types.py | f0acb03d4b263f52aa3724a8a637b532fd82b21b52c00882f1b907277d42c4ff | 106 | 40 | import pytest from typing import List, cast, Dict, Any from chromadb.api.types import Documents, Image, Document, Embeddings from chromadb.utils.embedding_functions import (     EmbeddingFunction, |
| .venv/lib/python3.13/site-packages/chromadb/test/ef/test_ef.py | 5bbf9159e46ef193524d20156168a8230a2f176994c82f5d157394d8b6bde407 | 108 | 49 | from chromadb.utils import embedding_functions from chromadb.utils.embedding_functions import (     EmbeddingFunction, |
| .venv/lib/python3.13/site-packages/chromadb/test/ef/test_multimodal_ef.py | a498be41ebc941f6719eeb47c7d169d1a0eaf67478403afcb27a8d43d3e8f317 | 170 | 28 | from chromadb.api.types import (     Embeddable,     EmbeddingFunction,     Embeddings,     Image, |
| .venv/lib/python3.13/site-packages/chromadb/test/ef/test_morph_ef.py | 05284a14f6320fc0d01e63442552e54c65bbc8d01e0ef6e2eb8cf483057a8548 | 135 | 43 | import pytest import numpy as np from chromadb.utils.embedding_functions.morph_embedding_function import (     MorphEmbeddingFunction, ) |
| .venv/lib/python3.13/site-packages/chromadb/test/ef/test_openai_ef.py | 9448ca7cce21b2b3a14c32e793e3a2b029cfd0b9401ae2a13bb846ff80f7f2cc | 39 | 13 | import pytest  from chromadb.utils.embedding_functions.openai_embedding_function import (     OpenAIEmbeddingFunction, ) |
| .venv/lib/python3.13/site-packages/chromadb/test/ef/test_voyageai_ef.py | 0c46513fe3934dc16d13071de5fbc05ce7036cd29688f70c1ac50fbc42fd0ab6 | 20 | 9 | import os import pytest from chromadb.utils.embedding_functions.voyageai_embedding_function import (     VoyageAIEmbeddingFunction, ) |
| .venv/lib/python3.13/site-packages/chromadb/test/ef/test_ollama_ef.py | 488c4148c9cafae6ddb75526d625f04a88da8d1df012d7f2329b9413057af1ee | 51 | 15 | import pytest  from chromadb.utils.embedding_functions.ollama_embedding_function import (     OllamaEmbeddingFunction, ) |
| .venv/lib/python3.13/site-packages/chromadb/test/ef/test_custom_ef.py | b01deacea814a8c2a391a0815162198921938648f2a237293631cc49b4d84a89 | 96 | 39 | from chromadb.api.types import EmbeddingFunction, Embeddable, Embeddings import numpy as np from typing import cast, Any |
| .venv/lib/python3.13/site-packages/chromadb/test/ef/test_onnx_mini_lm_l6_v2.py | 41282e4b1dc7f34564096c019f65fe414501304aff91f7b6d41ef6289541605b | 205 | 50 | from unittest.mock import patch, MagicMock  from chromadb.utils.embedding_functions import ONNXMiniLM_L6_V2, EmbeddingFunction   |
| .venv/lib/python3.13/site-packages/chromadb/test/ef/test_default_ef.py | 7e1b35344da04dc17dccb5cd0db2e807055af5dcd22cde07f69240b078e3867d | 91 | 2 | from hypothesis import given, settings  from chromadb.utils.embedding_functions.onnx_mini_lm_l6_v2 import (     ONNXMiniLM_L6_V2, ) |
| .venv/lib/python3.13/site-packages/chromadb/test/data_loader/test_data_loader.py | 82cde2783c352e2d3ffe6ecae78f214f0c4331bd0cdd5b88d6e2b234b3df654d | 123 | 2 |         name="collection_with_data_loader",         data_loader=DefaultDataLoader(),         embedding_function=hashing_multimodal_ef(),     )     yield collection |
| .venv/lib/python3.13/site-packages/chromadb/test/client/test_database_tenant.py | ea5c39e600579cef39897dda2747d477f8059fbcaa4dbfbd2319b39e9d13ba16 | 185 | 17 |     records_new = {         "ids": ["a", "b", "c"],         "embeddings": [[1.0, 2.0, 3.0] for _ in range(3)],         "documents": ["a", "b", "c"],     } |
| .venv/lib/python3.13/site-packages/chromadb/test/stress/test_many_collections.py | 5b3a8d871c4fbcd50a5151286a344bec3898b718ad146f3c00c1258f1d2c2b37 | 38 | 1 |         collections.append(new_collection)      # Add a few embeddings to each collection     data = np.random.rand(N, D).tolist()     ids = [f"test_id_{i}" for i in range(N)] |
| .venv/lib/python3.13/site-packages/chromadb/ingest/__init__.py | b35d8a57592b914072073f423d8ce316486c7d49b5a45d4dba6d2873d7067d50 | 122 | 25 |     LogRecord,     SeqId,     Vector,     ScalarEncoding, ) |
| .venv/lib/python3.13/site-packages/chromadb/ingest/impl/utils.py | e204a2db8a9835683e78281eb01dd4fcdab1d2567d830c93255be6f519e0ba50 | 50 | 7 |  from chromadb.db.base import SqlDB from chromadb.segment import SegmentManager, VectorReader  topic_regex = r"persistent:\/\/(?P<tenant>.+)\/(?P<namespace>.+)\/(?P<topic>.+)" |
| .venv/lib/python3.13/site-packages/chromadb/segment/__init__.py | f5f0ccae3894d2f6113a2a1c84439fc9993b7d5530ecb6c16747106d528c959c | 126 | 27 | from chromadb.types import (     Collection,     MetadataEmbeddingRecord,     Operation,     RequestVersionContext, |
| .venv/lib/python3.13/site-packages/chromadb/segment/impl/manager/local.py | 4bb4ef45e6a74f8d5c3f95dc5daef21662e88c56def39cb7569fc1e29df2feb5 | 270 | 31 |     MetadataReader,     SegmentType,     VectorReader,     S, ) |
| .venv/lib/python3.13/site-packages/chromadb/segment/impl/manager/distributed.py | 8ba74319d7a1bc47b7da1d385c03c8a01f0a0b2a6e8f71a06417b6493bfa6c34 | 98 | 4 | ) from chromadb.segment.distributed import SegmentDirectory from chromadb.segment.impl.vector.hnsw_params import PersistentHnswParams from chromadb.telemetry.opentelemetry import (     OpenTelemetryGr |
| .venv/lib/python3.13/site-packages/chromadb/segment/impl/vector/local_persistent_hnsw.py | 2bc13d0dcbdf62eb7ea868d734470e837fc96cb4468242faeeeef3c9460e5557 | 544 | 55 | from chromadb.db.base import ParameterValue, get_sql from chromadb.db.impl.sqlite import SqliteDB from chromadb.segment.impl.vector.batch import Batch from chromadb.segment.impl.vector.hnsw_params imp |
| .venv/lib/python3.13/site-packages/chromadb/segment/impl/vector/batch.py | 66e77d0ac959e46f8a5a747a704c88254fc2932238abceddb2f33b78ddb06128 | 107 | 9 | from typing import Dict, List, Set, cast from chromadb.types import LogRecord, Operation, Vector   |
| .venv/lib/python3.13/site-packages/chromadb/segment/impl/vector/brute_force_index.py | 175946a71e457bbec938a182353e05e317dc512279596c5a5a770714dce76cf2 | 152 | 30 | from chromadb.types import (     LogRecord,     VectorEmbeddingRecord,     VectorQuery,     VectorQueryResult, |
| .venv/lib/python3.13/site-packages/chromadb/segment/impl/vector/local_hnsw.py | e75e8a5746d206af222584daa60b5e14833d3f7d6d465efe3b5f2e5d26649186 | 333 | 48 | from typing import Optional, Sequence, Dict, Set, List, cast from uuid import UUID from chromadb.segment import VectorReader from chromadb.ingest import Consumer from chromadb.config import System, Se |
| .venv/lib/python3.13/site-packages/chromadb/segment/impl/metadata/sqlite.py | 973961b8b83baf6a91a84ff047bf8e5c33f5e85edac8f330e2b2d17027542249 | 724 | 90 |     Where,     WhereDocument,     MetadataEmbeddingRecord,     LogRecord,     SeqId, |
| .venv/lib/python3.13/site-packages/chromadb/segment/distributed/__init__.py | 05999860221af14ca6af227f183a83dec778f22fae72afd536dc275ec2916caf | 81 | 1 |     ) -> None:         """Registers a callback that will be called when the memberlist changes. May be called many times         with the same memberlist, so callers should be idempotent. May be calle |
| .venv/lib/python3.13/site-packages/chromadb/server/fastapi/__init__.py | e484ea46eb12ceadb29d3f41a1569f643cd64ce70d5703fbe4be11bcc02c594d | 2179 | 94 | from chromadb import __version__ as chromadb_version from chromadb.api.types import (     Embedding,     GetResult,     QueryResult, |
| .venv/lib/python3.13/site-packages/chromadb/server/fastapi/types.py | 7d6101e56a93ab8652b4ee20409722b10680c5cfc806ebbc1a2cc9e18bb9e726 | 79 | 9 |   class AddEmbedding(BaseModel):     # Pydantic doesn't handle Union types cleanly like Embeddings which has     # Union[int, float] so we use Any here to ensure data is parsed |
| .venv/lib/python3.13/site-packages/chromadb/utils/results.py | d173599117e521dd02fc49f976066015a94a3c209daf607f30dfbba685a7e6e6 | 126 | 11 |   def _transform_embeddings(     embeddings: Optional[List[np.ndarray]],  # type: ignore ) -> Optional[Union[List[List[float]], List[np.ndarray]]]:  # type: ignore |
| .venv/lib/python3.13/site-packages/chromadb/utils/batch_utils.py | ae205d3dfdbe5b9ac195a1f35381dda530ed81bad0e877a431271d3d30620840 | 37 | 8 | from chromadb.api.types import (     Documents,     Embeddings,     IDs,     Metadatas, |
| .venv/lib/python3.13/site-packages/chromadb/utils/data_loaders.py | 53e740a0b8a98479ba1594c0c144df3feef22de1fc4c62c9348590c1ebaa2ea8 | 32 | 1 | class ChromaLangchainPassthroughDataLoader(DataLoader[List[Optional[Image]]]):     # This is a simple pass through data loader that just returns the input data with "images"     # flag which lets the  |
| .venv/lib/python3.13/site-packages/chromadb/utils/rendezvous_hash.py | eab8694d578106367d4707de747daa9a6ded7036e41184ffa30c5deb801b07e4 | 69 | 1 |     ) % 2**64  # We need to mod here to prevent python from using arbitrary size int     acc ^= acc >> 33     acc = (acc * 0xC4CEB9FE1A85EC53) % 2**64     acc ^= acc >> 33     return acc |
| .venv/lib/python3.13/site-packages/chromadb/utils/distance_functions.py | a851532c12d33038bfbad32b969d3b7d08b44b1166b6b9ea04e8344df003118e | 33 | 7 | from numpy.typing import NDArray  Vector = NDArray[Union[np.int32, np.float32, np.int16, np.float16]]   |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/cloudflare_workers_ai_embedding_function.py | 192356615212008626d1522cc6c1de201a28dbddee188492897d89ead88c8136 | 153 | 16 | from chromadb.api.types import (     Embeddings,     Documents,     EmbeddingFunction, |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/text2vec_embedding_function.py | 07a971550fd46e782fb6c21090eeec4d692065175a505eee51cca09240447d23 | 91 | 18 | from chromadb.api.types import EmbeddingFunction, Space, Embeddings, Documents from chromadb.utils.embedding_functions.schemas import validate_config_schema from typing import List, Dict, Any |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/morph_embedding_function.py | 725406504d7a3caaed7576e407bc9df3f0776dc7735d83e2fdb304b5154f99f2 | 147 | 29 | from chromadb.api.types import Embeddings, Documents, EmbeddingFunction, Space from typing import List, Dict, Any, Optional import os |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/chroma_langchain_embedding_function.py | 8e982f226f9ab90a24d3ab83ccda47b544397e53d5e1084b1293ff8459219964 | 172 | 78 | from chromadb.api.types import (     Documents,     Embeddings,     Images,     Embeddable, |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/onnx_mini_lm_l6_v2.py | 3bee881392b56e7ec2dea1e9ddf1eb86a7cae2d56ab7131be1b3744108481d5e | 365 | 35 | from tenacity import retry, retry_if_exception, stop_after_attempt, wait_random  from chromadb.api.types import Documents, Embeddings, EmbeddingFunction, Space from chromadb.utils.embedding_functions. |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/baseten_embedding_function.py | 8c6add9d4f23221c3d22a54a580c7c3345efce67c92e66e143af7bbac2d065ea | 99 | 14 | import os from chromadb.utils.embedding_functions.openai_embedding_function import (     OpenAIEmbeddingFunction, ) |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/jina_embedding_function.py | 0018f384407db5ea9e49e3cd40b4062476c0132af5530741640cae55de57743d | 209 | 43 | from chromadb.api.types import Embeddings, Documents, EmbeddingFunction, Space from chromadb.utils.embedding_functions.schemas import validate_config_schema from typing import List, Dict, Any, Union,  |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/mistral_embedding_function.py | 7f5ae7c7e2a120f9303ee4b4395c130ac6b767c6a56c8830470d6523d3a2a31f | 93 | 16 | from chromadb.api.types import Embeddings, Documents, EmbeddingFunction, Space from chromadb.utils.embedding_functions.schemas import validate_config_schema from typing import List, Dict, Any |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/huggingface_embedding_function.py | ed57d7baad00ecb0b8fce3ca58c857660e9829dac0193a0ac30c4dbeac3b1139 | 237 | 44 | from chromadb.api.types import Embeddings, Documents, EmbeddingFunction, Space from typing import List, Dict, Any, Optional import os |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/__init__.py | 2696f6bb99648f4297e469a0e12abdb97a5f6cc06f7782066e4fdba122ea6278 | 254 | 167 | from typing import Dict, Any, Type, Set from chromadb.api.types import (     EmbeddingFunction,     Embeddings,     Documents, |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/open_clip_embedding_function.py | 43f626043aafa7064a984ba3da0ecb54ebe2638ea30323ea57b2fbc4d9c86e27 | 188 | 28 | from chromadb.api.types import EmbeddingFunction, Space from chromadb.utils.embedding_functions.schemas import validate_config_schema from chromadb.api.types import ( |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/google_embedding_function.py | 5c7b64ef5bd3c844d12a49aa6a8cafab8cc5e881dc151928a03ac38816f041a9 | 396 | 73 | from chromadb.api.types import Embeddings, Documents, EmbeddingFunction, Space from typing import List, Dict, Any, cast, Optional import os |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/openai_embedding_function.py | 351e817e6db0b2b6e577d5f4cb707940d8a18014cdef029d56a4ef15c83d9e34 | 205 | 31 | from chromadb.api.types import Embeddings, Documents, EmbeddingFunction, Space from typing import List, Dict, Any, Optional import os |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/roboflow_embedding_function.py | cc52aa8219fd3f75c1e67beeea3a4283c17e15ac264abe1ce421a71561bfcf70 | 160 | 21 | from chromadb.utils.embedding_functions.schemas import validate_config_schema from chromadb.api.types import (     Documents, |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/sentence_transformer_embedding_function.py | 2b7c4adcaeb2d8b91123322f3610177ca42563d03a00ff5ca5e53cfdb77789f9 | 122 | 31 | from chromadb.api.types import EmbeddingFunction, Space, Embeddings, Documents from typing import List, Dict, Any import numpy as np |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/ollama_embedding_function.py | cedde9ca0578379a0dda2a06886d3c435e9e8f609d8b08e0f6aa666fdd6d5022 | 118 | 24 | from chromadb.api.types import Embeddings, Documents, EmbeddingFunction, Space from chromadb.utils.embedding_functions.schemas import validate_config_schema from typing import List, Dict, Any |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/instructor_embedding_function.py | 002c1b750367ed6ce131cf3fcf54a062b9d9de4e420a785f0461005617638721 | 119 | 25 | from chromadb.api.types import Embeddings, Documents, EmbeddingFunction, Space from chromadb.utils.embedding_functions.schemas import validate_config_schema from typing import List, Dict, Any, Optiona |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/together_ai_embedding_function.py | 4bd33196d3eef08088c4df7e184c607fb981e0fb0eb6f87553f384c1875e1ae7 | 146 | 18 | from chromadb.api.types import (     Embeddings,     Documents,     EmbeddingFunction, |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/cohere_embedding_function.py | 2f33347dc38a7a5cef0ef67623fc7de397ef186fca293f2841ba778917119de4 | 177 | 19 | from chromadb.api.types import (     Embeddings,     Embeddable,     EmbeddingFunction, |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/voyageai_embedding_function.py | f2e5023d7ae9821ea57e18ddfce80fc37147b109d89496585eabec96c79e60fd | 137 | 20 | from chromadb.api.types import EmbeddingFunction, Space, Embeddings, Documents from chromadb.utils.embedding_functions.schemas import validate_config_schema from typing import List, Dict, Any, Optiona |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/amazon_bedrock_embedding_function.py | a9a9734fe8d40e7ac46ae131b15950031db5b563f3d5061db53496ff51ed8641 | 139 | 24 | from chromadb.utils.embedding_functions.schemas import validate_config_schema from chromadb.api.types import Embeddings, Documents, EmbeddingFunction from typing import Dict, Any, cast |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/schemas/schema_utils.py | c9b483e6cecce94819d0f0397186e3e20bc97055c3694f7c1cbb916616097648 | 86 | 1 |     ),     "schemas",     "embedding_functions", )  |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/schemas/registry.py | 179e3671ed79198000ceb6fdae6b84624ca90c47352ca15a84f826cca937f612 | 56 | 5 | """ Schema Registry for Embedding Functions  This module provides a registry of all available schemas for embedding functions. |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/schemas/__init__.py | dd700a0ee091728828dd6f909530c862651a93e54dd8d58b8ffb9eea1ccb0b88 | 20 | 4 | from chromadb.utils.embedding_functions.schemas.schema_utils import (     validate_config_schema,     load_schema, |
| .venv/lib/python3.13/site-packages/chromadb/utils/embedding_functions/schemas/README.md | 70071daf33e1b86685b3eef4cfc5309adc3d401855c0f411a665b3c98a0b8b72 | 42 | 10 | # Embedding Function Schemas  This directory contains JSON schemas for all embedding functions in Chroma. The purpose of having this schema is to support cross language compatibility, and to validate  |
| .venv/lib/python3.13/site-packages/chromadb/cli/cli.py | a005eea5a24c39f3e1abdb6d679bd0d04ce4c0a3fba13fa26218caf309499fde | 56 | 1 |          version_pattern = re.compile(r'^\d+\.\d+\.\d+$')         numeric_releases = [r["tag_name"] for r in releases if version_pattern.fullmatch(r["tag_name"])]          if not numeric_releases: |
| .venv/lib/python3.13/site-packages/chromadb/execution/executor/local.py | c628ee0abe28cef3235f64f458ff42430b2cf407ed85c485ed0403d8825bfb38 | 206 | 35 | from chromadb.execution.executor.abstract import Executor from chromadb.execution.expression.plan import CountPlan, GetPlan, KNNPlan from chromadb.segment import MetadataReader, VectorReader from chro |
| .venv/lib/python3.13/site-packages/chromadb/execution/executor/distributed.py | 5ed0136b1cc37a8de7061975d4be89d5bc9e9d688103f41a36930d41aa180c80 | 243 | 10 |          ids = [record["id"] for record in records]         embeddings = (             [record["embedding"] for record in records]             if plan.projection.embedding |
| .venv/lib/python3.13/site-packages/chromadb/execution/expression/operator.py | 0512c184bf71b38ba5d423cc6e902746008fe3b090eef4e805071ea6e781f503 | 70 | 6 | from typing import Optional  from chromadb.api.types import Embeddings, IDs, Include from chromadb.types import (     Collection, |
| .venv/lib/python3.13/site-packages/chromadb/db/__init__.py | 043f2b8c5fea25d358ab727c4fb283b83bba470f606da9f1f593391f0d01eecf | 123 | 7 | from uuid import UUID from chromadb.api.types import (     Embeddings,     Documents,     IDs, |
| .venv/lib/python3.13/site-packages/chromadb/db/migrations.py | 1c2da9617624b97c636fe987471a9c883f179a49e4250f4c51b46e204de91a76 | 277 | 1 |     @abstractmethod     def setup_migrations(self) -> None:         """Idempotently creates the migrations table"""         pass  |
| .venv/lib/python3.13/site-packages/chromadb/db/base.py | 1373e41360b198530fb3b3d0ca1395e57991c244cfa461c7bfb52282981e070d | 181 | 2 |     SQL string and parameters. This makes it easier to construct complex queries     programmatically and automatically matches up the generated SQL with the required     parameter vector.      Doing  |
| .venv/lib/python3.13/site-packages/chromadb/db/impl/sqlite.py | f32ce944e961633f9f9a037cd80559b338b14d98195d2c0a3bf7c7ff8e966c47 | 274 | 6 | from chromadb.config import System, Settings import chromadb.db.base as base from chromadb.db.mixins.embeddings_queue import SqlEmbeddingsQueue from chromadb.db.mixins.sysdb import SqlSysDB from chrom |
| .venv/lib/python3.13/site-packages/chromadb/db/impl/grpc/server.py | 42dc4029f7ea36f06b6f432424cbe6f4dd868386b12dba2fe2148fdd3adc6af4 | 497 | 1 |             SegmentScope.METADATA,             SegmentScope.RECORD,             SegmentScope.VECTOR,         }:             context.abort( |
| .venv/lib/python3.13/site-packages/chromadb/db/mixins/embeddings_queue.py | 662088a8acd22af98d03d36a6d4b7cf827c262789363f9c18e7ffbed5be9da4f | 508 | 102 | from chromadb.api.configuration import (     ConfigurationParameter,     EmbeddingsQueueConfigurationInternal, ) from chromadb.db.base import SqlDB, ParameterValue, get_sql |
| .venv/lib/python3.13/site-packages/chromadb/db/mixins/sysdb.py | 97a81d8bc3aa81963cfc9b5765c4140076c93c4b7840a4571146eed83d4ee8d4 | 983 | 1 |         offset: Optional[int] = None,     ) -> Sequence[Collection]:         """Get collections by name, embedding function and/or metadata"""          if name is not None and (tenant is None or datab |
| .venv/lib/python3.13/site-packages/chromadb/api/configuration.py | da5b60c7b225bd397a8b676edb7c8c9747fe62f898f4989bf7177b473e27fbcd | 411 | 1 |   class EmbeddingsQueueConfigurationInternal(ConfigurationInternal):     definitions = {         "automatically_purge": ConfigurationDefinition( |
| .venv/lib/python3.13/site-packages/chromadb/api/fastapi.py | 171a2c247d0ee0d4f1ff2c96cbaa9791d2c535f62a6716bde7f405e6ab063ee6 | 675 | 40 | from chromadb.api.types import (     Documents,     Embeddings,     PyEmbeddings,     IDs, |
| .venv/lib/python3.13/site-packages/chromadb/api/client.py | 8e2208d9ab0a156b573048b8ddce33641b1b5bd999e62c921967704ff3f1b685 | 539 | 54 |     CreateCollectionConfiguration,     UpdateCollectionConfiguration,     validate_embedding_function_conflict_on_create,     validate_embedding_function_conflict_on_get, ) |
| .venv/lib/python3.13/site-packages/chromadb/api/__init__.py | 0e541bd430cd3caf027349e984519742863f6e69a3ba85334875ac85ec6c3572 | 761 | 61 |     Documents,     Embeddable,     EmbeddingFunction,     DataLoader,     Embeddings, |
| .venv/lib/python3.13/site-packages/chromadb/api/types.py | e7c710605b8e749deec5f0da32d20a16319a2016279fdbfe891ca6f220ac1928 | 1053 | 184 |     Metadata,     UpdateMetadata,     Vector,     PyVector,     LiteralValue, |
| .venv/lib/python3.13/site-packages/chromadb/api/collection_configuration.py | 3d9c30fad43c294dcad147d82435ba3a43042c85a1b0ad601c848cacddcf1034 | 820 | 114 |     CollectionMetadata,     UpdateMetadata,     EmbeddingFunction, ) from chromadb.utils.embedding_functions import ( |
| .venv/lib/python3.13/site-packages/chromadb/api/async_fastapi.py | 672eadb4985e1f965dbad07a3f967b36be2147a2700c2b6bbc536c477df96b78 | 705 | 35 | from chromadb.utils.async_to_sync import async_to_sync from chromadb.types import Database, Tenant, Collection as CollectionModel from chromadb.api.types import optional_embeddings_to_base64_strings   |
| .venv/lib/python3.13/site-packages/chromadb/api/async_client.py | 8e40060dcc845b4865dc692b110e5eb1c309db1e7f99244beff3956f60d6603e | 522 | 54 |     CreateCollectionConfiguration,     UpdateCollectionConfiguration,     validate_embedding_function_conflict_on_create,     validate_embedding_function_conflict_on_get, ) |
| .venv/lib/python3.13/site-packages/chromadb/api/async_api.py | 16dfe8a50f7bde7616bee804decdb6b9dc8b954cf59547f9b0351a2e5794dcea | 754 | 63 |     Documents,     Embeddable,     EmbeddingFunction,     DataLoader,     Embeddings, |
| .venv/lib/python3.13/site-packages/chromadb/api/segment.py | 53fea4ec1ad901d645b30e31f19ddb09575535ad47af0ca6771a65c771a03462 | 1000 | 67 |     CollectionMetadata,     IDs,     Embeddings,     Metadatas,     Documents, |
| .venv/lib/python3.13/site-packages/chromadb/api/rust.py | 4f04c5486b82440d888ccfe3fb1f1e60a91b53ca0f1496898c5f53074e0c1771 | 580 | 26 | from chromadb import (     CollectionMetadata,     Embeddings,     GetResult,     IDs, |
| .venv/lib/python3.13/site-packages/chromadb/api/models/AsyncCollection.py | 03028a3941dc68f346e4949298639b45e2694b6ffaa3c0f9b4b4278353635b70 | 412 | 81 |     URI,     CollectionMetadata,     Embedding,     PyEmbedding,     Include, |
| .venv/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py | 180654658f14ed5e82aa5f99f224053ba09bb3ddf111f9fef4376b2eb9b90541 | 572 | 96 | from uuid import UUID  import chromadb.utils.embedding_functions as ef from chromadb.api.types import (     URI, |
| .venv/lib/python3.13/site-packages/chromadb/api/models/Collection.py | c7e901b4c51b4b8e027697e977df687c2d66e01a9f2bc6623a837ac74e602ff7 | 416 | 81 |     URI,     CollectionMetadata,     Embedding,     PyEmbedding,     Include, |
| .venv/lib/python3.13/site-packages/chromadb/quota/__init__.py | 45d4b1baaf0696bf4c2a62ca6781df3be26c3c9f6ac5d9bac55a0fc4c20a6e5c | 72 | 5 |  from chromadb.api.types import (     Embeddings,     Metadatas,     Documents, |
| .venv/lib/python3.13/site-packages/chromadb/quota/simple_quota_enforcer/__init__.py | 026ed31c5eb499ec5018bbd3a5206c60e7f3361bc47b83385a5538dfb1f381ef | 55 | 5 |  from chromadb.api.types import (     Embeddings,     Metadatas,     Documents, |
| .venv/lib/python3.13/site-packages/chromadb/telemetry/product/events.py | 1ca0ef499eae2d313206d80557c55efb37840d0d592f87668718c5b155079f24 | 257 | 15 |   # TODO: Re-enable embedding function tracking in create_collection class ClientCreateCollectionEvent(ProductTelemetryEvent):     collection_uuid: str |
| .venv/lib/python3.13/site-packages/chromadb/logservice/logservice.py | 4741d91125814761584a8fdcc300555e1bed904dcb52b8c415e3504319185bfa | 182 | 13 |         raise NotImplementedError("Not implemented")      @trace_method("LogService.submit_embedding", OpenTelemetryGranularity.ALL)     @override     def submit_embedding( |
| .venv/lib/python3.13/site-packages/redis/client.py | 5e6a3abdaf282a0ee4b03f2dbf9f8412b085ab73a1a5f7884ae47e9d60484520 | 1632 | 1 |             }          # if this is an unsubscribe message, remove it from memory         if message_type in self.UNSUBSCRIBE_MESSAGE_TYPES:             if message_type == "punsubscribe": |
| .venv/lib/python3.13/site-packages/redis/__init__.py | 7c3fc01594611d178531ba66445a923da96dc66b5aa5f20f5b2155ce225dd1e2 | 89 | 2 |     InvalidResponse,     MaxConnectionsError,     OutOfMemoryError,     PubSubError,     ReadOnlyError, |
| .venv/lib/python3.13/site-packages/redis/connection.py | 793e0c6e3e698c19bf47949242bac39258c9faa0b19ec8154410e56f0ac60ec5 | 1826 | 4 |         for arg in map(self.encode, args):             # to avoid large string mallocs, chunk the command into the             # output list if we're sending large values or memoryviews             ar |
| .venv/lib/python3.13/site-packages/redis/cluster.py | 0a0286167a6bce2623b2bfbea966e163efb6a1a6964116ee2a87e2d50afd9b97 | 3360 | 4 |                 "WAITAOF",                 "SAVE",                 "MEMORY PURGE",                 "MEMORY MALLOC-STATS",                 "MEMORY STATS", |
| .venv/lib/python3.13/site-packages/redis/exceptions.py | 6f738ef3b82770d091527c7577b3b9ecdda49233fe7de5e7ef47cf9171da2e64 | 248 | 6 |   class OutOfMemoryError(ResponseError):     """     Indicates the database is full. Can only occur when either: |
| .venv/lib/python3.13/site-packages/redis/typing.py | cf92508c690dcde8c4cdbdb2ed35dcb7bb52e72cc07cb42877da37ecc875fd48 | 58 | 5 |  Number = Union[int, float] EncodedT = Union[bytes, bytearray, memoryview] DecodedT = Union[str, int, float] EncodableT = Union[EncodedT, DecodedT] |
| .venv/lib/python3.13/site-packages/redis/commands/core.py | 46355b4f17bfbdf9eb6953aa4441faa1f354d8b317f3e646480cdde60df2a6f1 | 6735 | 26 |      def bgrewriteaof(self, **kwargs):         """Tell the Redis server to rewrite the AOF file from data in memory.          For more information see https://redis.io/commands/bgrewriteaof |
| .venv/lib/python3.13/site-packages/redis/commands/cluster.py | bdd59da65e263f9d68a9f6016478390945edea33da369eda08b1f24e2783aedf | 920 | 9 |         return self.execute_command("CLUSTER MYID", target_nodes=target_node)      def cluster_addslots(         self, target_node: "TargetNodesT", *slots: EncodableT     ) -> ResponseT: |
| .venv/lib/python3.13/site-packages/redis/commands/redismodules.py | fa42cce1106494384d87e3170ab6bcd594d2b2d210fae95169beafd1d6144dd0 | 102 | 7 |     from .search import AsyncSearch, Search     from .timeseries import TimeSeries     from .vectorset import VectorSet   |
| .venv/lib/python3.13/site-packages/redis/commands/timeseries/info.py | 99e65876eec857d29a51630a66cf6a5b8be8dd0f4cc21758f8406d290ce5b39a | 92 | 6 |     sourceKey = None     chunk_count = None     memory_usage = None     total_samples = None     retention_msecs = None |
| .venv/lib/python3.13/site-packages/redis/commands/timeseries/commands.py | f19d811323f6dea4d808947f7bdcdd1b5d725a6203c0604c3b63c934bb4ad810 | 1137 | 5 |                 key.             chunk_size:                 Memory size, in bytes, allocated for each data chunk. Must be a multiple                 of 8 in the range `[48..1048576]`. In earlier vers |
| .venv/lib/python3.13/site-packages/redis/commands/search/field.py | 83d2352c7ad524a3b52ad894c28b71ad0be983cf5efacc76ea80a51ee68a4e7f | 211 | 12 |     GEO = "GEO"     TAG = "TAG"     VECTOR = "VECTOR"     SORTABLE = "SORTABLE"     NOINDEX = "NOINDEX" |
| .venv/lib/python3.13/site-packages/redis/commands/search/commands.py | e259cbecc5eca7d5ea3325203f127d4baa7c0519ec22b8d7bb0bd24cbf6aa371 | 1157 | 2 |         """         Get info an stats about the the current index, including the number of         documents, memory consumption, etc          For more information see `FT.INFO <https://redis.io/comma |
| .venv/lib/python3.13/site-packages/redis/commands/json/commands.py | 8a1f2ea67c5e3a98cf65735fa9e1416318823760a6caff141aedc09509d3e894 | 432 | 3 |         path: Optional[str] = Path.root_path(),     ) -> Union[int, List[str]]:         """Return the memory usage in bytes of a value under ``path`` from         key ``name``.  |
| .venv/lib/python3.13/site-packages/redis/commands/vectorset/__init__.py | fdf33451d623bb3b3c6162148d0187f505f91702344a8f3f0fee402d65ab5857 | 47 | 5 |  from redis._parsers.helpers import pairs_to_dict from redis.commands.vectorset.utils import (     parse_vemb_result,     parse_vlinks_result, |
| .venv/lib/python3.13/site-packages/redis/commands/vectorset/utils.py | 37ec74511ca0efa5c2dfd08d7c1ca6e85905095826e4db61cd62819dcd87d177 | 95 | 2 | from redis._parsers.helpers import pairs_to_dict from redis.commands.vectorset.commands import CallbacksOptions   |
| .venv/lib/python3.13/site-packages/redis/commands/vectorset/commands.py | c577d0a88eff5566d4b3207051ae45a192c5d746a524332d6686bf1f955b1854 | 375 | 41 |   class VectorSetCommands(CommandsProtocol):     """Redis VectorSet commands"""  |
| .venv/lib/python3.13/site-packages/redis/commands/bf/info.py | fce076bff8403c8f66755362071f2352d1f632132872df59466f9ef089fac10a | 121 | 3 |     unmerged_weight = None     total_compressions = None     memory_usage = None      def __init__(self, args): |
| .venv/lib/python3.13/site-packages/redis/commands/bf/commands.py | c5e2adf04ec6f0707e97ddb62740cb834ec210865354d1b1ff62dfcb0d6021c9 | 539 | 1 |     def create(self, key, compression=100):         """         Allocate the memory and initialize the t-digest.         For more information see `TDIGEST.CREATE <https://redis.io/commands/tdigest.cre |
| .venv/lib/python3.13/site-packages/redis/asyncio/client.py | e9ae7eb7161c44cb4e6e46fb05f8b4f0c290418d35a32e4d2a91c095f84814d3 | 1619 | 1 |             }          # if this is an unsubscribe message, remove it from memory         if message_type in self.UNSUBSCRIBE_MESSAGE_TYPES:             if message_type == "punsubscribe": |
| .venv/lib/python3.13/site-packages/redis/asyncio/__init__.py | ba80c3f176158b42a3ea672e7d8c0b0d44d05e6051c7b6b46e1285f6cb59afb2 | 65 | 2 |     DataError,     InvalidResponse,     OutOfMemoryError,     PubSubError,     ReadOnlyError, |
| .venv/lib/python3.13/site-packages/redis/asyncio/connection.py | 0f6f0e79c7ee7d27fa736809f14849868ae158ca477851f1c48696c6fbd01e87 | 1340 | 4 |         for arg in map(self.encoder.encode, args):             # to avoid large string mallocs, chunk the command into the             # output list if we're sending large values or memoryviews        |
| .venv/lib/python3.13/site-packages/redis/asyncio/lock.py | 1b1815e84b322a932387be0ab5a38fc61e1f34fbb0029cfa4e1e3aaa1beb030b | 335 | 1 |         self,         redis: Union["Redis", "RedisCluster"],         name: Union[str, bytes, memoryview],         timeout: Optional[float] = None,         sleep: float = 0.1, |
| .venv/lib/python3.13/site-packages/redis/_parsers/encoders.py | 5f48ef4e9f84e13654959c55e4b249f3c4ee56b175be5cb9b6e0b4c63c466927 | 45 | 2 |     def encode(self, value):         "Return a bytestring or bytes-like representation of the value"         if isinstance(value, (bytes, memoryview)):             return value         elif isinstance |
| .venv/lib/python3.13/site-packages/redis/_parsers/socket.py | 08a0fc416ff0152365219cf195b35db9a1a98afd08f3005cb06b802288c37c98 | 163 | 2 |          # Only if we have read all of the buffer do we truncate, to         # reduce the amount of memory thrashing.  This heuristic         # can be changed or removed later.         if unread > 0: |
| .venv/lib/python3.13/site-packages/redis/_parsers/helpers.py | 63a9f5e1f13478261b1774c1b89c61c9c9c9d721ca898a0026b38251a896a258 | 884 | 8 |   def parse_memory_stats(response, **kwargs):     """Parse the results of MEMORY STATS"""     stats = pairs_to_dict(response, decode_keys=True, decode_string_values=True) |
| .venv/lib/python3.13/site-packages/redis/_parsers/commands.py | a66478865e2ef7752f0a678381e3c715cea9583af8b25aca12f0ac74c9ad8ff3 | 282 | 6 |         if cmd_name not in self.commands:             # try to split the command name and to take only the main command,             # e.g. 'memory' for 'memory usage'             cmd_name_split = cmd |
| .venv/lib/python3.13/site-packages/redis/_parsers/base.py | 93a9fbfa84e69b30148a2669681e957e3ce58ffb68af006c68f04461d3930da9 | 290 | 2 |     NoPermissionError,     NoScriptError,     OutOfMemoryError,     ReadOnlyError,     RedisError, |
| .venv/lib/python3.13/site-packages/jinja2/utils.py | ad1a77a3d7bb64a4b87f2ad645b10bc8b729b8655315c9e8a1a39ad6ac7f1489 | 767 | 1 |     used so that Jinja doesn't have to recreate environments and lexers all     the time.  Normally you don't have to care about that but if you are     measuring memory consumption you may want to cl |
| .venv/lib/python3.13/site-packages/jinja2/lexer.py | 2d88988a8e9bafe4dea7d9cf72ea565ec3c4b6396ec37a75994fa534155151f9 | 869 | 1 |                                 # If there's only whitespace between the newline and the                                 # tag, strip it.                                 if whitespace_re.fullmatch(tex |
| .venv/lib/python3.13/site-packages/jinja2/environment.py | f6786b3fb0a1f8d6c65f4d30bf2af8cb2fae84d1ead8e09ceb48201ab9e2fdf9 | 1673 | 3 |         :meth:`join_path` if necessary, not the filename on the file system.         the `filename` parameter is the estimated filename of the template on         the file system.  If the template cam |
| .venv/lib/python3.13/site-packages/jinja2/nativetypes.py | ec620600b54981dc8bf34a1925d4146947f04ade6ada549265b5edd1d35ffcce | 131 | 1 |             parse(raw, mode="eval")         )     except (ValueError, SyntaxError, MemoryError):         return raw  |
| .venv/lib/python3.13/site-packages/jinja2/tests.py | 54bb018551675a0f8fc52073d4c8519cd5a03f5a2f5e4de778ed452d031e0bd4 | 257 | 1 |  def test_sameas(value: t.Any, other: t.Any) -> bool:     """Check if an object points to the same memory address than another     object:  |
| .venv/lib/python3.13/site-packages/jinja2/filters.py | 3d0fc481df67f634a0b671906321782b98f69d8c21508ba584f9f28a691dafe9 | 1874 | 1 |      for scheme in extra_schemes:         if _uri_scheme_re.fullmatch(scheme) is None:             raise FilterArgumentError(f"{scheme!r} is not a valid URI scheme prefix.")  |
| .venv/lib/python3.13/site-packages/cryptography/utils.py | afdd15b5a9828e26dadfba2616aa7669afbe7844155e240832bbd678b4fe058e | 140 | 2 | # (and do things like take a `len()`). if sys.version_info >= (3, 9):     Buffer = typing.Union[bytes, bytearray, memoryview] else:     Buffer = typing.ByteString |
| .venv/lib/python3.13/site-packages/cryptography/hazmat/decrepit/ciphers/algorithms.py | 62b2a01d2e0c7f059a3263c1611ca6451942d298705a9f727080857b37893c69 | 113 | 2 |   class ARC4(CipherAlgorithm):     name = "RC4"     key_sizes = frozenset([40, 56, 64, 80, 128, 160, 192, 256]) |
| .venv/lib/python3.13/site-packages/cryptography/hazmat/primitives/kdf/scrypt.py | 5f259475452686e23d57a4ea00f3afba3092306bf55d0760d1adb52160a63be5 | 20 | 1 | from cryptography.hazmat.primitives.kdf import KeyDerivationFunction  # This is used by the scrypt tests to skip tests that require more memory # than the MEM_LIMIT _MEM_LIMIT = sys.maxsize // 2 |
| .venv/lib/python3.13/site-packages/cryptography/hazmat/primitives/serialization/ssh.py | 09e0d20ff2a6b5ca500d2520f106378ebb990ce2a38d604a7140720ce1905e76 | 1620 | 64 |  # padding for max blocksize _PADDING = memoryview(bytearray(range(1, 1 + 16)))   |
| .venv/lib/python3.13/site-packages/cryptography/hazmat/primitives/ciphers/algorithms.py | 4b4e23e0d7450810ede4a2c8bdb6288688513bef8c09685389afe5915b7cc43f | 184 | 6 | from cryptography import utils from cryptography.hazmat.decrepit.ciphers.algorithms import (     ARC4 as ARC4, ) from cryptography.hazmat.decrepit.ciphers.algorithms import ( |
| .venv/lib/python3.13/site-packages/cryptography/hazmat/primitives/ciphers/modes.py | db4b2da70843b5b02fa47d1231ff440c721c8b099317e24c054399f5b53c5a24 | 269 | 49 |   class ModeWithInitializationVector(Mode, metaclass=abc.ABCMeta):     @property     @abc.abstractmethod |
| .venv/lib/python3.13/site-packages/cryptography/hazmat/primitives/ciphers/base.py | 6810bb1c7041a22c5e6e6a5aad5af4525383b37543d00ec1ea8cff01a4630eff | 147 | 1 |         modes.ModeWithTweak,         modes.ECB,         modes.ModeWithInitializationVector,         None,     ] |
| .venv/lib/python3.13/site-packages/cryptography/hazmat/primitives/asymmetric/ec.py | 55fe628363dc4b73d59ec6f9378f4ac75b88905049ca18380565d3843cf972e8 | 448 | 4 |     name = "sect409k1"     key_size = 409     group_order = 0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFE5F83B2D4EA20400EC4557D5ED3E3E7CA5B4B5C83B8E01E5FCF  # noqa: E501   |
| .venv/lib/python3.13/site-packages/cryptography/x509/name.py | a22d02a98fc1ef6084260357cbd5e42726b6e905977f039e1890587d78d162f2 | 478 | 22 |  #: Short attribute names from RFC 4514: #: https://tools.ietf.org/html/rfc4514#page-7 _NAMEOID_TO_NAME: _OidNameMap = {     NameOID.COMMON_NAME: "CN", |
| .venv/lib/python3.13/site-packages/opentelemetry/metrics/_internal/__init__.py | ed585f637a65e062a91268d4da86412c96265fb24696c8e4a0b6ca791f60b288 | 890 | 1 |             )          To reduce memory usage, you can use generator callbacks instead of         building the full list::  |
| .venv/lib/python3.13/site-packages/opentelemetry/metrics/_internal/instrument.py | 1224975fa8cfb5399bdba16258d6ec01cf76cb38212bd709f800028714edd67e | 531 | 2 |         result: Dict[str, Optional[str]] = {}          if _name_regex.fullmatch(name) is not None:             result["name"] = name         else: |
| .venv/lib/python3.13/site-packages/opentelemetry/trace/span.py | e1021cd18b8fbe42ec57ccd6a15882a3e0e116385350ec35fca9a2a289a43ccc | 609 | 3 |     return (         isinstance(key, str)         and _KEY_PATTERN.fullmatch(key) is not None         and isinstance(value, str)         and _VALUE_PATTERN.fullmatch(value) is not None |
| .venv/lib/python3.13/site-packages/opentelemetry/proto/profiles/v1development/profiles_pb2.py | 909654ff53edba0c0338dd757851ff6831b261ae5523202f81b9a823012ec6b5 | 56 | 2 |   DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n9opentelemetry/proto/profiles/v1development/profiles.proto\x12*opentelemetry.proto.profiles.v1development\x1a*opentelemetry/proto/common |
| .venv/lib/python3.13/site-packages/opentelemetry/util/re.py | 2b73414271890591281543b63b4e5884bbbb571a2a9be41b6e3178cfac0c998f | 117 | 2 |         if not header:  # empty string             continue         header_match = _HEADER_PATTERN.fullmatch(header.strip())         if not header_match and not liberal:             _logger.warning( |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/metrics/__init__.py | 26b734b95d3c8d170abf873bb46ebf77dcecb22f37fcb85ea678535b8871b99d | 217 | 17 |     """      PROCESS_RUNTIME_JVM_MEMORY_INIT = "process.runtime.jvm.memory.init"     """     Measure of initial memory requested |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/metrics/cicd_metrics.py | cfa987b582edaf6d518fa9a97e551331ea6f6328cc517ea7278e88f51333d861 | 106 | 3 | CICD_SYSTEM_ERRORS: Final = "cicd.system.errors" """ The number of errors in a component of the CICD system (eg. controller, scheduler, agent) Instrument: counter Unit: {error} |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/metrics/container_metrics.py | c46f908861294ee1a02d0a3d18a5aa2407b84a6247e4bd94792696c7788d53b5 | 153 | 8 |   CONTAINER_MEMORY_USAGE: Final = "container.memory.usage" """ Memory usage of the container |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/metrics/faas_metrics.py | 84066e04a66f6be8ab5d4007be218d36c0abc68bb224a7166287333b81703d17 | 171 | 3 | FAAS_MEM_USAGE: Final = "faas.mem_usage" """ Distribution of max memory usage per invocation Instrument: histogram Unit: By |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/metrics/system_metrics.py | 67c3549ad4c9b0d0c886e7917a854baaee2ad866baaee170e1f9826f71c1c2ea | 633 | 51 |   SYSTEM_LINUX_MEMORY_AVAILABLE: Final = "system.linux.memory.available" """ An estimate of how much memory is available for starting new applications, without causing swapping |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/metrics/process_metrics.py | 104d698e79d6e10a2b4ab989bccd68163ccc4e2e3be3b9579e04484f5decb099 | 236 | 14 |   PROCESS_MEMORY_USAGE: Final = "process.memory.usage" """ The amount of physical memory in use |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/metrics/k8s_metrics.py | 128be8a49ecab944698ea77cf97dfebd79bdda9911588ef9807caf7550b91b4b | 1687 | 65 |   K8S_CONTAINER_MEMORY_LIMIT: Final = "k8s.container.memory.limit" """ Maximum memory resource limit set for the container |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/db_attributes.py | e911132501b673c92860e1daa0cdaa58580dfbccd95e19a09f537a15ede177b3 | 592 | 3 | """  DB_CASSANDRA_IDEMPOTENCE: Final = "db.cassandra.idempotence" """ Deprecated: Replaced by `cassandra.query.idempotent`. |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/k8s_attributes.py | 0c65f107780cca6d624ec8048de738da08243a6e3aa57fadd9b1a36590bd59be | 552 | 5 |     """The container image pull is in back off state."""     OOM_KILLED = "OOMKilled"     """The container was killed due to out of memory."""     COMPLETED = "Completed"     """The container has comp |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/system_attributes.py | 810a4d58a7157f1751382470e5d759429c4fb89dbd898407176447027d4cfbe3 | 222 | 8 | """  SYSTEM_MEMORY_STATE: Final = "system.memory.state" """ The memory state. |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/cassandra_attributes.py | 6b90266b1c8b13b443c0f948311ff20bf2ca46eecc570917c467f76ed56bd1e3 | 74 | 3 | """  CASSANDRA_QUERY_IDEMPOTENT: Final = "cassandra.query.idempotent" """ Whether or not the query is idempotent. |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/faas_attributes.py | 955feb4a953b4f1b395554fce825672adc7d718b5fceca053f8daaf8e8d0be5a | 162 | 5 | """  FAAS_MAX_MEMORY: Final = "faas.max_memory" """ The amount of memory available to the serverless function converted to Bytes. |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/linux_attributes.py | 20007567794819a30bcb331e473b0d7b6cb22e63b38b5727feff26f8c5cccf1a | 29 | 4 | from typing import Final  LINUX_MEMORY_SLAB_STATE: Final = "linux.memory.slab.state" """ The Linux Slab memory state. |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/hw_attributes.py | de287556bdbd5cc39b2e0ad2e8215ef5417f076b3ebc8ac171671aa17cd72e33 | 83 | 3 |     LOGICAL_DISK = "logical_disk"     """Logical disk."""     MEMORY = "memory"     """Memory."""     NETWORK = "network" |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/service_attributes.py | 4d3e1305a430e6d40f447a86fd506697fa3f2a4b08a7adfc267e4836785da470 | 63 | 1 |  Implementations, such as SDKs, are recommended to generate a random Version 1 or Version 4 [RFC 4122](https://www.ietf.org/rfc/rfc4122.txt) UUID, but are free to use an inherent unique ID as the sour |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/gen_ai_attributes.py | 6a56beff46577ce7cab4c69b9ff75d2242ae9ff0245df54393702b276698a86a | 336 | 33 | from typing_extensions import deprecated  GEN_AI_AGENT_DESCRIPTION: Final = "gen_ai.agent.description" """ Free-form description of the GenAI agent provided by the application. |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/process_attributes.py | d6094ce17063c20cba917f8b82501c4f1cefb42a68e9684e905fbb129b844dfd | 241 | 1 | PROCESS_COMMAND_ARGS: Final = "process.command_args" """ All the command arguments (including the command/executable itself) as received by the process. On Linux-based systems (and some other Unixoid  |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/browser_attributes.py | 1ce91da459092d1536f74d2de5bed43fbd66b86d291f8247e46f16d2eb701297 | 41 | 5 | """ Array of brand name and version separated by a space. Note: This value is intended to be taken from the [UA client hints API](https://wicg.github.io/ua-client-hints/#interface) (`navigator.userAge |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/http_attributes.py | 3cb0698eba29d7540cc80062b17dd6a699e44e5b868ad7eb70f5ef6200d0a615 | 204 | 3 | """  HTTP_USER_AGENT: Final = "http.user_agent" """ Deprecated: Replaced by `user_agent.original`. |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/security_rule_attributes.py | 80f7e6ec0e769be26881963a4874cbb45a97bbe294153fbf955b9eba5fdbfa58 | 57 | 1 | SECURITY_RULE_UUID: Final = "security_rule.uuid" """ A rule ID that is unique within the scope of a set or group of agents, observers, or other entities using the rule for detection of this event. """ |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/host_attributes.py | 9cfebc97950d6a19b56e37bfadc98f6519011276a03a9b109ca4475e07f9bad9 | 114 | 2 | HOST_CPU_CACHE_L2_SIZE: Final = "host.cpu.cache.l2.size" """ The amount of level 2 memory cache available to the processor (in Bytes). """  |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/user_agent_attributes.py | 679de5524eaec3a7c2a010f382b39fd6744c28f0094e54116adea8ba2b051ddb | 59 | 26 | from typing import Final  USER_AGENT_NAME: Final = "user_agent.name" """ Name of the user-agent extracted from original. Usually refers to the browser's name. |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/telemetry_attributes.py | b1726dda9bc05751e72ae741d24e138a24e6a7ba7c7bc0c5991702cb5aa84183 | 76 | 3 | TELEMETRY_DISTRO_NAME: Final = "telemetry.distro.name" """ The name of the auto instrumentation agent or distribution, if used. Note: Official auto instrumentation agents and distributions SHOULD set  |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/cicd_attributes.py | 6022c59d0c688cbb15491f5866dc98f2cbba179545d250ea0fd1a6ccfa0c2d4d | 163 | 2 | CICD_WORKER_STATE: Final = "cicd.worker.state" """ The state of a CICD worker / agent. """  |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/_incubating/attributes/aws_attributes.py | 62214092d424a083dc990f888f93a4fd8302864c01fff752fb5dec2b7c56d39d | 346 | 2 | from typing import Final  AWS_BEDROCK_GUARDRAIL_ID: Final = "aws.bedrock.guardrail.id" """ The unique identifier of the AWS Bedrock Guardrail. A [guardrail](https://docs.aws.amazon.com/bedrock/latest/ |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/trace/__init__.py | a291189c4f0e8eff7e9999a3792e55bbc4cb7ffe8f8d344a966014b4c04c58a0 | 2208 | 13 |     TYPE = "type"     """     The type of memory.     """  |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/attributes/http_attributes.py | 96e7757ecbdc78a02d842ff7ca3dfec6539c6d5a18890844aef04b92c7f65254 | 123 | 2 | Including all request headers can be a security risk - explicit configuration helps avoid leaking sensitive information.  The `User-Agent` header is already captured in the `user_agent.original` attri |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/attributes/user_agent_attributes.py | 3ac6b997a62e25891bc71acdec5c629fb8578388e46a89122020c9123300b5a3 | 21 | 4 | from typing import Final  USER_AGENT_ORIGINAL: Final = "user_agent.original" """ Value of the [HTTP User-Agent](https://www.rfc-editor.org/rfc/rfc9110.html#field.user-agent) header sent by the client. |
| .venv/lib/python3.13/site-packages/opentelemetry/semconv/resource/__init__.py | f305ad8ef142f538ce25e37497d4ca56c6864f67fc3d0d7edd9a0c12bfd0aaec | 887 | 18 |     """     Array of brand name and version separated by a space.     Note: This value is intended to be taken from the [UA client hints API](https://wicg.github.io/ua-client-hints/#interface) (`navig |
| .venv/lib/python3.13/site-packages/opentelemetry/sdk/environment_variables/__init__.py | fc9e1bac975448ad138fd6fe36bca8b5ed7119e7dfcc94b2f3f5e2cf41475c67 | 723 | 15 | """  OTEL_EXPORTER_JAEGER_AGENT_HOST = "OTEL_EXPORTER_JAEGER_AGENT_HOST" """ .. envvar:: OTEL_EXPORTER_JAEGER_AGENT_HOST |
| .venv/lib/python3.13/site-packages/opentelemetry/sdk/metrics/_internal/export/__init__.py | 82255da115475d7d6ed77b2a7d6a0a5cacc2320e7a62ac4207295de182146643 | 577 | 1 |   class InMemoryMetricReader(MetricReader):     """Implementation of `MetricReader` that returns its metrics from :func:`get_metrics_data`.  |
| .venv/lib/python3.13/site-packages/opentelemetry/sdk/metrics/export/__init__.py | 1a0e97da23151eb509ed49222993d4ccd851cbae47ab53c6f93940cfe47914a8 | 67 | 2 |     AggregationTemporality,     ConsoleMetricExporter,     InMemoryMetricReader,     MetricExporter,     MetricExportResult, |
| .venv/lib/python3.13/site-packages/opentelemetry/sdk/trace/export/in_memory_span_exporter.py | 1ffe1345a4e130ed47eaf510d0ea50bf3264fdf647d0e3ac440335899417b11f | 62 | 4 |   class InMemorySpanExporter(SpanExporter):     """Implementation of :class:`.SpanExporter` that stores spans in memory.  |
| .venv/lib/python3.13/site-packages/opentelemetry/sdk/_logs/_internal/export/in_memory_log_exporter.py | 6e45509869e49315f7c050cd33fe80ba68e3a70ec98e7bdfcde97fe7d6f22005 | 52 | 3 |   class InMemoryLogExporter(LogExporter):     """Implementation of :class:`.LogExporter` that stores logs in memory.  |
| .venv/lib/python3.13/site-packages/opentelemetry/sdk/_logs/export/__init__.py | 9d41dd5cd830a9f0ded0aa0690d057ed797f9a8e3bee2c8adcdd03e411fd8368 | 36 | 3 |  # The point module is not in the export directory to avoid a circular import. from opentelemetry.sdk._logs._internal.export.in_memory_log_exporter import (     InMemoryLogExporter, ) |
| .venv/lib/python3.13/site-packages/opentelemetry/exporter/otlp/proto/grpc/__init__.py | 076d73c7aa85d5560741cae02f897478aac55d8e5f40e68b484fd0ed87f97861 | 80 | 4 | from .version import __version__  _USER_AGENT_HEADER_VALUE = "OTel-OTLP-Exporter-Python/" + __version__ _OTLP_GRPC_CHANNEL_OPTIONS = [     # this will appear in the http User-Agent header |
| .venv/lib/python3.13/site-packages/opentelemetry/exporter/otlp/proto/common/_internal/metrics_encoder/__init__.py | 53709e0640ce7c8e613f8472da1dea7eca3786f5e11563a9e9c446dc5779ddda | 389 | 1 |             }          elif otel_exporter_otlp_metrics_temporality_preference == "LOWMEMORY":             instrument_class_temporality = {                 Counter: AggregationTemporality.DELTA, |
| .venv/lib/python3.13/site-packages/opentelemetry/baggage/__init__.py | 6264aef71e76813cc3aa40ba29957be7810096bdb5e3d4acbc7aab8c1578fd85 | 137 | 3 |  def _is_valid_key(name: str) -> bool:     return _KEY_PATTERN.fullmatch(str(name)) is not None   |
| .venv/lib/python3.13/site-packages/soupsieve/__meta__.py | ef6e27bc294fa195a70be6ca809aa2053d16c76a44c5b11123d3765614d9e26e | 198 | 1 |     Version(1, 2, 0, ".dev-alpha", pre=4)        1.2a4     Version(1, 2, 0, ".dev-beta", pre=4)         1.2b4     Version(1, 2, 0, ".dev-candidate", pre=4)    1.2rc4     Version(1, 2, 0, "final", post |
| .venv/lib/python3.13/site-packages/nltk/langnames.py | 3fdb86f930699dea9384e7c924a980bde597ac00d54f507e35c69901097be80a | 731 | 1 |     tags = tag.split("-")     code = tags[0].lower()     if codepattern.fullmatch(code):         if code in iso639retired:  # retired codes             return iso639retired[code] |
| .venv/lib/python3.13/site-packages/nltk/util.py | ebccedb76cfda03f1c9d22f931e354c0f43af2ac26406d2772ec2e04818837fa | 1307 | 2 |      print(f"{obj.__name__} supports the following operations:")     for name, method in sorted(pydoc.allmethods(obj).items()):         if name.startswith("_"):             continue |
| .venv/lib/python3.13/site-packages/nltk/collections.py | fee81aac5c4d553ad3de0156876139d9505452b0c4117ad26c5f8e6d29347825 | 657 | 8 |     The most common application of lazy sequences in NLTK is for     corpus view objects, which provide access to the contents of a     corpus without loading the entire corpus into memory, by loading |
| .venv/lib/python3.13/site-packages/nltk/featstruct.py | 2c11a2c1c7a06a856db894f449b71a0192fa2d2e14d551b25e6ca0df5b8b43fe | 2780 | 1 |         """         Display a single-line representation of this feature structure,         suitable for embedding in other representations.         """         return self._repr(self._find_reentrance |
| .venv/lib/python3.13/site-packages/nltk/tree/prettyprinter.py | b19a43336d5a94450131b2e6d74a81435848b138196e3e457adbca2f4c642efe | 628 | 1 |     "yellow": 33,     "blue": 34,     "magenta": 35,     "cyan": 36,     "white": 37, |
| .venv/lib/python3.13/site-packages/nltk/cluster/util.py | be6cc45297c5be531026a4913c89bff12b3c1e566833d3ca99dceb337b250191 | 301 | 60 |   class VectorSpaceClusterer(ClusterI):     """     Abstract clusterer which takes tokens and maps them into a vector space. |
| .venv/lib/python3.13/site-packages/nltk/cluster/__init__.py | 4d257d70159303ee3a23d318e44dc8504a2a97ef17645a8e0809554e1bec061c | 93 | 18 | This module contains a k-means clusterer, E-M clusterer and a group average agglomerative clusterer (GAAC). All these clusterers involve finding good cluster groupings for a set of vectors in multi-di |
| .venv/lib/python3.13/site-packages/nltk/cluster/gaac.py | 093a32f578f480594e236eb894cd29af1a62639ff1974a22117dca0a1b0b4776 | 171 | 28 |     pass  from nltk.cluster.util import Dendrogram, VectorSpaceClusterer, cosine_distance   |
| .venv/lib/python3.13/site-packages/nltk/cluster/em.py | 4cf17953256f83a44da6e3012f3400858de0ef40366ec52be25c0aa115290e7d | 220 | 41 |     pass  from nltk.cluster.util import VectorSpaceClusterer   |
| .venv/lib/python3.13/site-packages/nltk/cluster/kmeans.py | 295199fe56c5e8bbf66f0ed3a0f64901aa66526e72c9936266262960cc5262c8 | 231 | 45 |   from nltk.cluster.util import VectorSpaceClusterer   |
| .venv/lib/python3.13/site-packages/nltk/cluster/api.py | aef5bdd0bb5cdd62360ea4ba2be47acf4692b073d5d4dad64a41c5e31e1b578b | 75 | 7 |      @abstractmethod     def cluster(self, vectors, assign_clusters=False):         """         Assigns the vectors to clusters, learning the clustering parameters |
| .venv/lib/python3.13/site-packages/nltk/app/nemo_app.py | 60f87ee8ff6090cf21060b253e428fce339ad421c89ca5b3205a0a425e666bfd | 164 | 12 | """ images = {     "FIND": "R0lGODlhMAAiAPcAMf/////37//35//n1v97Off///f/9/f37/fexvfOvfeEQvd7QvdrQvdrKfdaKfdSMfdSIe/v9+/v7+/v5+/n3u/e1u/Wxu/Gre+1lO+tnO+thO+Ua+97Y+97Oe97Me9rOe9rMe9jOe9jMe9jIe9aMefe5+fe |
| .venv/lib/python3.13/site-packages/nltk/classify/util.py | f1b1a93f62629f60a04f1d127872956479ee1cfdc96980bb1431cdc144cb5d40 | 348 | 2 |         [(feature_func(tok), label) for (tok, label) in toks]      The primary purpose of this function is to avoid the memory     overhead involved in storing all the featuresets for every token      |
| .venv/lib/python3.13/site-packages/nltk/classify/weka.py | 029184f705733732c6e98abd8d9de2543e20c75a3b5adba396b8892db43ff417 | 378 | 2 |     _CLASSIFIER_CLASS = {         "naivebayes": "weka.classifiers.bayes.NaiveBayes",         "C4.5": "weka.classifiers.trees.J48",         "log_regression": "weka.classifiers.functions.Logistic",      |
| .venv/lib/python3.13/site-packages/nltk/classify/maxent.py | e6c3f7e9e81cab17334382ca3b30116dfc59c28416606b12b1ae1cfb313bc6c2 | 1632 | 61 | distribution with the highest entropy.  A probability distribution is "empirically consistent" with a set of training data if its estimated frequency with which a class and a feature vector value co-o |
| .venv/lib/python3.13/site-packages/nltk/classify/scikitlearn.py | 9d6640ab10fea4c2dbd0e0d1e1669d401e30cf6ecdf676d4af8e03dcd53efe68 | 144 | 7 |  try:     from sklearn.feature_extraction import DictVectorizer     from sklearn.preprocessing import LabelEncoder except ImportError: |
| .venv/lib/python3.13/site-packages/nltk/classify/megam.py | 83e1d7b124ec3270a6471692fd7fba2a2e75e8ec61d40191cea1004e99c0ab84 | 185 | 5 |     :type encoding: MaxentFeatureEncodingI     :param encoding: A feature encoding, used to convert featuresets         into feature vectors. May optionally implement a cost() method         in order  |
| .venv/lib/python3.13/site-packages/nltk/classify/tadm.py | 0dccc4b6b96b73ac707a0a646e59e7973aa959a33873b864df08c07d641c7536 | 123 | 2 |     :type encoding: TadmEventMaxentFeatureEncoding     :param encoding: A feature encoding, used to convert featuresets         into feature vectors.     :type stream: stream     :param stream: The st |
| .venv/lib/python3.13/site-packages/nltk/classify/svm.py | 62ee120774b3c073cfb33183b44db3fddc7744ae148fe8af539d89476c5ea149 | 18 | 1 | """ nltk.classify.svm was deprecated. For classification based on support vector machines SVMs use nltk.classify.scikitlearn (or `scikit-learn <https://scikit-learn.org>`_ directly). """ |
| .venv/lib/python3.13/site-packages/nltk/chat/eliza.py | 5ee3d6d03b8071510b4ce4e3bb1cc742ad7eb789051043890eab86dc43cacee7 | 338 | 1 |         (             "Did you have close friends as a child?",             "What is your favorite childhood memory?",             "Do you remember any dreams or nightmares from childhood?",           |
| .venv/lib/python3.13/site-packages/nltk/translate/api.py | 0b626e41b1d290a5739cdbd70118481930e0529875042ee1e15a73bb2598e49e | 336 | 1 | class PhraseTable:     """     In-memory store of translations for a given phrase, and the log     probability of the those translations     """ |
| .venv/lib/python3.13/site-packages/nltk/lm/__init__.py | 184b019088bb73b40ef58e20971bbdea17cc237e6a5d27b5cace9c90da3b5a5f | 236 | 1 |     >>> train, vocab = padded_everygram_pipeline(2, text)  So as to avoid re-creating the text in memory, both `train` and `vocab` are lazy iterators. They are evaluated on demand at training time.  |
| .venv/lib/python3.13/site-packages/nltk/sem/chat80.py | 212c1216efd402acfeee9c41728fcb669c8f62cbec3c8f8f33f0ed09bc5f4079 | 858 | 1 | def _str2records(filename, rel):     """     Read a file into memory and convert each relation clause into a list.     """     recs = [] |
| .venv/lib/python3.13/site-packages/nltk/sem/boxer.py | 67583a2efcadf8482d2f1725f16746267659cbea4ac147d78b432b501cda784d | 1610 | 1 |      def _handle_rel(self):         # rel(_G3993, _G3943, agent, 0)         self.assertToken(self.token(), "(")         var1 = self.parse_variable() |
| .venv/lib/python3.13/site-packages/nltk/sem/relextract.py | 99fc833de5a4b036dfd5eef8670ef5ef8b5e61755b2839c543c4bfdc6999053d | 540 | 2 |      If the sql parameter is set to True, then the entity pairs are loaded into     an in-memory database, and subsequently pulled out using an SQL "SELECT"     query.     """ |
| .venv/lib/python3.13/site-packages/nltk/corpus/util.py | e1049dbb778fc810cc3dfd46eb91535591368241f492416956e7f0e98ce470da | 154 | 1 |         # _unload support: assign __dict__ and __class__ back, then do GC.         # after reassigning __dict__ there shouldn't be any references to         # corpus data so the memory should be deall |
| .venv/lib/python3.13/site-packages/nltk/corpus/reader/reviews.py | be04dcd7cd260566f12e38d0640f93ee8da09ddce6a84a577b32afe419bfb460 | 332 | 1 | - Minqing Hu and Bing Liu. "Mining Opinion Features in Customer Reviews".     Proceedings of Nineteeth National Conference on Artificial Intelligence     (AAAI-2004), 2004.  - Xiaowen Ding, Bing Liu a |
| .venv/lib/python3.13/site-packages/nltk/corpus/reader/udhr.py | 24daafd442339ad85c0ead2258d295a7365934c7016a1e63234b5de620a7dd13 | 75 | 1 |         ("Amahuaca", "latin1"),         ("Turkish_Turkce-Turkish", "latin5"),         ("Lithuanian_Lietuviskai-Baltic", "latin4"),         ("Japanese_Nihongo-EUC", "EUC-JP"),         ("Japanese_Nihong |
| .venv/lib/python3.13/site-packages/nltk/corpus/reader/util.py | 6591aa9d58753397ac5929b9ae47aa6f0f8f69b76385902cbaccd6eb4ad07bcc | 781 | 2 |     it can be accessed by index, iterated over, etc.  However, the     tokens are only constructed as-needed -- the entire corpus is     never stored in memory at once.      The constructor to ``Strea |
| .venv/lib/python3.13/site-packages/nltk/corpus/reader/bcp47.py | 927f70a3f8028c00a3d1e961dd523aea93b9bcb1fa429114942298a9b3dfca6f | 219 | 2 |                 label = labels.pop(0)                 subtag = self.casing[label](subtag)                 if self.format[label].fullmatch(subtag):                     if subtag in self.db[label]:      |
| .venv/lib/python3.13/site-packages/nltk/corpus/reader/framenet.py | 31ce28f139fd356c877de67729f15ad600f0645625ae8d42bc3df002c5793f94 | 3429 | 1 | =========  buildindexes() loads metadata about all frames, LUs, etc. into memory to avoid   delay when one is accessed for the first time. It does not load annotations. readme() gives the text of the  |
| .venv/lib/python3.13/site-packages/nltk/corpus/reader/comparative_sents.py | 4208c247c152d6063bfefa8779f97cc5267fddaa058ca6af4d5fdcdd4708cb4e | 310 | 1 | - Nitin Jindal and Bing Liu. "Mining Comprative Sentences and Relations".    Proceedings of Twenty First National Conference on Artificial Intelligence    (AAAI-2006), 2006.  - Murthy Ganapathibhotla  |
| .venv/lib/python3.13/site-packages/nltk/corpus/reader/wordnet.py | 17a8fa8b757ae234adf8be5382c58f5ee9fa6e7970d71e64c95c84f9de97d8fc | 2489 | 2 |         self._load_lemma_pos_offset_map()          # load the exception file data into memory         self._load_exception_map()  |
| .venv/lib/python3.13/site-packages/nltk/parse/nonprojectivedependencyparser.py | be8b6521cfbdd3b7477b5a537158dc60e783c07aec5d4978ba4c66ab60344542 | 773 | 1 |         Trains a ``NaiveBayesClassifier`` using the edges present in         graphs list as positive examples, the edges not present as         negative examples.  Uses a feature vector of head-word,  |
| .venv/lib/python3.13/site-packages/nltk/tbl/template.py | aaf823586110bf031267b9d65651daee1327216c818fd7dbe4669ac2051221ce | 326 | 1 |         #With skipintersecting=False, then such Templates are allowed          WARNING: this method makes it very easy to fill all your memory when training         generated templates on any real-wor |
| .venv/lib/python3.13/site-packages/nltk/tbl/demo.py | 68a000d20f5ad35abf24184b7df0b61596ab5b57e45e88740f3cc6df31dbdb8c | 419 | 1 |     Deleting unused templates is mostly about saving time and/or space:     training is basically O(T) in the number of templates T     (also in terms of memory usage, which often will be the limiting |
| .venv/lib/python3.13/site-packages/nltk/inference/prover9.py | 3b8fef2b2ea51a272e6b5b68a75aee70bccfef0204b9fe8cff5bb6cb65f81e98 | 508 | 1 |     2: False,  # (SOS_EMPTY) Prover9 ran out of things to do     #   (sos list exhausted).     3: "(MAX_MEGS)",  # The max_megs (memory limit) parameter was exceeded.     4: "(MAX_SECONDS)",  # The ma |
| .venv/lib/python3.13/site-packages/nltk/draw/tree.py | 6cb8b3dbf45dcc4476b26932ec24d0ac14548803fb9020986280d33ebb9c4bf4 | 1130 | 6 |      tree4 = Tree.fromstring("(S (NP this tree) (VP (V is) (Adj horizontal)))")     tc4 = TreeWidget(         cf.canvas(),         tree4, |
| .venv/lib/python3.13/site-packages/nltk/draw/table.py | a83659ba40a54b4fef249572e9ebb9d569871c065b83491a6b6eb7f329812e31 | 1179 | 3 |         :return: A list of the identifiers of replaced binding             functions (if any), allowing for their deletion (to             prevent a memory leak).         """         return [label.bin |
| .venv/lib/python3.13/site-packages/nltk/tag/perceptron.py | 7d156558ab1db8f1a42ce0d2bb7b72191ab91406e741d9701d96637e2220b396 | 400 | 1 |      def __init__(self, weights=None):         # Each feature gets its own weight vector, so weights is a dict-of-dicts         self.weights = weights if weights else {}         self.classes = set() |
| .venv/lib/python3.13/site-packages/nltk/tag/tnt.py | e6965bed2f3676c1a14fdd39c32f466e82be2918f87d7f798a93e266b3c6d99d | 577 | 1 |                              l3*P(t_i\| t_i-1, t_i-2)      A beam search is used to limit the memory usage of the algorithm.     The degree of the beam can be changed using N in the initialization.     |
| .venv/lib/python3.13/site-packages/nltk/tag/hmm.py | 38d25b81898d3de5bb94bf517b1abef74c6abc8e49f38efed0c3e53f64401ae8 | 1327 | 5 |         return transitions_logprob.reshape((N, N)).T      def _outputs_vector(self, symbol):         """         Return a vector with log probabilities of emitting a symbol |
| .venv/lib/python3.13/site-packages/nltk/tokenize/texttiling.py | 1aa42b434aea785e71e5eb050da0b2a8d3f7a1efaba3dbed6c0704e2e7cd12d7 | 475 | 1 |      if x.size < window_len:         raise ValueError("Input vector needs to be bigger than window size.")      if window_len < 3: |
| .venv/lib/python3.13/site-packages/nltk/tokenize/punkt.py | a65b4477188b05dac496c4765f4f5249081c977de876bc7d7beea4cfb3792d58 | 1827 | 1 |     ):         """         Allows memory use to be reduced after much training by removing data         about rare tokens that are unlikely to have a statistical effect with         further training.  |
| .venv/lib/python3.13/site-packages/fsspec/conftest.py | 7d57f1f8d2eb1ff3994b54c8a583683f333b79f11c3282fadab78739d61e1420 | 56 | 2 | def m():     """     Fixture providing a memory filesystem.     """     m = fsspec.filesystem("memory") |
| .venv/lib/python3.13/site-packages/fsspec/parquet.py | ea26c0986e76ecbe493454b454ef010cd9711dd0376d562a741c9e8858295153 | 542 | 3 |         engine supports an explicit `ParquetFile` metadata object.         If a metadata object is supplied, the remote footer metadata         will not need to be transferred into local memory.     f |
| .venv/lib/python3.13/site-packages/fsspec/registry.py | 7a9a18af2145cc35a36e44097e1eb1905de712ef114e23b3577fafa22f0fb21b | 331 | 3 |     },     "local": {"class": "fsspec.implementations.local.LocalFileSystem"},     "memory": {"class": "fsspec.implementations.memory.MemoryFileSystem"},     "oci": {         "class": "ocifs.OCIFileSy |
| .venv/lib/python3.13/site-packages/fsspec/spec.py | edc3947b93c2e54c9fe7a1ed181507128ca6f24b4f8fe048f06e0747c5ddfc2f | 2271 | 1 |         https://docs.python.org/3/library/io.html#io.RawIOBase.readinto         """         out = memoryview(b).cast("B")         data = self.read(out.nbytes)         out[: len(data)] = data |
| .venv/lib/python3.13/site-packages/fsspec/caching.py | f3ab9280f6b9139e5bdbc5c486e0be74c70a03126d6599e942a9c74f0685de12 | 1005 | 6 |  class MMapCache(BaseCache):     """memory-mapped sparse file cache      Opens temporary file, which is filled blocks-wise when data is requested. |
| .venv/lib/python3.13/site-packages/fsspec/callbacks.py | 0432302f32baaebff4579721e79edf4b3b22bc2125a5daa15ebe5d67d4def841 | 325 | 1 |     >>> import fsspec     >>> from fsspec.callbacks import TqdmCallback     >>> fs = fsspec.filesystem("memory")     >>> path2distant_data = "/your-path"     >>> fs.upload( |
| .venv/lib/python3.13/site-packages/fsspec/mapping.py | 9b69dd07f82d4415d898d260d087b5f81551ef94c595e1e62100730bec968635 | 252 | 1 |             # arrays             value = value.view("int64")         value = bytes(memoryview(value))     return value  |
| .venv/lib/python3.13/site-packages/fsspec/fuse.py | 43edcd38ec8ba817d86b80dbe44d7dcff658dfacf3607b48b3598e51ab08b414 | 325 | 1 |     Examples:      python3 -m fsspec.fuse memory /usr/share /tmp/mem      python3 -m fsspec.fuse local /tmp/source /tmp/local \\ |
| .venv/lib/python3.13/site-packages/fsspec/implementations/libarchive.py | e7f2360e22d7c10d490bcc7e2bb8d7bbeb41c213bd763eed14b9dbd1b4e754c4 | 214 | 4 | from fsspec import open_files from fsspec.archive import AbstractArchiveFileSystem from fsspec.implementations.memory import MemoryFile from fsspec.utils import DEFAULT_BLOCK_SIZE  |
| .venv/lib/python3.13/site-packages/fsspec/implementations/git.py | a810d6333e4b36594fa958ebe637ffd45b8d85ae0fe65c9023722585883ec141 | 115 | 3 | from fsspec.spec import AbstractFileSystem  from .memory import MemoryFile   |
| .venv/lib/python3.13/site-packages/fsspec/implementations/memory.py | 29ce936526d9e2d762fba704e6db443c880ccaaf5a02de9c0dd54b1514c9bdff | 312 | 8 | from fsspec.utils import stringify_path  logger = logging.getLogger("fsspec.memoryfs")   |
| .venv/lib/python3.13/site-packages/fsspec/implementations/cache_metadata.py | add761e7ed125c87b25823e906938571a0325a83f27989857deb9b116b7e9d13 | 234 | 1 |      def update_file(self, path: str, detail: Detail) -> None:         """Update metadata for specific file in memory, do not save"""         self.cached_files[-1][path] = detail |
| .venv/lib/python3.13/site-packages/fsspec/implementations/gist.py | 3acb7df3986616be742ac03e403d2c858de13f8297e6a27dadbe42f97e1e84af | 233 | 3 | from ..spec import AbstractFileSystem from ..utils import infer_storage_options from .memory import MemoryFile   |
| .venv/lib/python3.13/site-packages/fsspec/implementations/reference.py | 9e9623e3d02647cae638df6dfc12e97c45ea860b1aadd51eca76a6ab2ada397a | 1306 | 4 |         """          This instance will be writable, storing changes in memory until full partitions         are accumulated or .flush() is called.  |
| .venv/lib/python3.13/site-packages/fsspec/implementations/github.py | 682b192fc52f5d981d91c075454b370dd2de36b8cb29c16c15879014359b045a | 334 | 4 | from ..spec import AbstractFileSystem from ..utils import infer_storage_options from .memory import MemoryFile   |
| .venv/lib/python3.13/site-packages/google/auth/aws.py | d95e4d2e16e8a2b90f2cbc2703ced5bb21fd8a6aee6a47baaa1c87295feb5583 | 862 | 2 |                         "environment_id": "aws1",                         "regional_cred_verification_url": "https://sts.{region}.amazonaws.com?Action=GetCallerIdentity&Version=2011-06-15",            |
| .venv/lib/python3.13/site-packages/google/logging/type/http_request_pb2.py | a62427e37c3f1dd21992ce8fd216347ef09bd4994e2f9a696c451a2c74e19ea5 | 50 | 1 |  DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(     b'\n&google/logging/type/http_request.proto\x12\x13google.logging.type\x1a\x1egoogle/protobuf/duration.proto"\xef\x02\n\x0bHttpRequest\x |
| .venv/lib/python3.13/site-packages/google/protobuf/descriptor.py | 87af655893f4aacc6ba40eb9f6a75ae48c70bc87450b57aa9e46717bbbbe6d32 | 1677 | 3 |     features.MergeFrom(unresolved)      # Use the feature cache to reduce memory bloat.     return self.file.pool._InternFeatures(features)  |
| .venv/lib/python3.13/site-packages/google/protobuf/service_reflection.py | 5871251a73e0cb00ed9f75fcc4a54db1964e0a024e4f38290324ddfab9822865 | 273 | 9 |     """      # CallMethod needs to operate with an instance of the Service class. This     # internal wrapper function exists only to be able to pass the service     # instance to the method that does |
| .venv/lib/python3.13/site-packages/google/protobuf/unknown_fields.py | af7089d9ee3f5d4ab8d5372007cc3a134c99c71cd24c240b1780bb38e1daf65a | 97 | 2 |         local_decoder = decoder.UnknownMessageSetItemDecoder()         for _, buffer in unknown_fields:           (field_number, data) = local_decoder(memoryview(buffer))           InternalAdd(field_n |
| .venv/lib/python3.13/site-packages/google/protobuf/text_format.py | 5118c6b53354a9ed0e489fb70008c48e11c7f4bd3ce0ea140fc82c185664be48 | 1885 | 1 |           # pylint: disable=protected-access           (embedded_unknown_message, pos) = decoder._DecodeUnknownFieldSet(               memoryview(field.data), 0, len(field.data))         except Except |
| .venv/lib/python3.13/site-packages/google/protobuf/descriptor_pb2.py | 85ba0c2c72f7223cee7f630b036fae6763920be98126d779bee9abe300ccd956 | 3364 | 33 |     serialized_options=b'\n\023com.google.protobufB\020DescriptorProtosH\001Z-google.golang.org/protobuf/types/descriptorpb\370\001\001\242\002\003GPB\252\002\032Google.Protobuf.Reflection',     creat |
| .venv/lib/python3.13/site-packages/google/protobuf/symbol_database.py | b34a44c6e63226f8b5ab4a43f36004a09b47d840d9daf019088aa36bce0229c7 | 180 | 3 |     """      def _GetAllMessages(desc):       """Walk a message Descriptor and recursively yields all message names."""       yield desc |
| .venv/lib/python3.13/site-packages/google/protobuf/message.py | 21ec9013af2b8ff61c521cb6d174b90ebded536eff25867918b2c79be4db6c3e | 449 | 1 |     Args:       serialized (bytes): Any object that allows us to call         ``memoryview(serialized)`` to access a string of bytes using the         buffer interface.  |
| .venv/lib/python3.13/site-packages/google/protobuf/descriptor_pool.py | 495ff9158b705eca95adce19dd285f82d6fb47f22b9d72e4bdd280a8784cc5c0 | 1371 | 1 |       # The proto compiler does not give any link between the FileDescriptor       # and top-level extensions unless the FileDescriptorProto is added to       # the DescriptorDatabase, but this can im |
| .venv/lib/python3.13/site-packages/google/protobuf/internal/decoder.py | 4f06935e6f48a1ec37a0edd66b58605582e21d57bb045745e0d02c8efd85c86b | 1067 | 14 |  def ReadTag(buffer, pos):   """Read a tag from the memoryview, and return a (tag_bytes, new_pos) tuple.    We return the raw bytes of the tag rather than decoding them.  The raw |
| .venv/lib/python3.13/site-packages/google/protobuf/internal/containers.py | c42eb201307c1b108095542d663d1021f48f70639125bd240f1a1600a455ed84 | 691 | 1 |   """Base container class."""    # Minimizes memory usage and disallows assignment to other attributes.   __slots__ = ['_message_listener', '_values']  |
| .venv/lib/python3.13/site-packages/google/protobuf/internal/python_message.py | 4782b54e8d85f69561fcc2ccf02df6d6859182150055e94780e3623c45bc115a | 1592 | 7 |       bases += (well_known_types.WKTBASES[descriptor.full_name],)     _AddClassAttributesForNestedExtensions(descriptor, dictionary)     _AddSlots(descriptor, dictionary)      superclass = super(Gener |
| .venv/lib/python3.13/site-packages/google/protobuf/internal/message_listener.py | ba1f2f894fccbd67437b82a5d780aba26295140cc130f94ccc5678bdec3f5097 | 56 | 1 |   class NullMessageListener(object):    """No-op MessageListener implementation.""" |
| .venv/lib/python3.13/site-packages/referencing/_core.py | d1225f656ebc74eacb31a15d84ccaec98cdbd018bd77405c3e31b08a37ac7fd1 | 740 | 4 |     A registry of `Resource`\ s, each identified by their canonical URIs.      Registries store a collection of in-memory resources, and optionally     enable additional resources which may be stored  |
| .venv/lib/python3.13/site-packages/detect_secrets/core/potential_secret.py | 109814aea014f95076a7b6fbe181d421cca80631e791aca59e13c6096c65ed50 | 140 | 2 |         self.secret_hash: str = self.hash_secret(secret)          # Note: Originally, we never wanted to keep the secret value in memory,         #       after finding it in the codebase. However, to  |
| .venv/lib/python3.13/site-packages/detect_secrets/plugins/gitlab_token.py | 15b9cda6e015ef0e6cc3c3e6f58b91e2656cbd31602644701a18843389cc8219 | 60 | 2 |         re.compile(r'glptt-[A-Za-z0-9_\-]{40}(?!\w)'),          # Agent Token - generated by `Devise.friendly_token(50)`         # tokens have a minimum length of 50 chars, up to 1024 chars         re |
| .venv/lib/python3.13/site-packages/detect_secrets/transformers/yaml.py | 9f5d3824c23f739411c81f5043d9a7e94242ef187936da4455129d5834f5564c | 353 | 2 |     The difficulty comes from determining the line number which these values     come from. To do this, we transform the string into a dictionary of     meta-tags, in the following format:      >>> { |
| .venv/lib/python3.13/site-packages/pre_commit/commands/install_uninstall.py | 568259d7c95182121a761ec825197504babb7de2390dbcd9c25215dffbb3e194 | 168 | 1 | PRIOR_HASHES = (     b'4d9958c90bc262f47553e2c073f14cfe',     b'd8ee923c46731b42cd95cc869add4062',     b'49fd668cb42069aa1b6048464be5d395',     b'79f09a650522a87b0da915d0d983b2de', |
| .venv/lib/python3.13/site-packages/colorama/ansitowin32.py | bcf3586b73996f18dbb85c9a568d139a19b2d4567594a3160a74fba1d5e922d9 | 278 | 8 |                 AnsiFore.YELLOW: (winterm.fore, WinColor.YELLOW),                 AnsiFore.BLUE: (winterm.fore, WinColor.BLUE),                 AnsiFore.MAGENTA: (winterm.fore, WinColor.MAGENTA),      |
| .venv/lib/python3.13/site-packages/colorama/ansi.py | 4e8a7811e12e69074159db5e28c11c18e4de29e175f50f96a3febf0a3e643b34 | 103 | 4 |     YELLOW          = 33     BLUE            = 34     MAGENTA         = 35     CYAN            = 36     WHITE           = 37 |
| .venv/lib/python3.13/site-packages/colorama/winterm.py | 5c24050c78cf8ba00760d759c32d2d034d87f89878f09a7e1ef0a378b78ba775 | 196 | 1 |     CYAN    = 3     RED     = 4     MAGENTA = 5     YELLOW  = 6     GREY    = 7 |
| .venv/lib/python3.13/site-packages/colorama/tests/ansi_test.py | 15e5620eb50834865caf9d393c0c6f5380235f3d5ab048802ecf465cc87045a1 | 77 | 4 |         self.assertEqual(Fore.YELLOW, '\033[33m')         self.assertEqual(Fore.BLUE, '\033[34m')         self.assertEqual(Fore.MAGENTA, '\033[35m')         self.assertEqual(Fore.CYAN, '\033[36m')     |
| .venv/lib/python3.13/site-packages/colorama/tests/winterm_test.py | aa85853c48f29b9826d91b8cc297f7a4e8acddae6bfcf259142ccadb9e092fc0 | 132 | 3 |         self.assertEqual(term.get_attrs(), WinColor.YELLOW)          term._back = WinColor.MAGENTA         self.assertEqual(             term.get_attrs(), |
| .venv/lib/python3.13/site-packages/cffi/api.py | 6a506fea1650923a66669941a6175a467da53cef7e08e46cfccee2c5a6ef6562 | 968 | 18 |         self._init_once_cache = {}         self._cdef_version = None         self._embedding = None         self._typecache = model.get_typecache(backend)         if hasattr(backend, 'set_ffi'): |
| .venv/lib/python3.13/site-packages/cffi/recompiler.py | b229b84e6ee56a6b76267f2ecca374c0c629e8e0c1ca4de0ee87f8efe87d2c3e | 1599 | 16 |         self._f = f         prnt = self._prnt         if self.ffi._embedding is not None:             prnt('#define _CFFI_USE_EMBEDDING')         if not USE_LIMITED_API: |
| .venv/lib/python3.13/site-packages/cffi/verifier.py | a17f23a5aa21836426dda1dcce789d01dbeb566e4de2c4181b46b7128e66225e | 307 | 1 |             self._write_source_to(file)         else:             # Write our source file to an in memory file.             f = NativeIO()             self._write_source_to(f) |
| .venv/lib/python3.13/site-packages/codespell_lib/tests/test_dictionary.py | 52f5b29a68b4923142f73228c7b0d13ed5d02ffcda3d535503db097c773bf0da | 375 | 1 |     # 1. check the dict against itself (diagonal)     for err, reps in this_err_dict.items():         assert word_regex.fullmatch(err), (             f"error {err!r} does not match default word regex  |
| .venv/lib/python3.13/site-packages/starlette/responses.py | 4a6c5ce19ba6fb1ecb1b393aae0eeaa6ed183c7163061d36117317dd9176049b | 549 | 4 |         self.init_headers(headers)      def render(self, content: Any) -> bytes \| memoryview:         if content is None:             return b"" |
| .venv/lib/python3.13/site-packages/starlette/testclient.py | 3d1fd48a29850522a51c985ba3d0843adbc9d34a01cf1066c0d4b2e3db68734a | 746 | 9 |         The sub-thread in which the websocket session runs.         """         send: anyio.create_memory_object_stream[Message] = anyio.create_memory_object_stream(math.inf)         send_tx, send_rx  |
| .venv/lib/python3.13/site-packages/starlette/requests.py | 8e2b38b016c4699d661154db9c658e1c3c6cd679b7aab1d9e728b7274cd541da | 324 | 1 |     "accept-language",     "cache-control",     "user-agent", }  |
| .venv/lib/python3.13/site-packages/starlette/datastructures.py | ce16c619c99e45507a3aebedf47c2807c8122bd9396e21f7cd48636f9715fa8c | 693 | 6 |      @property     def _in_memory(self) -> bool:         # check for SpooledTemporaryFile._rolled         rolled_to_disk = getattr(self.file, "_rolled", True) |
| .venv/lib/python3.13/site-packages/starlette/middleware/cors.py | 1e9d4e0450753906d81916ba85f4f306a9242473a15298ebb11af2ac722d1c54 | 173 | 1 |             return True          if self.allow_origin_regex is not None and self.allow_origin_regex.fullmatch(origin):             return True  |
| .venv/lib/python3.13/site-packages/starlette/middleware/base.py | e30dabe4f2b9d476363dd31828cbd4c650a0f597aea6ae7c93476718b30057df | 236 | 4 | DispatchFunction = Callable[[Request, RequestResponseEndpoint], Awaitable[Response]] BodyStreamGenerator = AsyncGenerator[Union[bytes, MutableMapping[str, Any]], None] AsyncContentStream = AsyncIterab |
| .venv/lib/python3.13/site-packages/starlette/middleware/wsgi.py | c8d421a371552b405c0d3553d8d1a660b3b1b6bc4f154a31f5a537714a860e07 | 154 | 1 |         self.status = None         self.response_headers = None         self.stream_send, self.stream_receive = anyio.create_memory_object_stream(math.inf)         self.response_started = False        |
| .venv/lib/python3.13/site-packages/rsa/key.py | 3204a50847969c444e2ebaff143092aaf0befc26d66dd8e591c3b8920878b23c | 859 | 1 |          >>> import base64         >>> b64der = 'MC4CAQACBQDeKYlRAgMBAAECBQDHn4npAgMA/icCAwDfxwIDANcXAgInbwIDAMZt'         >>> der = base64.standard_b64decode(b64der)  |
| .venv/lib/python3.13/site-packages/pathspec/_meta.py | 0da4931c5fb29e4925bc105b2884029cd6125b4c9725a2940d8124bd61c16161 | 59 | 1 | """ This module contains the project meta-data. """  |
| .venv/lib/python3.13/site-packages/markdown_it/common/utils.py | 976ca952ea7b8d507019925bf0cda5c659664d6abcc0de53315e3432776abb50 | 319 | 8 |      code: None \| int = None     if pat := DIGITAL_ENTITY_BASE10_RE.fullmatch(name):         code = int(pat.group(1), 10)     elif pat := DIGITAL_ENTITY_BASE16_RE.fullmatch(name): |
| .venv/lib/python3.13/site-packages/markdown_it/rules_inline/balance_pairs.py | be27dab269ded36b0d681070b99b00e32234daf9afd60bd5378a91f9bf66eb61 | 138 | 1 |         # for each marker, each delimiter length modulo 3,         # and for whether this closer can be an opener;         # https://github.com/commonmark/cmark/commit/34250e12ccebdc6372b8b49c44fab57c |
| .venv/lib/python3.13/site-packages/cachecontrol/filewrapper.py | da4b5734f1342aa9f2cc5db868eb0a080e7c1d0ab5c5e0ba97683aff3c238217 | 120 | 8 |     The data is stored in a temporary file until it is all available.  As long     as the temporary files directory is disk-based (sometimes it's a     memory-backed-``tmpfs`` on Linux), data will be  |
| .venv/lib/python3.13/site-packages/cachecontrol/cache.py | 397c2fec59f60309ca3626a12479e3b6f68a2e776f54bbfffb33be96d955f6a2 | 76 | 1 | """ The cache object API for implementing caches. The default is a thread safe in-memory dictionary. """  |
| .venv/lib/python3.13/site-packages/cachecontrol/caches/file_cache.py | d037fd09c2816868ca1787619051a770bc7e60769ed0138f7748e8ebb986d6b4 | 146 | 3 | class FileCache(_FileCacheMixin, BaseCache):     """     Traditional FileCache: body is stored in memory, so not suitable for large     downloads.     """ |
| .venv/lib/python3.13/site-packages/imagesize/imagesize.py | 955631fd5661ce576af667154cf8924c1509329915791ffd7b67a0feeff32e13 | 377 | 1 |                 size = 2                 ftype = 0                 while not 0xc0 <= ftype <= 0xcf or ftype in [0xc4, 0xc8, 0xcc]:                     fhandle.seek(size, 1)                     byte =  |
| .venv/lib/python3.13/site-packages/idna/idnadata.py | 5b7d067081afb4e598c008d98f8663ba8b94bad0ba7df80dbb28c9cbb7d9fa5a | 4244 | 36 |     0x5C1: 84,     0x5C2: 84,     0x5C4: 84,     0x5C5: 84,     0x5C7: 84, |
| .venv/lib/python3.13/site-packages/idna/uts46data.py | aedf742bd278d20512c29a433c2ae18e08b9000ea958ceb974419149feab2213 | 8682 | 50 |         (0xC2, "M", "â"),         (0xC3, "M", "ã"),         (0xC4, "M", "ä"),         (0xC5, "M", "å"),         (0xC6, "M", "æ"), |
| .venv/lib/python3.13/site-packages/humanfriendly/terminal/__init__.py | e41cf15472ab8b39dc9518eb5b060493697572dd2ad1676ea4922b92e23d8257 | 777 | 2 | """The ANSI escape sequence to show the text cursor (a string)."""  ANSI_COLOR_CODES = dict(black=0, red=1, green=2, yellow=3, blue=4, magenta=5, cyan=6, white=7) """ A dictionary with (name, number)  |
| .venv/lib/python3.13/site-packages/bs4/_typing.py | 5ee528ba606bf60749104652003aa792152827c352123ee13aca9f46aa6c1bbc | 202 | 1 | _IncomingMarkup: TypeAlias = Union[str, bytes, IO[str], IO[bytes]]  #: Markup that is in memory but has (potentially) yet to be converted #: to Unicode. _RawMarkup: TypeAlias = Union[str, bytes] |
| .venv/lib/python3.13/site-packages/bs4/__init__.py | cddcf733a060ea2e4bc786bfe1d573ad4bc446c84bd9a1eb6eb6bcfcef96786c | 1175 | 1 |          matching the SoupStrainer will be considered. This is useful          when parsing part of a document that would otherwise be too          large to fit into memory.          :param from_encod |
| .venv/lib/python3.13/site-packages/bs4/dammit.py | 62421103267229fca8aad55e23f2d3ed6bd1636f22ce3fe3481188e7cfac53ce | 1409 | 4 |         byte order mark has failed. In HTML terms, this         corresponds to the step "user has explicitly instructed         the user agent to override the document's character         encoding", d |
| .venv/lib/python3.13/site-packages/click/_winconsole.py | fefc54b946b1c01868474bd458236e1d8f1551e7e231d088c94d925cfaa817e0 | 297 | 3 |  ERROR_SUCCESS = 0 ERROR_NOT_ENOUGH_MEMORY = 8 ERROR_OPERATION_ABORTED = 995  |
| .venv/lib/python3.13/site-packages/click/formatting.py | 061ab1e105dd290f56e162a49c8c23e4a3ca166b5db863ae1aad72c3f4c72d9f | 302 | 1 |     exposed so that developers can write their own fancy outputs.      At present, it always writes into memory.      :param indent_increment: the additional increment for each level. |
| .venv/lib/python3.13/site-packages/click/termui.py | bc062b282d9aedffcd7c42210138445587dafff89be5741b4d2086b499400510 | 878 | 4 |     "yellow": 33,     "blue": 34,     "magenta": 35,     "cyan": 36,     "white": 37, |
| .venv/lib/python3.13/site-packages/torch/_storage_docs.py | 2b2c4c67a8fd50f4a89627518d1ed60eeee0256918a2df1316081f3c0d5fca02 | 43 | 3 | from_file(filename, shared=False, nbytes=0) -> Storage  Creates a CPU storage backed by a memory-mapped file.  If ``shared`` is ``True``, then memory is shared between all processes. |
| .venv/lib/python3.13/site-packages/torch/_meta_registrations.py | dd63b024ee7ecfd99c155834ca683aeb4e5942f73698034f260351fd55969c31 | 8017 | 205 |     make_contiguous_strides_for,     Number,     suggest_memory_format,     TensorLike, ) |
| .venv/lib/python3.13/site-packages/torch/library.py | 12b4bf43705cd1edec8c83d5bfbe2c4065239e1c711cc8c91fb6a1b59990f300 | 1621 | 1 |         lib = Library(namespace, "FRAGMENT")         _keep_alive.append(lib)     if not NAMELESS_SCHEMA.fullmatch(schema):         raise ValueError(             f"define(qualname, schema, ...): expect |
| .venv/lib/python3.13/site-packages/torch/_jit_internal.py | fb87a208a0d4f38c9ff759b9ae06aadf6508f7b685ccea6ec9b100f1574e6ef2 | 1553 | 9 |              class MyModule(nn.Module):                 def __init__(self, use_memory_efficient):                     super().__init__()                     self.use_memory_efficient = use_memory_effi |
| .venv/lib/python3.13/site-packages/torch/_torch_docs.py | 4a04093cd08ff286f4ff14e81b0c19d5623e9f36fb604a69454b349be57d66be | 14141 | 151 |     generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling     out (Tensor, optional): the output tensor.     memory_format (:class:`torch.memory_format`, optiona |
| .venv/lib/python3.13/site-packages/torch/quasirandom.py | 1f5dcb75e3d3b2bede49e0aba78bf5dcbed3dd810ab1011c9d342fbc3f566d50 | 218 | 2 |             self._scramble()          self.quasi = self.shift.clone(memory_format=torch.contiguous_format)         self._first_point = (self.quasi / 2**self.MAXBIT).reshape(1, -1)         self.num_gen |
| .venv/lib/python3.13/site-packages/torch/_tensor_docs.py | e5bc09d43bc26a6d672ee1a73e49e391262bb40ce2fcaab757b43831028dd122 | 6972 | 124 | common_args = parse_kwargs(     """     memory_format (:class:`torch.memory_format`, optional): the desired memory format of         returned Tensor. Default: ``torch.preserve_format``. """ |
| .venv/lib/python3.13/site-packages/torch/__init__.py | 2f0deb66d5dff6b9c02a62832c3bf3824c2ee031c462a3afeb9ca170466da5bf | 2867 | 10 |     .. note::          This doesn't affect functions that create tensors that share the same memory as the input, like:         :func:`torch.from_numpy` and :func:`torch.frombuffer`  |
| .venv/lib/python3.13/site-packages/torch/overrides.py | a66ffe18cb5c806377c35a818d1043af390b2c3692cf6ee5be82cceb98ad601c | 2118 | 32 |         torch.has_openmp,         torch.iinfo,         torch.memory_format,         torch.qscheme,         torch.set_grad_enabled, |
| .venv/lib/python3.13/site-packages/torch/types.py | 74cf0309dc4c17a2704e98d62be5422653fc29100c2ad7b58f8d47f2f6f92c78 | 131 | 3 | PySymType: TypeAlias = Union[SymInt, SymFloat, SymBool]  # Meta-type for "numeric" things; matches our docs Number: TypeAlias = Union[int, float, bool] # tuple for isinstance(x, Number) checks. |
| .venv/lib/python3.13/site-packages/torch/_linalg_utils.py | e2fa59ed8129cdd22ad2779a1048d98269677cb2c840ebc9747b427667be82f4 | 151 | 4 | def _symeig(     input,     eigenvectors=False,     upper=True,     *, |
| .venv/lib/python3.13/site-packages/torch/_tensor.py | 991589d60a0c177977a17ecd5a6f4b800fa942900cd11e2021fde44985c69637 | 1797 | 42 |         ``.grad`` attributes or set them to ``None`` before calling it.         See :ref:`Default gradient layouts<default-grad-layouts>`         for details on the memory layout of accumulated gradie |
| .venv/lib/python3.13/site-packages/torch/hub.py | a553dab3bb8d51bc9a9e3727aa250e54cd5bab2be20e3e444b81d004d6d2951c | 876 | 1 |     """     file_size = None     req = Request(url, headers={"User-Agent": "torch.hub"})     u = urlopen(req)     meta = u.info() |
| .venv/lib/python3.13/site-packages/torch/_tensor_str.py | 0f75428b90a5a77bacd541f4d36cde51b6c091fe6c8dde5e561600be3513f9fd | 727 | 2 |   def _vector_str(self, indent, summarize, formatter1, formatter2=None):     # length includes spaces and comma between elements     element_length = formatter1.width() + 2 |
| .venv/lib/python3.13/site-packages/torch/functional.py | aabc3c345c7670842c2537284139ac398fb7d80cb9f515c1ed04ac692399e962 | 2238 | 17 |          More than one element of a broadcasted tensor may refer to a single         memory location. As a result, in-place operations (especially ones that         are vectorized) may result in incor |
| .venv/lib/python3.13/site-packages/torch/_lowrank.py | ec5628b7fe7a4357dd3cb27c1a4cc96d75b6ef2d99a665bc45f96b23d059edd8 | 295 | 1 |                 - :math:`U` is m x q matrix                  - :math:`S` is q-vector                  - :math:`V` is n x q matrix |
| .venv/lib/python3.13/site-packages/torch/storage.py | ed06de01cc398ad7f428b472049f07944ae892aa1a10d88bd66bba97de4bc785 | 1552 | 59 |   _share_memory_lock = threading.Lock() _share_memory_map: dict[int, threading.RLock] = {}  |
| .venv/lib/python3.13/site-packages/torch/_lobpcg.py | d093d83fb7d22ac15816194abc5489cdb6875ac0b1338d499e136786c6c4076e | 1155 | 15 |     # we assume p(x) = x^n + a_{n-1} * x^{n-1} + ... + a_1 * x + a_0,     # so poly_coeffs = {a_0, ..., a_n, a_{n+1}(== 1)},     # but we insert one extra coefficient to enable better vectorization be |
| .venv/lib/python3.13/site-packages/torch/_guards.py | 37c77abaaa9770489e257117d7671e7cecd71750e8c83632c356ec329a25945e | 1142 | 2 | # CompiledId represents a unique program-level identifier, and we want to keep that # property as the codebase evolves. This property is relied on even outside of the pytorch # repo, e.g. tlparse or o |
| .venv/lib/python3.13/site-packages/torch/serialization.py | b50f806f9aee71df8c412db95332218deca1ebcb74e694d3e5241da8eefc056c | 2131 | 5 |                  if (                     config.save.use_pinned_memory_for_d2h                     and (                         acc := torch.accelerator.current_accelerator( |
| .venv/lib/python3.13/site-packages/torch/_utils.py | 12ff7e61f18338a85cba1de9865fd46e50984de7cdeb703ed7cc6f3aed9266bd | 1112 | 7 |     Args:         dtype (type or string): The desired type         non_blocking (bool): If ``True``, and the source is in pinned memory             and destination is on the GPU or vice versa, the cop |
| .venv/lib/python3.13/site-packages/torch/_higher_order_ops/cond.py | ef401baf213def28dfcf8e6144a6136e4125a07a28888c0e95e5ceb70d4695ff | 733 | 1 |                     raise RuntimeError(                         f"It seems one of cond's output stride is not a simple accumulative multiplication of sizes. "                         f"This could be b |
| .venv/lib/python3.13/site-packages/torch/_higher_order_ops/utils.py | e609026976de211be94820650aac4d4a7ff1654b6db8910baca304901aeb37a8 | 1135 | 2 |             f"{name} where aliases appear. "             + f"In particular, these inputs \             {set(el for el_map in aliases if len(el_map.keys()) > 0 for el in el_map.keys())} "  # noqa: C401 |
| .venv/lib/python3.13/site-packages/torch/_higher_order_ops/scan.py | e00444e6427cb36c6bfe2560b599e2cbf6f58914d2b27edff9ac8ef46f507671 | 930 | 4 |         y.unsqueeze(0)         .repeat(*([scan_length] + [1] * y.ndim))         .clone(memory_format=torch.contiguous_format)     )  |
| .venv/lib/python3.13/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py | 1fd489ff35806e70cf8e586c2c403740b6c33a556f62deeede6c328af1a7b1cd | 2052 | 2 |                 # for on-device TMA.                 # experimental_tensormap_store(a, b, ...) stores b to the location specified                 # by descriptor in the memory of a.                 #  |
| .venv/lib/python3.13/site-packages/torch/_higher_order_ops/flex_attention.py | 3418008a39b449a6202bf6161abb6a848f76c8784a0474a3ae02bd5ea071fdca | 1269 | 6 |     """Eager implementation      This implementation uses vmap to vectorize the score_mod function over the batch, head, m, and n dimensions.     We then apply the vectorized score_mod function to the |
| .venv/lib/python3.13/site-packages/torch/_prims/debug_prims.py | 90fbc11c09d8ca54f6fe4e41623e621d68dbb133f90f97598114f3bcac92e39a | 55 | 1 |     assert LOAD_TENSOR_READER is None     # load_tensor is an "op", and we will play merry hell on     # Inductor's memory planning if we return a tensor that     # aliases another tensor that we prev |
| .venv/lib/python3.13/site-packages/torch/_prims/__init__.py | 491b62878a469ea7324004c039bcc1905702a5d0eeedb1dfd352e69453551247 | 2959 | 17 |  def _clone_meta(     input: TensorLikeType, *, memory_format: torch.memory_format = torch.preserve_format ) -> TensorLikeType:     if memory_format != torch.preserve_format: |
| .venv/lib/python3.13/site-packages/torch/_logging/_internal.py | 8ce23c80c970393bf006049471cbe3488a6d6f27b91b6bbfcdb89562e27a908b | 1344 | 1 |  def _validate_settings(settings):     return re.fullmatch(_gen_settings_regex(), settings) is not None   |
| .venv/lib/python3.13/site-packages/torch/_functorch/partitioners.py | 085b40222462b537710e9fc1826b83424fdfb186c67fe209b9dd424febea4857 | 2725 | 55 |      Returns:         float: Memory size in MB     """     # Get number of elements and size per element |
| .venv/lib/python3.13/site-packages/torch/_functorch/config.py | 89b2527072a8bc14cd5811497e6aa2a9ce094b80d1827ce240d9018f329767c0 | 312 | 20 |  # By default, the partitioner is purely trying to optimize for runtime (although # it should always use less memory than eager) # This knob controls the partitioner to make that tradeoff for you, cho |
| .venv/lib/python3.13/site-packages/torch/_functorch/top_operators_github_usage.py | 0fa0ca32e10f6feca58d82da6f243f6d9b1186282c6d81c33ceabbad66522113 | 630 | 13 |     ("nn.functional.max_pool2d", 876),     ("nn.functional.nll_loss", 863),     ("nn.functional.embedding", 737),     ("nn.functional.tanh", 664),     ("nn.functional.leaky_relu", 640), |
| .venv/lib/python3.13/site-packages/torch/_functorch/apis.py | 316582b90db884a5a150392d2b8c8c1ae5a0c0a83b21b44eb90d43c19a82b92c | 449 | 11 | ) -> Callable:     """     vmap is the vectorizing map; ``vmap(func)`` returns a new function that     maps ``func`` over some dimension of the inputs. Semantically, vmap     pushes the map into PyTor |
| .venv/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py | 5a3997ea045848c68cf67ce8fffcf36e166ed77823772bd2ea6b38ca9e40d0cf | 1738 | 2 | # instead of (say) just storing metadata about the size/stride of the output somewhere to generate the alias. There are two reasons: # (1) Getting the actual alias tensor allows us to use view-replay  |
| .venv/lib/python3.13/site-packages/torch/_functorch/compilers.py | facbb52f8342028207e79030230150b0fd057b401003ec7904b0afd8dfb8a22f | 446 | 2 |   def memory_efficient_fusion(     fn: Union[Callable, nn.Module],     **kwargs, |
| .venv/lib/python3.13/site-packages/torch/_functorch/eager_transforms.py | 114bb4a90c8339fee672dd32e629482aea27881c0ce8b474bc9db8abd4e69318 | 1818 | 11 | def vjp(func: Callable, *primals, has_aux: bool = False):     """     Standing for the vector-Jacobian product, returns a tuple containing the     results of ``func`` applied to ``primals`` and a func |
| .venv/lib/python3.13/site-packages/torch/_functorch/functional_call.py | b93e6425af4356487015531f30c9e295642789ef243725590f4a34efe1ef4b6e | 254 | 2 |      .. note:: If the user does not need grad tracking outside of grad transforms, they can detach all of the         parameters for better performance and memory usage          Example:: |
| .venv/lib/python3.13/site-packages/torch/_functorch/_activation_checkpointing/graph_info_provider.py | 8af496cd57c252fb44ada79e6301672b72d95e513d6ba7f6cc19b66b6348d267 | 322 | 10 | class GraphInfoProvider:     """     This class provides information about the graph, such as the nodes, edges, and their runtime and memory requirements.     It also provides methods to create graphs |
| .venv/lib/python3.13/site-packages/torch/_functorch/_activation_checkpointing/knapsack.py | 466beae7f294222db596c5f9f5947df89614e805a7c35be70c5a5b43bee895db | 122 | 40 |  def greedy_knapsack(     memory: list[float], runtimes: list[float], max_memory: float ) -> tuple[float, list[int], list[int]]:     n = len(runtimes) |
| .venv/lib/python3.13/site-packages/torch/_functorch/_activation_checkpointing/ac_logging_utils.py | 0221ccfe57c13effe38d9f07d4347bc0c75b19950737618c389de5192c668c2e | 146 | 1 |         if node_info["is_recomputable_candidate"]:             idx = recomputable_node_info[node_name]             node_info["recomputable_candidate_info"]["memory"] = memories_banned_nodes[           |
| .venv/lib/python3.13/site-packages/torch/_functorch/_activation_checkpointing/knapsack_evaluator.py | 909b9929d87143d8eabd9ce716dd102cc5d6a380536d39bfc558c7a0f6ffedbc | 274 | 72 | class KnapsackEvaluator:     """     This class evaluates the theoretical runtime and peak memory usage of a given checkpointing strategy.     It takes in a graph and a list of nodes that are saved an |
| .venv/lib/python3.13/site-packages/torch/_functorch/_aot_autograd/input_output_analysis.py | 098ad621002a6374e9177d9627e49ff067e09ba7412a86c9a13dbe04fadae610 | 439 | 14 | from torch.fx.experimental.symbolic_shapes import is_concrete_int  from .collect_metadata_analysis import coerce_tangent_and_suggest_memory_format from .schemas import (     BackwardSignature, |
| .venv/lib/python3.13/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py | 6f4bf752d8630075562c142ae74b5fc9e4110300935afea345a56f942c691bb4 | 2486 | 24 |     AOTConfig,     InputAliasInfo,     MemoryFormatMeta,     MutationType,     OutputType, |
| .venv/lib/python3.13/site-packages/torch/_functorch/_aot_autograd/schemas.py | 98be53e1b2d5c4c6f88661cd5ddd915d1286d098e6bd42230a8c31636711105b | 969 | 20 |  @dataclass class MemoryFormatMeta:     # For static shapes we assume tangents have the same strideness as outputs     size: Optional[Sequence[int]] = None |
| .venv/lib/python3.13/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py | 4772b4f0d153623aca56aaa96f20c0c03dea1f232e7a2596fab67f224200265f | 1846 | 1 |      # The main use case for saved_tensors_hooks is activation quantization,     # for memory usage optimization.     # Desired behavior is to quantize saved activations to free the original saved ten |
| .venv/lib/python3.13/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py | e04913dce18a9b35c10e193588848308437c51c2cc362382ddbd793916cb78f1 | 814 | 28 |     FunctionalTensorMetadataEq,     InputAliasInfo,     MemoryFormatMeta,     MutationType,     OutputAliasInfo, |
| .venv/lib/python3.13/site-packages/torch/_functorch/_aot_autograd/subclass_utils.py | ad22f19c6f4cc5bfb01e10bcc9ba3dae3a4a6a253ab8080ef332a8c8a9284ad1 | 477 | 21 |   from .schemas import MemoryFormatMeta   |
| .venv/lib/python3.13/site-packages/torch/_numpy/linalg.py | d18c2c7578e776aaa27e9ce7c72c7353d922eda422e6adef651acc2b8d4db20c | 244 | 2 |   # ### Matrix and vector products ###   |
| .venv/lib/python3.13/site-packages/torch/_numpy/_funcs_impl.py | f509a99a6f61b047f72bfbdf609cafbd543def3887d723efb3f500e2348e65f2 | 2059 | 2 |      if not sparse:         # Return the full N-D matrix (not only the 1-D vector)         output = torch.broadcast_tensors(*output)  |
| .venv/lib/python3.13/site-packages/torch/_numpy/testing/utils.py | c7a0d13d4085ed13c878f214353e8176af59b93163a2378f68a3330481312b7c | 2387 | 16 |     """     generator producing data with different alignment and offsets     to test simd vectorization      Parameters |
| .venv/lib/python3.13/site-packages/torch/_export/converter.py | 80e9f1aacc0091d70aee8e11262a48d59cad68973b1e810f647b4bb65e76f914 | 1615 | 3 |         inp_list = [             self.get_fx_value_by_ir_value(inp) for inp in node.inputs()         ]  # noqa: C416         fx_node = self.fx_graph.call_function(             to_float_tensor, |
| .venv/lib/python3.13/site-packages/torch/_export/pass_base.py | 8f974546f2a23a1da18094464dfad5fce87f7917e5af41e7ce73337b5f7a6636 | 479 | 2 |                         device="meta",                         requires_grad=tensor_meta.requires_grad,                         memory_format=tensor_meta.memory_format,                     ),          |
| .venv/lib/python3.13/site-packages/torch/_export/non_strict_utils.py | 62493b8e4dd9c9b03b9f0b67fb54b829ec930bd8ec6ad3a59287fb0d68b3c94b | 1055 | 1 |     kp_args, kp_kwargs = tree_map_with_path(         lambda kp, _: _KeyPath(kp),         (tuple(None for _ in args), {k: None for k in kwargs}),  # noqa: C420     )     kp_combined_args = _combine_arg |
| .venv/lib/python3.13/site-packages/torch/_export/verifier.py | 9c90e28ec759094545f7d7ec971ac5971247e8a1bd18dcea2d9e850afafd73eb | 503 | 1 |             return True         elif isinstance(             val, (torch.memory_format, torch.dtype, torch.device, torch.layout)         ):             return True |
| .venv/lib/python3.13/site-packages/torch/_export/passes/replace_quantized_ops_with_standard_ops_pass.py | 77e303b6c0713ece4a634e17594bf3df9fdf1d69edcc7de9d9c5b18396ed69e9 | 674 | 1 |     # In quantized version, conv1d is emulated using conv2d with squeeze and unsqueeze     # operations before and after the conv2d operation to match the dimension of weights.     # Reference: https: |
| .venv/lib/python3.13/site-packages/torch/_export/passes/replace_view_ops_with_view_copy_ops_pass.py | 1ff1d5119b19349600137b08004bc72dfbe4b384d29dc9638527878c913da0bf | 66 | 1 |     purposes, we keep view ops around while functionalizing the exported     program. This pass replaces view ops with view copy ops for backends that     need AOT memory planning.     """  |
| .venv/lib/python3.13/site-packages/torch/_export/passes/constant_folding.py | 84266ab96a280ceed4740126eab63f5808ed79eecc5efaf93ec604646458f8fa | 304 | 1 |          # skip constructors, since inductor generates optimal code for them already         # and turning into tensor would result in an additional global memory read         # TODO - more complicate |
| .venv/lib/python3.13/site-packages/torch/_export/serde/serialize.py | 0ed73ecd6ae5586e0a5eb3feb99e3f84b667df0e71bdcfb99158105df8881cf4 | 3557 | 15 |     Layout,     LossOutputSpec,     MemoryFormat,     ModuleCallEntry,     ModuleCallSignature, |
| .venv/lib/python3.13/site-packages/torch/_export/serde/schema_check.py | 1547509412bffa77a2e9ccfc4a5c70239c17aa49576d4dcbf76aa60eba326036 | 739 | 2 |                     yaml_head, cpp_head, thrift_head, thrift_tail = (                         "List",                         "std::vector",                         "list<",                         "> |
| .venv/lib/python3.13/site-packages/torch/_export/serde/schema.yaml | 55e17e600097ff8649e5090ca5065b36d5c34f6abd0d496fc19dea1e598f7503 | 537 | 4 | # @generated by update_schema.py # checksum<<110c364974d3b0f7dcbdf6862781212bdcc7178925c43c894c336fc2b6ca6628>> AOTInductorModelPickleData:   kind: struct |
| .venv/lib/python3.13/site-packages/torch/_export/serde/schema.py | fa59d8422633f725d90e836a05bc1dd8c88e57c6e857dcae99a6586c2641dd74 | 506 | 3 |   class MemoryFormat(IntEnum):     Unknown = 0     ContiguousFormat = 1 |
| .venv/lib/python3.13/site-packages/torch/_subclasses/functional_tensor.py | 0266ca754b02339585ae9348968ead06ae8e07a131f9970e32dbca65d1088761 | 782 | 4 |     metadata_fns = [         torch.ops.aten.is_contiguous.default,  # type: ignore[has-type]         torch.ops.aten.is_contiguous.memory_format,  # type: ignore[has-type]         torch.ops.aten.is_str |
| .venv/lib/python3.13/site-packages/torch/_subclasses/meta_utils.py | db568d9a923e83b8f201b50cf662e2a492ff0d974143774d44c7f8f8fea48efd | 1938 | 3 |      # This is only populated on copy_data, and typically is not used at all,     # except for some of our meta-ification paths that don't properly use     # storage (pro-tip: you should use storage)  |
| .venv/lib/python3.13/site-packages/torch/_subclasses/fake_impls.py | 47f8a3cf0a311f3b6d45f0f6c98b93da63c450196b2b1ec71a5a996fcdf46916 | 1103 | 16 | from torch._ops import OpOverload from torch._prims_common import (     definitely_contiguous_for_memory_format,     elementwise_dtypes,     ELEMENTWISE_TYPE_PROMOTION_KIND, |
| .venv/lib/python3.13/site-packages/torch/_subclasses/fake_tensor.py | 7c1b68672956ba27d23cd407bc7977aa97a9d00aa791b98ace4311c2b87bd62c | 3259 | 14 | from torch._library.fake_profile import MissingOpProfile from torch._logging import dtrace_structured from torch._prims_common import suggest_memory_format from torch._subclasses.meta_utils import (   |
| .venv/lib/python3.13/site-packages/torch/linalg/__init__.py | 770c457d67b846f73e477216e5794254d0652e8ec92a01577177b7e5b1c82f40 | 3017 | 71 |   Computes the cross product of two 3-dimensional vectors.  Supports input of float, double, cfloat and cdouble dtypes. Also supports batches |
| .venv/lib/python3.13/site-packages/torch/nn/__init__.py | 4866a43389cd1a3235619c0d8a7b4f7e03554d5e45ad52a18855dbab90dbf0f9 | 63 | 1 |     if kwargs is None:         return {}     simple_keys = {"device", "dtype", "memory_format"}     expected_keys = simple_keys \| {"factory_kwargs"}     if not kwargs.keys() <= expected_keys: |
| .venv/lib/python3.13/site-packages/torch/nn/functional.py | 2b6eb4aff305990cff9e32c6ff40ff82c1fec4b5ceba1f43540146a8eb64e952 | 6497 | 127 |       logits: `[..., num_features]` unnormalized log probabilities       tau: non-negative scalar temperature       hard: if ``True``, the returned samples will be discretized as one-hot vectors,      |
| .venv/lib/python3.13/site-packages/torch/nn/init.py | db4b017dc9c1128c0b6afe191a8f404309010fdfd01273b7d41e2a3a7b816d52 | 769 | 1 |         ... )  # leaky_relu with negative_slope=0.2      .. _Self-Normalizing Neural Networks: https://papers.nips.cc/paper/2017/hash/5d44ee6f2c3f71b73125876103c8f6c4-Abstract.html     """     linear_ |
| .venv/lib/python3.13/site-packages/torch/nn/parameter.py | 5d16c7cab0554bead354b75962101feed0abb06d29a35a8f7e2649f11002e5bd | 281 | 4 |         else:             result = type(self)(                 self.data.clone(memory_format=torch.preserve_format), self.requires_grad             )             memo[id(self)] = result |
| .venv/lib/python3.13/site-packages/torch/nn/attention/flex_attention.py | 4a83aaed88b0817e40c3b1f50d0a46b5fc6502ea491e7a729664d4ddfa493e16 | 1452 | 20 |     col_indices = torch.argsort(dense_mask, dim=-1, descending=True, stable=True)     return (         num_blocks_in_row.to(torch.int32, memory_format=torch.contiguous_format),         col_indices.to( |
| .venv/lib/python3.13/site-packages/torch/nn/attention/experimental/_paged_attention.py | 0102e5752ddccdb0d8b5ae2a311b9f67af9b046f1be59de65352788088e5b496 | 337 | 1 |     With PagedAttention, a batch of key/value tensors with varying kv length     is splitted into tensor blocks of fixed length and cached in a compact way.     Thus we can avoid redundant memory cons |
| .venv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py | 5d7bbb624eae61dccaa4a0aff186b0cb3b4eae9aec587a30ccf8f51b6f4e4040 | 132 | 1 |                 "Was asked to gather along dimension 0, but all "                 "input tensors were scalars; will instead unsqueeze "                 "and return a vector."             )             |
| .venv/lib/python3.13/site-packages/torch/nn/parallel/data_parallel.py | 011cc3ad95b58296ca3546358ed5ad61eff15d1ca383c4b1019c79e24c2e6abb | 287 | 3 |     imbalance_warn = """     There is an imbalance between your GPUs. You may want to exclude GPU {} which     has less than 75% of the memory or cores of GPU {}. You can do so by setting     the devi |
| .venv/lib/python3.13/site-packages/torch/nn/parallel/distributed.py | 1045aff705a6d95f69e912456e1440358ed2f35581e5fe33223c5bb1ae7dfa22 | 2415 | 11 |         ``DistributedDataParallel`` can be used in conjunction with         :class:`torch.distributed.optim.ZeroRedundancyOptimizer` to reduce         per-rank optimizer states memory footprint. Pleas |
| .venv/lib/python3.13/site-packages/torch/nn/qat/__init__.py | 60759ea4757af61f1e208674f5680cf7ac11c184ca01d679217246e1a8e1b072 | 20 | 2 |     "Conv2d",     "Conv3d",     "Embedding",     "EmbeddingBag", ] |
| .venv/lib/python3.13/site-packages/torch/nn/qat/modules/__init__.py | c470703960bbd43cdbf4c2cfbcb90c31d70396bdfdadff9d7a332294eb6c8473 | 22 | 6 |  from torch.ao.nn.qat.modules.conv import Conv1d, Conv2d, Conv3d from torch.ao.nn.qat.modules.embedding_ops import Embedding, EmbeddingBag from torch.ao.nn.qat.modules.linear import Linear from torch. |
| .venv/lib/python3.13/site-packages/torch/nn/qat/modules/embedding_ops.py | d413f71f25355e4afcc90047d5136abf6af064cf54bfa5a5e97e7e0ccfc9965b | 15 | 5 | """  from torch.ao.nn.qat.modules.embedding_ops import Embedding, EmbeddingBag   |
| .venv/lib/python3.13/site-packages/torch/nn/quantized/__init__.py | 39332865b8699bc9c8d6831532e07cb6de09be90cddccb08a18c30da75097d03 | 40 | 2 |     "Dropout",     "ELU",     "Embedding",     "EmbeddingBag",     "GroupNorm", |
| .venv/lib/python3.13/site-packages/torch/nn/quantized/_reference/modules/__init__.py | ca3806d8c45fad6b3ebbc97508220b0683d36be14139115987d8bceaf60a772f | 40 | 4 | from torch.ao.nn.quantized.reference.modules.linear import Linear from torch.ao.nn.quantized.reference.modules.rnn import GRUCell, LSTM, LSTMCell, RNNCell from torch.ao.nn.quantized.reference.modules. |
| .venv/lib/python3.13/site-packages/torch/nn/quantized/_reference/modules/sparse.py | 8123570d85e5c752284ab44dd22fe924726dd739c11f7b003ef0e98af75f6ac9 | 13 | 2 | """  from torch.ao.nn.quantized.reference.modules.sparse import Embedding, EmbeddingBag |
| .venv/lib/python3.13/site-packages/torch/nn/quantized/modules/__init__.py | a0da20cf9787d981187c78d1918044aa9fd70f619db83a9cf52b649c4196c78d | 98 | 6 |     DeQuantize,     dropout,     embedding_ops,     functional_modules,     linear, |
| .venv/lib/python3.13/site-packages/torch/nn/quantized/modules/embedding_ops.py | b26b265ecda1eeddb2e966d3a0db89d3ad2178c41b64e5ce7e435b7703aa54ee | 19 | 7 | """  from torch.ao.nn.quantized.modules.embedding_ops import (     Embedding,     EmbeddingBag, |
| .venv/lib/python3.13/site-packages/torch/nn/utils/spectral_norm.py | 349bb210366763d410a90ad76f5a34803104d717ff010aa6d23372191a1c38ae | 368 | 10 |      def compute_weight(self, module: Module, do_power_iteration: bool) -> torch.Tensor:         # NB: If `do_power_iteration` is set, the `u` and `v` vectors are         #     updated in power iterat |
| .venv/lib/python3.13/site-packages/torch/nn/utils/convert_parameters.py | 2ab396fd6315ae788d2b6eb59d95c1393013e9eb130c0fa912782368aa58044a | 92 | 9 |   def parameters_to_vector(parameters: Iterable[torch.Tensor]) -> torch.Tensor:     r"""Flatten an iterable of parameters into a single vector.  |
| .venv/lib/python3.13/site-packages/torch/nn/utils/parametrize.py | cf07845070806c4a1edbf88d541ee532f542f679634e818f5d19b9a8a37d15a8 | 825 | 2 |         >>> class RankOne(nn.Module):         >>>     def forward(self, x, y):         >>> # Form a rank 1 matrix multiplying two vectors         >>>         return x.unsqueeze(-1) @ y.unsqueeze(-2)   |
| .venv/lib/python3.13/site-packages/torch/nn/utils/memory_format.py | 146de739668cdec9c81eb5c988a2f346c8e296364bb79ea288947e10e62927ad | 173 | 46 |   def convert_conv2d_weight_memory_format(     module: _M, memory_format: torch.memory_format ) -> _M: |
| .venv/lib/python3.13/site-packages/torch/nn/utils/__init__.py | 38abc4ba98b85be6c4f67d62c541d1dd0068da63811bbe143f0790007e8b978d | 48 | 9 |     clip_grad_value_, ) from .convert_parameters import parameters_to_vector, vector_to_parameters from .fusion import (     fuse_conv_bn_eval, |
| .venv/lib/python3.13/site-packages/torch/nn/utils/prune.py | 44696905380761f556bb5644ac0c00e1340e3b4e1764a711f9495515fa6bc542 | 1380 | 7 |                 getattr(module, name + "_mask")                 .detach()                 .clone(memory_format=torch.contiguous_format)             )  |
| .venv/lib/python3.13/site-packages/torch/nn/utils/parametrizations.py | 739597c4d6cd45d36c9b3bbabb7ca8953e1204b770e90ca1821211b8c35edce1 | 629 | 12 |     where an extra matrix :math:`B \in \mathbb{K}^{n \times n}` is stored under     ``module.parametrizations.weight[0].base``. This helps the     convergence of the parametrized layer at the expense  |
| .venv/lib/python3.13/site-packages/torch/nn/utils/rnn.py | fa747718b23b349e2dafec681d735c755542f850f646576a8a8415163a9f1c65 | 599 | 6 |     # See the note above in doc string (starting with ":attr:`data` can be on     # arbitrary device...").     def pin_memory(self) -> Self:         # Why not convert `batch_sizes`?         # See NOTE |
| .venv/lib/python3.13/site-packages/torch/nn/utils/clip_grad.py | 534f39d7308c6ab4fa9e5994a177803abe958ce53d5681e66049a9917e0115c1 | 294 | 7 |      The norm is computed over the norms of the individual tensors, as if the norms of     the individual tensors were concatenated into a single vector.      Args: |
| .venv/lib/python3.13/site-packages/torch/nn/utils/_expanded_weights/__init__.py | 3c721ef47de5d22b88990eb3dd6a8c916212dfb143415435eaf328d1ad3c9ad0 | 11 | 2 | from .conv_expanded_weights import ConvPerSampleGrad from .embedding_expanded_weights import EmbeddingPerSampleGrad from .expanded_weights_impl import ExpandedWeight from .group_norm_expanded_weights  |
| .venv/lib/python3.13/site-packages/torch/nn/utils/_expanded_weights/embedding_expanded_weights.py | 26801bfd4f601689096a7be60d94c6def40a86b03b7ad1aad71c5c3559bd09ef | 84 | 8 |   @implements_per_sample_grads(F.embedding) class EmbeddingPerSampleGrad(torch.autograd.Function):     @staticmethod |
| .venv/lib/python3.13/site-packages/torch/nn/modules/instancenorm.py | e36db29de90f4512200218b577ccbe73f4f31b86afbe38f7cdb19ff00cf15390 | 472 | 3 |      The mean and standard-deviation are calculated per-dimension separately     for each object in a mini-batch. :math:`\gamma` and :math:`\beta` are learnable parameter vectors     of size `C` (wher |
| .venv/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py | 5e07f9e100fe79a7c43bf9bd258c37520e7fa2f92aed7c3e740852046dca8ae1 | 885 | 4 |      The mean and standard-deviation are calculated per-dimension over     the mini-batches and :math:`\gamma` and :math:`\beta` are learnable parameter vectors     of size `C` (where `C` is the numbe |
| .venv/lib/python3.13/site-packages/torch/nn/modules/_functions.py | af8248dcc43fa263092a767cc918dc5e91723b2eb4e8e896eef93ebed337ee1e | 316 | 4 |     ):         if not (             input.is_contiguous(memory_format=torch.channels_last)             or input.is_contiguous(memory_format=torch.channels_last_3d)         ): |
| .venv/lib/python3.13/site-packages/torch/nn/modules/__init__.py | 7213950bbbdbd5028f57067b23531ec57f5fc5acd019f6ec9ac692b51f9c3a06 | 335 | 8 |     BCELoss,     BCEWithLogitsLoss,     CosineEmbeddingLoss,     CrossEntropyLoss,     CTCLoss, |
| .venv/lib/python3.13/site-packages/torch/nn/modules/distance.py | 696d4211da72d5dd74e902ebd1d6c6d4f863c684a86c71fe997c748441515450 | 95 | 4 | class PairwiseDistance(Module):     r"""     Computes the pairwise distance between input vectors, or between columns of input matrices.      Distances are computed using ``p``-norm, with constant ``e |
| .venv/lib/python3.13/site-packages/torch/nn/modules/adaptive.py | 304fcf5d96f61adfe3b39f69fedffe9c94e2cf20e92e15c1a04e227bcec5a21b | 333 | 1 |     each.     Additionally, clusters containing less frequent labels assign lower     dimensional embeddings to those labels, which speeds up the computation.     For each minibatch, only clusters for |
| .venv/lib/python3.13/site-packages/torch/nn/modules/loss.py | 79385d5acd77f326cae6fee38f1f57eaa1440491495b34e07bfad795fd87658d | 2033 | 21 |     "BCELoss",     "BCEWithLogitsLoss",     "HingeEmbeddingLoss",     "MultiLabelMarginLoss",     "SmoothL1Loss", |
| .venv/lib/python3.13/site-packages/torch/nn/modules/activation.py | 79dfe46d31be2e8e8ce68908838f42eb83ecc2ffb364e065149d112c8afc8e02 | 1759 | 10 |         >>> attn_output, attn_output_weights = multihead_attn(query, key, value)      .. _`FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness`:          https://arxiv.org/abs/ |
| .venv/lib/python3.13/site-packages/torch/nn/modules/transformer.py | 5489e57073dbbfa2d0ca2f8515fe914b606d8e63103ad92a01b6a227b10a36c2 | 1235 | 72 |         src_mask: Optional[Tensor] = None,         tgt_mask: Optional[Tensor] = None,         memory_mask: Optional[Tensor] = None,         src_key_padding_mask: Optional[Tensor] = None,         tgt_k |
| .venv/lib/python3.13/site-packages/torch/nn/modules/sparse.py | 9efa8d236f5b29c42ffb2ed2822c01d8b255c54bb5853a8f919e70c06d101fab | 549 | 181 |   __all__ = ["Embedding", "EmbeddingBag"]   |
| .venv/lib/python3.13/site-packages/torch/nn/modules/module.py | 0cb24956454199a46e8fc37a7cce4fc1cff52130f25fb6eb052745e9eca89067 | 3035 | 9 |            :noindex:          .. function:: to(memory_format=torch.channels_last)            :noindex:  |
| .venv/lib/python3.13/site-packages/torch/nn/modules/normalization.py | bb4a027c559afd1fdca5ee6475ac68d2536879b96286e3b45352331fbbbe1897 | 417 | 6 |          >>> # NLP Example         >>> batch, sentence_length, embedding_dim = 20, 5, 10         >>> embedding = torch.randn(batch, sentence_length, embedding_dim)         >>> layer_norm = nn.LayerNor |
| .venv/lib/python3.13/site-packages/torch/nn/modules/rnn.py | 10f560ff680379df780263dd0b09051390359e879e9a2ad6bcffb68dd2ff8d70 | 1824 | 4 |                 )                 b_ih = Parameter(torch.empty(gate_size, **factory_kwargs))                 # Second bias vector included for CuDNN compatibility. Only one                 # bias vect |
| .venv/lib/python3.13/site-packages/torch/nn/modules/fold.py | 8d8183d9a966454f6c1616d3a966f5addba96eb52421e77f3509311cbac32bc1 | 324 | 3 |     where :math:`N` is batch dimension, :math:`C \times \prod(\text{kernel\_size})`     is the number of values within a block (a block has :math:`\prod(\text{kernel\_size})`     spatial locations eac |
| .venv/lib/python3.13/site-packages/torch/mps/__init__.py | 2fffa2ecc27a2ceb014acdcf6ec3d4058dcf2e809b6cd9c7cfe91d764ef63531 | 195 | 25 |             Default: ``'mps'`` (i.e., ``torch.device('mps')``, the current MPS device).     """     new_state_copy = new_state.clone(memory_format=torch.contiguous_format)     _get_default_mps_generat |
| .venv/lib/python3.13/site-packages/torch/onnx/_type_utils.py | 5ea1d076f60c571e72eadd9f8f7b2bc3543caad2154c961d5f3dfbfc2375ddb4 | 392 | 2 |     """      # Order defined in https://github.com/pytorch/pytorch/blob/344defc9733a45fee8d0c4d3f5530f631e823196/c10/core/ScalarType.h     UINT8 = 0     INT8 = enum.auto()  # 1 |
| .venv/lib/python3.13/site-packages/torch/onnx/symbolic_caffe2.py | 157e91d5aac586b4fd630918576c6278955bc481429352f336929b2bf38aa821 | 362 | 2 |     zero_point,     dtype,     pin_memory,     memory_format,     layout, |
| .venv/lib/python3.13/site-packages/torch/onnx/symbolic_opset11.py | 9582eda1c3c104371d9fbc63b2781a95c7c3a2057a1a11c7dfb626a913ba2f88 | 1470 | 21 |     "cumsum",     "Delete",     "embedding_bag",     "embedding_renorm",     "flatten", |
| .venv/lib/python3.13/site-packages/torch/onnx/verification.py | ee8e46a0adcb3c6dbde603c7769da6d903a36bbe788bd6916c213ea4cc64de4f | 1873 | 1 |         onnx_session = _onnx_backend_session(model_f, verification_options.backend)         onnx_outs = _run_onnx(onnx_session, onnx_inputs)         del onnx_session  # To free device memory           |
| .venv/lib/python3.13/site-packages/torch/onnx/symbolic_opset10.py | b8aabe3d0b37e47a2148c463d6a7a44814c52a8deb399c266274757a6ed9e871 | 1189 | 25 |     "dequantize",     "div",     "embedding_bag",     "fake_quantize_per_tensor_affine",     "flip", |
| .venv/lib/python3.13/site-packages/torch/onnx/symbolic_opset20.py | a52397b91f495edb5ebadb36ea7798c80cb28613b2f76873eef5fbe08cf9a9b8 | 93 | 1 |     ReduceMax     ReduceMin     RegexFullMatch     StringConcat     StringSplit |
| .venv/lib/python3.13/site-packages/torch/onnx/symbolic_opset14.py | 7824cef7d9229566fcb579a74259dc764dca1cc67e056e437e1d24600953b7b2 | 286 | 2 |         ),     )     embedding_size = g.op(         "Cast",         query_shape_last, |
| .venv/lib/python3.13/site-packages/torch/onnx/symbolic_helper.py | 49fb3144fde57aee70612b10b1a861e5db9c0a1d00861eaabb7d3659076e69d7 | 2268 | 28 |   def _embedding_bag_helper(     g: jit_utils.GraphContext,     embedding_matrix, |
| .venv/lib/python3.13/site-packages/torch/onnx/symbolic_opset9.py | 33b8b45e0d61a0e0d253cd92b1faf3e3c1ee9a19d531c6d6f067139362925564 | 6654 | 82 |     "dropout",     "elu",     "embedding_bag",     "embedding",     "empty_like", |
| .venv/lib/python3.13/site-packages/torch/onnx/__init__.py | 38fd9ee0ad012274da4628f4535b6fc660b44a560e16bf85bbc7a27b3595e2af | 554 | 2 |             "the new torch.export-based ONNX exporter will be the default. To switch now, set "             "dynamo=True in torch.onnx.export. This new exporter supports features like exporting "      |
| .venv/lib/python3.13/site-packages/torch/onnx/symbolic_opset8.py | 0250d51a7a0a3a93f0196b7132197d908c2965301da56ff30a8c57172b1325da | 464 | 16 |     Where     NonZero     TfIdfVectorizer     MeanVarianceNormalization  |
| .venv/lib/python3.13/site-packages/torch/onnx/utils.py | 5262586714b85deb6c24a9c7646cc467a6f4cc6ff890ab0333943f8f70ad9965 | 1881 | 3 |     # constructor.     #     # For example, torch.nn.Embedding has the `freeze` variable and its     # type specified in the class but the attribute is not created in the     # constructor. In other w |
| .venv/lib/python3.13/site-packages/torch/onnx/symbolic_opset18.py | 1bb77af45e7bec0b42cb0b80fb8542009ed84655de66c2379a1f6bab26a6b039 | 266 | 8 |   @_onnx_symbolic("aten::embedding_bag") @symbolic_helper.parse_args("v", "v", "v", "i", "i", "i", "v", "i", "i") def embedding_bag( |
| .venv/lib/python3.13/site-packages/torch/onnx/symbolic_opset13.py | ee1a0799eba7c01751294326d6247c50c59cc761472ffcc9a35bd816e0294453 | 1114 | 3 | ):     # NOTE: (0, 127) is allowed as special case. PyTorch restricts activations to be in the range (0, 127).     #   https://github.com/pytorch/pytorch/blob/b34b192d6b97325c9f78e5995c48c8498ede34bd/ |
| .venv/lib/python3.13/site-packages/torch/onnx/_internal/_exporter_legacy.py | 3a6534115a002000842e6ce219d4ad059cb417e40b0a7f4eccd9578f80e57d5f | 497 | 3 |     actually do computation through tensors allocated on a ``meta`` device. Because     there is no actual data being allocated on the device, this API allows for     initializing and exporting large  |
| .venv/lib/python3.13/site-packages/torch/onnx/_internal/onnxruntime.py | 6b14d3dab9b93a6648a117763a301b20d3cd8d1b2ca27348ae164cd442c09d54 | 1261 | 14 |             return ORTC.OrtDevice(                 _get_ort_device_type(value.device.type),                 ORTC.OrtDevice.default_memory(),                 _device_id_or_zero(value.device.index),     |
| .venv/lib/python3.13/site-packages/torch/onnx/_internal/fx/type_utils.py | 1ae7692b81f6c47a2d4a1d8fd8950c4c55bdc63ce9fbf9ab6c8eeda54727a625 | 195 | 1 |     torch.Tensor,     torch.device,     torch.memory_format,     torch.layout,     torch._ops.OpOverload, |
| .venv/lib/python3.13/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py | fd3f8d021a747c6fb36f93ffa558bb9efbc578d899249377252fefa99b4386e7 | 719 | 2 |             "device",             "requires_grad",             "pin_memory",             "memory_format",             "implicit", |
| .venv/lib/python3.13/site-packages/torch/onnx/_internal/fx/serialization.py | d33e730ee19b0fb75cdf088cc54c3e24863867a5ebaa3ec0453cad9ace608906 | 251 | 5 |         if isinstance(el, dict):             # Useful for when state_dict is loaded with torch.load(..., mmap=True, map_location="cpu") by the user             # Using torch.save wouldn't leverage mma |
| .venv/lib/python3.13/site-packages/torch/onnx/_internal/fx/passes/modularization.py | 0854c7c52b30401de85052a5c0755a3d7faa4eadcfb8d8b1f7d49b8205944ec0 | 858 | 41 |      Attributes:         _module_class: The class of the module. E.g. `torch.nn.module.sparse.Embedding`.         _module_name: The name of the module. E.g. `L__self___h_1_mlp_c_proj`.         _raw_me |
| .venv/lib/python3.13/site-packages/torch/onnx/_internal/exporter/_dispatching.py | 94be142a645984049661dcccaf2a7791a338e996b12e1e6d4db5001bed936595 | 370 | 1 |     if isinstance(value, torch.dtype):         return attr.type is ir.AttributeType.INT     if isinstance(value, (torch.device, torch.memory_format, torch.layout)):         return attr.type is ir.Attr |
| .venv/lib/python3.13/site-packages/torch/onnx/_internal/exporter/_core.py | d6e34e8ea5ab701e550ab4b9defd34d9dd864ed011a6d50232c43aefaf42546a | 1666 | 5 |      def tobytes(self) -> bytes:         # Implement tobytes to support native PyTorch types so we can use types like bloat16         # Reading from memory directly is also more efficient because      |
| .venv/lib/python3.13/site-packages/torch/onnx/_internal/exporter/_torchlib/ops/nn.py | e6da5a7de52c7ce9ccf4e3c07fb217f251ad44d5f414f8b41baa5b2ebde1ad02 | 286 | 3 |      where Q, K, V are the query, key, and value tensors, respectively.     L is the target sequence length, S is the source sequence length, and E is the embedding size.     """     assert (not is_ca |
| .venv/lib/python3.13/site-packages/torch/onnx/ops/_impl.py | 887575535038d77c66217b776d0ac3f9fb770fbaa5d7bb81a966d1e3de3c28ce | 397 | 21 |   @_onnx_op("RotaryEmbedding", 23) def rotary_embedding_23(     x: torch.Tensor, |
| .venv/lib/python3.13/site-packages/torch/onnx/ops/__init__.py | e34b3cb88ce13287b7a0067a2c240b82bf708525dddbc6c746ad757cd92eafc6 | 468 | 29 |     "symbolic",     "symbolic_multi_out",     "rotary_embedding",     "attention", ] |
| .venv/lib/python3.13/site-packages/torch/_vendor/packaging/version.py | 5e34412cd2b5ed430380b78ff141e7ab0898dd37528b4df1150511b5e736d750 | 564 | 1 | A string containing the regular expression used to match a valid version.  The pattern is not anchored at either end, and is intended for embedding in larger expressions (for example, matching a versi |
| .venv/lib/python3.13/site-packages/torch/distributed/rendezvous.py | 97033de21ed4826d170048cc25e06d785d31b5e881f62b4e4b17ba0d32535216 | 291 | 7 |   def _torchelastic_use_agent_store() -> bool:     return os.environ.get("TORCHELASTIC_USE_AGENT_STORE", None) == str(True)  |
| .venv/lib/python3.13/site-packages/torch/distributed/run.py | abdd056876a52fef6584c01f3f9b92ed9c38ddc81381920f221bb024c2d3de9d | 906 | 6 |    passed as ``--rdzv-endpoint`` to ``torchrun``)  2. Single-node multi-worker: Start ``torchrun`` on the host to start the agent process which    creates and monitors a local worker group.  |
| .venv/lib/python3.13/site-packages/torch/distributed/_state_dict_utils.py | 5e767c12b298618349245bf6be89ba2d696df8c6f90ad145651cdd23eb9458c1 | 820 | 29 |  import torch import torch.cuda._pin_memory_utils as pin_memory_utils import torch.distributed as dist import torch.nn.functional as F |
| .venv/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py | e4c6153239d6ff863ebc89187c5dda41dc93fd1b728c033bd50bbb1429cd385b | 5645 | 4 |             use that backend         2. Else if user specifies multiple "device:backend" pairs in init_process_group:             If "cpu" is among those pairs, use "cpu" (because the object is in cpu |
| .venv/lib/python3.13/site-packages/torch/distributed/utils.py | 76294bc63531dc1bc1c6733a399a1125ffa98d4048a96b93a23b29851234ba18 | 377 | 1 |                     # Sync the current stream with the copy stream                     current_stream.wait_stream(stream)                     # Ensure tensor memory is not reused until work on         |
| .venv/lib/python3.13/site-packages/torch/distributed/launcher/__init__.py | 5742796344951b5c9b8467879e36ab31ce1d70e832851b07a673fb941332078f | 15 | 1 | from torch.distributed.launcher.api import (  # noqa: F401     elastic_launch,     launch_agent,     LaunchConfig, ) |
| .venv/lib/python3.13/site-packages/torch/distributed/launcher/api.py | fcbfed3094b267277483fee0afdb9b3b2ff3da6f5e6c87d7671ac734a4bcb3f4 | 298 | 21 | import torch.distributed.elastic.rendezvous.registry as rdzv_registry from torch.distributed.elastic import events, metrics from torch.distributed.elastic.agent.server.api import WorkerSpec from torch |
| .venv/lib/python3.13/site-packages/torch/distributed/checkpoint/_async_process_executor.py | a954166a192d7bacd1ad378ae5edee7440b4ecd1b4ba15c59bcf00a821517e5d | 331 | 2 | from torch.distributed.checkpoint.storage import StorageWriter from torch.distributed.checkpoint.utils import _DistWrapper from torch.distributed.elastic.agent.server.api import _get_fq_hostname from  |
| .venv/lib/python3.13/site-packages/torch/distributed/checkpoint/planner.py | fb31cb6cef8d3622a39a7b978772f4220b87b4c671e941b9a8c0c632b087248d | 451 | 4 |     def resolve_data(self, write_item: WriteItem) -> Union[torch.Tensor, io.BytesIO]:         """         Transform and prepare ``write_item`` from ``state_dict`` for storage, ensuring idempotency and |
| .venv/lib/python3.13/site-packages/torch/distributed/checkpoint/metadata.py | 834bb99b4ef199bc9dbe60f0a4e06d1b0e21b162449d77d7f1205f196c0b0f06 | 185 | 22 |  class _MEM_FORMAT_ENCODING(Enum):     """Describe the memory format of a tensor."""      TORCH_CONTIGUOUS_FORMAT = 0 |
| .venv/lib/python3.13/site-packages/torch/distributed/checkpoint/filesystem.py | 12b316549d02728c494f291472c157587635159c2706fe2bddbfcf208e493898 | 977 | 1 |             per_thread_copy_ahead: How many bytes to copy from the GPU ahead of saving then. Default 10Mb.             cache_staged_state_dict: Whether to cache the staged state_dict. This option decr |
| .venv/lib/python3.13/site-packages/torch/distributed/checkpoint/state_dict_saver.py | ec55593cfa87b9544ab050a7a77d7786455d377c3938c50e07956423900874d3 | 380 | 1 | ) -> Future:     """Asynchronous version of ``save``. This code first de-stages the state_dict on to the     staging storage (defaults to CPU memory), and then calls the `save` in a separate thread.   |
| .venv/lib/python3.13/site-packages/torch/distributed/checkpoint/utils.py | 9befe614e05b12e56292409ef86772c35c062c5396424137677cda56579e1fb7 | 478 | 1 |             return 0         if len(b) > max_size:             b = memoryview(b)[:max_size]         return self.base_stream.readinto(b)  # type: ignore[attr-defined]  |
| .venv/lib/python3.13/site-packages/torch/distributed/checkpoint/storage.py | 5ac72840147f81d1dd51cff2179120e8f668878d8be6a064da8ddbe0bf338364 | 285 | 1 |         from the plan to get access to the underlying object to write.          Subclasses should lazily call `resolve_data` as it can allocate memory.         In case of tensors, make following assum |
| .venv/lib/python3.13/site-packages/torch/distributed/checkpoint/_state_dict_stager.py | faae57dce49b8a6c631661b53d9853d55532801c7a679f342ea5508cb36fb8ab | 355 | 29 |  import torch import torch.cuda._pin_memory_utils as pin_memory_utils from torch.storage import UntypedStorage from torch.utils.weak import WeakIdKeyDictionary |
| .venv/lib/python3.13/site-packages/torch/distributed/checkpoint/planner_helpers.py | 0cd90227751f77e5a0a99d8878c2e781cf9e610e74af7a844c5c97942beb7ddf | 491 | 4 |         layout=shard_properties.layout,         requires_grad=shard_properties.requires_grad,         memory_format=shard_properties.memory_format,         pin_memory=shard_properties.pin_memory,      |
| .venv/lib/python3.13/site-packages/torch/distributed/checkpoint/optimizer.py | d07cbc563f8d59bf50cdee5ddadbb9f7d6d9fc8335cdf242724396a4e00e860d | 358 | 6 |         layout=props.layout,         requires_grad=props.requires_grad,         pin_memory=props.pin_memory,         device=device,     ) |
| .venv/lib/python3.13/site-packages/torch/distributed/checkpoint/staging.py | fad178980b865e56ce9608ec7f9bf3a251ae754056752f003568b383c73c5783 | 116 | 3 |     """     An implementation of AsyncStager which stages the state_dict on CPU RAM and blocks until the copy is complete.     This implementation also provides an option to optimize stage latency usi |
| .venv/lib/python3.13/site-packages/torch/distributed/checkpoint/_extension.py | 000f36db335161a8b2619164bc68c2c9c0e4cb45664ae53503297c8feb66e8f0 | 222 | 3 |     or encryption.      Implementations should try to be memory friendly and performant.  For example, don't     read the whole input, then transform it, and write it back.  If at all possible, do it  |
| .venv/lib/python3.13/site-packages/torch/distributed/nn/functional.py | 56f0206329b4f5606cf96f9974ed535051ab185b0057357b746111d62d78edd8 | 453 | 1 |         ctx.group = group         ctx.op = op         tensor = tensor.clone(memory_format=torch.contiguous_format)         dist.all_reduce(tensor, op=op, group=group)         return tensor |
| .venv/lib/python3.13/site-packages/torch/distributed/nn/api/remote_module.py | d51779fdbafb1ca1d99d002e6f32cf17bc1fef730a6251e3ef0278d8078bd112 | 755 | 9 |                 >>>     def __init__(self) -> None:                 >>>         nn.Module.__init__(self)                 >>>         self.remote_embedding = RemoteModule(...)                 >>>       |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/__init__.py | 40c3e29452b64240e3f3de62e1faabb44e5bcf23b9e46264578b7810cff5433c | 78 | 20 | """  Torchelastic agent and user worker failover contract:  **TL;DR;**: |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/metrics/__init__.py | b862cc6af711998f8f7386523050aca6875ff15adaacd81cbf9349403c07b6d7 | 169 | 4 |           platform level metrics that it produces.           For instance torchelastic may output the latency (in milliseconds)           of a re-rendezvous operation from the agent as           ``(to |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/metrics/api.py | 484611e644832f5c2e6efc6c8d0cd86b96bbf70f69daa558c9f35c7a51412795 | 218 | 5 |     "MetricHandler",     "ConsoleMetricHandler",     "NullMetricHandler",     "MetricStream",     "configure", |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/api.py | f4223e7e3407fdb6999205bb8299c1063bd9387641d62a947792a3794baddbac | 391 | 1 |      @property     def use_agent_store(self) -> bool:         """Indicates that store reference returned by :py:meth:`next_rendezvous` can be shared with user         applications and will be availabl |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py | e30ba1d7af704712e640912854cd2e30acfd046e86b64be4555e9bb19013c300 | 1456 | 1 |      @property     def use_agent_store(self) -> bool:         """See base class."""         return os.getenv("TORCH_DISABLE_SHARE_RDZV_TCP_STORE", "0") != "1" |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py | 971ffd5b74b019562a14835d623949e9eb6d66ad164af655b0f07f083163b1fd | 129 | 2 |      Creates TCPStore based on the input parameters with the     listener on the agent with group_rank=0     """  |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/api.py | 1d8384edd84e06512890de38e86598369e833ceef8e52e5a93155aa5866a47a0 | 927 | 5 | class SignalException(Exception):     """     Exception is raised inside the torchelastic agent process by the termination handler     if the death signal got received by the process.     """ |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/subprocess_handler/subprocess_handler.py | 9871ee801f346c4952fcaf2cc87965f3c997d974b550df70e1fc7f4534c66e87 | 79 | 1 |     """     Convenience wrapper around python's ``subprocess.Popen``. Keeps track of     meta-objects associated to the process (e.g. stdout and stderr redirect fds).     """  |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py | 57a490021fa643f248bcb9f70637b9add1825c7190597cb2930c82679cd8274b | 386 | 13 |  """ Each host in a distributed PyTorch job runs with a single TorchElastic agent, and multiple workers (as children processes of the TorchElastic agent). Since the workers are user-provided (your PyT |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/timer/__init__.py | 210efd18aad05ff50a69bfcb6e9d2ea8cb8b81bd90cc342077d117ecd24ee5a5 | 55 | 8 |  """ Expiration timers are set up on the same process as the agent and used from your script to deal with stuck workers. When you go into a code-block that has the potential to get stuck you can acqui |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/utils/store.py | 4c1e0c72d7d479ecb3b9219eb7e8af33551261c8c9f9138deda8bcabbeca95d4 | 227 | 5 | ) -> list[bytes]:     """     Synchronizes ``world_size`` agents between each other using the underlying c10d store.     The ``data`` will be available on each of the agents.  |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/agent/server/health_check_server.py | 5c374b390139244ed4df957297639c3ddf45c17ef8923bd204315b345d3941cf | 66 | 2 |     Args:          alive_callback: Callable[[], int], callback to last progress time of agent          port: int, port number to start tcp/http server |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/agent/server/__init__.py | a7a3a6677502d91376efa1f724b5199b4ca067518159170e3aae0e430a334e8e | 42 | 9 |  """ The elastic agent is the control plane of torchelastic.  It is a process that launches and manages underlying worker processes. |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/agent/server/api.py | 23b2855079e0cb007b00f5e31c35546a1555a8d5fb54934890be13f3aa5f0773 | 967 | 67 |     "WorkerGroup",     "RunResult",     "ElasticAgent",     "SimpleElasticAgent", ] |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py | 24d0c86e6120057be3a3730a8942064df4a9bc57ea86ae58aa52ed0f03485bc1 | 412 | 33 | import torch.distributed.elastic.timer as timer from torch.distributed.elastic import events from torch.distributed.elastic.agent.server.api import (     RunResult,     SimpleElasticAgent, |
| .venv/lib/python3.13/site-packages/torch/distributed/elastic/events/api.py | 0ee09e52ba71883d08ebb8f1a5bec07f8b14a90baadf0e7b7bba36f6bfaf5d72 | 115 | 3 |     """Known identifiers of the event producers."""      AGENT = "AGENT"     WORKER = "WORKER"  |
| .venv/lib/python3.13/site-packages/torch/distributed/pipelining/_IR.py | c52dbd768077da13b98f03bb21ba1d431740ac16757d5fbc2ac5395f0bbd3f04 | 1247 | 1 |                 submod.recompile()          # [aliasing] This step is not super necessary, but helps reduce parameter usage/memory.         # After _sink_params() routine has run, clean up unused attr |
| .venv/lib/python3.13/site-packages/torch/distributed/pipelining/_backward.py | c05ffcf94b3790c1c25b8b13013a9c5d495d8662930adfb25ce67d65526cd9ca | 405 | 3 |     that aren't needed for dW because when we do dW calculation, we start from saved intermediates.     Detaching the stage_outputs_or_loss at the end of this function is important as     it frees up  |
| .venv/lib/python3.13/site-packages/torch/distributed/pipelining/stage.py | c1779619cae8fba25e2a1d77b99346025fb1cee96a67879525b3425f8a1eb490 | 1510 | 1 |             # stage_output is no longer used in the last stage for backward and only needed             # to return to the user in merge_output_chunks, therefore             # this should be detached  |
| .venv/lib/python3.13/site-packages/torch/distributed/pipelining/schedules.py | f20a2df5bcb9577d1598509cbcda8d49f7798837e612d33fb70284a6a0c64061 | 2774 | 3 |      UNSHARD refers to fetching the full contents of an FSDP-sharded layer, requiring an all-gather operation.     RESHARD does the opposite, releasing memory (but doing no communication)      We aban |
| .venv/lib/python3.13/site-packages/torch/distributed/algorithms/_comm_hooks/default_hooks.py | 8fc6595ee9327b427d042632bef73714606cb35c112e81fc765d6290063bdc4b | 193 | 1 |         ) from e      # Don't let this memory get reused until after the transfer.     orig_grad_data.record_stream(backend.current_stream())  # type: ignore[arg-type]  |
| .venv/lib/python3.13/site-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py | df706f293970d4177f2ba2133c9e5ffb4e98e424df56c7a42a450a0007629b08 | 325 | 2 |      def forward(self, *args, **kwargs):         with save_on_cpu(pin_memory=True):             return self._checkpoint_wrapped_module(*args, **kwargs)  |
| .venv/lib/python3.13/site-packages/torch/distributed/algorithms/model_averaging/utils.py | 7273c5d2d6144a06e3be3609a54cab5726f71f77d1b49dfcfd37e9f3e34c3a86 | 93 | 1 |      For allreduce efficiency, all the parameters are flattened into a contiguous buffer.     Thus, it requires extra memory of the same size as the given parameters.     """     group_to_use = proces |
| .venv/lib/python3.13/site-packages/torch/distributed/algorithms/ddp_comm_hooks/__init__.py | 74904328f788e2ab285f5b366ebba78f31de772546a606e3c4bec34fbb724444 | 111 | 1 |     )     # Rank-2 PowerSGD can give a higher accuracy than the default rank-1 version,     # but it runs slower and consumes more memory.     POWER_SGD_RANK2 = partial(         _powerSGD_comm_hook_wr |
| .venv/lib/python3.13/site-packages/torch/distributed/algorithms/ddp_comm_hooks/default_hooks.py | 4073ec7a6ec818dff053efaf7d9a3c24ffa255faf0d9e7bd56e38bd2a85e5222 | 206 | 3 |     def decompress(fut):         decompressed_tensor = buffer         # Decompress in place to reduce the peak memory.         # See: https://github.com/pytorch/pytorch/issues/45968         value = fu |
| .venv/lib/python3.13/site-packages/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py | 0093b7b94ce1688119ca49bfc9ec7e9894f7102d55e588cce0cf3dced326e834 | 861 | 50 |     4. ``orthogonalization_epsilon`` can be a very small value (e.g., 1e-8) added to every normalized matrix column in orthogonalization step, to prevent div-by-zero error if any column has all 0s. If |
| .venv/lib/python3.13/site-packages/torch/distributed/optim/functional_adagrad.py | 42a429c59544ccdf129c562005ca5a16c0a367cd27acd5b2cf13f63dbeaa2c13 | 116 | 1 |          # TODO: no union or any types in TorchScript, make step a scalar tensor instead         # This is also needed by if we want to share_memory on the step across processes         for p in self. |
| .venv/lib/python3.13/site-packages/torch/distributed/optim/functional_adamw.py | 5018b16c679e342d605bad7e0a68c08fb07ff29e418ad7fde0f3d6f65c184a55 | 204 | 6 |             # Exponential moving average of gradient values             state["exp_avg"] = torch.zeros_like(                 param, memory_format=torch.preserve_format             )             # Expo |
| .venv/lib/python3.13/site-packages/torch/distributed/optim/apply_optimizer_in_backward.py | b93359ca5c416815502b5b5e6323c9ed1e39fadf1aa86ea3a1e193deaca2d004 | 122 | 3 | __all__: list[str] = []  # WeakTensorKeyDictionary to store relevant meta-data for the Tensor/Parameter # without changing it's life-time. # NOTE: Alternative is to add the meta-data as an attribute t |
| .venv/lib/python3.13/site-packages/torch/distributed/optim/functional_adam.py | ae25b4144b862327c3821f9d9200c02ba5fb39f210e8b2ee38238e80c620f239 | 203 | 6 |             state["step"] = torch.tensor(0.0)             state["exp_avg"] = torch.zeros_like(                 param, memory_format=torch.preserve_format             )             state["exp_avg_sq"]  |
| .venv/lib/python3.13/site-packages/torch/distributed/optim/functional_rprop.py | 7794a768baf8f51ad8f4ac6e2312a6e53cdffdf7698d08fb50ed2a4686ef47ee | 108 | 1 |                     state["step"] = torch.tensor(0.0)                     state["prev"] = torch.zeros_like(                         param, memory_format=torch.preserve_format                     )     |
| .venv/lib/python3.13/site-packages/torch/distributed/optim/functional_adadelta.py | f1cb0f28143ecb1506dc5c5d88194d97e931c8f0804e6856884e6d4bd2f314ea | 112 | 2 |                     state["step"] = torch.tensor(0.0)                     state["square_avg"] = torch.zeros_like(                         param, memory_format=torch.preserve_format                     |
| .venv/lib/python3.13/site-packages/torch/distributed/optim/functional_rmsprop.py | 7a15a3959acfc7600a7f5c9005088248082c5ba434f9ea624e37156bae06ee08 | 131 | 3 |                     state["step"] = torch.tensor(0.0)                     state["square_avg"] = torch.zeros_like(                         param, memory_format=torch.preserve_format                     |
| .venv/lib/python3.13/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py | 08301d21ab96b99fa4ee9c69ac511ca489435b3f66128d4cc72a84ae73b50c15 | 1658 | 2 |     ``ZeroRedundancyOptimizer`` can be used in conjunction with     :class:`torch.nn.parallel.DistributedDataParallel` to reduce per-rank peak     memory consumption.      ``ZeroRedundancyOptimizer``  |
| .venv/lib/python3.13/site-packages/torch/distributed/optim/functional_adamax.py | e70d6eedde26f208a506276bd5864dbabe694a18fb9c361505921b9ced2921ef | 124 | 2 |                     # Exponential moving average of gradient values                     state["exp_avg"] = torch.zeros_like(                         param, memory_format=torch.preserve_format          |
| .venv/lib/python3.13/site-packages/torch/distributed/_tools/mem_tracker.py | 12cdef4620c111f141632dce669ee0921993a351fdf63f20227266a2ace96b56 | 950 | 91 | # https://github.com/pytorch/pytorch/blob/5fba5d83f0703ff8077ab65448a998e9ad6598fd/c10/cuda/CUDACachingAllocator.cpp#L117 _PYTORCH_MIN_ALLOCATE = (     2**9 if int(os.environ.get("PYTORCH_NO_CUDA_MEMO |
| .venv/lib/python3.13/site-packages/torch/distributed/_tools/ilp_utils.py | 8308a28370ec0b6f2c6bc78e06f96b0537f7099a8b398700ac95b5f69c544006 | 293 | 18 |     # Total ac run-time of the module     sac_runtime: float     # Total ac_memory for the module     sac_memory: int     # Number of piecewise-linear functions used for approximating ac tradeoff curv |
| .venv/lib/python3.13/site-packages/torch/distributed/_tools/runtime_estimator.py | b524c579574ccddaec710290de68301f1ec381a49e736c5e41bcb989eb490ace | 528 | 8 | # https://github.com/pytorch/pytorch/blob/5fba5d83f0703ff8077ab65448a998e9ad6598fd/c10/cuda/CUDACachingAllocator.cpp#L117 _PYTORCH_MIN_ALLOCATE = (     2**9 if int(os.environ.get("PYTORCH_NO_CUDA_MEMO |
| .venv/lib/python3.13/site-packages/torch/distributed/_tools/fsdp2_mem_tracker.py | a8b657880e80bc9791d9d71518f3e1d3d034f89bd0cafe51d1319998fa3017dd | 548 | 39 | class _FSDPRefType(_RefType):     """     Enumerates categories of memory usage in FSDP modules, including parameters, gradients, activations,     and optimizer states.  |
| .venv/lib/python3.13/site-packages/torch/distributed/_tools/sac_estimator.py | 57372e15473590f8ebfbb1fdd95c40649c600038e2fa3497b4de63575b9ecce6 | 961 | 75 | # https://github.com/pytorch/pytorch/blob/5fba5d83f0703ff8077ab65448a998e9ad6598fd/c10/cuda/CUDACachingAllocator.cpp#L117 _PYTORCH_MIN_ALLOCATE = (     2**9 if int(os.environ.get("PYTORCH_NO_CUDA_MEMO |
| .venv/lib/python3.13/site-packages/torch/distributed/_tools/__init__.py | 0d854ead53bfeaf059b84b96f0468a771b11f1b155a04d7a4760e219f2a8e893 | 13 | 2 | from .fsdp2_mem_tracker import FSDPMemTracker from .mem_tracker import MemTracker from .memory_tracker import MemoryTracker from .mod_tracker import ModTracker from .runtime_estimator import RuntimeEs |
| .venv/lib/python3.13/site-packages/torch/distributed/_tools/memory_tracker.py | 6f6f3b58c35afab5263a6127823f66abab20f53ff50812fa9247f1bf1a8c9e93 | 301 | 62 |   class MemoryProfileDispatchMode(TorchDispatchMode):     """Run in ``TorchDispatchMode`` to get memory stats at operator level."""  |
| .venv/lib/python3.13/site-packages/torch/distributed/_tools/fake_collectives.py | fe47faa3196e03911f22039e2aff19252c805ede4404d03973f1ffd1e8c3ae0e | 308 | 5 |     @staticmethod     def sum_tensors(arg: Any) -> int:         """Calculate total memory consumed by the tensors in the argument."""         total_memory = 0  |
| .venv/lib/python3.13/site-packages/torch/distributed/_tools/sac_ilp.py | 4f8355687c07083f218aaf145f6c7d94471dde31bf77ee22a4de83ad6bf64438 | 296 | 47 | def sac_milp(     graph: Graph,     memory_budget: float,     world_size: int = 1,     ac_units: Optional[list[str]] = None, |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/_state_dict_utils.py | bed3818e99f9761821de7bc8d2c577a5d3a700baf13416be09c2094dc5e45474 | 920 | 1 |                     f"Failed to clone() tensor with name {fqn} on rank {fsdp_state.rank}. "                     "This may mean that this state_dict entry could point to invalid "                     " |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py | 05ac88cfdcbc54939e4f7447115b7decd1ae10268c90c5d031febaafa7ed8a58 | 2176 | 29 |     pre-forward where the CPU thread is not issuing any kernels. This is     intentional and shows the rate limiter in effect. Synchronizing the CPU     thread in that way prevents over-allocating mem |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/_wrap_utils.py | 225606e881e6ca707f7ff2eff29907b289ba0a5aa6c646c81ab13709d0b31cf6 | 263 | 1 |                     msg += (                         " We do not recommend wrapping such modules since "                         "the gradient memory usage will be higher than expected "               |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/_optim_utils.py | f8fef1f7783114ee941f856f30d653c0fbbeb6166fc82571f79abf7b74d2e355 | 2073 | 6 |                 for state_name, param_state in list(unflat_osd_state[fqn].items()):                     if fsdp_state.rank > 0:                         # Deference the tensor so that PyTorch can colle |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/api.py | c00596878c002db35e8e2d3ef9f707e5335363067990a55536564e52cf2e4800 | 418 | 13 |     This configures explicit backward prefetching, which improves throughput by     enabling communication and computation overlap in the backward pass at the     cost of slightly increased memory usa |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/_unshard_param_utils.py | 468009e35a82484ce618e9d7ab8284a6949b5601e709befe2160c0d26a4c6d40 | 338 | 2 |         warnings.warn(             "offload_to_cpu=True and rank0_only=False may result in the"             "unsharded parameters being redundantly copied to CPU memory for "             "GPUs sharing |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/_shard_utils.py | 7a6d767e5d0c49626a8fb416976c4073eeb6409d6d29518c87c9078e80fcd9da | 138 | 2 |             layout=tensor.layout,             requires_grad=False,             memory_format=torch.contiguous_format,             pin_memory=tensor.is_pinned(),         ), |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/wrap.py | 769e98769e43248bcf24bc53e9b74d1c1a7ccf3c5b2ba68ae39fa7c3e9ddb06b | 597 | 2 |     same as ``module_classes``. Note that shared parameters must be wrapped in     the same FSDP instance, so this auto wrap policy can help wrap shared     embeddings into the same FSDP instance for  |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/_runtime_utils.py | 2f073baced74b301c7d187ff285f41f209804df877fd6b98d174dc32f76f052d | 1646 | 3 |             handle.flat_param._cpu_grad = torch.zeros_like(                 handle.flat_param._local_shard, device=torch.device("cpu")             ).pin_memory()          should_cast_forward_inputs =  |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/_flat_param.py | 9cc4ed5a598f9edf93a202842fcd67c818acc138a4540d3198496d1f61771747 | 2789 | 10 |         Shard the handle's ``FlatParameter``.          This allocates new memory for         the sharded flat parameter and frees the unsharded flat parameter's         storage. |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_api.py | 649484198fd0dba028f25a9f732b59bd7570aaf24082c8d70f056dea3caf89dc | 76 | 8 |      FSDP works well with module-level mixed precision since it keeps the     high-precision sharded parameters in memory anyway. In other words, FSDP     does not require any extra memory to keep a h |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param_group.py | 2798a87b2631091df738afaff6dfcead38ce0cc421585b4331ecaaefb4e784f5 | 770 | 8 | current all-gather. We do so using a separate copy-in stream. However, since we have the all-gather input as a view into the output, we must make sure to copy into different memory from the current al |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_param.py | 12e459491589b623158627846f837175eae353e685f691875b5eb6b7884896e1 | 897 | 13 | so it's safe to call .copy_() in the middle of the graph to update its content and start using the nn.Parameter downstream. (2) We always re-allocate the buffer for nn.Parameter to store the AllGather |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_init.py | 95cd101f9d5c1da7db1965fc2ecd2b344878e58a4d81299fdad1a1223e0a61aa | 243 | 1 |     for tensor in itertools.chain(params, buffers):         if tensor.device == device or tensor.device.type == "meta":             # Keep meta-device tensors on meta device for deferred init          |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/_fully_shard/_fsdp_collectives.py | 3bf079219682d1a9439b81754af65e87f69157ec69f20f065e5565519f7093d9 | 662 | 16 |   def allocate_memory(     size: int,     dtype: torch.dtype, |
| .venv/lib/python3.13/site-packages/torch/distributed/fsdp/_fully_shard/_fully_shard.py | 901220efd8b6ea015eebd468a689a8edcf5023cfcc3694159d892950261d8e15 | 673 | 13 |     Apply fully sharded data parallelism (FSDP) to ``module``, where FSDP     shards module parameters, gradients, and optimizer states across data     parallel workers to save memory at the cost of c |
| .venv/lib/python3.13/site-packages/torch/distributed/_shard/sharded_tensor/metadata.py | f768ac207d0ed93a8fcb72e2d421b4d11d026b5059e348063361872a426b6940 | 95 | 21 |     layout: torch.layout = field(default=torch.strided)     requires_grad: bool = False     memory_format: torch.memory_format = field(default=torch.contiguous_format)     pin_memory: bool = False  |
| .venv/lib/python3.13/site-packages/torch/distributed/_shard/sharded_tensor/__init__.py | cd13ef71cd9ed0a0f48231a745429a9d7c2e829204fc0a706e1a4e294a6a1e5f | 491 | 51 |     layout=torch.strided,     requires_grad=False,     pin_memory=False,     memory_format=torch.contiguous_format,     process_group=None, |
| .venv/lib/python3.13/site-packages/torch/distributed/_shard/sharded_tensor/api.py | 043b23a94f3d58ef8a61cfc0c991fbdbc07ed0bbcf5914b0ed92a416ca5d6fe9 | 1358 | 58 |         dtype = kwargs["dtype"]         layout = kwargs["layout"]         pin_memory = kwargs["pin_memory"]         requires_grad = kwargs["requires_grad"]  |
| .venv/lib/python3.13/site-packages/torch/distributed/_shard/sharded_tensor/utils.py | 0ceebdae3e06fc93ebfc294acb26aa1a4a9180ae743fd6c060eec67425307d5f | 324 | 10 |      if worker_name is not None:         if not rpc._is_current_rpc_agent_set():             raise RuntimeError(                 f"RPC framework needs to be initialized for using worker names: {worker |
| .venv/lib/python3.13/site-packages/torch/distributed/_shard/sharded_tensor/_ops/tensor_ops.py | 05e193172930597b2e589223d9092bb985f4f24a2fe81e89dd8e53e885046757 | 220 | 6 | def sharded_clone(args, kwargs, pg):     self_st = args[0]     desire_memory_format = kwargs.get("memory_format", None)     if desire_memory_format and desire_memory_format != torch.preserve_format:   |
| .venv/lib/python3.13/site-packages/torch/distributed/_shard/sharded_tensor/_ops/__init__.py | 356e135f2c394461426d67e2902bb1c423ab5ae548528bd7d3a8c8f0f81ca8d3 | 14 | 4 |  # Import all ChunkShardingSpec ops from torch.distributed._shard.sharding_spec.chunk_sharding_spec_ops.embedding import (     sharded_embedding, ) |
| .venv/lib/python3.13/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec.py | 5f7dbbd6c17aed47c52997ff03925676ea3c20e0c8b6778d356880eb35ec18de | 229 | 3 |             layout=tensor.layout,             requires_grad=tensor.requires_grad,             memory_format=torch.contiguous_format,             pin_memory=tensor.is_pinned(),         ) |
| .venv/lib/python3.13/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/embedding.py | bc2495f165eef0348ef414289fc84d13c99fe318aa6d302f36fea8ff78e98fe5 | 295 | 31 |   @custom_sharding_spec_op(ChunkShardingSpec, torch.nn.functional.embedding) def sharded_embedding(types, args, kwargs, pg):     """ |
| .venv/lib/python3.13/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/_common.py | e48e27f2f2764c4151427c86825b20888e08321589b62bb47bfed9edf894d1b5 | 349 | 16 |         gathered_inputs: list of inputs from all ranks. If specified, we             don't need to communicate with each rank any more.         mode: aggregation mode of EmbeddingBag.         gathered |
| .venv/lib/python3.13/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/embedding_bag.py | 8c553da9f8af534a796b02dae988d255889a072f27b26bdd678442c554430479 | 478 | 37 |   @custom_sharding_spec_op(ChunkShardingSpec, torch.nn.functional.embedding_bag) def sharded_embedding_bag(types, args, kwargs, pg):     """ |
| .venv/lib/python3.13/site-packages/torch/distributed/_shard/sharded_optim/api.py | 7566f9ffc9326918227bb10457352207d5d9ea945fe958f1e9a842653ba9aa39 | 103 | 1 |         Args:             set_to_none (bool): instead of setting to zero, set the grads to None.                 This will in general have lower memory footprint, and can modestly improve performance. |
| .venv/lib/python3.13/site-packages/torch/distributed/_symmetric_memory/__init__.py | 2c614d812bc0e6ddf4b3deb129fed5515cf1b570fd28d0ff1b53c556f7f68338 | 1731 | 39 | import torch.distributed.distributed_c10d as c10d from torch._C._autograd import DeviceType from torch._C._distributed_c10d import _SymmetricMemory, Work as _Work   |
| .venv/lib/python3.13/site-packages/torch/distributed/tensor/_shards_wrapper.py | 8bc2422a5c29f58e557acc8251556b9adedebb17167d0a875c1cf8dad89bac60 | 360 | 8 |     def handle_clone(args, kwargs) -> "LocalShardsWrapper":         self_ls = args[0]         desired_memory_format = kwargs.get("memory_format", None)         if desired_memory_format and desired_mem |
| .venv/lib/python3.13/site-packages/torch/distributed/tensor/_sharding_prop.py | f57ead5c030aae4098cbe5059c9ca9941ed6f70e580713ab8dd58e4f0a4b4e8d | 533 | 1 |          # NOTE: We must call the tracing in fake tensor mode so that it         # avoids materializing memory         with FakeTensorMode():             fake_args = op_schema.gen_fake_args() |
| .venv/lib/python3.13/site-packages/torch/distributed/tensor/_api.py | 8aaadd817b0f78d9c6e67c02efe08b3142342ab6f43023c4ccca06ac8359b062 | 1316 | 1 |         )          # We want a fresh Tensor object that shares memory with the input tensor         dist_tensor = DTensor(             input.view_as(input), |
| .venv/lib/python3.13/site-packages/torch/distributed/tensor/experimental/_attention.py | 6b5b81e533348467c3ce83b3291e06b876c64f576694b1ec110f0160f339f152 | 1459 | 2 |     else:         raise NotImplementedError(             "CP only supports flash attention and memory efficient attention now."         )  |
| .venv/lib/python3.13/site-packages/torch/distributed/tensor/parallel/fsdp.py | e9e356fdbc9e92d2195d25c07fc9bae9cb003f9dd913fb70cb726faaa819976b | 391 | 2 |             layout=dt.layout,             requires_grad=dt.requires_grad,             # ignore memory_format and pin_memory as those are not supported by DT         ),     ) |
| .venv/lib/python3.13/site-packages/torch/distributed/tensor/parallel/style.py | 9a3f52a8a4799476417f49a94136a8d1022c4550d0696e723ef23157090d4b72 | 813 | 13 | class ColwiseParallel(ParallelStyle):     """     Partition a compatible nn.Module in a column-wise fashion. Currently supports nn.Linear and nn.Embedding.     Users can compose it together with Rowwi |
| .venv/lib/python3.13/site-packages/torch/distributed/tensor/parallel/loss.py | 96c6b591bccc5e1383d3809dd38ac27364c79c7c6addaa782350102b1d9a2a64 | 491 | 2 | from torch.distributed.tensor import DTensor, Replicate, Shard from torch.distributed.tensor._dtensor_spec import DTensorSpec, TensorMeta from torch.distributed.tensor._ops._embedding_ops import _Mask |
| .venv/lib/python3.13/site-packages/torch/distributed/tensor/_ops/_embedding_ops.py | 74deafc10c34722a21a4875852af8e0c22a94b97dd4491a4250e0f891cfe08d8 | 273 | 21 |             raise RuntimeError("MaskBuffer has not been materialized")          # NOTE: _MaskPartial is being used by the embedding op and the gather op.         # For gather, the mask has the same di |
| .venv/lib/python3.13/site-packages/torch/distributed/tensor/_ops/_tensor_ops.py | 20e5dd89ec72fbea52ec1d92cfab36b663843543578d58d52547dee8706122e2 | 916 | 2 | ) from torch.distributed.tensor._ops._common_rules import pointwise_rule from torch.distributed.tensor._ops._embedding_ops import _MaskPartial from torch.distributed.tensor._ops.utils import (     exp |
| .venv/lib/python3.13/site-packages/torch/distributed/tensor/_ops/__init__.py | 6d00d1796a8f2e03407e30490b5f3f43c620f704e3fd9948bade829d0fca0626 | 10 | 1 | # Copyright (c) Meta Platforms, Inc. and affiliates from ._conv_ops import *  # noqa: F403 from ._embedding_ops import *  # noqa: F403 from ._math_ops import *  # noqa: F403 from ._matrix_ops import * |
| .venv/lib/python3.13/site-packages/torch/distributed/tensor/_ops/_math_ops.py | bbb4a29875d07a39c7f266b64596033d057e1cc76a02e8aa66993a5f1f52c30c | 1093 | 3 | class _NormPartial(Partial):     """     This placement is used for partial vector norm.      For p-norms (where p not inf or -inf), the p-norm over n elements computes |
| .venv/lib/python3.13/site-packages/torch/distributed/tensor/_ops/utils.py | 68276849e99549eb947957031ccb070e135a65eecdd4e2da55326c98f0eaaddf | 299 | 1 |     # that they get specialized here.     arg_names_that_require_specializing_cache_strategy = [         "memory_format",     ]  |
| .venv/lib/python3.13/site-packages/torch/distributed/tensor/debug/_visualize_sharding.py | 854f7479754b4a2f8a5ec89d4d4975b615e5ab0627d36ea2a9dc78d16903ceb4 | 228 | 1 |  def _get_text_color(color: str) -> str:     r, g, b = map(lambda x: int(x, 16), (color[1:3], color[3:5], color[5:7]))  # noqa: C417     if (r * 0.299 + g * 0.587 + b * 0.114) > 186:         return "# |
| .venv/lib/python3.13/site-packages/torch/distributed/rpc/options.py | 03ba2e757ce798d14c80ef116d3a8ed9b5e50a624d0c16a94db64a483965eb5e | 181 | 7 |     r"""     The backend options for     :class:`~torch.distributed.rpc.TensorPipeAgent`, derived from     :class:`~torch.distributed.rpc.RpcBackendOptions`.  |
| .venv/lib/python3.13/site-packages/torch/distributed/rpc/internal.py | cbc2b4e6be903f0472da02912d530d1b9c460b2d8abe1a84a41bf84b6bcec57b | 286 | 2 | import torch import torch.distributed as dist from torch._C._distributed_rpc import _get_current_rpc_agent   |
| .venv/lib/python3.13/site-packages/torch/distributed/rpc/constants.py | 005ceec488bd8085716fd9f264d67a87bd08b3e0d432c08767e5843b730e30ff | 25 | 2 |   # For any RpcAgent. DEFAULT_RPC_TIMEOUT_SEC: float = _DEFAULT_RPC_TIMEOUT_SEC DEFAULT_INIT_METHOD: str = _DEFAULT_INIT_METHOD |
| .venv/lib/python3.13/site-packages/torch/distributed/rpc/__init__.py | 8474ae8306a9e4c48e6311457784bfb819987c4e1070e72ec8e2541342c3b823 | 258 | 15 |         _enable_jit_rref_pickle,         _enable_server_process_global_profiler,         _get_current_rpc_agent,         _invoke_remote_builtin,         _invoke_remote_python_udf, |
| .venv/lib/python3.13/site-packages/torch/distributed/rpc/api.py | 88ee6a9e55966c067f07eafd81fc6b187e103c9ea18fafa2ca082bcf4d640396 | 966 | 31 |     _delete_all_user_and_unforked_owner_rrefs,     _destroy_rref_context,     _get_current_rpc_agent,     _invoke_remote_builtin,     _invoke_remote_python_udf, |
| .venv/lib/python3.13/site-packages/torch/distributed/rpc/server_process_global_profiler.py | b7cc86c68d2d8f8d6148cfdc3cc9c2490967619801ec3d5a301f94ee25ab8ec3 | 187 | 6 |             collection.          profile_memory (bool, optional): Whether to report memory usage, default: ``False``      .. warning:: |
| .venv/lib/python3.13/site-packages/torch/distributed/rpc/_utils.py | b5cab400338632677b3a4298158edaa6ee9ce3855b8052f108b38287e6a2caf5 | 48 | 5 |  def _update_group_membership(worker_info, my_devices, reverse_device_map, is_join):     from . import api, TensorPipeAgent      agent = cast(TensorPipeAgent, api._get_current_rpc_agent()) |
| .venv/lib/python3.13/site-packages/torch/distributed/rpc/backend_registry.py | 43a191e3741e79ff23b7f5c973a950cc71215f2b9e6363d00006b896d2203604 | 431 | 31 |         init_backend_handler (function): Handler that is invoked when the             `_init_rpc_backend()` function is called with a backend.              This returns the agent.     """     global B |
| .venv/lib/python3.13/site-packages/torch/distributed/rpc/_testing/__init__.py | c5253fd4e2b90f4bda153192c4f9735fa01de0212fb19bfb0c82586357765279 | 19 | 4 |  def is_available() -> bool:     return hasattr(torch._C, "_faulty_agent_init")   |
| .venv/lib/python3.13/site-packages/torch/distributed/rpc/_testing/faulty_agent_backend_registry.py | 2a6799d8a1c3c1258907799d7c0d3a85d69a6eddb9bca924514d61f12155935a | 63 | 5 |     from torch.distributed.rpc import api      from . import FaultyTensorPipeAgent, FaultyTensorPipeRpcBackendOptions      if not isinstance(store, dist.Store): |
| .venv/lib/python3.13/site-packages/torch/autograd/graph.py | ee04db40dc182b9e9f225dda52a14bf92ccdbcef8021137cb4409aec3d70d405 | 835 | 10 |     if you are doing inplace operation on the Tensor data in a way that Pytorch doesn't     know about. For example a custom kernel that reads the Tensor data_ptr and modifies     the memory inplace b |
| .venv/lib/python3.13/site-packages/torch/autograd/forward_ad.py | cbf7de1b0614b9f513a275974b3d6b986387677010f824c6909a83613ed3ee50 | 230 | 2 |     This function is backward differentiable.      Given a function `f` whose jacobian is `J`, it allows one to compute the Jacobian-vector product (`jvp`)     between `J` and a given vector `v` as fo |
| .venv/lib/python3.13/site-packages/torch/autograd/__init__.py | 0439167a6a8a4c50f73457c9961698611109638a1b146f0a084fa1ee3825273d | 607 | 17 |                     assert isinstance(out, torch.Tensor)                     new_grads.append(                         torch.ones_like(out, memory_format=torch.preserve_format)                     )   |
| .venv/lib/python3.13/site-packages/torch/autograd/functional.py | f61f0d78a8a92ae10c0ff234fe318291a3cc9ecb8917d189b45b60976fc71431 | 1195 | 36 |  def vjp(func, inputs, v=None, create_graph=False, strict=False):     r"""Compute the dot product between a vector ``v`` and the Jacobian of the given function at the point given by the inputs.      A |
| .venv/lib/python3.13/site-packages/torch/autograd/grad_mode.py | 1347d413ee8e7753a8c0c0ccaffc66496391cd8608991f5f2d551d0ff2af16d9 | 405 | 2 |      Disabling gradient calculation is useful for inference, when you are sure     that you will not call :meth:`Tensor.backward()`. It will reduce memory     consumption for computations that would o |
| .venv/lib/python3.13/site-packages/torch/autograd/profiler_util.py | a18d7340db376de8ee057ef5e73ab06523a7e5c69031d5563ad3f529764aaae8 | 1151 | 78 |     def __init__(self, *args, **kwargs):         use_device = kwargs.pop("use_device", None)         profile_memory = kwargs.pop("profile_memory", False)         with_flops = kwargs.pop("with_flops",  |
| .venv/lib/python3.13/site-packages/torch/autograd/profiler_legacy.py | 9f25ee2336b482816844459d02fce732517e10352f9516d0444637990a31f9d6 | 313 | 37 |     EventList,     FunctionEvent,     MEMORY_EVENT_NAME, )  |
| .venv/lib/python3.13/site-packages/torch/autograd/gradcheck.py | ddb15be455841f2f0797a7e8b045d1f91596046d7c7433c522ab01e7c032b259 | 2274 | 17 | def _compute_numerical_gradient(fn, entry, v, norm_v, nbhd_checks_fn):     # Computes numerical directional derivative as finite difference     # of function `fn` at input `entry`, perturbed by vector |
| .venv/lib/python3.13/site-packages/torch/autograd/profiler.py | df76dcc7b27c3315940e035c792f4482b0a2e8b43133476fed6503380b3f10f0 | 1214 | 35 |     EventList,     FunctionEvent,     MEMORY_EVENT_NAME,     MemRecordsAcc,     OUT_OF_MEMORY_EVENT_NAME, |
| .venv/lib/python3.13/site-packages/torch/autograd/function.py | 742354903fca26f5f71ff60d870fbb9d1f17e03707feb562010af32ff24f7aa9 | 845 | 1 |         All tensors intended to be used in the backward pass should be saved         with ``save_for_backward`` (as opposed to directly on ``ctx``) to prevent         incorrect gradients and memory le |
| .venv/lib/python3.13/site-packages/torch/fx/graph_module.py | e37eac2ee7214a78e06eb7e0aca5793f10b7f921cbd47d6a94392ba23fc24d70 | 1091 | 1 |     Deserialize a GraphModule given the dictionary of the original module,     using the code to reconstruct the graph. We delete the actual graph before     saving the dictionary so that changes to t |
| .venv/lib/python3.13/site-packages/torch/fx/graph.py | 1345909f76c26b048a09c718891f96320d32fd1ccf3d177cd93823e181319e1f | 2004 | 3 | _torch_but_not_dynamo = re.compile(     r"^torch(?:\.(?!_dynamo\.\|_inductor\.)[^.]+)*$" ).fullmatch   |
| .venv/lib/python3.13/site-packages/torch/fx/interpreter.py | 824d18575c4b1347d9c65d08f93802cd589e4f517da8b3f1a99b99b9239b1cfc | 604 | 1 |         module (torch.nn.Module): The module to be executed         garbage_collect_values (bool): Whether to delete values after their last             use within the Module's execution. This ensures |
| .venv/lib/python3.13/site-packages/torch/fx/_symbolic_trace.py | 3e3b9434a386e0b0d53a171611c0bf3b6a468ab718b6ca45c4d3ddfbafb4dcd0 | 1336 | 2 |  if os.environ.get("FX_PATCH_GETITEM") == "1":     # This change is needed to trace models like PositionalEmbedding from BERT:     # https://github.com/pytorch/benchmark/blob/master/torchbenchmark/mod |
| .venv/lib/python3.13/site-packages/torch/fx/node.py | c8c9a520d27d524d96f66ba964c4b439829ffd4b418a69c1ba8ee21611cbadc2 | 889 | 1 |     torch.Tensor,     torch.device,     torch.memory_format,     torch.layout,     torch._ops.OpOverload, |
| .venv/lib/python3.13/site-packages/torch/fx/experimental/meta_tracer.py | 35ffd6f09b624e2e5280eb2fcd4cd82f0e1aea8be2c6c86bbb4aa95415539658 | 312 | 4 |   def embedding_override(self, input):     return torch.empty(*input.shape, self.weight.shape[-1], device="meta")  |
| .venv/lib/python3.13/site-packages/torch/fx/experimental/partitioner_utils.py | 3a58ad0fdd4019dbab179f8fee1213ca0c9602b5f9bcbf622fde62665c241970 | 318 | 2 |  class NodeLatency(NamedTuple):     # Latency due to the memory bandwidth     mem_latency_sec: float     # Latency due to the computation |
| .venv/lib/python3.13/site-packages/torch/fx/experimental/accelerator_partitioner.py | 0a202eba56a310dcf06047bbc6f3131a487c306105fd7dc16959acd39b0fd74e | 1081 | 59 |     """Given a list of partitions and a list of devices, returns:     1. A mapping from device to partitions on it;     2. A mapping from device to its remaining memory size;     3. A list of partitio |
| .venv/lib/python3.13/site-packages/torch/fx/experimental/sym_node.py | 44bc9633ba125dc6d02e6f4a4605966bcafec491676991ff55ffba6b3e06412f | 1848 | 2 |         r &= sympy.Ne(sizes[d], 0) & (strides[d] >= m)         # Fallback to NCHW as default layout for ambiguous cases         # This is the flaw of implicit memory_format from strides.         # N11 |
| .venv/lib/python3.13/site-packages/torch/fx/experimental/symbolic_shapes.py | 5149dde2ea39f25fe40933abcc2519b823fa77ca1f988489f96e96f8c63ca4b4 | 8056 | 6 |  @dataclass(frozen=True) class CallMethodKey:     name: str  |
| .venv/lib/python3.13/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_transformation.py | e3b4da5731e43aed03057c26e910aec3f099ba9dc04f62c4465e47759c78f4ac | 1323 | 12 |     )      [c2, c3, c4, c5], counter = gen_greatest_upper_bound(constraint, counter)      return Disj([c1, c2, c3, c4, c5]), counter |
| .venv/lib/python3.13/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py | 0f5e47499fd687dd2805d42f2152084741c54f75d778066d3bfd9b4effcb0354 | 1563 | 27 |     "conv2d_inference_rule",     "cumsum_inference_rule",     "embedding_inference_rule",     "embedding_inference_rule_functional",     "eq_inference_rule", |
| .venv/lib/python3.13/site-packages/torch/fx/passes/shape_prop.py | d85ad6810163e7c02ee7d98feae0631ae02e127bb1e7e9e2457ed82fdb817dc4 | 231 | 10 | from torch._dispatch.python import enable_python_dispatcher from torch._guards import detect_fake_mode from torch._prims_common import definitely_contiguous_for_memory_format from torch._subclasses.me |
| .venv/lib/python3.13/site-packages/torch/fx/passes/runtime_assert.py | c5ed881d3e3c6ed07c773de6cc43cb189ed6921b3a906553a0d6f853181d0017 | 634 | 3 |         _get_placeholder_expr,         _has_uninterpretable_sympy_function,         CallMethodKey,         cast_symbool_to_symint_guardless,         ConvertIntKey, |
| .venv/lib/python3.13/site-packages/torch/fx/passes/reinplace.py | e06818303ccdb8b87e2f4f8a8628d7755c2bfe6e1a5689712d691742878361e9 | 755 | 3 |            that directly use inplace comparison ops though.             We also cannot re-inplace on tensors that have overlapping memory,            e.g. torch.ones(1).expand(4, 4).add_(1)  |
| .venv/lib/python3.13/site-packages/torch/fx/passes/splitter_base.py | c60001b257180d041179cddf7df141df9a5c215335a14070cf546a4d4148dc48 | 926 | 3 |     def get_node_submodule_map(self) -> dict[str, str]:         """Returns a map from node name to submodule name, e.g.         node: main_module_impl_impl_over_arch_unary_multiple_embedding           |
| .venv/lib/python3.13/site-packages/torch/fx/passes/backends/cudagraphs.py | 47dfdca772710e5ce3b046ef149c0eb34fb31f989c25dca3ccfcac6f8adc8e1c | 62 | 1 |             return False          if node.target in [torch.ops.aten.embedding_dense_backward.default]:             return False  |
| .venv/lib/python3.13/site-packages/torch/_prims_common/__init__.py | 5716115f93924a28c5e5b51c21daa7f0ba77f45a321698aeaf860416a05fbf12 | 2108 | 39 |   _memory_formats = {     torch.contiguous_format,     torch.preserve_format, |
| .venv/lib/python3.13/site-packages/torch/_prims_common/wrappers.py | 56548da46a137bd62811bbbb7509ebad89fb3b3eb0b8062aaab4ff2a0e7be8f7 | 480 | 10 |     out: TensorLikeType,     shape: ShapeType,     memory_format: Optional[torch.memory_format] = None, ):     if _resize_output_check(out, shape): |
| .venv/lib/python3.13/site-packages/torch/multiprocessing/__init__.py | 3b00cb1453bdb5c280091caecb4a9ecab95c2ca5b50a5a9335ec64b70958897c | 123 | 4 | """torch.multiprocessing is a wrapper around the native :mod:`multiprocessing` module.  It registers custom reducers, that use shared memory to provide shared views on the same data in different proce |
| .venv/lib/python3.13/site-packages/torch/multiprocessing/reductions.py | 8d2ff4ea1fccf967b8dba8e51b3883f11ef41974d8b994b894e72cf807abc1f1 | 648 | 4 |     # receiver side. However, cudaIpcMemHandles from each device in a given process may     # only be opened by one context per device per other process.     # If we open and close a memory handle mul |
| .venv/lib/python3.13/site-packages/torch/multiprocessing/pool.py | 1d0b5dfd5de858a9e4a5046b47872eb5515d970c56c200a25153d84905da53b3 | 53 | 1 |     """Pool implementation which uses our version of SimpleQueue.      This lets us pass tensors in shared memory across processes instead of     serializing the underlying data.     """ |
| .venv/lib/python3.13/site-packages/torch/cuda/_pin_memory_utils.py | ad74fe0826894c0556780af291a2706bb31fd026ab4a676126862ca99f1cadb1 | 25 | 4 |   def pin_memory(data_ptr: int, size: int) -> None:     cudart = torch.cuda.cudart()     succ = int( |
| .venv/lib/python3.13/site-packages/torch/cuda/memory.py | 3afde64252800d6ce537ff62d471d1c60f9c07ea9c0022074db299d90d1f865d | 1238 | 257 | # mypy: allow-untyped-defs r"""This package adds support for device memory management implemented in CUDA."""  import collections |
| .venv/lib/python3.13/site-packages/torch/cuda/jiterator.py | 0efaba743d0a7785c1bd2704effe818ec742cd377f724834f318d3ead98b67d0 | 188 | 1 |     The code string has to be a valid CUDA function that describes the computation for a single element. The code     string has to follow the c++ template pattern, as shown in the example below. This |
| .venv/lib/python3.13/site-packages/torch/cuda/__init__.py | d3f653e93dae15f5c8ea3cf65e66cce3156d1f8ddeaa000e970b14c0a29718a8 | 1933 | 42 |                 _lazy_seed_tracker.queue_seed(callable, traceback.format_stack())             else:                 # Don't store the actual traceback to avoid memory cycle                 _queued_cal |
| .venv/lib/python3.13/site-packages/torch/cuda/_gpu_trace.py | 71528299c44148e5fff9bc18ba9bc5c58a27e9ca14d4258d303773113fca5b1b | 74 | 8 | ) EventWaitCallbacks: "CallbackRegistry[int, int]" = CallbackRegistry("CUDA event wait") MemoryAllocationCallbacks: "CallbackRegistry[int]" = CallbackRegistry(     "CUDA memory allocation" ) |
| .venv/lib/python3.13/site-packages/torch/cuda/_sanitizer.py | edf5b060bced327669b8c723fb3448a60f9f675926500cbe6ff18236acef98f3 | 663 | 6 |         self.syncs.stream_wait_for_event(stream, event)      def _handle_memory_allocation(self, data_ptr: DataPtr) -> None:         self.tensors_accessed.ensure_tensor_does_not_exist(data_ptr)        |
| .venv/lib/python3.13/site-packages/torch/cuda/random.py | ce480614c20e483997acab385e058e08da59aaaa9918e856332ca9117c233255 | 185 | 1 |             # Clone the state because the callback will be triggered             # later when CUDA is lazy initialized.             new_state = new_state.clone(memory_format=torch.contiguous_format)   |
| .venv/lib/python3.13/site-packages/torch/cuda/_memory_viz.py | fde8803c74de4dee6a28618983727325356ce603f2446678f1bbb1b15c808f20 | 740 | 39 | cache = lru_cache(None)  __all__ = ["format_flamegraph", "segments", "memory", "compare"]   |
| .venv/lib/python3.13/site-packages/torch/cuda/tunable.py | 2566cf78f1fe1e75569f6fe815c952a5942a8fd662f0821365a4e0181eadd580 | 822 | 4 | There are several use cases for offline tuning.  One use case involves a workload with a high-memory utilization, where regular tuning might lead to running out of memory.  Another use case is for com |
| .venv/lib/python3.13/site-packages/torch/cuda/graphs.py | b707ce7ada16e40bed7e588da0ef46b2b31a74a20ad77f4d100a5b89f13f44b9 | 527 | 22 | # Python shim helps Sphinx process docstrings more reliably. def graph_pool_handle():     r"""Return an opaque token representing the id of a graph memory pool.      See :ref:`Graph memory management< |
| .venv/lib/python3.13/site-packages/torch/cuda/_utils.py | c4d4a1c5324d4b348b5df5b619e7f146342a03af921e93e8d329f31e30d2a3af | 364 | 1 |             args (list): List of arguments to pass to the kernel.                          PyTorch tensor arguments will be automatically converted to pointers.             shared_mem (int): Shared me |
| .venv/lib/python3.13/site-packages/torch/backends/cpu/__init__.py | 57795130bf5b1e536f7c4e6238724ff6437e3f85af10ddb749e1902cb0d81273 | 22 | 1 |     - "DEFAULT"     - "VSX"     - "Z VECTOR"     - "NO AVX"     - "AVX2" |
| .venv/lib/python3.13/site-packages/torch/backends/cuda/__init__.py | 7aee59100e0ab8dc41d4002871ae6223f710cda03cad7397d3c57ea240ddecdd | 537 | 2 |     .. warning:: This flag is beta and subject to change.      Returns whether memory efficient scaled dot product attention is enabled or not.     """     return torch._C._get_mem_efficient_sdp_enabl |
| .venv/lib/python3.13/site-packages/torch/backends/xeon/run_cpu.py | 9224ebeb0d1eb32d35fbff605639a1d41785ad59e951502a8863641bc71ae6ee | 943 | 20 |     +-----------------------------+----------------------+-------+  To get the peak performance on Intel(R) Xeon(R) Scalable Processors, the script optimizes the configuration of thread and memory man |
| .venv/lib/python3.13/site-packages/torch/backends/_nnapi/serializer.py | 344dd21c4628545a032e6f129d785b72a0e25fd8d12ffc8c3207e223c575375e | 2229 | 14 |     DEPTH_TO_SPACE = 5     DEQUANTIZE = 6     EMBEDDING_LOOKUP = 7     FLOOR = 8     FULLY_CONNECTED = 9 |
| .venv/lib/python3.13/site-packages/torch/backends/_nnapi/prepare.py | 3e31cc39c0a24c4bd9c9ebd006c75604a39aaf301712e8f327c61f32a3b5383f | 200 | 1 |      This module handles preparing the weights, initializing the     NNAPI TorchBind object, and adjusting the memory formats     of all inputs and outputs.     """ |
| .venv/lib/python3.13/site-packages/torch/_decomp/decompositions.py | 7c377696572667d07da49147dff5fba77b9ee1079a9ff3eb40b3dfa1f29a811d | 5225 | 73 |     IntLike,     NumberType,     suggest_memory_format,     TensorLike,     TensorSequenceType, |
| .venv/lib/python3.13/site-packages/torch/_decomp/__init__.py | fc54d1278b405bad3ee5e16e16c23d13cad76a10b2f0684ba01153c929fa8eb5 | 545 | 2 |             aten.elu_,             aten.elu_backward,             aten._embedding_bag,             aten.embedding_dense_backward,             aten.empty_like, |
| .venv/lib/python3.13/site-packages/torch/_decomp/decompositions_for_rng.py | 4caf88b8808abf0da6351754cc176298981562cadfc5e82b848183f62ac8efbb | 267 | 3 | # ops like dropout which have fused implementation and can hide the rand inside. @register_rng_decomposition(aten.rand) def rand(shape, dtype=None, layout=torch.strided, device=None, pin_memory=False) |
| .venv/lib/python3.13/site-packages/torch/xpu/memory.py | 234a0517f082953f47829e430b4e30cafd3d43c2f7048806ad488047a98de9fb | 209 | 53 |  def empty_cache() -> None:     r"""Release all unoccupied cached memory currently held by the caching     allocator so that those can be used in other XPU application.  |
| .venv/lib/python3.13/site-packages/torch/xpu/__init__.py | 6dae6219ca075f20d407d40f928712a60f0ec4c3515b5756d67000f66eeb8b5b | 562 | 18 |             _lazy_seed_tracker.queue_seed(callable, traceback.format_stack())         else:             # Don't store the actual traceback to avoid memory cycle             _queued_calls.append((calla |
| .venv/lib/python3.13/site-packages/torch/xpu/_gpu_trace.py | 1cf591d60b855b0306b0d32f540696e5c8cfb5ab0e48ba9978e73478bd829249 | 70 | 8 | ) EventWaitCallbacks: "CallbackRegistry[int, int]" = CallbackRegistry("XPU event wait") MemoryAllocationCallbacks: "CallbackRegistry[int]" = CallbackRegistry(     "XPU memory allocation" ) |
| .venv/lib/python3.13/site-packages/torch/xpu/random.py | 1a76fcaaf6e9d9a57cbafd79bd27e296e227ae7bde9d0941fa8feca091d61a36 | 178 | 1 |     """     with torch._C._DisableFuncTorch():         new_state_copy = new_state.clone(memory_format=torch.contiguous_format)     if isinstance(device, str):         device = torch.device(device) |
| .venv/lib/python3.13/site-packages/torch/masked/_ops.py | 8d9681d35949643e9ff74533f865cb198644a173be66255b0b38e5cd4861a004 | 1812 | 5 | dim (int): the dimension along which {operation name} is computed.""",         ord="""\ ord (int, float, optional): the order of vector norm. Default: 2.   See :func:`torch.linalg.vector_norm` for a l |
| .venv/lib/python3.13/site-packages/torch/masked/_docs.py | 26bfa20fc306ff817a229ff2c5ba04f0eaf59acf9ba376b2ffaa5d8206df578e | 1178 | 4 | Args:     input (Tensor): the input tensor     ord (int, float, optional): the order of vector norm. Default: 2.       See :func:`torch.linalg.vector_norm` for a list of supported norms.     dim (int  |
| .venv/lib/python3.13/site-packages/torch/optim/rmsprop.py | e40c58be6b30bdf353c6f30cdbda42adcaa5c052ab12cac2c942adb20f038670 | 540 | 4 |                 )                 state["square_avg"] = torch.zeros_like(                     p, memory_format=torch.preserve_format                 )                 if group["momentum"] > 0: |
| .venv/lib/python3.13/site-packages/torch/optim/_adafactor.py | f7d699faa24fb680911364d62eb946990ccf9e81ad36cd50579fa8e0d7b8b33e | 655 | 15 |                 else:                     state["variance"] = torch.zeros_like(                         p.grad, memory_format=torch.preserve_format                     )  |
| .venv/lib/python3.13/site-packages/torch/optim/sparse_adam.py | d2832bda6e1e984ebfaa4136e4fcc5bd7d623c63d530a79517127a9784b09a0e | 185 | 4 |                         # Exponential moving average of gradient values                         state["exp_avg"] = torch.zeros_like(                             p, memory_format=torch.preserve_format  |
| .venv/lib/python3.13/site-packages/torch/optim/rprop.py | 7d8db83de6efdb312beddb972027aff052f2c5070b757e1f70b4fc6c8b94e88c | 470 | 5 |                 )                  state["prev"] = torch.zeros_like(p, memory_format=torch.preserve_format)                 if p.dtype.is_complex:                     # Complex Number should be as if  |
| .venv/lib/python3.13/site-packages/torch/optim/sgd.py | d687c42d1b805a041e6a5ced6e287ca59d18ec432791a1624b0d7e4ece2ea314 | 539 | 1 |          if weight_decay != 0:             # Re-use the intermediate memory (device_grads) already allocated for maximize             if maximize:                 torch._foreach_add_(device_grads, dev |
| .venv/lib/python3.13/site-packages/torch/optim/adamax.py | 47e41437326765d4a59a7c54741198230ebfdfb7f4578f03ca1dac621c491741 | 483 | 3 |                 )                 state["exp_avg"] = torch.zeros_like(                     p, memory_format=torch.preserve_format                 )                 state["exp_inf"] = torch.zeros_like( |
| .venv/lib/python3.13/site-packages/torch/optim/adagrad.py | b4913c0273ae16979f6b6831bfd2030a1c04cf5701184c3049805ec1445ca54b | 574 | 5 |                 )                 state["sum"] = torch.full_like(                     p, init_value, memory_format=torch.preserve_format                 )  |
| .venv/lib/python3.13/site-packages/torch/optim/lbfgs.py | 0cf551690abe063350dc3d22923f6809b230424f55d4b105988b9e17f678fcb8 | 496 | 13 |     # ported from https://github.com/torch/optim/blob/master/lswolfe.lua     d_norm = d.abs().max()     g = g.clone(memory_format=torch.contiguous_format)     # evaluate objective and gradient using i |
| .venv/lib/python3.13/site-packages/torch/optim/radam.py | 89ef232391523005d24c2c4b8107115c73d2b443f7001e3722bc48f40a1d5421 | 620 | 4 |                     # Exponential moving average of gradient values                     state["exp_avg"] = torch.zeros_like(                         p, memory_format=torch.preserve_format              |
| .venv/lib/python3.13/site-packages/torch/optim/adam.py | 46296644b82ae5f2ecae17ee30ce4691f4cc2078a0e478ec2beef10ffbe8018e | 970 | 5 |                     # Exponential moving average of gradient values                     state["exp_avg"] = torch.zeros_like(                         p, memory_format=torch.preserve_format              |
| .venv/lib/python3.13/site-packages/torch/optim/optimizer.py | 22e21ad10aa7cd994189a9fa7d19c169df4dc9d0c4f4a8dc3fca6aa4568fcabe | 1154 | 3 |             foreach over the for-loop implementation on CUDA, since it is usually             significantly more performant. Note that the foreach implementation uses             ~ sizeof(params) more |
| .venv/lib/python3.13/site-packages/torch/optim/nadam.py | a088dc776dad97562bd4a3320c66f8ccffd997592c58b1370532c1e574c8a64d | 667 | 9 |                     # Exponential moving average of gradient values                     state["exp_avg"] = torch.zeros_like(                         p, memory_format=torch.preserve_format              |
| .venv/lib/python3.13/site-packages/torch/optim/asgd.py | b739cecb1a02a86bfe713531e16d252c29329cc638523ebaacc6031844dc92fa | 475 | 1 |                     )                     state["ax"] = torch.zeros_like(                         p, memory_format=torch.preserve_format                     )  |
| .venv/lib/python3.13/site-packages/torch/optim/adadelta.py | cbd503a18d57033143fdb4f1c66a7bf2f01bb6a9d65a021ab37d7e6233ef4fb9 | 471 | 3 |                  state["square_avg"] = torch.zeros_like(                     p, memory_format=torch.preserve_format                 )                 state["acc_delta"] = torch.zeros_like( |
| .venv/lib/python3.13/site-packages/torch/_inductor/cudagraph_trees.py | cf39245a97cc8cbfc056259fd4818d3af45ad85fc77c90d337a28037a4fbeb08 | 2576 | 62 | """ CUDA graph trees are a safety abstraction over CUDAGraphs, similar to make_graph_callables, which share the same memory pool.  Sharing a memory pool is an extremely important optimization when cha |
| .venv/lib/python3.13/site-packages/torch/_inductor/select_algorithm.py | 622d14e8b9675f3bdca1c0baaa005b07359e7be09839e938d12d20c93d709907 | 3182 | 2 |         self.subgraphs: Optional[list[ir.ComputedBuffer]] = subgraphs          # Some templates use extra global memory as a workspace         self.workspace_arg = workspace_arg         if workspace_a |
| .venv/lib/python3.13/site-packages/torch/_inductor/ops_handler.py | ebd867cdaa3fbc8f94542cfab6c8c974c1ff4483b2ffefed8c8392c1f3e14eab | 1148 | 5 |     def to_dtype_bitcast(self, x: T, dtype: torch.dtype, src_dtype: torch.dtype) -> T:         """         Reinterpret cast x to dtype (reinterpreting the bits in memory as another dtype.)         src |
| .venv/lib/python3.13/site-packages/torch/_inductor/codecache.py | 971ca0978de4e920fd45e2e92b660216eb8a14b962e410c1388afc371b77feb4 | 4043 | 11 |             torch.are_deterministic_algorithms_enabled(),             torch.is_deterministic_algorithms_warn_only_enabled(),             torch.utils.deterministic.fill_uninitialized_memory,  # type: i |
| .venv/lib/python3.13/site-packages/torch/_inductor/cpp_builder.py | 2345a91613597748715e0c4f6d4c26eadd8e1ba53177cfbbe427c5f78628db3a | 1862 | 2 |          if sys.platform != "darwin":             # on macos, unknown argument: '-fno-tree-loop-vectorize'             if _is_gcc(cpp_compiler):                 cflags.append("fno-tree-loop-vectorize" |
| .venv/lib/python3.13/site-packages/torch/_inductor/cpu_vec_isa.py | 2f78c89f6a40a3e36eb91d9f1fcbdbfacace1e6476410864719d621507efe428 | 448 | 15 |     _dtype_nelements: dict[torch.dtype, int]      # Note [Checking for Vectorized Support in Inductor]     # TorchInductor CPU vectorization reuses PyTorch vectorization utility functions     # Hence, |
| .venv/lib/python3.13/site-packages/torch/_inductor/config.py | 9c9f68771e08689e8f75a7972c98578403cdbd41065a74ebe8e9f1b0c62333cd | 1771 | 28 |  # Enable pooled allocations for non-output tensors memory_planning = os.environ.get("TORCHINDUCTOR_MEMORY_PLANNING", "0") == "1"  # Enable to allow using ftz variant of exponenet instruction in trito |
| .venv/lib/python3.13/site-packages/torch/_inductor/compile_fx_ext.py | e09b40a785ab79b85f936d2990fbb20111774e5ec877f28b7cffcec4202ed703 | 682 | 3 | from .debug import DebugContext from .graph import GraphLowering from .output_code import complex_memory_overlap as complex_memory_overlap  # noqa: F401 from .virtualized import V  |
| .venv/lib/python3.13/site-packages/torch/_inductor/comms.py | 298ca1306b84bc7b98d251048bd0f6a1a6deb4a3e6e6a09e65eddfbb03bbbb83 | 1064 | 39 | from . import config, ir from .dependencies import WeakDep from .memory import estimate_peak_memory, FreeableInputBuffer, get_freeable_input_buf from .utils import (     contains_collective, |
| .venv/lib/python3.13/site-packages/torch/_inductor/memory.py | 439a20b3d2395ca727202f74419d2cd6429a06240331bbfd1004d1ea19ebc8bb | 698 | 100 |  @dataclasses.dataclass class PeakMemoryResult:     order: list[BaseSchedulerNode]     peak_memory: int |
| .venv/lib/python3.13/site-packages/torch/_inductor/async_compile.py | fe664d214acbd5b8349d378c25ffa8d92fe6405df331ecca6458ff4321c62e91 | 542 | 1 | class CompiledTritonKernels:     """     In memory cache for storing compiled triton kernels.      Each triton kernel is keyed by the hash of its source code. Each value stored |
| .venv/lib/python3.13/site-packages/torch/_inductor/pattern_matcher.py | 7ab2de204af88b880c4c49b5c85d77d86a9cddae948b296374c94358ada76961 | 2269 | 5 |   class CallMethod(_TargetArgsExpr):     """     Matches a call_method node in the FX graphs: `fns[i].method(*args, **kwargs)` |
| .venv/lib/python3.13/site-packages/torch/_inductor/aoti_eager.py | f1ec8a2644668b3bc7314038b9f3708503b7be56e8242eec237d59f4ef2a5802 | 299 | 3 |                                 torch, metadata["layout_value"].split(".")[-1]                             )                         if "memory_format_value" in metadata:                             m |
| .venv/lib/python3.13/site-packages/torch/_inductor/graph.py | b0f880077a7e1afdcbe5ffb00aab87ca750e2af516963c46a6be1abf1da4e5a8 | 2433 | 5 |         # Note: [Input Alignment handling in Inductor]         # Alignment matters for generating efficient code. Some operations,         # e.g. vectorized loads, can only be performed on aligned inp |
| .venv/lib/python3.13/site-packages/torch/_inductor/lowering.py | 4355cabd252f503c438e7965e967ebed199e35e38f4c7f9f94a63db150f0c063 | 7152 | 66 |         input.get_dtype() in [torch.int8, torch.uint8] for input in inputs     ):         # TODO <leslie> Remove this fallback when we support vectorization         # code gen with uint8 data type dir |
| .venv/lib/python3.13/site-packages/torch/_inductor/jagged_lowerings.py | d24feb89ca8618eae1134d6c8f50b9cbd001ca33d5a5c748798109055222be74 | 269 | 5 |     # ops.bucketize takes offsets.get_name() which doesn't exist on Pointwise     # kernels, i.e. we need to realize it before using. In other words, we need     # offsets to be in global memory so th |
| .venv/lib/python3.13/site-packages/torch/_inductor/compile_fx.py | 44e139ec125ce96d8ac44df157766453a70f7c5b1521ae6f0cc37acf8280b51b | 2615 | 9 | from .graph import GraphLowering from .ir import get_device_type, IRNode from .output_code import complex_memory_overlap as complex_memory_overlap  # noqa: F401 from .triton_bundler import TritonBundl |
| .venv/lib/python3.13/site-packages/torch/_inductor/ir.py | d2f3bbc708a44a6d942f2c69889d9e286b7908cbcd5a15c157f759720c87f87a | 8452 | 32 |         If the IRNode refers to data which has not been materialized (e.g.,         it is a Pointwise/Reduction that could potentially have more         compute fused into it), realize the IRNode into |
| .venv/lib/python3.13/site-packages/torch/_inductor/compile_fx_async.py | f964d6c77337b5d67dfd6d3f1997a6a7a0d0ff32fb502addc78cfa385af41b8c | 182 | 2 |  from .compile_fx import _CompileFxKwargs, _InProcessFxCompile, FxCompile from .output_code import complex_memory_overlap as complex_memory_overlap  # noqa: F401   |
| .venv/lib/python3.13/site-packages/torch/_inductor/constant_folding.py | 61644e8f393d3b22b20a21ce8c3f6db58754b3bdac7ed5c7bc25aa7c770b7c2d | 416 | 1 |          # skip constructors, since inductor generates optimal code for them already         # and turning into tensor would result in an additional global memory read         # TODO - more complicate |
| .venv/lib/python3.13/site-packages/torch/_inductor/inductor_prims.py | cacc834d04b34ca3051d6221187c5eec6c407cabbdc17439d7564e4b6703f239 | 226 | 8 |   def _low_memory_max_pool_with_offsets_aten(     self,     kernel_size, |
| .venv/lib/python3.13/site-packages/torch/_inductor/autotune_process.py | c2d42316590fe7e5997b34cde2298947c988ded9061739a4cc103f96f9240c4e | 891 | 1 |     A class to handle CUDA (CUTLASS) benchmark requests. This class is for     managing the lifecycle of a CUDA kernel benchmark, including compiling     the source code, managing workspace memory, an |
| .venv/lib/python3.13/site-packages/torch/_inductor/utils.py | c7edbcbe63f61b0d8e192dd4f11ad7a4017e2684d5aa617eb7ff80c26ec305d8 | 3205 | 5 |     This could be more accurate as it doesn't count CPU side overhead.     However, this also requires manually excluding irrelevant event, e.g.     vectorized_elementwise_kernel which is used to fill |
| .venv/lib/python3.13/site-packages/torch/_inductor/fuzzer.py | 5e8005e4d367a22863947c08a1e1d4999426b490f5981b6ac63346b5a339b4fa | 1001 | 1 |             zipped = zip(args, default)             return tuple(                 map(  # noqa: C417                     lambda x: SamplingMethod._generate_value_for_type(                         rand |
| .venv/lib/python3.13/site-packages/torch/_inductor/comm_lowering.py | a7d7e849b667c8eb92d7c7cf9b26ecfbbfe6dc6979b1f048c7cb2f70eda2c1bd | 361 | 2 | # ops for different cases). Later, the codegen will perform "persistent # allocation" to satisfy the aforementioned constraints, and optionally, # perform buffer planning to optimize overall memory us |
| .venv/lib/python3.13/site-packages/torch/_inductor/decomposition.py | 575ba358c9592457e510afd9c894363adcef36a042aa1f26c628919fe9ca4d3a | 1153 | 41 |     _grid_sampler_2d as decomp_grid_sampler_2d,     _index_add,     embedding_dense_backward as decomp_embedding_dense_backward,     pw_cast_for_opmath,     pw_cast_for_opmath_non_tensor_args, |
| .venv/lib/python3.13/site-packages/torch/_inductor/compile_fx_subproc.py | e367730d2ddeb6c40484aad0105182183488ca706f43273f21d9eb04c1614814 | 94 | 2 |     _WireProtocolPickledOutput, ) from .output_code import complex_memory_overlap as complex_memory_overlap  # noqa: F401   |
| .venv/lib/python3.13/site-packages/torch/_inductor/scheduler.py | 03e758dd5398591310f37dfe4daffc44c8a96b2df7cfc69db8545b761e2a65c0 | 5027 | 96 | from .codegen.common import BackendFeature, get_scheduling_for_device, Kernel from .comm_analysis import estimate_nccl_collective_runtime from .dependencies import Dep, MemoryDep, StarDep, WeakDep fro |
| .venv/lib/python3.13/site-packages/torch/_inductor/wrapper_benchmark.py | 6048081d9b6e0c65bd7265203b79623531f155ac05c04c3076eda3815ffad3be | 496 | 16 |   def collect_memory_snapshot(     benchmark_compiled_module_fn: BenchmarkCallableType, ) -> None: |
| .venv/lib/python3.13/site-packages/torch/_inductor/choices.py | df9e60445eb32e635154ee88a02b76401ce95319072490a89dbc2ef18c3b40e6 | 433 | 11 |             return False  # heuristic not needed for correctness          if scheduler.can_fusion_increase_peak_memory(node1, node2):             WhyNoFuse(node1, node2)("Fusion will increase peak mem |
| .venv/lib/python3.13/site-packages/torch/_inductor/comm_analysis.py | 8201518ed271e717493c24bcfdcd473e37507302ff420f3b717a1c1e3b3716c2 | 265 | 4 |  # LL128 max BW per channel llMaxBws = [     # Volta-N1/Intel-N2/Intel-N4     [ |
| .venv/lib/python3.13/site-packages/torch/_inductor/output_code.py | 9015c12513e48a553384bb942e9a1ac5c9b8c65bbe5b25f5d010945d34a7b203 | 759 | 8 |   # copy_ fails when trying to write to tensors with memory overlap, # for expanded dimensions (a dimension which used to have size 1 -> ?) # we can select one element from that dimension and write to |
| .venv/lib/python3.13/site-packages/torch/_inductor/freezing.py | 1a6553d8690f93c6b4c5f3e47007a2cc0fa581b28444fffaf6ea98a599a3a06e | 289 | 4 |     """     Inlines parameters that are not mutated into constants and optimizes the graph through constant propagation     and other techniques. If enabled, the function also discards the original pa |
| .venv/lib/python3.13/site-packages/torch/_inductor/dependencies.py | 58d0fd4550015d2746ecdfe74c7a2c8625ae90b43bb890ee143d6ba06ff0fae6 | 823 | 34 |  @dataclasses.dataclass(frozen=True) class MemoryDep(Dep):     name: str     index: sympy.Expr |
| .venv/lib/python3.13/site-packages/torch/_inductor/tiling_utils.py | a2b2a7a69783864da88d9338589d66ca31468cee3df16a292fc1d13fbd0a140c | 765 | 11 | @dataclasses.dataclass(frozen=True) class CoalesceVarAnalysis:     # Var -> Memory Score - not strictly the amount of memory     # because we multiply writes x2     # TODO: separate into dataclass tha |
| .venv/lib/python3.13/site-packages/torch/_inductor/loop_body.py | b00ea5a7f0de34f781e9a719f6bd08078768b46fb87e4acf1cce844d871fafd4 | 703 | 47 |   class MemoryEntry(NamedTuple):     index_name: str  # LoopBody.indexing_exprs[index_name]     buffer_name: Optional[str] |
| .venv/lib/python3.13/site-packages/torch/_inductor/template_heuristics.py | 086b2b069f1066a8f76ab6d6df235fda01968c41bed3c899f3733d26fa52ab26 | 1181 | 3 |             device = torch.cuda.current_device()             props = torch.cuda.get_device_properties(device)             sm_available = props.shared_memory_per_block_optin  # type: ignore[attr-define |
| .venv/lib/python3.13/site-packages/torch/_inductor/runtime/triton_heuristics.py | a1da4475ec957075bbc508c35e826bab3eb4b48eee13a6ef0e3826abb79f8044 | 3023 | 10 |                 # the register usage.                 # For kernel https://gist.github.com/shunting314/e4cccc031fe30d378b9b23c08c238cbd                 # from PLBartForCausalLM, latency improve from   |
| .venv/lib/python3.13/site-packages/torch/_inductor/runtime/coordinate_descent_tuner.py | d7a0fa63a1de21192c2555f87615b35273f5447b09df297d726bd05f8dbd23c8 | 303 | 1 |             return False, float("inf")          if self.has_improvement(best_timing, candidate_timing):             log.debug(                 "Tune from %s %f -> %s %f", |
| .venv/lib/python3.13/site-packages/torch/_inductor/runtime/compile_tasks.py | 52d5e9f6692fbf1ce50bfc6570e521e3e6da9a8ad624845033fd361c929a0717 | 68 | 1 |         elapsed_ns = time.time_ns() - start_ns         kernel.prepare_for_pickle()         # We can release this memory in the compile subprocesses:         linecache.clearcache()         return kerne |
| .venv/lib/python3.13/site-packages/torch/_inductor/runtime/triton_helpers.py | 4c01a94ad6e15f073778252514a7c80683680dc689f73e1317e87b7a3780ef27 | 738 | 2 |     Ref: https://research.nvidia.com/publication/2016-03_single-pass-parallel-prefix-scan-decoupled-look-back      scratch_base: Pointer to scratch space in global memory     block_value: Scalar value |
| .venv/lib/python3.13/site-packages/torch/_inductor/runtime/benchmarking.py | df1719b1232915cbfcd8c8a7c70b882da2397de87c80867592a62b0516ca2fcc | 291 | 6 |         _callable: Callable[[], Any],         estimation_iters: int = 5,         memory_warmup_iters: int = 100,         benchmark_iters: int = 100,         max_benchmark_duration: int = 25, |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/wrapper.py | a609e9385cba825a6835d14a635833ccafcdaa644f22bf5805192987e88f0164 | 3414 | 45 | from torch._inductor.runtime.runtime_utils import cache_dir from torch.fx.experimental.symbolic_shapes import (     CallMethodKey,     ConvertIntKey,     DivideByKey, |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/triton.py | 9c7f09ca6dd38e200f463b32aac51b9fbe5ae88f12b9fad170422c42281414ed | 4527 | 3 |                     # For persistent reductions, don't bother with                     # welford's algorithm since it uses more registers, and                     # taking two reductions doesn't incre |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/mps.py | 4625f11dcfb04047a36e53018bc184e363ed16987273c78ecad746125796005d | 989 | 1 |         # When reducing the tensor whose size exceeds max threadgroup size         # loop over extra indices per reduction thread and perform part of the operation         # using values in the shared |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/simd.py | fbdbb9494c09ad821164694b416efde36a963a0168e725770f34338f41328cad | 2463 | 21 | import torch import torch._logging from torch._inductor.tiling_utils import analyze_memory_coalescing from torch.fx.experimental.symbolic_shapes import free_unbacked_symbols from torch.fx.immutable_co |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/memory_planning.py | d0d8565f31e3d5ccc513105f70b0f13dd9f111200650c02679aa705914af1948 | 776 | 27 |     BufferLike,     FreeIfNotReusedLine,     MemoryPlanningLine,     NullLine,     ReuseLine, |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cpp_flex_attention_template.py | e55a91849287cac7b598e24b90fe25c376fea1c26eb9abe2099fa6aff733acdc | 1082 | 31 |     T2* out,     T1& val) {   auto vec_size = at::vec::Vectorized<T1>::size();   auto vec_max = at::vec::Vectorized<T1>(val);   T1 tmp_sum = 0; |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cpp_micro_gemm.py | 4c4d8726dd6ed4812c71f92e68f7d627fba2313f11fab7271cd6e8aa9b019ca6 | 2012 | 59 |     ALLOCATE_WEIGHT_BUFFER = r"""     {%- if is_msvc_compiler %}     // MSVC doesn't support stack-allocated dynamic-sized arrays, so using heap memory here.     std::unique_ptr<{{buffer_dtype}}[]> he |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cpp.py | 7d07e9c89d2d4bf96dbccc5ba01d949a65396902f9b767f4a496462ab4fd2964 | 5567 | 122 |     "welford_combine": "welford", } VECTORIZABLE_RTYPES = OrderedSet(     [         "max", |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py | 415f0bd902ce1386e57513d2975b88c2e00a4d6e01dadda48c2c938d0422668b | 2748 | 33 |         self.used_cached_dtypes: OrderedSet[str] = OrderedSet()         self.used_cached_layouts: OrderedSet[str] = OrderedSet()         self.used_cached_memory_formats: OrderedSet[str] = OrderedSet() |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/common.py | b076eda45c8a55a54a88aba256d05770e662abc73217a4a18f9b24813aced3b3 | 2692 | 2 |         if (             isinstance(string, CSEVariable)             or _RE_PAREN_NOT_NEEDED.fullmatch(string)             or _all_in_parens(string)         ): |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cpp_gemm_template.py | 32cd797f834c181cf429c011133c10adff1f1eeb00be0a64727ec8eb0c5cfb44 | 1778 | 1 |     for candidate_node in get_candidates(input_nodes, new_input_nodes):         # By using the new packed weight for the GEMM template, we can prune the         # old weight if it has no other users.  |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu_array_ref.py | a304358b70f57a88d73cb07c4f0ff5ae42a62ccb036d1b653c18dfa2a478081a | 879 | 15 |     EnterSubgraphLine,     ExitSubgraphLine,     MemoryPlanningLine,     MemoryPlanningState,     PythonWrapperCodegen, |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/triton_split_scan.py | 8caa52f05e9559ee02b139bdb8d663ce56cfbb08f2e8dd4a4e16f6b39d465637 | 208 | 1 |     For this kernel, loop numels will always take the form ``(xdim, rdim)``     and the grid has the shape ``(CeilDiv(rdim, RBLOCK), xdim)``. Communication     between blocks occurs within a global me |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/halide.py | 37302eb17a7f596b94fac8f8cd5119d51ce3e361aeed7fcc1ffb735fc97721ee | 1700 | 1 |         for _, arg in self.halide_argdefs():             # fallback=1 below because halide requires buffers to be at least as large as the estimates             # This causes crashes if our estimate i |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/subgraph.py | 776372f99c999fabc7965952312789277a1f730f18fe8130dfeea31258f796db | 209 | 1 |         Args:             input_nodes: List of input nodes to the subgraph             layout: Memory layout information for the output             example_inputs: Example tensor inputs used to trace  |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cpp_utils.py | 04372432d2b465bc8e0677b7c4764aad718a9aa825b001232110ca7b618c22d4 | 777 | 6 |         with code.indent():             code.writeline(rand_function)         num_vectors = V.kernel._get_num_vectors(dtype=dst_dtype)         if num_vectors == 1:             code.writeline( |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/simd_kernel_features.py | 5dd7d210713ecff3f2d9f05c3c74f12ef5d058447de2b41380b7d71ac6d32cb1 | 619 | 39 | from ...utils._sympy.functions import FloorDiv, ModularIndexing from ...utils._sympy.symbol import make_symbol, SymT from ..dependencies import Dep, extract_loop_body_with_args, MemoryDep from ..runti |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cuda/cuda_cpp_scheduling.py | d0d28ed46657db94b4b67a3ff0312b45896b1552ee5fdac72dbe98848855912c | 294 | 1 |             # for this kernel we've already generated the C++ code, but we still             # need to let the kernel know about loads/stores that occur in the fused             # kernel for memory pl |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cuda/cuda_template.py | 5f9b93ef1eeabca51b111d0a5a4637e605820e8ad4b347b321fc3c07b9b5b5ec | 319 | 3 |                 #include <exception>                 #include <iostream>                 #include <memory>                 #include <random>                 #include <vector> |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cuda/gemm_template.py | 200fa66b34b14fdddd2924bef1a54d86f889661c9c00a11bb9490643bcaf50f6 | 1906 | 3 |         """         Helper method to determine whether we should do an explicit transpose by switching the order of the         matmul operands. This might be necessary when we can't otherwise arrive  |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cuda/cutlass_python_evt.py | d52e3b4a83a33c0d76b1bbd9a9e350b30c4670cf7df48fbbbeb87ea87ae47d44 | 323 | 1 |  class MockCutlassHandler(CutlassEVTOpsMixIn, WrapperHandler):     """Passthrough handler for cutlass ops, used for running epilogue nodes for memory planning"""   |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cuda/serialization.py | 7516537dd769c237f3d6646a6a2ecde8df6d254efc478733f048929bedbbbe2f | 467 | 8 |             "ScaleFactorNVecSize",             "ScaleFactorKVecSize",             "ScaleFactorVectorSize",             "is_3x",         ] |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py | fd79accc9243a4161e462ced422c417fdaf511ea7c11fb05e7b645e004ed8135 | 675 | 2 |     def load(self, name: str, index: Expr, mode: Any = None) -> CSEVariable:         """         Mock load function for memory planning to optimize allocations properly.         """         return sel |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cuda/cutlass_lib_extensions/gemm_operation_extensions.py | 31deb3ee2c130a15cb8529315dcb43db387febc0fc2385a227518bc65edc69f6 | 412 | 6 |  # copied / modified from original at # https://github.com/NVIDIA/cutlass/blob/8783c41851cd3582490e04e69e0cd756a8c1db7f/tools/library/scripts/gemm_operation.py#L658  if try_import_cutlass(): |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/cuda/cutlass_lib_extensions/evt_extensions.py | 885a184b07eef08d01997a66d5c4d39ca22d0181d1bb3e9031799d3994a66c58 | 241 | 1 |          # Today, arguments are either a pointer to the         # node's memory, a stride tuple, the datatype         # Once again, need to check for local class type for stride tuple         if ( |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/rocm/rocm_template.py | 45cc3d5145f67845239fadf7a014c1cadcd7216888a20434a1605a88c7199c7e | 193 | 2 |                 #include <exception>                 #include <iostream>                 #include <memory>                 #include <random>                 #include <vector> |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/rocm/ck_conv_template.py | 77233f4b6dd50784ce0a0d952ccd052c0b0a9b040e5edebf03d7ae9fe7763593 | 609 | 15 | def torch_layout_to_ck_layouts(torch_layout):     # logically, torch tensors are always NCHW,     # and channels-last memory layout is visible in the strides     if V.graph.sizevars.statically_known_e |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/rocm/rocm_template_buffer.py | 00095f8790882885c647d23a624cce587535ae826f249f6cde976d9603119cbf | 28 | 1 |     ) -> None:         super().__init__(layout, inputs, make_kernel_render)         # Global memory (in bytes) needed for this template.         self.workspace_size = workspace_size         self.templ |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/rocm/ck_universal_gemm_template.py | 53771d456f9a9b041b7ca4cceddfc23e3c81db7efb92a024b34ae1c754b19c33 | 1017 | 17 |             """                 #include "host_tensor.cpp"                 #include "device_memory.cpp"             """         ) |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/rocm/ck_template.py | 54d0d4753c8acfdc2d4851baedfcec80e59a7c78ec11888b68b5406a80c0c359 | 109 | 1 |                 #include "ck/utility/data_type.hpp"                 #include "ck/library/utility/check_err.hpp"                 #include "ck/library/utility/device_memory.hpp"                 #include |
| .venv/lib/python3.13/site-packages/torch/_inductor/codegen/rocm/ck_tile_universal_gemm_template.py | bdbd8560f95d01df9c3642ef1b6bd2c5775ea7d0c24c3ddacc9eabf43fd503ea | 968 | 18 |                  template <ck_tile::index_t PrefetchStages, typename Dispatcher>                 void dispatch_memory_pipeline_hot_loop(const ck_tile::TailNumber tail_num, Dispatcher dispatch)         |
| .venv/lib/python3.13/site-packages/torch/_inductor/compile_worker/subproc_pool.py | 72a8e44a7ea586e8a5274834c4367f62125fa4ff5ea78334398dd36936214fc3 | 380 | 1 |  def _warm_process_pool(pool: ProcessPoolExecutor, n: int) -> None:     # We have to fork processes for compiler workers, but the more memory and other resources that are loaded, the     # slower the  |
| .venv/lib/python3.13/site-packages/torch/_inductor/autoheuristic/autoheuristic.py | babda036ef474a983623897df86b36d28fa322ed2ffcc1fb62026971dbd281c4 | 316 | 2 | from torch._inductor.ir import ChoiceCaller from torch._inductor.runtime.runtime_utils import cache_dir from torch._inductor.utils import get_gpu_shared_memory   |
| .venv/lib/python3.13/site-packages/torch/_inductor/autoheuristic/autoheuristic_utils.py | 22c500f82318e9012fa8f2f1c7633ae8489e716a10ba3897204141e8ada986d8 | 340 | 8 |     def __init__(         self,         shared_memory: Any,         device_capa: tuple[int, int],         choices: list[Choice], |
| .venv/lib/python3.13/site-packages/torch/_inductor/autoheuristic/artifacts/_MixedMMH100.py | 2160fb78a85b8df2a70b2a91ecfaaf2f7ef42b9cd600a652d8bb655aca38f269 | 150 | 1 |         return (             metadata.name == self.get_name()             and metadata.shared_memory == 232448             and str(metadata.device_capa) == "(9, 0)"         ) |
| .venv/lib/python3.13/site-packages/torch/_inductor/autoheuristic/artifacts/_PadMMA100.py | 29178a47107cb4340d7c12da957bf0e47d0b96e76dbb87845de9581e4e76c5b6 | 110 | 1 |         return (             metadata.name == self.get_name()             and metadata.shared_memory == 166912             and str(metadata.device_capa) == "(8, 0)"         ) |
| .venv/lib/python3.13/site-packages/torch/_inductor/autoheuristic/artifacts/_MMRankingH100.py | f7052e9197b62a8fd5595fccb88fbaef1391c3a29f0776ac7abdb5bd7716e168 | 322 | 1 |         return (             metadata.name == self.get_name()             and metadata.shared_memory == 232448             and str(metadata.device_capa) == "(9, 0)"         ) |
| .venv/lib/python3.13/site-packages/torch/_inductor/autoheuristic/artifacts/_MMRankingA100.py | bed08dcfefdaeaab5641363c8a73cb3c3ee9b5bc953f3f1378a6e4b4dd59dd60 | 297 | 1 |         return (             metadata.name == self.get_name()             and metadata.shared_memory == 166912             and str(metadata.device_capa) == "(8, 0)"         ) |
| .venv/lib/python3.13/site-packages/torch/_inductor/autoheuristic/artifacts/_MixedMMA100.py | a8af39e49ce10188c720204cd05874310de7b9fbab0b8224e0df8f823a06ee58 | 151 | 1 |         return (             metadata.name == self.get_name()             and metadata.shared_memory == 166912             and str(metadata.device_capa) == "(8, 0)"         ) |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/post_grad.py | 7c224f2c86bf9da812734ad5d95d49d86373df36588247364e9ea93fd6b6b0d6 | 1794 | 4 |      We could rewrite it with a scan with the benefits of reducing compilation time/binary size, reducing     memory usage, supporting loops over unbacked shapes and cudagraph etc.          def g(): |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/replace_random.py | d65d9f2d37c07ecfeb0c73fca75ff98ec4bcbb7e9d9f95fa43e56f96decfaec8 | 144 | 2 |     device=None,     layout=None,     pin_memory=None, ):     if generator is not None: |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/numeric_utils.py | 8807f8833a619ce5b34705c6522916bdbe801fd492e9f2600f5b11e968e42679 | 214 | 3 |   def clean_memory() -> None:     """Clean memory to avoid OOM."""     gc.collect() |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/reinplace.py | f56e10435f5aa233e3d303e8c2dba2561d174fb53f5b4ce7ae879ff85a78e096 | 767 | 1 |             "For node %s, attempted to reinplace %s. We were unable to reinplace %s; "             "%s (if non-empty) are possible missed reinplacing opportunities that may be bad for "             "m |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/quantization.py | 02b86ac045cdb694804e746b0c714d4644cd6a41eae32e25320a87991014c409 | 3892 | 7 |     aten.clone.default,     dequantize_per_channel_weight_pattern,     memory_format=KeywordArg("memory_format"), )  |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/split_cat.py | 3ac97a2a08a4707801d9c428ee3945e541297c1df2b6475952578eaed88b0e9c | 2961 | 8 |     CallFunction,     CallFunctionVarArgs,     CallMethodVarArgs,     FailedMatch,     get_arg_value, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/efficient_conv_bn_eval.py | b3f09b127c28bfbd37ebc4b88fb06f6ee54cdd523b4c1522055dc932a817ac20 | 410 | 4 | from ..pattern_matcher import (     CallFunctionVarArgs,     CallModuleVarArgs,     Match,     register_graph_pattern, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/fuse_attention.py | 9253a6992b9e349a557cea4dd76aa2cd31f8c699c448ea1b1564aef69b82d32a | 1090 | 5 |  def _sfdp_pattern_18(query, key, value, causal_mask, dropout_p):     # for hf_GPT2 with dropout (introduces clone node) for inference     # it also returns permuted key & value     query = query.perm |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/micro_pipeline_tp.py | 4e5f246e58feeca0fe3b69f2cee05632dc45676ca67083215482acef8adfad59 | 1080 | 2 |         return      from torch.distributed._symmetric_memory import (         is_symm_mem_enabled_for_group,         restride_A_shard_for_fused_all_gather_matmul, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/joint_graph.py | 45f40bb381e1090fdc4a6693972620ac411292bc762ac2dbf7b3ec7eeba3c034 | 944 | 6 |                 dtype=tensor_val.dtype,                 device=tensor_val.device,                 pin_memory=False,             )             self.add_node_replacement(op, t) |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/b2b_gemm.py | 98b85cac4de36036d1229c383fc30f9219ea6bd6a660467f8279c722dd19b818 | 761 | 1 |   # the block sizes are limited by hardware (the shared memory) # intuitively, the optimization works when the intermediate matrix is large # and we assign large block sizes to large dimensions |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py | f9ca5414ec532aa3b0b4c52cecf68b26b72d3b04ed7ae05c7c0130ae8c1029d9 | 1528 | 1 |     def _eliminate_duplicate_packed_nodes(gm):         """         Combine packed weight nodes with the same inputs to reduce memory usage.         for example:         class Model(nn.Module): |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/pad_mm.py | d08a27154c6b8e13d2a3475c47c51bb28f9248be2bdd7cf4b2452755f0a91314 | 926 | 4 |         return False      # optimistically assume we should be able to memory plan away     # all non inputs     return node_def.op != "placeholder" |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_12.py | ea8d3b38c00fdcfe32b8e4ab9ac5bf02c4aaf6061e4d50f64a4c4987cc50a197 | 221 | 18 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_5.py | 8a4e464fcae01144385b4dda62ba95c73fa8f137a576abc22ef530827c210f41 | 179 | 4 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_22.py | 8f7a7292276165a5758d0360ab98bf41bf663ba939dce1aaf73f3ee43a5f6d24 | 230 | 16 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_16.py | fb5b505363320bd85e4460fab0e89b2d1111fcc973c7d722bd52eb44475048ca | 600 | 28 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_1.py | 8cb937bbdbf2c8f873ce62427fcd87fa511aff2708f45191d85d5ed78045ec90 | 175 | 4 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_23.py | c2fc66f7c991bfb5f88f7add99f11cecfdbf80ff2ca6bb1e0810ad23c0c5b806 | 226 | 16 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_17.py | e8cb0233253ec02014c563a61ade9f4ea99b9939a6d413de6f742123c48342e7 | 247 | 22 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_13.py | c90399e327f29873cffe03484a8c6ae293addf13e273c78963422732bf61b0f8 | 131 | 6 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_4.py | c779868ef4984bb8489a20455295dbc92615c3c64d5630b2aa38d3acd2221ec8 | 191 | 6 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/addmm_pattern.py | f5c97d2fc2f6083bbef9c8c859117adcd825ed85fd177f2019709e133debd1b6 | 54 | 4 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_18.py | 3805f28a0e86acb8ccce763971a1d4a441e2226b4ed05c3531b571cf25b91f6c | 454 | 36 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_19.py | 1768ab20a732aa51402c735ca286f6327a791d49a70c841badcdf732c39c2138 | 210 | 14 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_9.py | 9f7281799ca9fa86baf53d0008cb63dc37004b50e79959834fc38675a319599c | 222 | 18 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_8.py | b0e90c7c83cdd3a60507633b010b9472020ebd97b3fc6f6d52d2b58975a9d2c7 | 206 | 16 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/mm_pattern.py | 308131af0b9ff999a832e3a2514dd210db4c5bc0239d6db22fd43e90ab22aacd | 46 | 4 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_20.py | 28e43c5b045ede7555de0767affa8d939db78cc5ed2fc0ed5e5c61296e9d0612 | 245 | 22 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_14.py | a7bdbda2c82293b501d324b328c72d8488fd3e4debaa1e8e74feb029914daaf0 | 211 | 16 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_3.py | 180cb33ce19233391d0315e4937aa97fef32f06ad663e59eb73a72d5a254e282 | 191 | 6 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_10.py | ebc5b62f73aa108ca2baee97bdfc325e5d0f29ea3210a455ab12af76ddc3adf2 | 206 | 16 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_7.py | 5455b008d2d7691c3226b0cc6cf980dca669784d7eafc3598b580771ddda4edd | 222 | 18 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_11.py | 633280769d70291129c21fa66be30f8cc2910089a77c81695aba9ba41b4904f7 | 205 | 16 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_6.py | cb1504aa0bcb1acff74daef6e8676437e2b6a22e18598829c2a54bfbf7115dd4 | 195 | 6 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/bmm_pattern.py | e8f60fc8ccfc74e54d604288211ebb32f7dd58be93945d310bc567cec6c704ba | 46 | 4 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_21.py | 5121d57ee89ef1da287794955e1971585befdd0d1e8183573eca1febccdd9731 | 218 | 16 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_15.py | 31d7d51ed5099f467380fb03a0b22c8fb4a56b71e77e51422042df4b5b80632d | 231 | 20 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/fx_passes/serialized_patterns/_sfdp_pattern_2.py | f90797a4e4e12dff70e87b0a253e6725d09fc9744ae2c83113a272e2ff3bb5dc | 175 | 4 |    CallFunction,    CallFunctionVarArgs,    CallMethod,    CallMethodVarArgs,    CallModule, |
| .venv/lib/python3.13/site-packages/torch/_inductor/kernel/mm_scaled_grouped.py | 57829bbb8680635639fe92bd3a746030365390332ba128c1615feaf52c3527f2 | 742 | 6 | ) from ..utils import (     get_gpu_shared_memory,     get_num_sms,     has_free_symbols, |
| .venv/lib/python3.13/site-packages/torch/_inductor/kernel/flex_decoding.py | 0b1df11e1ac06696ff0f21d1014ebace5d1e4467941b851915d2a4890130d1b3 | 629 | 2 |     # reduction buffers: M rowmax across local KV split, L local sumexp across local KV split     # M: Number of queries, N: Number of keys/values     # QK_HEAD_DIM: The dimension of the query and key |
| .venv/lib/python3.13/site-packages/torch/_inductor/kernel/bmm.py | a7a97a1ec865bb8b241db08c7ac7f862988b240cea76291076aa0909ad85daee | 295 | 1 |     """     if all(x.get_device().type == "cpu" for x in [mat1, mat2]):         # decompose to small ops when memory bound         if mat1.get_size()[1] == 1 or mat2.get_size()[2] == 1:             ma |
| .venv/lib/python3.13/site-packages/torch/_inductor/kernel/flex_attention.py | a975ea606bc89eeb9e63da8f08143da526ccbab7a113a8f8b73e938d27f8e3e3 | 2764 | 8 |     # Q: Query, K: Key, V: Value     # M: Number of queries, N: Number of keys/values, D: Model dimension     # QK_HEAD_DIM: The dimension of the query and key embeddings     # V_HEAD_DIM: The dimensi |
| .venv/lib/python3.13/site-packages/torch/utils/checkpoint.py | 255ec2eccfa184eb3e13ef4791955d1f6f010d8ef1f59e7a8eccb9da26161314 | 1587 | 2 |     r"""Checkpoint a model or part of the model.      Activation checkpointing is a technique that trades compute for memory.     Instead of keeping tensors needed for backward alive until they are us |
| .venv/lib/python3.13/site-packages/torch/utils/deterministic.py | 683c0ff3d163613213fb783646d581a1a80de7dfc96ea1360596e05781edb4c5 | 23 | 6 | class _Deterministic(types.ModuleType):     @property     def fill_uninitialized_memory(self):         """         Whether to fill uninitialized memory with a known value when |
| .venv/lib/python3.13/site-packages/torch/utils/backend_registration.py | bfd8a57ac6154e2647f4cd9b21ce4143440fe72599b5b49846fa71e1f8a4e234 | 441 | 5 |         Args:             device (int, optional): if specified, all parameters will be copied to that device             non_blocking (bool): If ``True`` and the source is in pinned memory,            |
| .venv/lib/python3.13/site-packages/torch/utils/throughput_benchmark.py | 7f9d02355c26fe6be97af154929cfb7600dd59a6f9d7d8e664845e07caa1541d | 161 | 1 |     def add_input(self, *args, **kwargs):         """         Store a single input to a module into the benchmark memory and keep it there.          During the benchmark execution every thread is goin |
| .venv/lib/python3.13/site-packages/torch/utils/dlpack.py | 9eba1073c3a02a614e441f37182a9e24b7956965e435d5f4e079deabc817d225 | 128 | 4 |     tensor: a tensor to be exported  The DLPack capsule shares the tensor's memory. """)  |
| .venv/lib/python3.13/site-packages/torch/utils/bundled_inputs.py | 253637959ea76e251b0a75db26c422e1af39f7075397860a58af0c1aa34381e3 | 471 | 2 |         # These can be represented compactly.         for fmt in [torch.contiguous_format, torch.channels_last]:             if arg.is_contiguous(memory_format=fmt) and (arg == arg.flatten()[0]).all() |
| .venv/lib/python3.13/site-packages/torch/utils/_python_dispatch.py | 4498a17d8d1b8ca9baaa3d06301c15b62cf603f9a1181510fca3ebafae11a115 | 722 | 6 |         copy: bool = False,         *,         memory_format: Optional[torch.memory_format] = None,     ) -> torch.Tensor:         ... |
| .venv/lib/python3.13/site-packages/torch/utils/flop_counter.py | 8b0bccd4f694350b64c39347eb3e19ab3fd32f0571929089ec186fc8fa51971c | 793 | 1 |         # Skip ops from non-standard dispatch_sizes_strides_policy such as NJT         if func in {torch.ops.aten.is_contiguous.default,                     torch.ops.aten.is_contiguous.memory_format, |
| .venv/lib/python3.13/site-packages/torch/utils/_content_store.py | 38e0e4b7a0f7da244855d1dc447d1895b76b42ecd39e89c85ede027017ebf2df | 240 | 2 | # of "reopening" a content store to add more things to it.  But we don't # assume that you can keep all of the tensors you want to add to the store # in memory at once, because you probably can't!  No |
| .venv/lib/python3.13/site-packages/torch/utils/mobile_optimizer.py | cab8c19c14e35a572952512793fbbd54506a4a5c8ed35187bb92b50f976637b4 | 136 | 1 |         if param.requires_grad:             lint_list.append({"name": LintCode.REQUIRES_GRAD.name, "message": f"Param {name} requires grad, "                              "please set torch.no_grad() t |
| .venv/lib/python3.13/site-packages/torch/utils/benchmark/op_fuzzers/binary.py | 86aaf9fd51be18cc0388d091344e27aa30599bd9b07f442f3aab7343e2d88c89 | 108 | 1 |                 ],                  # Steps for `x` and `y`. (Benchmarks strided memory access.)                 [                     FuzzedParameter( |
| .venv/lib/python3.13/site-packages/torch/utils/benchmark/op_fuzzers/spectral.py | b5bd988b38c9cf0b5e7a84294b57b79798eacf1e63ed098d1ca5d1033d21e889 | 95 | 1 |                 ],                  # Steps for `x`. (Benchmarks strided memory access.)                 [                     FuzzedParameter( |
| .venv/lib/python3.13/site-packages/torch/utils/benchmark/op_fuzzers/unary.py | ecca547a268bebfd33844281ea81f3d11b7f08780d4996214ca3b2d61bd9bcd0 | 83 | 1 |                 ],                  # Steps for `x`. (Benchmarks strided memory access.)                 [                     FuzzedParameter( |
| .venv/lib/python3.13/site-packages/torch/utils/benchmark/utils/timer.py | 4a3f2bbba14216b21474d52464f27b07b3e8c813fed15b79b66b061087c552d1 | 542 | 1 |          Because there is a process boundary between the caller (this process)         and the `stmt` execution, `globals` cannot contain arbitrary in-memory         data structures. (Unlike timing me |
| .venv/lib/python3.13/site-packages/torch/utils/benchmark/utils/common.py | 6be796caee2c184ab39f10458d1c8e6afd5b4cd66f4f45fc54b77dd8420689b1 | 357 | 3 |      This function is conceptually similar to `tempfile.mkdtemp`, but with     the key additional feature that it will use shared memory if the     `BENCHMARK_USE_DEV_SHM` environment variable is set. |
| .venv/lib/python3.13/site-packages/torch/utils/benchmark/utils/fuzzer.py | f5c82cc964b54742e3eb178ea705ddf0c6aad211b254bfac19b2fd128de16151 | 463 | 3 |                 and steps is (1, 4), then a tensor `t` of size (4, 32) will be                 created and then `t[:, ::4]` will be used. (Allowing one to test                 Tensors with strided mem |
| .venv/lib/python3.13/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py | d4ea2117f083cc2e6930cf7d425561cc3430c8b5a840cc13c8e78e979c93301a | 911 | 2 |     This is a practical consideration when collecting Callgrind statistics.     Unlike `exec` based execution (which `timeit` uses under the hood) which     can share in-memory data structures with th |
| .venv/lib/python3.13/site-packages/torch/utils/serialization/config.py | 62aaaf398db79fc47f52a1da340035c712a775e87814b7fb0deaa95b5913d0ed | 26 | 1 | class save:     compute_crc32: bool = True     use_pinned_memory_for_d2h: bool = False     storage_alignment: int = 64  |
| .venv/lib/python3.13/site-packages/torch/utils/hipify/cuda_to_hip_mappings.py | f24e024fbc869de2c404920f4cfc377cf93c573fe1f8a1804d81ecd659689e71 | 8822 | 127 |             ("hipMemAttachFlags_t", CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED),         ),         ("CUmemorytype", ("hipMemType_t", CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)),         ("CUmemorytype_enum" |
| .venv/lib/python3.13/site-packages/torch/utils/viz/_cycles.py | 495015071400e5b78ab0a55fed3963b8a7dab141cfd5a12d2025ed0d5e446be0 | 500 | 11 | from tempfile import NamedTemporaryFile import torch from torch.cuda._memory_viz import _frames_fmt, _block_extra import atexit import logging |
| .venv/lib/python3.13/site-packages/torch/utils/tensorboard/_pytorch_graph.py | 799a3ff00d5888a5e2cf9e867231bc5dfae80dcd489e6be35fbb7f0e78ea0eae | 377 | 1 |     def to_proto(self):         """Convert graph representation of GraphPy object to TensorBoard required format."""         # TODO: compute correct memory usage and CPU time once         # PyTorch su |
| .venv/lib/python3.13/site-packages/torch/utils/tensorboard/_embedding.py | e84c575c84224a7036708012f512f119d2859ae053d353ea741ef7f71df24fa1 | 87 | 4 | from ._utils import make_grid from tensorboard.compat import tf from tensorboard.plugins.projector.projector_config_pb2 import EmbeddingInfo   |
| .venv/lib/python3.13/site-packages/torch/utils/tensorboard/writer.py | aaeaa5419f5c4e8c45dc54bd5256a0709a600f48b22d2e3f41084b8c96d8a15e | 1209 | 18 |  from ._convert_np import make_np from ._embedding import get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt from ._onnx_graph import load_onnx_graph from ._pytorch_graph import graph |
| .venv/lib/python3.13/site-packages/torch/utils/model_dump/__init__.py | 9cb933d3eae46139f86e7475c0988902b414a19abebfaa382c9201f3d0899988 | 411 | 3 | This makes for easier development (just refresh, usually), allows for more laziness and dynamism, and lets us add more views of the same data without bloating the HTML file.  Currently, this code does |
| .venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py | fbd260c9587fadb2f81dc255b080356261df3a6827272c07f11ab1ac20276ef0 | 1665 | 104 |     The :class:`~torch.utils.data.DataLoader` supports both map-style and     iterable-style datasets with single- or multi-process loading, customizing     loading order and optional automatic batchi |
| .venv/lib/python3.13/site-packages/torch/utils/data/_utils/worker.py | d3652cf902df501a6e824659b5a07941db9b689834a2acd18dabf16f2e0633e8 | 375 | 1 |                         )             data_queue.put((idx, data))             del data, idx, index, r  # save memory     except KeyboardInterrupt:         # Main process will raise KeyboardInterrupt a |
| .venv/lib/python3.13/site-packages/torch/utils/data/_utils/collate.py | 99ccd4e95f8f927d13248f3f17ce7b494c505e3e03131ccf4931353cafb6e20e | 399 | 1 |     if torch.utils.data.get_worker_info() is not None:         # If we're in a background process, concatenate directly into a         # shared memory tensor to avoid an extra copy         numel = sum |
| .venv/lib/python3.13/site-packages/torch/utils/data/_utils/pin_memory.py | 724e4b4170d73cf46870915793a1224386d63ee82726fc8ee7fc769137f54566 | 111 | 17 | # mypy: allow-untyped-defs r"""Contains definitions of the methods used by the _BaseDataLoaderIter to put fetched tensors into pinned memory.  These **needs** to be in global scope since Py2 doesn't s |
| .venv/lib/python3.13/site-packages/torch/utils/data/_utils/__init__.py | b5e3527d87e6397cf3f2b8ced32a45f085979cc3885fb8c7a6fa032be54f5c90 | 55 | 1 |   from . import collate, fetch, pin_memory, signal_handling, worker |
| .venv/lib/python3.13/site-packages/torch/utils/data/datapipes/datapipe.py | 7a7cc09d129046d1575aa23cf62db6b994f3a186d6f62b84c207a9ea158c86f6 | 417 | 1 |     All DataPipes that represent an iterable of data samples should subclass this.     This style of DataPipes is particularly useful when data come from a stream, or     when the number of samples is |
| .venv/lib/python3.13/site-packages/torch/quantization/fx/quantization_patterns.py | 15aeddf5604ce8de38027aeaf0cb1a9ca6bf338c78842894312f2afa4a9ee6e2 | 49 | 2 |     CustomModuleQuantizeHandler,     DefaultNodeQuantizeHandler,     EmbeddingQuantizeHandler,     FixedQParamsOpQuantizeHandler,     GeneralTensorShapeOpQuantizeHandler, |
| .venv/lib/python3.13/site-packages/torch/testing/_creation.py | bcd52282b140ad18d2592eaec4656320a17b3373fddf63fd819ec0007c56e693 | 277 | 13 |     noncontiguous: bool = False,     exclude_zero: bool = False,     memory_format: Optional[torch.memory_format] = None, ) -> torch.Tensor:     r"""Creates a tensor with the given :attr:`shape`, :att |
| .venv/lib/python3.13/site-packages/torch/testing/_comparison.py | 28c448353b4dd0dfc3232f839ffee6aff045f1d2280b8071945028fa81c17f79 | 1638 | 2 |         If ``actual`` and ``expected`` are ...          - ... not on the same :attr:`~torch.Tensor.device`, they are moved CPU memory.         - ... not of the same ``dtype``, they are promoted  to a  |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/common_nn.py | 9353951a17535aca0b2bf495cae557d3820088714cb8d77b2f2fda69fe845dfc | 3994 | 95 | #    `wrap_functional(F.interpolate, size=12, scale_factor=None, mode='nearest')`, #    then the `cpp_options_args` entry should be #    "F::InterpolateFuncOptions().size(std::vector<int64_t>({12})).s |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/autocast_test_lists.py | 2063fed1287f96c60acdacef9f446ea38a40fa6611b333f4b184719c9d3b4a11 | 473 | 4 |             ("cosine_similarity", mat0_fp16 + mat1_fp16),             ("poisson_nll_loss", mat0_fp16 + mat1_fp16 + (True, False, 1.e-8, torch.nn._reduction.get_enum('mean'))),             ("cosine_emb |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/common_fsdp.py | 038729b63bc2b383d550f9f93dddedb8ffbb404cd83831dfa2569de69674d824 | 1577 | 2 |         d_model = 16          self.embed_tokens = nn.Embedding(d_vocab, d_model)         self.transformer = nn.Transformer(             d_model=d_model, |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/common_optimizers.py | e63783f58a43f8c33376c06663b58373971eaabd5b3adf854de49535c606d77f | 2212 | 2 |                 skipIfTorchDynamo("See #133268 regarding dtype being None"),                 "TestOptimRenewed",                 "test_peak_memory_foreach",             ),             DecorateInfo( |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/common_device_type.py | 08b93dc2b6d5c3b8a3fdaee3b39549f275aa759eebd3df8d5e58e0ae1adca8fb | 1982 | 17 | class CUDATestBase(DeviceTypeTestBase):     device_type = "cuda"     _do_cuda_memory_leak_check = True     _do_cuda_non_default_stream = True     primary_device: ClassVar[str] |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/inductor_utils.py | e9f1d7c007c35c09b1467f3f79d1a1985543ac24816264f0a2836a9716255cff | 344 | 6 | ) from torch._inductor.codegen.wrapper import PythonWrapperCodegen from torch._inductor.utils import get_gpu_shared_memory, is_big_gpu from torch._inductor.utils import GPU_TYPES, get_gpu_type, is_gpu |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/common_distributed.py | ca2b2d657697c477eb033d07087877464160c76979b566b079b21b4704e63349 | 1800 | 3 | import torch.nn as nn from torch._C._autograd import DeviceType from torch._C._distributed_c10d import _SymmetricMemory from torch._logging._internal import trace_log from torch.testing._internal.comm |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/common_methods_invocations.py | 7a0257f519e0969c4af3050ac604e1db81078da61d43db48d0582e813b3aa7b7 | 24913 | 150 |      yield ErrorInput(SampleInput(make_input(1), args=(make_input(3, dtype=torch.float16),)),                      error_regex='dot : expected both vectors to have same dtype')     yield ErrorInput(Sa |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/logging_tensor.py | 184db734267a861c24724e3c80e3b23853b94a2827b55ed5792c5474d17c8ee9 | 169 | 1 |     def __new__(cls, elem, *args, **kwargs):         # The wrapping tensor (LoggingTensor) shouldn't hold any         # memory for the class in question, but it should still         # advertise the sa |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/common_cuda.py | 0d249f3e7193394b73f443fef765e6213099df48babaacd0537c772e4673a23b | 348 | 1 |     assert TEST_CUDA, 'CUDA must be available when calling initialize_cuda_context_rng'     if not __cuda_ctx_rng_initialized:         # initialize cuda context and rng for memory tests         for i  |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/common_quantization.py | 550ca86002e74f0ded3538371bd2d551734c5e29fee68df63541a206edbc0120 | 3412 | 102 |     default_dynamic_qconfig,     default_dynamic_quant_observer,     default_embedding_qat_qconfig,     default_observer,     default_per_channel_qconfig, |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/common_modules.py | ac30371e325df2814e025f75f71601cc8f3c2c38235ad642eb291dfc812a9341 | 4421 | 146 | from torch.testing._internal.common_methods_invocations import DecorateInfo from torch.testing._internal.common_nn import (     cosineembeddingloss_reference, cross_entropy_loss_reference, ctcloss_ref |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/common_mps.py | b8befeba988c369b3804eba090ce99c94920e55b96f4e96654d462ecab6a2399 | 1007 | 2 |             "nn.functional.avg_pool3d": None,             "nn.functional.ctc_loss": None,             "nn.functional.embedding_bag": None,             "nn.functional.max_pool3d": None,             "nn |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/jit_metaprogramming_utils.py | d64c26e696dcf3afb3f0424981a7719c326880deca9ba3f4a7c67d3da21bb67e | 726 | 4 |         ('linear', (S, S), ((M, S), (M,)), 'addmm', (True, ['aten::linear'])),         ('bilinear', (S, S, S), ((S, S, M), torch.zeros(M, S, M),),),         ('embedding', torch.tensor([[1, 2, 4, 5], [ |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/common_utils.py | 67eef1d02c965a4838eeeb834eac9b20954ff50e03c020fad0cc138c27144b10 | 5713 | 61 |  def gcIfJetson(fn):     # Irregular Jetson host/device memory setup requires cleanup to avoid tests being killed     @functools.wraps(fn)     def wrapper(*args, **kwargs): |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/common_quantized.py | 8f0c51c669872c6262270ae025586b6f6b3ef9a5b380a4dca8a4a24b40796240 | 483 | 2 |  # copy-pasted from # https://github.com/pytorch/ao/blob/bc4f51da86956275da7db0da6e420c506df97820/torchao/prototype/custom_fp_utils.py#L27C1-L142C29 def _n_ones(n: int) -> int:     return (1 << n) - 1 |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/common_subclass.py | 2ae47c9150641311f31f29913e2f53e2d49b9225936d7825b60af50a193afb74 | 347 | 2 |         if "requires_grad" not in kwargs:             kwargs["requires_grad"] = False         # Ignore memory_format and pin memory for now as I don't know how to         # safely access them on a Ten |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/dist_utils.py | 581973be5e2c6fb6d797c4ff0efffe2c3819b54a786dd18215f08da5b0e359c9 | 200 | 2 |      Note: pass the string representation of MessageTypes that should be used     with the faulty agent's send function. By default, all retriable messages     ("RREF_FORK_REQUEST", "RREF_CHILD_ACCEPT |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/jit_utils.py | e0f7f499adddc5315fc4fb0cc6f569e11eb98933c42a1f7dab2ec171bf91679f | 894 | 1 |  class JitTestCase(JitCommonTestCase):     _do_cuda_memory_leak_check = True     _restored_warnings = False  |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/generated/annotated_fn_args.py | 67165e6e0c8dd5c80ab960128842c778a50f8808b28c9025da7e75973d85f661 | 2892 | 12 |     torch._C._VariableFunctions.cosh: [{'is_kwarg_only': 'False', 'name': 'self', 'simple_type': 'Tensor'}],     torch._C._VariableFunctions.cosh_: [{'is_kwarg_only': 'False', 'name': 'self', 'simple_ |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/opinfo/core.py | 01d387817cf5470a2f447c81157b2668f9d19a9b87d23f35bea3ed835ac90f2b | 3219 | 5 | #   and with the requested dtype. # # This function is intended to test the non-vectorized and vectorized code #   paths of elementwise binary functions, as well as their handling of odd tensor #   si |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py | 1425460df86f568c7008b17adbd5ed043b48495ce356ddb17fd909f14e47f3a8 | 2370 | 39 |   def sample_kwargs_vector_norm(t, **kwargs):     # orders with / without identity     def ords(): |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py | 401194229c34d0bbae0a714f76b2a196ab39fa6bbe6354abc54a011a9d16f3fd | 925 | 3 |             sample = ErrorInput(                 sample,                 error_regex="crow_indices is supposed to be a vector, but got 3 dimensional tensor.",             )  |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/opinfo/definitions/nested.py | 2dae343b99323ad3bf75fb81c58b32bc032f82f731559c43cb45fbea0fbbc71e | 1594 | 28 |     "linalg.tensorsolve": ExtraOpData(dim_args=[["dims..."]]),     "linalg.vecdot": ExtraOpData(dim_args=[["dim"]]),     "linalg.vector_norm": ExtraOpData(dim_args=[["dim..."]]),     "log_softmax": Ex |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/ddp_under_dist_autograd_test.py | 2e3855164bd51dea22d4b19fcffc9f17be5a3fde3d8c6959422b82c5d9347009 | 744 | 15 | ) from torch.testing._internal.dist_utils import dist_init, INIT_METHOD_TEMPLATE from torch.testing._internal.distributed.rpc.rpc_agent_test_fixture import (     RpcAgentTestFixture, ) |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/checkpoint_utils.py | 1e48413f5b412f87ba6d9a482592d4c4ef904e0543ca2163aafb1adf497448ae | 160 | 2 |     @staticmethod     def _rot13bytes(b: Buffer, count: int) -> None:         b = memoryview(b)         for i in range(count):             ch = b[i] |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/distributed_test.py | 7c4f34ed61cd706b4c8e4889c3fe6d86f22e589c407b6a59be3cea02daba9b6c | 10392 | 52 |   class EmbeddingNetDifferentParams(nn.Module):     """     A module containing an embedding with different dimension or different # of |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/common_state_dict.py | 1b6fc3a4a45e6b8d0f552308584bd8a7c8cab7c999e9859d49c97c5bcab72c8c | 171 | 23 |   class FusionEmbedding(nn.Module):     def __init__(self, vocab_size: int, fusion_vocab_size: int, embed_dim: int) -> None:         super().__init__() |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/rpc_utils.py | ff2b4bf5cd8353348ccd3572a0e4ca83c50956520d35dcb44789ad157051d2b2 | 189 | 35 |     CudaDistAutogradTest,     DistAutogradTest,     FaultyAgentDistAutogradTest,     TensorPipeAgentDistAutogradTest,     TensorPipeCudaDistAutogradTest, |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py | fa0b4ab2a1dc4aa06ecc832e279e8517f2b218560e49a970d613b84dee60733d | 616 | 16 |   # A toy transformer model, partly inspired by the nanoGPT model: # https://github.com/karpathy/nanoGPT. class Transformer(nn.Module): |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py | 991dd8ae1709c8de8268f671d68d07b79a3c691dd8e626adf6a434816c72d10c | 753 | 6 | from torch.testing._internal.common_distributed import skip_if_lt_x_gpu from torch.testing._internal.common_utils import TemporaryFileName, TEST_WITH_ROCM from torch.testing._internal.distributed.rpc. |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/rpc/faulty_rpc_agent_test_fixture.py | ce2551f59e2d0e1746d2898a12f1957ce5c3376235d1e79709c31827a1bfbd89 | 65 | 6 | import torch.distributed.rpc as rpc import torch.distributed.rpc._testing  # noqa: F401 from torch.testing._internal.distributed.rpc.rpc_agent_test_fixture import (     RpcAgentTestFixture, ) |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/rpc/faulty_agent_rpc_test.py | cdc611226597a08834aa6556a643e54ca03fb749de40f6328bd6179bc21d813a | 338 | 6 |     worker_name, ) from torch.testing._internal.distributed.rpc.rpc_agent_test_fixture import (     RpcAgentTestFixture, ) |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py | df2d136653e0d18a82c28706e770369dd55c7b9b4957ab10955dbccf5325e1c3 | 2756 | 33 |     worker_name, ) from torch.testing._internal.distributed.rpc.rpc_agent_test_fixture import (     RpcAgentTestFixture, ) |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/rpc/rpc_agent_test_fixture.py | cb93f6ec10b193cd883d354ece8bf8f8e8ebdffb7290838694b952130584bffc | 64 | 4 |   class RpcAgentTestFixture(ABC):     @property     def world_size(self) -> int: |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/rpc/tensorpipe_rpc_agent_test_fixture.py | e914e5b12d2c281876899aaf2e6fe27aa210a634aec2a95873ba9d8236fde983 | 29 | 5 | import torch.distributed.rpc as rpc from torch.testing._internal.common_distributed import tp_transports from torch.testing._internal.distributed.rpc.rpc_agent_test_fixture import (     RpcAgentTestFi |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py | 4ef5047b3c9c8e23eb913cd449e767fdaa69de6777654622559dfea9d0a713de | 6319 | 67 |     worker_name, ) from torch.testing._internal.distributed.rpc.rpc_agent_test_fixture import (     RpcAgentTestFixture, ) |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/rpc/dist_optimizer_test.py | 1e26c316ddf1513b8e9a6da65ce02713309cb5be3c58a1b334f599f8146bfa19 | 282 | 3 | from torch.distributed.optim import DistributedOptimizer from torch.testing._internal.dist_utils import dist_init from torch.testing._internal.distributed.rpc.rpc_agent_test_fixture import (     RpcAg |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/rpc/jit/dist_autograd_test.py | 6f3abf6a368c0a2544145988d48b2b2bf6d12a77840cccb228e917ba2baafd91 | 114 | 3 | from torch.testing import FileCheck from torch.testing._internal.dist_utils import dist_init, worker_name from torch.testing._internal.distributed.rpc.rpc_agent_test_fixture import (     RpcAgentTestF |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py | d5e0db445cf90431b41ca50bdc806c24bcd5ec65f8785c0ec2fecc1dcb0d24be | 1384 | 3 |     worker_name, ) from torch.testing._internal.distributed.rpc.rpc_agent_test_fixture import (     RpcAgentTestFixture, ) |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test_faulty.py | f138c93b302f0256c4daacb78b3a430541e7533a20eabee38c43dc898a0bb3b5 | 220 | 5 |     worker_name, ) from torch.testing._internal.distributed.rpc.rpc_agent_test_fixture import (     RpcAgentTestFixture, ) |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/rpc/examples/reinforcement_learning_rpc_test.py | 4f317218aef460faeed8f3946561a9380ce628f016965cc7c6398175e8b18163 | 266 | 33 | from torch.distributions import Categorical from torch.testing._internal.dist_utils import dist_init, worker_name from torch.testing._internal.distributed.rpc.rpc_agent_test_fixture import (     RpcAg |
| .venv/lib/python3.13/site-packages/torch/testing/_internal/distributed/rpc/examples/parameter_server_test.py | 419c72e0ab5200f0e20844d21eabd9687df95a75d4bb0c72db6fb26bdcb3dfe4 | 141 | 3 | from torch import optim from torch.testing._internal.dist_utils import dist_init, worker_name from torch.testing._internal.distributed.rpc.rpc_agent_test_fixture import (     RpcAgentTestFixture, ) |
| .venv/lib/python3.13/site-packages/torch/_library/triton.py | 02e948a73446a3637af743303079d069a6e12f74810c1c0ebd63683486e6d1f4 | 275 | 1 |         >>> print(gm.code)         >>> # def forward(self, x_1, y_1):         >>> #     empty_like = torch.ops.aten.empty_like.default(x_1, pin_memory = False)         >>> #     triton_kernel_wrapper_ |
| .venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py | 53bdb300c5030c5ead29c8a60a578dcff309777e00cd1b97420530918f6ce5bd | 694 | 1 |                     torch.Tensor,                     sum(                         [  # noqa: C419                             t.to(scaler.device, non_blocking=True)                             for t  |
| .venv/lib/python3.13/site-packages/torch/jit/_script.py | d9bc53fe00db3db0905f1c1c7398c4bc01a566ce55099f0a612e332f2cb885b6 | 1741 | 3 |   # For each user-defined class that subclasses ScriptModule, this meta-class: # (1) finds all the methods annotated with @script_method in a ScriptModule and #     removes them from the class attribu |
| .venv/lib/python3.13/site-packages/torch/jit/_shape_functions.py | 7812ace036442cc105c62d08847d65f8e4c716784209d2de7dfb03c1a0982de9 | 1475 | 12 |   def embedding(     weight: list[int],     indices: list[int], |
| .venv/lib/python3.13/site-packages/torch/jit/_builtins.py | 21f5908e4f21049cf2657dd2b6b00cac94cbcb9f3af49799e335802cf3c9932c | 205 | 2 |     (torch._C._infer_size, "aten::_infer_size"),     (         torch.nn.functional._no_grad_embedding_renorm_,  # type: ignore[attr-defined]         "aten::_no_grad_embedding_renorm_",     ), |
| .venv/lib/python3.13/site-packages/torch/jit/_dataclass_impls.py | d204b16e90a5e82b09ca1516cffcd8f4039e99c363b9d840b11ea323f9db0698 | 191 | 2 |      # Handle InitVars if needed (only works on Python 3.8+, when a `type` attribute was added to InitVar);     # see CPython commit here https://github.com/python/cpython/commit/01ee12ba35a333e8a6a25 |
| .venv/lib/python3.13/site-packages/torch/jit/_trace.py | 8af91c4851f82424bde7e0ad157281f551fb6491d4625a1e700b1aed125af94a | 1508 | 5 |             if self._return_inputs:                 ret_inputs.append(                     tuple(x.clone(memory_format=torch.preserve_format) for x in args)                 )             if self._retu |
| .venv/lib/python3.13/site-packages/torch/_dynamo/config.py | 49608bfeb561948be7f91621859f11112487c8326333fe0e46d8c2f3efc8384f | 632 | 2 | # If True, when testing if two models are the same, we will test them against # a third fp64 reference and only report a problem if the RMSE relative to the # fp64 is greater.  However, this will use  |
| .venv/lib/python3.13/site-packages/torch/_dynamo/guards.py | e709448534d11812932c8808f75855750616351d8e17c5365d80dd61fd7b479b | 3634 | 6 |     AttrSource,     CallFunctionNoArgsSource,     CallMethodItemSource,     ChainedSource,     ConstantSource, |
| .venv/lib/python3.13/site-packages/torch/_dynamo/device_interface.py | 98672ae3aac2dbc242e0b1b7f024cc0e279a91d38176c1f5fa968d52e31811b8 | 516 | 5 |      @staticmethod     def memory_allocated(device: torch.types.Device = None) -> int:         raise NotImplementedError  |
| .venv/lib/python3.13/site-packages/torch/_dynamo/__init__.py | f6db767504e985d298f78c23211d468d9967cefb39c5e78d5aaf1e4009165b7a | 162 | 1 | def reset_code_caches() -> None:     """     Clears in-memory code cache, which is what stores compiled products.  This     resets less state than :func:`reset` and is mostly only used for testing     |
| .venv/lib/python3.13/site-packages/torch/_dynamo/bytecode_analysis.py | 61fd66c5e902f880e3db6c7573cf1e1a7786154d7c4e03f9b0c41e6b1125f575 | 261 | 1 | def get_indexof(insts):     """     Get a mapping from instruction memory address to index in instruction list.     Additionally checks that each instruction only appears once in the list.     """ |
| .venv/lib/python3.13/site-packages/torch/_dynamo/output_graph.py | ded833fb0f1624407c3335f6e9cf74c6c7cf02c91509058be77900f17604da8c | 3146 | 1 |             self.remove_tensorify_specialized_graphargs()              # free a bit of memory             self.real_value_cache.clear()  |
| .venv/lib/python3.13/site-packages/torch/_dynamo/compiled_autograd.py | 3063524bea61d339bcde1c814a117412bc92f503ab4165c134e34930cbe8be2d | 1545 | 2 |                  for i in runtime_inputs_to_move:                     inputs[i] = inputs[i].pin_memory().cuda(non_blocking=True)                  with _disable(), make_compile_context(self.id): |
| .venv/lib/python3.13/site-packages/torch/_dynamo/utils.py | fc826dcd7852ee50af288d41c79fae00f0447b2e40bf8fc2707eb2b6df3d2336 | 4693 | 4 |     except TypeError:         return False     # cannot hash writable memoryview object     except ValueError:         return False |
| .venv/lib/python3.13/site-packages/torch/_dynamo/trace_rules.py | 7df52c2b33193e756f9729a9568a5e721a92d0c01541ce1f466f46bc4cd04904 | 3984 | 144 |         "torch._C._construct_CUDA_Tensor_From_Storage_And_Metadata",         "torch._C._construct_storage_from_data_pointer",         "torch._C._conv_determine_backend_memory_format",         "torch._ |
| .venv/lib/python3.13/site-packages/torch/_dynamo/testing.py | a184774c1f10065685a7348c8152c161a55441ac4e5774ca24bcbd303e946550 | 554 | 1 |         "MaskedLMOutput",         "Seq2SeqLMOutput",         "CausalLMOutputWithCrossAttentions",     ):         return reduce_to_scalar_loss(out.logits) |
| .venv/lib/python3.13/site-packages/torch/_dynamo/pgo.py | ff124c89f3b7a75a3cd2c112bb1c6113c2103ef6db0f487694bfa68946cb7beb | 880 | 1 | LOCK_TIMEOUT = 10  # How does in memory representation work?  Concretely, this module is # responsible for holding GLOBAL state representing the state it holds, no # other copies permitted.  So we ret |
| .venv/lib/python3.13/site-packages/torch/_dynamo/source.py | 74333c7b9a1374fa8b0262b377910643a0cf1c455fe2e99bcb226c7eb2caa1f0 | 1029 | 1 |  @dataclasses.dataclass(frozen=True) class CallMethodItemSource(ChainedSource):     def name(self) -> str:         return f"{self.base.name()}.item()" |
| .venv/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py | b0d356e8f972450707b79ab680bd3b289d3f5d52dccc35f57d21803cedfbb46b | 2167 | 2 |             One can also provide additional context for the backend, like             torch.jit.fuser("fuser2"), by setting the backend_ctx_ctor attribute.             See AOTAutogradMemoryEfficientFu |
| .venv/lib/python3.13/site-packages/torch/_dynamo/code_context.py | 6fb6d048d59bf0306ec034fd43ca801e1fe349520cdf73391dfe8c21661b3b54 | 61 | 2 | The CodeContextDict class maintains a mapping between Python code objects and their associated context data, using weak references to automatically clean up entries when code objects are garbage colle |
| .venv/lib/python3.13/site-packages/torch/_dynamo/debug_utils.py | ac564264ba0063eb9d61783b01b41d6b820caa50ff4b9365cabe378cde105c12 | 897 | 3 | - Neural network module string conversion via NNModuleToString - Profiling tools and system information collection - Buck build system integration for Meta-internal testing  Key classes: |
| .venv/lib/python3.13/site-packages/torch/_dynamo/backends/debugging.py | ce7bf7e034c2773aa637ded859512cc32e52125cacc72c061ab2c68fcbb0d3d2 | 471 | 2 |     with functorch_config.patch(config_patches):         return aot_autograd(             # these are taken from memory_efficient_fusion()             fw_compiler=get_nop_func(),             bw_compil |
| .venv/lib/python3.13/site-packages/torch/_dynamo/backends/common.py | 2c3fbc98632a1abb2ef2c248d1e74b9216e6761ad2f181f6eeb1c1866ad4d411 | 168 | 2 |   - Fake tensor conversion   - Device/dtype detection from inputs   - Memory efficient fusion   - Graph flattening   - Common compiler configurations |
| .venv/lib/python3.13/site-packages/torch/_dynamo/backends/inductor.py | 78a21152668c954681317534b5eaa12b5946e882bf51b1d56b9ac2948774891a | 26 | 3 | TorchInductor is a compiler backend that generates optimized code for both CPU and GPU. This module lazily imports and registers the TorchInductor compiler to avoid loading it into memory when it is n |
| .venv/lib/python3.13/site-packages/torch/_dynamo/backends/tvm.py | c231c29be2b2c7659c54eedda79d4af32abf2f119ff132f7bccd98dc409fff70 | 213 | 1 |   - Default scheduler   - Auto-scheduler for automatic optimization   - Meta-schedule for evolutionary search-based tuning - Hardware-specific optimizations:   - CUDA GPU support |
| .venv/lib/python3.13/site-packages/torch/_dynamo/variables/builder.py | 07e1a9e8923ae853533b9d1659c824ec4dbf673bd67dbac2f8fbcdc6cb3f49d6 | 3634 | 4 |     AttrProxySource,     AttrSource,     CallMethodItemSource,     ChainedSource,     ConstDictKeySource, |
| .venv/lib/python3.13/site-packages/torch/_dynamo/variables/tensor.py | 75f1af734075e045ea98c6ca1286604606f6c74b759e724351042d31a097da16 | 1746 | 10 |         using the user-provided inputs.         NOTE: this runs actual tensor computation and may be         slow and memory-intensive.         """         return get_real_value(self.proxy.node, self. |
| .venv/lib/python3.13/site-packages/torch/_dynamo/variables/higher_order_ops.py | a8db06f67738808c2d94dc15c8fb66bdac8c0d8bb1649c0dab53ebd2feb3ffe1 | 3441 | 3 |         # We set include contiguity=False because we have vmap x HOP tests, where if         # include_contiguity=True will call t.is_contiguous inside of vmap and get an error         # "querying is_ |
| .venv/lib/python3.13/site-packages/torch/_dynamo/variables/builtin.py | f8afd94d3fa80e5b9fe8f5dbd1a91c304d04909c6716413751d59fe329b09e50 | 2553 | 2 |      def call_bool(self, tx: "InstructionTranslator", arg):         # Emulate `PyBool_Type.tp_vectorcall` which boils down to `PyObject_IsTrue`.         # https://github.com/python/cpython/blob/3.12/O |
| .venv/lib/python3.13/site-packages/torch/_dynamo/repro/after_aot.py | ee1148d93a38d9d7ab83297d7b49552ec3381825e5bc42eff957c8a2a5d542e1 | 1063 | 1 |     # TODO: The logic for cloning inputs/models here is intentionally     # modeled off of run_fwd_maybe_bwd, but arguably it is better not to     # clone inputs (as you are doubling your effective GP |
| .venv/lib/python3.13/site-packages/torch/_lazy/extract_compiled_graph.py | 60228458f990f5122a5ad168ac34ddb02f9f832a3bffe7dea190093bc71c1033 | 226 | 1 |         # eager tensors on the default device         # (check https://gist.github.com/shunting314/eabdf6c769c59bc384469717b8f9bb7f for yolove,         # and https://gist.github.com/shunting314/8d5e2d |
| .venv/lib/python3.13/site-packages/torch/ao/nn/qat/dynamic/modules/linear.py | dce0b106cf34cd5198ecdcf715cf6b4dda030aba672c7aa5b6a58ca084141a43 | 41 | 2 |     ) -> None:         super().__init__(in_features, out_features, bias, qconfig, device, dtype)         if not torch.ao.quantization.qconfig._activation_is_memoryless(qconfig):  # type: ignore[arg-ty |
| .venv/lib/python3.13/site-packages/torch/ao/nn/qat/modules/__init__.py | 466299eddd1db3de842114aa006193ac3c2e5d559eac4fd2fcd096b84b97ff6d | 14 | 5 | from .conv import Conv1d, Conv2d, Conv3d from .embedding_ops import Embedding, EmbeddingBag from .linear import Linear  |
| .venv/lib/python3.13/site-packages/torch/ao/nn/qat/modules/embedding_ops.py | 87e6cc40506faeeb4e4a979300aad107cb6b6eda0fa06fef645ab022555e6293 | 251 | 54 |   __all__ = ["Embedding", "EmbeddingBag"]   |
| .venv/lib/python3.13/site-packages/torch/ao/nn/quantized/__init__.py | 36d1de72c615b60f5ed4885309dbe85d257ea101174509ede7875995270fa3a2 | 40 | 2 |     "DeQuantize",     "ELU",     "Embedding",     "EmbeddingBag",     "GroupNorm", |
| .venv/lib/python3.13/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py | fdfc7277363765c80220c22e7a57f26fc5bc99b9a8bcf786924e7727f19586d6 | 1364 | 1 |  class LSTMCell(RNNCellBase):     r"""A long short-term memory (LSTM) cell.      A dynamic quantized LSTMCell module with floating point tensor as inputs and outputs. |
| .venv/lib/python3.13/site-packages/torch/ao/nn/quantized/modules/__init__.py | bc562d11ce6270b09d4ba6bf23b7492803691529a8c047a101d80a5eb6315fad | 163 | 5 | ) from .dropout import Dropout from .embedding_ops import Embedding, EmbeddingBag from .functional_modules import FloatFunctional, FXFloatFunctional, QFunctional from .linear import Linear |
| .venv/lib/python3.13/site-packages/torch/ao/nn/quantized/modules/rnn.py | aaafba71ee1df5fda5cf280cc28d3158d1b8bca82a935a2bbc852d07913ea039 | 59 | 1 |  class LSTM(torch.ao.nn.quantizable.LSTM):     r"""A quantized long short-term memory (LSTM).      For the description and the argument types, please, refer to :class:`~torch.nn.LSTM` |
| .venv/lib/python3.13/site-packages/torch/ao/nn/quantized/modules/embedding_ops.py | d5fe85ee77351b13bbbb5e54bdc0356525b8a2341ae8f4d784f49b843080b0ac | 414 | 126 |   __all__ = ["EmbeddingPackedParams", "Embedding", "EmbeddingBag"]   |
| .venv/lib/python3.13/site-packages/torch/ao/nn/quantized/reference/__init__.py | 86ede1ca8ccc26d91cf3a06ed6ff2d9b26b2bb101d7834afd2c52239e340affb | 20 | 2 |     "LSTM",     "GRU",     "Embedding",     "EmbeddingBag", ] |
| .venv/lib/python3.13/site-packages/torch/ao/nn/quantized/reference/modules/__init__.py | 612f0c60a96a04fa00d94101712f8c81b3b367cfc70e9fbb113e010bb2ad0819 | 30 | 4 | from .linear import Linear from .rnn import GRU, GRUCell, LSTM, LSTMCell, RNNCell from .sparse import Embedding, EmbeddingBag   |
| .venv/lib/python3.13/site-packages/torch/ao/nn/quantized/reference/modules/sparse.py | 34d4c95b691223d1adfdc666155be6863fa4fa7cc257ba0990a30e58383720db | 163 | 26 |   __all__ = ["Embedding", "EmbeddingBag"]   |
| .venv/lib/python3.13/site-packages/torch/ao/nn/quantizable/modules/activation.py | ec75e7956af8e541c5f0699dc020128f5fda79547d3c6d88c01809f2a4d691c8 | 553 | 4 |             - Inputs:             - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is               the embedding dimension. :math:`(N, L, E)` if ``batch_first` |
| .venv/lib/python3.13/site-packages/torch/ao/nn/quantizable/modules/rnn.py | 7f2bb9f23042714cf003816e2cdfc51d1181dec80855e4e378515de3f06887a3 | 600 | 2 |  class LSTMCell(torch.nn.Module):     r"""A quantizable long short-term memory (LSTM) cell.      For the description and the argument types, please, refer to :class:`~torch.nn.LSTMCell` |
| .venv/lib/python3.13/site-packages/torch/ao/ns/_numeric_suite_fx.py | b1018155a438391791d330ae1d240601d2d790bebd7b5e7e1ff0a70a7e0c4d20 | 1125 | 1 |         # string representation of qconfig         self.qconfig_str = qconfig_str         # this can be turned off to reduce memory usage during calibration         self.save_activations = True  |
| .venv/lib/python3.13/site-packages/torch/ao/ns/fx/graph_matcher.py | f3a15c891204d6124dfa801a55fcce825385f28ae6de9aae23234f6713db7d38 | 473 | 1 |     Why are we not just using the node name? Answer: because of two requirements:     A. fusions must be supported     B. some Numeric Suite APIs can be called without having all of the models in memo |
| .venv/lib/python3.13/site-packages/torch/ao/ns/fx/n_shadows_utils.py | f5fc75b7e72729b518db41667ef2c181be7b386d39847c80e94cc39c2e5ce7f3 | 1379 | 2 |      # If there are no quantization configs for this subgraph, skip adding     # loggers. This reduces memory usage for models where not all layers are     # quantized.     # TODO(future): consider ma |
| .venv/lib/python3.13/site-packages/torch/ao/ns/fx/mappings.py | ceb9df9ec900684d268809f2b95f07eb62b4fb33f5271705ff92edc41d3d55b5 | 758 | 8 |             nn.ELU,         },         # Embedding         {             nn.Embedding, |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/observer.py | b77b59a7665feb6db54e309b5ec5bac3eb8720fd1058734a86ec8bc8354d178e | 2132 | 2 |         x_dim = x.size()          new_axis_list = [i for i in range(len(x_dim))]  # noqa: C416         new_axis_list[self.ch_axis] = 0         new_axis_list[0] = self.ch_axis |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/quantization_mappings.py | e25e7ac46d666bcda738f3986df64007450ed3ddc7ff8446520b34cb3dd467cc | 366 | 26 |     "get_default_static_quant_module_mappings",     "get_default_static_quant_reference_module_mappings",     "get_embedding_static_quant_module_mappings",     "get_default_static_sparse_quant_module_ |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/_correct_bias.py | 8ac51c0d6e3bd1971cf458b5c3667da180a47c804cfbc91603a35632541ca64d | 157 | 1 |      Using numeric suite shadow module, the expected output of the floating point and quantized modules     is recorded. Using that data the bias of supported modules is shifted to compensate for the  |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/quantize.py | 91d5e72dece08ad494ef3abdd359aed491f2503bee9e95f0ce56e201935630fe | 820 | 5 | from torch.ao.quantization.observer import _is_activation_post_process from torch.ao.quantization.qconfig import (     _activation_is_memoryless,     _add_module_to_qconfig_obs_ctr,     default_dynami |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/fake_quantize.py | ca6c17b8e903a5e9ea8421293b5b4ad794d1c23fd170b7bb396dfc2e817f0c41 | 651 | 8 |     "default_affine_fixed_qparams_fake_quant",     "default_per_channel_weight_fake_quant",     "default_embedding_fake_quant",     "default_embedding_fake_quant_4bit",     "default_histogram_fake_qua |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/qconfig.py | 9dba5267aab3ca8f1e07d4ff00c51409027d23d0efaa4734f444c25869b4979f | 702 | 14 | from torch.ao.quantization.fake_quantize import (     default_dynamic_fake_quant,     default_embedding_fake_quant,     default_embedding_fake_quant_4bit,     default_fake_quant, |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/__init__.py | 67f1f8db53967db3874394ca7d1e823f8c54202cfefb39c9edf087cf3473df27 | 235 | 4 |     "default_dynamic_fake_quant",     "default_dynamic_quant_observer",     "default_embedding_fake_quant",     "default_embedding_fake_quant_4bit",     "default_eval_fn", |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py | 2ab0993e37a5c804a92f236ed2b22c69b80a983bbf03394939377b32fc8f837a | 783 | 21 |   def _get_embedding_op_configs(     dtype_configs: list[DTypeConfig], ) -> list[BackendPatternConfig]: |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/backend_config/qnnpack.py | 3e43d3cc24be437a7c32252aea6cad26516df99a31ec03b69316d3839431f805 | 172 | 4 |     _get_conv_configs,     _get_default_op_configs,     _get_embedding_op_configs,     _get_fixed_qparams_op_configs,     _get_linear_configs, |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/backend_config/fbgemm.py | 742b060e7f8f6c04b27b508f7fff69a0d33a78e30dd74fcd5054d06adf79fb44 | 130 | 4 |     _get_conv_configs,     _get_default_op_configs,     _get_embedding_op_configs,     _get_fixed_qparams_op_configs,     _get_linear_configs, |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/backend_config/native.py | c4a0638c2fae67ca99b1b1e5b9fb6a0ba4e7f6fa3fea2bdcb1560558b14542d4 | 232 | 7 |     _get_conv_configs,     _get_default_op_configs,     _get_embedding_op_configs,     _get_fixed_qparams_op_configs,     _get_linear_configs, |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/backend_config/onednn.py | e5b2f585924fc0a2639d356d3de38d1384535697d329143e36c4f5b502689217 | 641 | 4 |     _get_conv_configs,     _get_default_op_configs,     _get_embedding_op_configs,     _get_fixed_qparams_op_configs,     _get_linear_configs, |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/backend_config/executorch.py | b7bd9eb1c567af7ced4d80e98b21c82653964f01e01359b8c27e9fce2231c8fe | 499 | 25 |   def _get_embedding_op_configs() -> list[BackendPatternConfig]:     dtype_configs = [         executorch_weight_only_quint8_dtype_config, |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/backend_config/x86.py | e207962ebea6905852118897157a6407c35e812d3911786fd9f6074e96a33728 | 127 | 4 |     _get_conv_configs,     _get_default_op_configs,     _get_embedding_op_configs,     _get_fixed_qparams_op_configs,     _get_linear_configs, |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/pt2e/export_utils.py | 9c1557179edeea6f4c45cbff583aae2c7f426fc15fe1ea419bca3c0296500c17 | 241 | 2 |     QAT users should call this before performing inference on the model.      This call is idempotent; if the model is already in eval mode, nothing will happen.     """     is_training = getattr(mode |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/pt2e/_affine_quantization.py | d58305556947bf203a8597f1cc3330bac3bc37bd1b22991cf9a9f062019bbd63 | 867 | 1 |         # TODO: this seems to be a detail for tinygemm (converting from uint to int, probably need to refactor this)         mid_point = (quant_max + quant_min + 1) / 2         # This should allocate  |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/pt2e/prepare.py | 54e7883541e096f2781972619fae7f8715d8536948feccdde4789e4374285936 | 575 | 2 |         new_args.append(new_arg)      # Clone has a memory_format kwarg, zeros_like has a pin_memory kwarg, and     # gelu has a has an approximate kwarg that persist in exported graph.     # This is  |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/fx/quantize_handler.py | 9782ec4a2eb7592500ea1f3d1f09859de94d076b37587e993c61e5e69c161c9d | 226 | 2 |     "LinearReLUQuantizeHandler",     "BatchNormQuantizeHandler",     "EmbeddingQuantizeHandler",     "RNNDynamicQuantizeHandler",     "DefaultNodeQuantizeHandler", |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py | 2073288bc4f9093cf2ee888d636d5fbdc639ae5060cd1a0278cb317ba3fafc36 | 1365 | 4 | # TODO: correct the namespace for these modules WEIGHT_ONLY_LOWER_MODULE_MAP: dict[type[nn.Module], type[nn.Module]] = {     nnqr.Embedding: nnq.Embedding,     nnqr.EmbeddingBag: nnq.EmbeddingBag, } |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/fx/_decomposed.py | 1e6a07cbd12752a75b206fbf27389f7f582a69893cffa7c1f7558b7e795462bc | 1222 | 3 | ):     assert group_size > 1     # needed for GPTQ single column quantize     if group_size > input.shape[-1] and scales.shape[-1] == 1:         group_size = input.shape[-1] |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/fx/_model_report/detector.py | dcdfb16de4b34059fc64a3f2abc34e8b9a03b64188690ec50f3a1e1843865509 | 1734 | 1 |                 x_dim = x_copy.size()                  new_axis_list = [i for i in range(len(x_dim))]  # noqa: C416                 new_axis_list[self.ch_axis] = 0                 new_axis_list[0] = s |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/fx/_model_report/model_report_observer.py | 056bb18236e1e44820d71c6af5e210b77bfc8036f1336f00426846d0dd63506d | 286 | 2 |         x_dim = x_copy.size()          new_axis_list = [i for i in range(len(x_dim))]  # noqa: C416         new_axis_list[self.ch_axis] = 0         new_axis_list[0] = self.ch_axis |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/quantizer/embedding_quantizer.py | 47a0c18bceba79c800a6e3e39d25c1f368e2adb4433065b8b8f30a2b02131858 | 98 | 15 |  __all__ = [     "get_embedding_operators_config",     "EmbeddingQuantizer", ] |
| .venv/lib/python3.13/site-packages/torch/ao/quantization/quantizer/composable_quantizer.py | 08927e399a821f59e506a9c66f95291fb5b3b2c509c4258f9211ef45d081454c | 84 | 4 |     """     ComposableQuantizer allows users to combine more than one quantizer into a single quantizer.     This allows users to quantize a model with multiple quantizers. E.g., embedding quantizatio |
| .venv/lib/python3.13/site-packages/torch/ao/pruning/sparsifier/nearly_diagonal_sparsifier.py | a6a492bb002bba366a48e866bfd29e5a80f84758de1224ef2d6aef8d575c3376 | 61 | 1 |      Note:         This can be accelerated (vectorized) once the Spdiagonal feature (PR: #78439) is landed or the banded matrix         feature is landed: https://stackoverflow.com/questions/52463972/ |
| .venv/lib/python3.13/site-packages/torch/ao/pruning/_experimental/data_sparsifier/base_data_sparsifier.py | 2dbe3fd8d61bf83d4c031b00b22446a45b7ce167525557db8664be66566e54ad | 332 | 7 | __all__ = ["BaseDataSparsifier"]  EMBEDDING_TYPES = {     nn.Embedding,     nn.EmbeddingBag, |
| .venv/lib/python3.13/site-packages/torch/ao/pruning/_experimental/data_sparsifier/quantization_utils.py | 29d8ee422eb109b83f53891f931667193622faff166a311421c09b351619818e | 151 | 43 |   SUPPORTED_MODULES = {nn.Embedding, nn.EmbeddingBag}   |
| .venv/lib/python3.13/site-packages/torch/ao/pruning/_experimental/pruner/saliency_pruner.py | 8bad2c7add3a202892637fc6dffe0d12b274847b700926031077992bacdcfafb | 33 | 1 |     This pruner works on N-Dimensional weight tensors.     For each row, we will calculate the saliency, whic is the sum the L1 norm of all weights in that row.     We expect that the resulting salien |
| .venv/lib/python3.13/site-packages/torch/mtia/memory.py | e3450d7f9a9a745a02a0086fe6fb0d2d97a7d29f92fb9edcf0c0b17255e8fc48 | 58 | 13 | # pyre-strict  r"""This package adds support for device memory management implemented in MTIA."""  from typing import Any, Optional |
| .venv/lib/python3.13/site-packages/torch/mtia/__init__.py | 52dd4a96ffdaa5b89434a5004f8e49e3bbd76742581e8a2bb5301549237cdfd7 | 409 | 15 |   def record_memory_history(     enabled: Optional[str] = "all", stacks: str = "python", max_entries: int = 0 ) -> None: |
| .venv/lib/python3.13/site-packages/torch/_refs/_conversions.py | 0643726a604b3902e52b2ea607805274f46300a3f5821679c5cc900e452cfbfb | 120 | 5 | def _make_conversion_method(name: str, dtype: torch.dtype):     def fn(         self: TensorLikeType, memory_format: torch.memory_format = torch.preserve_format     ) -> TensorLikeType:         return |
| .venv/lib/python3.13/site-packages/torch/_refs/__init__.py | fa3ef08f08baf99fba06876b3f180a67a911928bcd77c7f4ef2056cb0f5cfbfe | 6708 | 184 |     BoolLike,     definitely_contiguous,     definitely_contiguous_for_memory_format,     DeviceLikeType,     Dim, |
| .venv/lib/python3.13/site-packages/torch/_refs/linalg/__init__.py | a96cbf38dac57036a65a32f6057915e35afe17a02ce5ba06902257d0ef81ffa5 | 344 | 12 |     "svd",     "svdvals",     "vector_norm",     "vecdot",     "cross", |
| .venv/lib/python3.13/site-packages/torch/_refs/nn/functional/__init__.py | 923722cc8d7dbd01011eb6ec758afd73cd92a3ed98b4af76333bbb081005edac | 1290 | 9 |     "hardshrink",     "hardtanh",     "hinge_embedding_loss",     "huber_loss",     "l1_loss", |
| .venv/lib/python3.13/site-packages/torch/profiler/_memory_profiler.py | 1a44b13be36002ed59f27c035120ca0ce92ab8bd220eab34e26847c86d9dd61c | 1197 | 35 |     `torch/csrc/profiler/collection.h` when `TensorID` is declared. To     summarize, multiple Storage buffers can map to the same logical Tensor.     This dataclass is used to refer to a concrete in- |
| .venv/lib/python3.13/site-packages/torch/profiler/_pattern_matcher.py | 4d85d0aa49cc458982cd00520f9b666256e55932edac407380a8b2da9465021b | 663 | 2 |     """     This pattern identifies if we use a for loop to index a tensor that     can be vectorized.     example:     tensor = torch.empty((100, 100)) |
| .venv/lib/python3.13/site-packages/torch/profiler/profiler.py | 05bcdb18d1e7e3083ed6e4d280a6d8a30e2744d12227907dabdc7dd8c1a36334 | 1135 | 41 | from torch._utils_internal import profiler_allow_cudagraph_cupti_lazy_reinit_cuda12 from torch.autograd import kineto_available, ProfilerActivity from torch.profiler._memory_profiler import MemoryProf |
| .venv/lib/python3.13/site-packages/torch/sparse/_semi_structured_conversions.py | e0c25b4be251f7dee42cf11bdb8fe1e99e3cc1854fe478383f20e994ff201f9c | 357 | 1 |     # [0 0 1 1]      # reshape tensor to expand tiles into 8-bit vectors     bitmask_binary_representation = bitmask_4x4_chunks.reshape(         *bitmask_4x4_chunks.shape[:2], 4, 2, 8 |
| .venv/lib/python3.13/site-packages/torch/sparse/__init__.py | 116de7aa1d042373e9b945745987f3816d2ef6eda63598f93ff1692108d863f6 | 704 | 1 | Args:     diagonals (Tensor): Matrix storing diagonals row-wise     offsets (Tensor): The diagonals to be set, stored as a vector     shape (2-tuple of ints): The desired shape of the result Keyword a |
| .venv/lib/python3.13/site-packages/torch/sparse/_triton_ops.py | 036410dd44c60493f1bd4336570fc7201b2f638bdd1a1e0fb2df95625123f14a | 2530 | 4 |      - ``"bsr_strided_mm_compressed"`` - matrix multiplications       scattered in batches of tensors and a tensor. A memory and       processor efficient version of ``"bsr_strided_mm"`` format.  If   |
| .venv/lib/python3.13/site-packages/torch/sparse/_triton_ops_meta.py | 61cbfb62c137ea44769026d71e0811048bf713779f994c6cf9ce522f4e9e372e | 7757 | 1 | operations typically outperforms the corresponding operation with strided-only inputs when the blocked representation of a tensor provides a better alignment with memory access than what the strided r |
| .venv/lib/python3.13/site-packages/torch/export/exported_program.py | 5235b2fb5b327b50ec5cae1aa4bed4a68e07168395e02e65042c15996da1d616 | 1697 | 2 |         gm = torch.fx.GraphModule(root, graph)     except SyntaxError:         # If custom objects stored in memory are being used in the graph,         # the generated python code will result in a sy |
| .venv/lib/python3.13/site-packages/torch/export/_trace.py | f6d5631c26ae2ce66d21249787414bd0f9b20f93a43ad3f9f5a74a187f35689e | 2268 | 1 |         allow_complex_guards_as_runtime_asserts:          With the current dynamic shapes language for dims and derived dims, we can run into constraints          that are not expressible with the lan |
| .venv/lib/python3.13/site-packages/torch/nested/__init__.py | 00c1711b6f3939204c8a0627420e89afbd58bc32c01a0538d920f5d6844e49f0 | 517 | 8 |      :func:`to_padded_tensor` always copies the underlying data,     since the nested and the non-nested tensors differ in memory layout.  Args: |
| .venv/lib/python3.13/site-packages/torch/nested/_internal/nested_tensor.py | d1952b7d171bfb96322cd0c32a252bab0b5b71af80de7f75fa9f5f5800505701 | 666 | 3 |     if len(tensors) == 0:         raise RuntimeError("Cannot construct a nested tensor from an empty tensor list")     if not len(set(t.dtype for t in tensors)) == 1:  # noqa: C401         raise Runti |
| .venv/lib/python3.13/site-packages/torch/nested/_internal/ops.py | 60042b9e01d0e25fddf38926564677ddf9e88d618a2a0b73b9f240ed197e33a6 | 2744 | 16 | @register_jagged_func(torch.ops.aten.is_contiguous.default, "self: jt_all") def is_contiguous_general(func, *args, **kwargs):     from torch._prims_common import is_contiguous_for_memory_format      _ |
| .venv/lib/python3.13/site-packages/torch/nested/_internal/sdpa.py | e6545f4a41626bfc41037d82b0f160a55439117f76f7192e89d43103d3ba0e53 | 935 | 1 |                 return SDPBackend.MATH      log.warning("Memory efficient kernel not used because:")     can_use_efficient_attention(params, debug=True)     _can_use_efficient_sdpa_jagged(params, debu |
| .venv/lib/python3.13/site-packages/torch/_strobelight/compile_time_profiler.py | b15ef2cb04594eb3f7261e7d60995d3912f2a4c6a9822526d8fe60375658a2e7 | 225 | 1 |         cls._cls_init()         # profiler_class should have public API similar to that of StrobelightCLIFunctionProfiler.         # we have pass different functionProfilerClass for meta-internal fbco |
| .venv/lib/python3.13/site-packages/torch/compiler/__init__.py | d6d5b0ec3488e37ac30018b8b06234433c07e22e6c40484c0d27bcbcd9432d80 | 633 | 2 |               dynamism from the first two invocations instead of wasting a static compile on               the first invocation.             - "aot_eager_then_compile": Run the first invocation with A |
| .venv/lib/python3.13/site-packages/torch/distributions/categorical.py | 39e348adf4c9bb145532f8aaa8df096929ee87d1a9d133935e64786ed913703d | 167 | 2 |      If `probs` is N-dimensional, the first N-1 dimensions are treated as a batch of     relative probability vectors.      .. note:: The `probs` argument must be non-negative, finite and have a non-z |
| .venv/lib/python3.13/site-packages/torch/distributions/transforms.py | 559b01ce0f22ba5f83eb63b985b1809cfaa56378a8a79d1669c9a61c11d0915f | 1288 | 6 |         scale (Tensor or float): Scale parameter.         event_dim (int): Optional size of `event_shape`. This should be zero             for univariate random variables, 1 for distributions over vec |
| .venv/lib/python3.13/site-packages/torch/distributions/geometric.py | a65bc6d5b3836cba124892c114ab8076aa6a956d61af6036fd4ec31566bfc647 | 141 | 1 |             self._validate_sample(value)         value, probs = broadcast_all(value, self.probs)         probs = probs.clone(memory_format=torch.contiguous_format)         probs[(probs == 1) & (value  |
| .venv/lib/python3.13/site-packages/torch/distributions/studentT.py | bd16f19fa39ce8b03dc2c368cae248374e870a80a34f83c19885dd79e5571772 | 128 | 2 |     @property     def mean(self) -> Tensor:         m = self.loc.clone(memory_format=torch.contiguous_format)         m[self.df <= 1] = nan         return m |
| .venv/lib/python3.13/site-packages/torch/distributions/multivariate_normal.py | 7e1f8b92ddacd72ea86597a85e444ff92ef5dd628d6a6733d2b800a64bb85984 | 270 | 5 | def _batch_mv(bmat, bvec):     r"""     Performs a batched matrix-vector product, with compatible but different batch shapes.      This function takes as input `bmat`, containing :math:`n \times n` ma |
| .venv/lib/python3.13/site-packages/torch/distributions/relaxed_categorical.py | f64cfd5e0d34fa8b35cbaa4cea6201fc0878b1a87d703a0b88b04c7f2a6e38c8 | 161 | 3 |     """      arg_constraints = {"probs": constraints.simplex, "logits": constraints.real_vector}     support = (         constraints.real_vector |
| .venv/lib/python3.13/site-packages/torch/distributions/lowrank_multivariate_normal.py | 819a374bd90303f4733f030b8b4baf775fe2fa0869add27ac89424e5a168dc6f | 252 | 4 |     r"""     Computes Cholesky of :math:`I + W.T @ inv(D) @ W` for a batch of matrices :math:`W`     and a batch of vectors :math:`D`.     """     m = W.size(-1) |
| .venv/lib/python3.13/site-packages/torch/distributions/lkj_cholesky.py | 004ce4be92bb6e1b44acbc4a26eae215c613b43822c1a5ee1f060787b6ea6dab | 153 | 2 |         batch_shape = self.concentration.size()         event_shape = torch.Size((dim, dim))         # This is used to draw vectorized samples from the beta distribution in Sec. 3.2 of [1].         ma |
| .venv/lib/python3.13/site-packages/torch/distributions/multinomial.py | 822213bd559440fa501252d438b49f7f07449b7cc90fe5afc6b27634f1fa8d61 | 147 | 2 |     """      arg_constraints = {"probs": constraints.simplex, "logits": constraints.real_vector}     total_count: int  |
| .venv/lib/python3.13/site-packages/torch/distributions/distribution.py | 76eae5c516af86ec569e728533719a73c15867c1acc694c9d933a092bcb37278 | 347 | 1 |         `batch_shape`. This method calls :class:`~torch.Tensor.expand` on         the distribution's parameters. As such, this does not allocate new         memory for the expanded distribution instan |
| .venv/lib/python3.13/site-packages/torch/distributions/utils.py | 8950158b4694de1d59e1f643ab0893fe89a503cbd23d23eadc5590269c946642 | 222 | 4 | def tril_matrix_to_vec(mat: Tensor, diag: int = 0) -> Tensor:     r"""     Convert a `D x D` matrix or a batch of matrices into a (batched) vector     which comprises of lower triangular elements from |
| .venv/lib/python3.13/site-packages/torch/distributions/fishersnedecor.py | ae1cfce7ad4ad88d09b0f01592273198036ddf64c1597ac2b768bfaa16a5d7c5 | 108 | 2 |     @property     def mean(self) -> Tensor:         df2 = self.df2.clone(memory_format=torch.contiguous_format)         df2[df2 <= 2] = nan         return df2 / (df2 - 2) |
| .venv/lib/python3.13/site-packages/torch/distributions/constraints.py | 6f409e12c2d77304390516d44646fb87c4c1000c63a27d44f46adcbe40ad0096 | 738 | 5 | - ``constraints.positive_semidefinite`` - ``constraints.positive_definite`` - ``constraints.real_vector`` - ``constraints.real`` - ``constraints.simplex`` |
| .venv/lib/python3.13/site-packages/torch/distributions/one_hot_categorical.py | 0b46667ce216c41436e95fed6f22afd9af8983d73756b1bdc11eece15d91b103 | 143 | 2 |     :attr:`logits`.      Samples are one-hot coded vectors of size ``probs.size(-1)``.      .. note:: The `probs` argument must be non-negative, finite and have a non-zero sum, |
| .venv/lib/python3.13/site-packages/torch/package/glob_group.py | 25b42150c051a9e2c512df7932f6d970e55a311bbcd67be14b1931f7fbcb6e78 | 86 | 2 |     def matches(self, candidate: str) -> bool:         candidate = self.separator + candidate         return any(p.fullmatch(candidate) for p in self.include) and all(             not p.fullmatch(cand |
| .venv/lib/python3.13/site-packages/mdit_py_plugins/attrs/parse.py | 4ce70d6283145468e0e1329507fa8a7daa787790524c61395a0772101f6c3cc7 | 258 | 9 |         tokens.set_start(pos)         return State.SCANNING_CLASS     if REGEX_KEY_CHARACTERS.fullmatch(char):         tokens.set_start(pos)         return State.SCANNING_KEY |
| .venv/lib/python3.13/site-packages/mdit_py_plugins/admon/port.yaml | cb3e32219ce4109b8195a9248380d1d47f9443c46ea62dac15f52012845dec7b | 5 | 1 | - package: markdown-it-admon   commit: 9820ba89415c464a3cc18a780f222a0ceb3e18bd   date: Jul 3, 2021   version: 1.0.0 |
| .venv/lib/python3.13/site-packages/zipp/__init__.py | 89e5e1f4620c7400632915ff25426d3fd939c1d04b2b832de57e27b334a49981 | 457 | 1 |         prefix = re.escape(self.at)         tr = Translator(seps='/')         matches = re.compile(prefix + tr.translate(pattern)).fullmatch         return map(self._next, filter(matches, self.root.na |
| .venv/lib/python3.13/site-packages/zipp/glob.py | 0cb57d2c1b03c40e98556f367b7fad92836bbacd61e11fa3dc147a56a4b40331 | 117 | 1 |         matches newlines (valid on Unix).          Append '\z' to imply fullmatch even when match is used.         """         return rf'(?s:{pattern})\z' |
| .venv/lib/python3.13/site-packages/websockets/server.py | a3694f42063bb201daaacb7ec0c703b6c8b1684b2c6a95bf03bc991c60732e21 | 588 | 2 |          """         # "The user agent MUST NOT include more than one Origin header field"         # per https://datatracker.ietf.org/doc/html/rfc6454#section-7.3.         try: |
| .venv/lib/python3.13/site-packages/websockets/version.py | 3ce864661d56d11715a2a5d9996507051fbee21afcf81c7fdfe5c39f25e8b6e8 | 93 | 2 |         else:             description_re = r"[0-9.]+-([0-9]+)-(g[0-9a-f]{7,}(?:-dirty)?)"             match = re.fullmatch(description_re, description)             if match is None:                 ra |
| .venv/lib/python3.13/site-packages/websockets/protocol.py | 172a20d44b15f31b619c9757dcc1fdf9b1db10680f442d2dab019608f2b826b8 | 759 | 1 |           any new events.          :meth:`receive_eof` is idempotent.          """ |
| .venv/lib/python3.13/site-packages/websockets/http11.py | 6b6204bd353a13952da33a9db56a1a9b7d6b2a7d4f395285c2095a7930528ee6 | 428 | 7 | __all__ = [     "SERVER",     "USER_AGENT",     "Request",     "Response", |
| .venv/lib/python3.13/site-packages/websockets/frames.py | a7a7b7474e7e48ab4c0dc1e1f121d8b2914e1c6d5e8b9c89bd35abe4b79bc71b | 431 | 3 |   BytesLike = bytes, bytearray, memoryview   |
| .venv/lib/python3.13/site-packages/websockets/headers.py | c909cf963559c15d7f57ea4e49128d2c6feef36ef0142d61ef671c8a88dc43c3 | 587 | 3 |      """     match = _quotable_re.fullmatch(value)     if match is None:         raise ValueError("invalid characters for quoted-string encoding") |
| .venv/lib/python3.13/site-packages/websockets/legacy/server.py | 04d868a3c43a8c3ae6778d87ad99416062fbc5f892a15bd407ec91068ce1f83d | 1192 | 2 |          """         # "The user agent MUST NOT include more than one Origin header field"         # per https://datatracker.ietf.org/doc/html/rfc6454#section-7.3.         try: |
| .venv/lib/python3.13/site-packages/websockets/legacy/protocol.py | 1aa3d1d8422b61ed2172e3b3a926b4ea3cd7ee608d8d40920ba4e93f34b359a5 | 1642 | 14 |     The ``max_queue`` parameter sets the maximum length of the queue that     holds incoming messages. The default value is ``32``. Messages are added     to an in-memory queue when they're received;  |
| .venv/lib/python3.13/site-packages/websockets/legacy/client.py | d8926ab15087cf87174937fefa34ae50abc2d3819c3985c4832ff5190cf118c2 | 706 | 15 |     validate_subprotocols, ) from ..http11 import USER_AGENT from ..typing import ExtensionHeader, LoggerLike, Origin, Subprotocol from ..uri import WebSocketURI, parse_uri |
| .venv/lib/python3.13/site-packages/websockets/legacy/http.py | 70e0909835a120a4269bc5161973d6ec20d9834df08e8802b1bd0b3fda1eb4d4 | 202 | 3 |     if not 100 <= status_code < 1000:         raise ValueError(f"unsupported HTTP status code: {d(raw_status_code)}")     if not _value_re.fullmatch(raw_reason):         raise ValueError(f"invalid HTT |
| .venv/lib/python3.13/site-packages/websockets/extensions/permessage_deflate.py | fedbb8f8de15ebe518f668418414c4d34f53483aaf635cba3e461a9c862984e3 | 698 | 2 |             # 0x00 0x00 0xff 0xff, which must be removed.             assert data[-4:] == _EMPTY_UNCOMPRESSED_BLOCK             # Making a copy is faster than memoryview(a)[:-4] until 2kB.             |
| .venv/lib/python3.13/site-packages/websockets/sync/client.py | eb75f4c8736a64630129a55561ee6cade8b2b1e5eedc2c2b892bcfa64e0985fa | 649 | 22 | from ..extensions.permessage_deflate import enable_client_permessage_deflate from ..headers import build_authorization_basic, build_host, validate_subprotocols from ..http11 import USER_AGENT, Respons |
| .venv/lib/python3.13/site-packages/websockets/sync/connection.py | 02f667220b611cf92312cc43464ba9b0714432a4659c0480d5793271301b3a06 | 1073 | 4 |         A string (:class:`str`) is sent as a Text_ frame. A bytestring or         bytes-like object (:class:`bytes`, :class:`bytearray`, or         :class:`memoryview`) is sent as a Binary_ frame.     |
| .venv/lib/python3.13/site-packages/websockets/asyncio/server.py | a16ae1f59679cb0deff7d8e967c72cd9a8c2c3dca07428ef1fb10b87f57172be | 982 | 1 |         * Wait until all connection handlers terminate.          :meth:`close` is idempotent.          """ |
| .venv/lib/python3.13/site-packages/websockets/asyncio/client.py | 947d3cdc61ae9c57c41733a92f59cf729ee89787e9f67de59e1c27044eca14bd | 821 | 25 | from ..extensions.permessage_deflate import enable_client_permessage_deflate from ..headers import build_authorization_basic, build_host, validate_subprotocols from ..http11 import USER_AGENT, Respons |
| .venv/lib/python3.13/site-packages/websockets/asyncio/connection.py | ea1a0fa5a9e9f93ba2ac42223a2e8ed8fcaae70250984da8b02a8829bdb65e9a | 1238 | 7 |         A string (:class:`str`) is sent as a Text_ frame. A bytestring or         bytes-like object (:class:`bytes`, :class:`bytearray`, or         :class:`memoryview`) is sent as a Binary_ frame.     |
| .venv/lib/python3.13/site-packages/isort/api.py | 257fe429b24267bc77111b2ddc401df20e091a5eaf9c4715dc8d60c452865eba | 660 | 2 |  @contextlib.contextmanager def _in_memory_output_stream_context() -> Iterator[TextIO]:     yield StringIO(newline=None)  |
| .venv/lib/python3.13/site-packages/isort/main.py | dfa4ff5f70680b5757edcf937e4787266a5646d09617774e4e44756b8617a004 | 1308 | 1 |         "--overwrite-in-place",         help="Tells isort to overwrite in place using the same file handle. "         "Comes at a performance and memory usage penalty over its standard "         "appr |
| .venv/lib/python3.13/site-packages/filelock/_api.py | d9a01305e277fa3b4c8f93929bb104e77f6235a4c1b1fd77297b5c04ca22f283 | 404 | 1 | # This is a helper class which is returned by :meth:`BaseFileLock.acquire` and wraps the lock to make sure __enter__ # is not called twice when entering the with statement. If we would simply return * |
| .venv/lib/python3.13/site-packages/sqlalchemy/inspection.py | a8a10a1b7ecdd4e8f1a50795ce86f5abd5705a305b8c8d71d26a2f246edf609e | 175 | 1 | The :func:`_sa.inspect` function is the entry point to SQLAlchemy's public API for viewing the configuration and construction of in-memory objects.   Depending on the type of object passed to :func:`_ |
| .venv/lib/python3.13/site-packages/sqlalchemy/util/_concurrency_py3k.py | 52d3c391bebb38e55662f06a61a42010d83493f8ce036990384d385e6adb62ad | 289 | 1 |  # implementation based on snaury gist at # https://gist.github.com/snaury/202bf4f22c41ca34e56297bae5f33fef # Issue for context: https://github.com/python-greenlet/greenlet/issues/173  |
| .venv/lib/python3.13/site-packages/sqlalchemy/util/__init__.py | 7c09e566297c226cced9942086b43e4b61f53ced5588a3da25c2372c3f1b3149 | 161 | 2 | from .langhelpers import memoized_instancemethod as memoized_instancemethod from .langhelpers import memoized_property as memoized_property from .langhelpers import MemoizedSlots as MemoizedSlots from |
| .venv/lib/python3.13/site-packages/sqlalchemy/util/_collections.py | 2509069b7301ab7456af958a1b5f92c2870f2b73f040736c956f10a93ec202ad | 718 | 1 |     # compare to .index version below, this version introduces less function     # overhead and is usually the same speed.  At 15000 items (way bigger than     # a relationship-bound collection in mem |
| .venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py | bde1f4296eb53f3f21a2888cf713264c4cd0aa78d9d0ac4119dc56e59fd16ed7 | 2304 | 2 |   class MemoizedSlots:     """Apply memoized items to an object using a __getattr__ scheme.  |
| .venv/lib/python3.13/site-packages/sqlalchemy/ext/orderinglist.py | 2c31c846931b97cc349a30eecfaa618e75a102998b454d0faeaa2e5540d3bbe2 | 440 | 1 | in a related ``bullet`` table.   The bullets within a slide are displayed in order based on the value of the ``position`` column in the ``bullet`` table.   As entries are reordered in memory, the valu |
| .venv/lib/python3.13/site-packages/sqlalchemy/ext/serializer.py | ff3f79c193139f71b7b0218de76830cc3e02b8a8eb84632be44bbc83d33140d8 | 186 | 1 |   typically one which was reflected from an existing database at some previous   point in time.  The serializer module is specifically for the opposite case,   where the Table metadata is already pres |
| .venv/lib/python3.13/site-packages/sqlalchemy/ext/mutable.py | 27c8b1e93e750e455fafd5c37bddcc77ff7665feadcd799d123322c8e457f741 | 1097 | 2 |            :meth:`.associate_with` for types that are permanent to an            application, not with ad-hoc types else this will cause unbounded            growth in memory usage.          """ |
| .venv/lib/python3.13/site-packages/sqlalchemy/ext/asyncio/result.py | 4aa1bd2bd6abf408730d00c8cedeadbbad12a01bbadee6351e5cdcee4d46b4a4 | 963 | 1 |            SQL query which was invoked to produce this            :class:`_asyncio.AsyncResult`;            for a DBAPI driver that buffers results in memory before yielding            rows, all rows  |
| .venv/lib/python3.13/site-packages/sqlalchemy/testing/util.py | 06e038abef1c98d86b515a8f3f7e51af5e4c9d81928e65b486651d4b5488d3f2 | 536 | 1 |  def total_size(o):     """Returns the approximate memory footprint an object and all of its     contents.  |
| .venv/lib/python3.13/site-packages/sqlalchemy/testing/requirements.py | deef257f348e2c4fbf4140fa887921cd145b5c3c84b9c9b3d93f1544ef101b4f | 1919 | 2 |      @property     def memory_intensive(self):         from . import config  |
| .venv/lib/python3.13/site-packages/sqlalchemy/testing/plugin/plugin_base.py | 4c159d8365e05c1e9081450574a2efd4ef7e497322b631cb9b6acd348cd76614 | 780 | 4 |     )     make_option(         "--nomemory",         action="callback",         zeroarg_callback=_set_tag_exclude("memory_intensive"), |
| .venv/lib/python3.13/site-packages/sqlalchemy/testing/suite/test_types.py | 0b7c099f70c69467f9f1e36bd364a8611de214097ebe79c73c94bf492588bbcd | 2146 | 1 |         )          # support sqlite :memory: database...         data_table.create(engine, checkfirst=True)         with engine.begin() as conn: |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/postgresql/pg_catalog.py | c27cc59bd4b42456a0d5305dc920c91f754e1529095a6c008d5708010db98c78 | 327 | 7 |   class INT2VECTOR(TypeDecorator[Sequence[int]]):     impl = ARRAY(SmallInteger)     cache_ok = True |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/postgresql/_psycopg_common.py | 8782669075b1cbf36ca67e818bd60aa5af65d0e930227c10cd82ae7be7c99d50 | 190 | 13 | from .base import PGExecutionContext from .hstore import HSTORE from .pg_catalog import _SpaceVector from .pg_catalog import INT2VECTOR from .pg_catalog import OIDVECTOR |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/postgresql/__init__.py | 903f16f925797b609eb2f5a0d8c400b67717b9917018f7d1fd4383be6457134f | 168 | 4 | from .ext import plainto_tsquery from .ext import to_tsquery from .ext import to_tsvector from .ext import ts_headline from .ext import websearch_to_tsquery |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/postgresql/types.py | a0a843b058884ca6d97023fae8bddd8627f9e299ac16f55fbfe319416037b18a | 314 | 4 |   class TSVECTOR(sqltypes.TypeEngine[str]):     """The :class:`_postgresql.TSVECTOR` type implements the PostgreSQL     text search type TSVECTOR. |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/postgresql/pg8000.py | afa2e0e6d830b9fe0513f440fe41dc7c73d6e465d474d596af713ce3a678688d | 670 | 7 | from .json import JSONB from .json import JSONPathType from .pg_catalog import _SpaceVector from .pg_catalog import OIDVECTOR from .types import CITEXT |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/postgresql/base.py | 443b9e84e64bde12cf86ae3fec6fbdd4180033d2de4e81e288853e4631465665 | 5227 | 14 |   The :class:`_postgresql.TSVECTOR` type can provide for explicit CAST::      from sqlalchemy.dialects.postgresql import TSVECTOR |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/postgresql/ext.py | be8c69033fb3a0238ef9f8e90b3af0ed4012ccd22f773daee24152b8672c8652 | 537 | 6 |   class to_tsvector(_regconfig_fn):     """The PostgreSQL ``to_tsvector`` SQL function.  |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/oracle/vector.py | 62d37b1394db0c8411d8508809a49e79a3a7bf31cffced265cdab5824d364b84 | 365 | 81 | # dialects/oracle/vector.py # Copyright (C) 2005-2025 the SQLAlchemy authors and contributors # <see AUTHORS file> |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/oracle/__init__.py | e6aac97054c5def801f41e0f9300498f789713b3f9ecb75a1cd93131ad4d5ee8 | 82 | 18 | from .base import VARCHAR from .base import VARCHAR2 from .base import VECTOR from .base import VectorIndexConfig from .base import VectorIndexType |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/oracle/oracledb.py | bdeaada3501421b4b1466a544229f4cac315f18eac5809335eded6f08225d75f | 948 | 6 |     engine = create_engine("oracle+oracledb://scott:tiger@myalias")  Connecting to Oracle Autonomous Database ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/oracle/cx_oracle.py | 998ad70f49c9cee4d8d61f3bf1be747cd5c850182373d4352c98e3635547c77c | 1556 | 8 |     )  Connections with tnsnames.ora or to Oracle Autonomous Database ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/oracle/dictionary.py | 27bb46544d0ac943d92a93cb39aaf2dc7743ab50d6776f5aac5e6e74b82ff3fa | 508 | 8 |     Column("has_identity", VARCHAR2(3)),     Column("container_data", VARCHAR2(3)),     Column("inmemory", VARCHAR2(8)),     Column("inmemory_priority", VARCHAR2(8)),     Column("inmemory_distribute", |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/oracle/base.py | cc497cf39fa546cd3b14675616e4b305f6b516aad43d3ee5db0a5c06bf63a08b | 3803 | 131 | columns for non-unique indexes, all but the last column for unique indexes).  .. _oracle_vector_datatype:  VECTOR Datatype |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/sqlite/aiosqlite.py | 7995b8345a4b4bacf4da47881de24b239b45524ce19f43294bcaf69249741b42 | 444 | 2 | based on the kind of SQLite database that's requested:  * When a ``:memory:`` SQLite database is specified, the dialect by default   will use :class:`.StaticPool`. This pool maintains a single   conne |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/sqlite/provision.py | 561a838c300bab129063fdd9de18f39263d027ebed9360e4935038a8b4ecf86f | 197 | 3 |     name_token = None      if filename and filename != ":memory:":         assert "test_schema" not in filename         tokens = re.split(r"[_\.]", filename) |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/sqlite/base.py | ad161a86d403c92c3ee2fea58c4a2651dbe38a0193357a9aa8fba243978ea5ae | 2954 | 1 |     ), "bug is fixed in this version"      conn = sqlite3.connect(":memory:")     cursor = conn.cursor()  |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/sqlite/pysqlite.py | e368cf0e2d6767ff5854a29668a9e4bab2fc34e1545fff116e7edb6aa470d09f | 727 | 17 |     e = create_engine("sqlite:///C:\\path\\to\\database.db")  To use sqlite ``:memory:`` database specify it as the filename using ``sqlite:///:memory:``. It's also the default if no filepath is prese |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/mysql/reserved_words.py | 886eb36fbf2c9fe45da9641193617f4eeb9f939b54a1d91ca076f14dd819624c | 571 | 1 |  # generated using: # https://gist.github.com/kkirsche/4f31f2153ed7a3248be1ec44ca6ddbc9 # # https://mariadb.com/kb/en/reserved-words/ |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/mysql/reflection.py | 081c418afd6608b2cd1f3f88f218092800931772b479812959dd27742042ab92 | 728 | 1 |         #   COMMENT 'comment'         #  COLUMN_FORMAT (FIXED\|DYNAMIC\|DEFAULT)         #  STORAGE (DISK\|MEMORY)         self._re_column = _re_compile(             r"  " |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/mysql/types.py | 94092435154f0473fc1fb01043b37291f27c63181d50300791f77ba83f8bc2fa | 836 | 1 |      This type is for MySQL 5.0.3 or greater for MyISAM, and 5.0.5 or greater     for MyISAM, MEMORY, InnoDB and BDB.  For older versions, use a     MSTinyInteger() type.  |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/mssql/__init__.py | eadfda36981b30b74f13d8291d84dff68e907d56af9dcced44b6ebdb597635a6 | 89 | 2 | from .base import SMALLDATETIME from .base import SMALLINT from .base import SMALLMONEY from .base import SQL_VARIANT from .base import TEXT |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/mssql/pyodbc.py | 0a73bb2835b16f16fb028661a7f3cc0c1bd548cbb3c2ad61e026afd88585583a | 761 | 1 | The PyODBC driver includes support for a "fast executemany" mode of execution which greatly reduces round trips for a DBAPI ``executemany()`` call when using Microsoft ODBC drivers, for **limited size |
| .venv/lib/python3.13/site-packages/sqlalchemy/dialects/mssql/base.py | 6ec0c676523d509de8fcafc5426fa5af29f6f068dcb2cf23a6253057eaddbb0a | 4085 | 8 |   class SMALLMONEY(sqltypes.TypeEngine):     __visit_name__ = "SMALLMONEY"  |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/sync.py | 45da319e1be03639f72e1b68ab8423bd7a63f2a7cecffff0ca26e1d0530e3740 | 165 | 1 |         # technically the "r.primary_key" check isn't         # needed here, but we check for this condition to limit         # how often this logic is invoked for memory/performance         # reasons |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/interfaces.py | 0b444bd1a39507b135e04569ecc0fd0b9e45db2ace7ee38c6745fea198371428 | 1497 | 1 |     _MappedAttribute[_T],     InspectionAttrInfo,     util.MemoizedSlots, ):     """Represent a particular class attribute mapped by :class:`_orm.Mapper`. |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/instrumentation.py | 5a1125bef3963a7dc5b9cf80b1ce4799c2835fa13316d06578b24a3d911ce40d | 755 | 1 |             util.warn(                 "__del__() method on class %s will "                 "cause unreachable cycles and memory leaks, "                 "as SQLAlchemy instrumentation often creates " |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/query.py | 84f2ec94b2f9d254e1c3efb91bc9771ad3e011d218d3b86a2033843bed3ec13f | 3454 | 2 |         (> 10K rows), to batch results in sub-collections and yield them         out partially, so that the Python interpreter doesn't need to declare         very large areas of memory which is both  |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/attributes.py | a21f652a86fccfec0284242e0275ba32891071a6a1eb1f6635023dfe36c05fb4 | 2846 | 3 |     sql_base.Immutable,     cache_key.SlotsMemoizedHasCacheKey,     util.MemoizedSlots,     EventTarget, ): |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/strategies.py | ce4dac83ee43d39741265cc4ce92c3e527e777959c087e9d0e6e3e6f165d30a2 | 3471 | 2 | @relationships.RelationshipProperty.strategy_for(lazy="baked_select") class LazyLoader(     AbstractRelationshipLoader, util.MemoizedSlots, log.Identified ):     """Provide loading behavior for a :cla |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/properties.py | c97c5de34576e45205f6f4847aff80c47e7cc9989ef2664c08642d8059a851ef | 908 | 1 |             )      class Comparator(util.MemoizedSlots, PropComparator[_PT]):         """Produce boolean, comparison, and other operators for         :class:`.ColumnProperty` attributes. |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/util.py | b7b947ab4fb615d4a93d3e79f2febbe3eea3f63e034c29964ce23dc5b0f2de76 | 2404 | 2 | from ..sql.elements import KeyedColumnElement from ..sql.selectable import FromClause from ..util.langhelpers import MemoizedSlots from ..util.typing import de_stringify_annotation as _de_stringify_an |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/mapper.py | fbbab7ac7aa3df1fda72fea9aeadec0c45d9987c7b906495f46fa05bf270697e | 4436 | 2 |         :param always_refresh: If True, all query operations for this mapped            class will overwrite all data within object instances that already            exist within the session, erasing  |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/scoping.py | 23ff812fcc40150b19ada16d035c1fe70819d56cb0070064fbd3b08920233d33 | 2163 | 1 |     @classmethod     def close_all(cls) -> None:         r"""Close *all* sessions in memory.          .. container:: class_bases |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/session.py | b4d7540d1853c74a8507a7026e73916ad5b8696a0d7c92aec4dc1c8782937771 | 5295 | 3 |     )     def close_all(cls) -> None:         """Close *all* sessions in memory."""          close_all_sessions() |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/collections.py | 708a1721a80f06fe01f9340dec126cb06c10714d1280486729aeb02d6b22b72b | 1628 | 2 | instrumentation package works under the general assumption that collection mutation will not raise unusual exceptions.  If you want to closely orchestrate append and remove events with exception manag |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/_orm_constructors.py | d29561174e8df111e6dcfe35f31a6464e0702adad4b18eec408db1cf47fccd3e | 2662 | 2 |         constructs that may be used to load and modify rows in bulk. Used for         large collections that are never appropriate to load at once into         memory.          The ``write_only`` load |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/decl_api.py | 56244d4580358d77312425f650f5bbba0ca6a33a9b579e566c88f573de973e94 | 1921 | 2 |         function :func:`_orm.configure_mappers` function may be used to ensure         configuration is complete for all :class:`_orm.registry` objects in         memory. This is generally simpler to  |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/bulk_persistence.py | 7afc4e40a9df2d1681c8d5e4b9d1721fcb853e6b559428cff340a2213e0bc9bf | 2136 | 1 |             # to align against the behavior of "evaluate".  Additionally,             # in a large number (if not the majority) of cases, we have the             # "evaluate" answer, usually a fixed v |
| .venv/lib/python3.13/site-packages/sqlalchemy/orm/relationships.py | b77caa8b1678d5c84c54e9e67a535aa6cee3c23e6fc0df5d645481d2028af4fc | 3509 | 3 |         )      class Comparator(util.MemoizedSlots, PropComparator[_PT]):         """Produce boolean, comparison, and other operators for         :class:`.RelationshipProperty` attributes. |
| .venv/lib/python3.13/site-packages/sqlalchemy/engine/result.py | e3a277acfd19c03c2ca94fb80806841d74e9c7c3aa0843fd0f2e0b430b475048 | 2388 | 4 |  class SimpleResultMetaData(ResultMetaData):     """result metadata for in-memory collections."""      __slots__ = ( |
| .venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py | 68da76b463415a5073da91e23af789dcf79a2510c994b9277a4510e743090e35 | 3375 | 2 |           usually combined with setting a fixed number of rows to to be fetched           in batches, to allow for efficient iteration of database rows while           at the same time not loading all |
| .venv/lib/python3.13/site-packages/sqlalchemy/pool/impl.py | d9c83a4557da5c7387f893ef271d084cdfb10ef8cd3fe7a89219aaa438ec0601 | 580 | 4 |      :class:`.QueuePool` is the default pooling implementation used for     all :class:`_engine.Engine` objects other than SQLite with a ``:memory:``     database.  |
| .venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py | fd49eb515a69c07d200648aa3d63dcc61d45814e2b8c4b020ee081070ef7b808 | 1517 | 1 | # GC under pypy will call ConnectionFairy finalizers.  linked directly to the # weakref that will empty itself when collected so that it should not create # any unmanaged memory references. _strong_re |
| .venv/lib/python3.13/site-packages/sqlalchemy/event/api.py | c7e565305257cee6c3e9fb81e154534de00979e40d519e631d95c3d5a2f44248 | 221 | 2 |       target. It does not however imply automatic de-registration of the       listener function; associating an arbitrarily high number of listeners       without explicitly removing them will cause  |
| .venv/lib/python3.13/site-packages/sqlalchemy/event/attr.py | 6213d75413e3eb709fca7d274ba87c2e3ab44846c3de6b40667f47625cc66edc | 656 | 1 |   class RefCollection(util.MemoizedSlots, Generic[_ET]):     __slots__ = ("ref",)  |
| .venv/lib/python3.13/site-packages/sqlalchemy/sql/traversals.py | ec600b1ede6615c794bf648c5229087406fd4947126c00aa870a1e8b9acf9317 | 1025 | 1 |   class TraversalComparatorStrategy(HasTraversalDispatch, util.MemoizedSlots):     __slots__ = "stack", "cache", "anon_map"  |
| .venv/lib/python3.13/site-packages/sqlalchemy/sql/cache_key.py | 86739815b53fbe6b69aa8ad6f9d13567d87f08afd88bfdd85d9a4e029df465b3 | 1058 | 2 |   class SlotsMemoizedHasCacheKey(HasCacheKey, util.MemoizedSlots):     __slots__ = ()  |
| .venv/lib/python3.13/site-packages/sqlalchemy/sql/visitors.py | 9cc2bf75d3e0e0dbc484480aa2b0f4ac6a32fa3aacf9d4feba8bbe4bc1c01326 | 1165 | 1 |   class ExternalTraversal(util.MemoizedSlots):     """Base class for visitor objects which can traverse externally using     the :func:`.visitors.traverse` function. |
| .venv/lib/python3.13/site-packages/sqlalchemy/sql/elements.py | 134942a2a4096d6c10df8c5d85dc465ea19c160aef95aff1ae74a95a0b38530a | 5554 | 1 |   class quoted_name(util.MemoizedSlots, str):     """Represent a SQL identifier combined with quoting preferences.  |
| .venv/lib/python3.13/site-packages/sqlalchemy/sql/sqltypes.py | 90c34dc4fd33df17caf0e799088e3032c7b100dd3b3b7d4ed568fab9a14dcdd9 | 3931 | 1 |     # Python 3 has native bytes() type     # both sqlite3 and pg8000 seem to return it,     # psycopg2 as of 2.5 returns 'memoryview'     def result_processor(self, dialect, coltype):         if diale |
| .venv/lib/python3.13/site-packages/sqlalchemy/sql/selectable.py | e4bde2b6a1da442c9dee2b2fa37544df68f26a3755f15650ef26e7cd6826bb5e | 7220 | 3 |         # (just saw it happen on CI)          # construct against original to prevent memory growth         # for repeated generations         new_alias: TableValuedAlias = TableValuedAlias._construct |
| .venv/lib/python3.13/site-packages/sqlalchemy/sql/base.py | 970c61cd0ba6b52ec60341dbeefdd38144fda5bc042c4906a328fd5ea45c4b66 | 2220 | 1 |          For reasons of both time to construct new .c collections as well as         memory conservation for large numbers of large .c collections, the         proxy_index is only filled if correspond |
| .venv/lib/python3.13/site-packages/alabaster/support.py | b14987462a0ac90773b20b548bef08769202a22e49684f14de927430b0d155c7 | 90 | 1 |         # to look the same as ordinary variables.         Name: "#000000",  # class: 'n'         Name.Attribute: "#c4a000",  # class: 'na' - to be revised         Name.Builtin: "#004461",  # class: 'n |
| .venv/lib/python3.13/site-packages/shellingham/posix/__init__.py | a41ebdaadbd927fc887f8f27978f997d2df02f0c2e5ee9275ce6610670b64f5a | 113 | 1 |         return _get_login_shell(cmd)     name = os.path.basename(cmd).lower()     if name == "rosetta" or QEMU_BIN_REGEX.fullmatch(name):         # If the current process is Rosetta or QEMU, this like |
| .venv/lib/python3.13/site-packages/regex/test_regex.py | d861ffce66e02fcb364184e52b93f2e42e881f03066031de6463357befd77bb6 | 4541 | 85 |             (r'\b.\b', 'a', '0', ascii('a')),             (r'\b.\b', '\N{LATIN CAPITAL LETTER A WITH DIAERESIS}', '0',               ascii('\xc4')),             (r'\w', '\N{LATIN CAPITAL LETTER A WITH |
| .venv/lib/python3.13/site-packages/regex/regex.py | 71b6a4bae2fbb3eb91070555b43ffa9dbb63d48b0ab399d24181f3e6b4fe6e90 | 747 | 4 | This module exports the following functions:     match      Match a regular expression pattern at the beginning of a string.     fullmatch  Match a regular expression pattern against all of a string.  |
| .venv/lib/python3.13/site-packages/bandit/plugins/injection_sql.py | 0d5ac613bcf31e62d71fce8c0c02d29dd7d77ea2d58cc72d0d6cc10aaaa51fb4 | 144 | 3 |  An SQL injection attack consists of insertion or "injection" of a SQL query via the input data given to an application. It is a very common attack vector. This plugin test looks for strings that rese |
| .venv/lib/python3.13/site-packages/bandit/plugins/django_sql_injection.py | 90406328d917a61cc109aed58b2a23227b65d9aed2e6c95db8f549550736048a | 145 | 4 |     .. code-block:: none          >> Issue: [B610:django_extra_used] Use of extra potential SQL attack vector.            Severity: Medium Confidence: Medium            CWE: CWE-89 (https://cwe.mitre. |
| .venv/lib/python3.13/site-packages/bandit/blacklists/calls.py | 40254e78109932bc4b328e042d46ee842b76428ad37147bdbf3a850d1d13d665 | 671 | 6 | +======+=====================+====================================+===========+ \| B304 \| ciphers             \| - Crypto.Cipher.ARC2.new           \| High      \| \|      \|                     \| - Crypto. |
| .venv/lib/python3.13/site-packages/numpy/conftest.py | a5776ff822a8728204a6bd03b18b2dbbb4e0aaf35dcd2bdf88334c94cc26a989 | 259 | 5 |  def pytest_addoption(parser):     parser.addoption("--available-memory", action="store", default=None,                      help=("Set amount of memory available for running the "                     |
| .venv/lib/python3.13/site-packages/numpy/__init__.py | 8236a753805db34c29ef9cd03694e0af883b6325eb4fd246cc83d2be0b847e89 | 929 | 3 |         max,         maximum,         may_share_memory,         mean,         memmap, |
| .venv/lib/python3.13/site-packages/numpy/matlib.py | fd2f4df12d8d36c1c6414725a31af1001b490de8c7894c8c74c24eed26b23e40 | 381 | 2 |         Whether to store multi-dimensional data in row-major         (C-style) or column-major (Fortran-style) order in         memory.      See Also |
| .venv/lib/python3.13/site-packages/numpy/exceptions.py | c75cfb0b6463ac3156f2d2dec1b663c8c890a24d16066e642ae44f23154b5238 | 248 | 2 |     AxisError          Given when an axis was invalid.     DTypePromotionError   Given when no common dtype could be found.     TooHardError       Error specific to `numpy.shares_memory`.  """ |
| .venv/lib/python3.13/site-packages/numpy/linalg/__init__.py | ee956f17038914a380ac6794b3a30d8f730daaab31ef1c74beddbfedabcd020e | 99 | 2 |   Matrix and vector products --------------------------  |
| .venv/lib/python3.13/site-packages/numpy/linalg/_linalg.py | 5d2051cf996c76667da25206bdda862209da8f323e992c787816ca358b182750 | 3682 | 128 |            'matrix_rank', 'LinAlgError', 'multi_dot', 'trace', 'diagonal',            'cross', 'outer', 'tensordot', 'matmul', 'matrix_transpose',            'matrix_norm', 'vector_norm', 'vecdot']  i |
| .venv/lib/python3.13/site-packages/numpy/linalg/tests/test_linalg.py | 1b6832f5ccaf4cd6d5286471da177dc9b3cbd0c16db60949b5ddd4d1b7ded5bd | 2431 | 28 |     def do(self, a, b, tags):         ev = linalg.eigvals(a)         evalues, evectors = linalg.eig(a)         assert_almost_equal(ev, evalues)  |
| .venv/lib/python3.13/site-packages/numpy/linalg/tests/test_regression.py | f5af7aa32784190314c5fc3ff86523356aa7e758aee027fb925949d1b2a9f70b | 182 | 13 |         assert_array_almost_equal(b, np.zeros((2, 2)))      def test_norm_vector_badarg(self):         # Regression for #786: Frobenius norm for vectors raises         # ValueError. |
| .venv/lib/python3.13/site-packages/numpy/ctypeslib/_ctypeslib.py | 36d114a62b108437c44c12c092a61fec08ead3188d859bab6f94a61861f9e290 | 604 | 2 |  Our result type, an ndarray that must be of type double, be 1-dimensional and is C-contiguous in memory:  >>> array_1d_double = np.ctypeslib.ndpointer( |
| .venv/lib/python3.13/site-packages/numpy/ma/extras.py | 7fca9feadff1f64df838a98788d21fb7d3c50b22d831e0521a18988e152e2297 | 2345 | 3 |         but the type will be cast if necessary.     overwrite_input : bool, optional         If True, then allow use of memory of input array (a) for         calculations. The input array will be modi |
| .venv/lib/python3.13/site-packages/numpy/ma/__init__.py | 5e90d6617c1ab83738f7e20db24e39e43d37530e29eb115db1d58e9f6aedf3b5 | 54 | 1 |  .. moduleauthor:: Pierre Gerard-Marchant .. moduleauthor:: Jarrod Millman  """ |
| .venv/lib/python3.13/site-packages/numpy/ma/core.py | 4ded11216c3c2721b6889263792886fedd5a84a00808376beffa65e06e90d587 | 8937 | 13 |          ``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a view         of the array's memory with a different data-type.  This can cause a         reinterpretation of the bytes of m |
| .venv/lib/python3.13/site-packages/numpy/ma/tests/test_core.py | 9e8bcca72a94a9ff4eefdef46950761d4a93052894a8c40834c6acdcf6d38233 | 5887 | 20 |     temppath, ) from numpy.testing._private.utils import requires_memory  pi = np.pi |
| .venv/lib/python3.13/site-packages/numpy/ma/tests/test_extras.py | 06715a4f1df790d74b0ee2c9ef80edd5fee01ac0ff9e8605981180f147a552a2 | 1999 | 2 |         assert_equal(test[2], [0, 0, 3, 1, 3, 2])      def test_unique_allmasked(self):         # Test all masked         data = masked_array([1, 1, 1], mask=True) |
| .venv/lib/python3.13/site-packages/numpy/ma/tests/test_mrecords.py | 64312ff8b6cf971e107fd350b3cba735782b757ba946fe084258dfe3fbc2af7e | 498 | 2 |                   (2, 'xy', 6.6999998092651367, 1),                   (0, ' ', 0.40000000596046448, 0)]         pa = recfromrecords(palist, names='c1, c2, c3, c4')         mpa = fromrecords(palist, na |
| .venv/lib/python3.13/site-packages/numpy/_core/fromnumeric.py | b347fa59f908455c0564c943add61bdc48f217dbcc1abd1b9acd0f73e55c3803 | 4270 | 13 |         elements using Fortran-like index order, with the first index         changing fastest, and the last index changing slowest. Note that         the 'C' and 'F' options take no account of the me |
| .venv/lib/python3.13/site-packages/numpy/_core/_dtype.py | 70ce899e3a072d445608780df15990ca37a28838dcc210792ff7cf30e7b5bae3 | 367 | 1 |     is the object passed as the first parameter to the dtype     constructor, and if no additional constructor parameters are     given, will reproduce the exact memory layout.      Parameters |
| .venv/lib/python3.13/site-packages/numpy/_core/_add_newdocs.py | c922ae3ffe2c54f34b1e9d688e04cc8524568b7775f02701147147903f177fe5 | 6968 | 88 |         Fortran order, 'A' means 'F' order if all the arrays are Fortran         contiguous, 'C' order otherwise, and 'K' means as close to the         order the array elements appear in memory as pos |
| .venv/lib/python3.13/site-packages/numpy/_core/_internal.py | 619ea730654ebdf4c3d67ce4d97a91773f24d395959d81a29636f54e71ef32af | 959 | 4 |     def data(self):         """         A pointer to the memory area of the array as a Python integer.         This memory area may contain data that is not aligned, or not in         correct byte-ord |
| .venv/lib/python3.13/site-packages/numpy/_core/multiarray.py | cf01c17723a8c6205170e846d9007fc410189bea7c0114a941bc9ef44cebac1a | 1763 | 38 |     'get_handler_name', 'get_handler_version', 'inner', 'interp',     'interp_complex', 'is_busday', 'lexsort', 'matmul', 'vecdot',     'may_share_memory', 'min_scalar_type', 'ndarray', 'nditer', 'nes |
| .venv/lib/python3.13/site-packages/numpy/_core/_asarray.py | 7c23472da6823fee486be451fdb22b1f1598df1925726be56621a12480e228b3 | 135 | 2 |     ascontiguousarray : Convert input to a contiguous array.     asfortranarray : Convert input to an ndarray with column-major                      memory order.     ndarray.flags : Information about |
| .venv/lib/python3.13/site-packages/numpy/_core/records.py | 8685c20ecc0cea16f2b6219d6069214484b34239ea2265dc21d1a536e3940d7e | 1090 | 4 |         By default, a new array is created of the given shape and data-type.         If `buf` is specified and is an object exposing the buffer interface,         the array will use the memory from th |
| .venv/lib/python3.13/site-packages/numpy/_core/_add_newdocs_scalars.py | 67959c2005f2d95b3c9162c2ce0cafc56547d02025f8eeb86052b7b6d6d4ef27 | 391 | 1 |     :ref:`python:bufferobjects`, exposing its contents as UCS4:      >>> m = memoryview(np.str_("abc"))     >>> m.format     '3w' |
| .venv/lib/python3.13/site-packages/numpy/_core/memmap.py | c88b10ea7f64a59ba58204492459136e35709c1e257a8ca2cef529736894e27f | 364 | 11 | @set_module('numpy') class memmap(ndarray):     """Create a memory-map to an array stored in a *binary* file on disk.      Memory-mapped files are used for accessing small segments of large files |
| .venv/lib/python3.13/site-packages/numpy/_core/getlimits.py | df641eeed94115dca20ef7528c6d5ca766b4349d2b48cc5e0d18a3dda8223eb8 | 749 | 1 | # Uses division to work around deficiencies in strtold on some platforms. # See: # https://perl5.git.perl.org/perl.git/blob/3118d7d684b56cbeb702af874f4326683c45f045:/Configure  _KNOWN_TYPES = {} |
| .venv/lib/python3.13/site-packages/numpy/_core/_dtype_ctypes.py | 28f3e56a40ec3e4b938523abe6a1705b48c9f559e36ef5b811684e6c21d81881 | 121 | 3 |      def dtype_from_ctypes_type(t):         # needed to ensure that the shape of `t` is within memoryview.format         class DummyStruct(ctypes.Structure):             _fields_ = [('a', t)] |
| .venv/lib/python3.13/site-packages/numpy/_core/defchararray.py | d6d4af2d611e69cdb40e87690c1c5aa492b0c1cce9246d65572daa8d27085578 | 1428 | 9 | """ This module contains a set of functions for vectorized string operations and methods.  |
| .venv/lib/python3.13/site-packages/numpy/_core/shape_base.py | ef20cfac85d39a606764c512b475ecab58893621a623110071ea7143da3e2554 | 999 | 1 |     # A 2D array using repeated concatenation requires 2 copies of the array.     #     # The fastest algorithm will depend on the ratio of CPU power to memory     # speed.     # One can monitor the r |
| .venv/lib/python3.13/site-packages/numpy/_core/numeric.py | fc3727bd7bbaa1a1d74a2f50f8157dc86cdfc7bb5cf620b1ebdafd3272439b98 | 2761 | 40 |     lexsort,     matmul,     may_share_memory,     min_scalar_type,     ndarray, |
| .venv/lib/python3.13/site-packages/numpy/_core/einsumfunc.py | 85e15e0a210a8e2faa7d593ccc06756f96ca9be31430bcc2113310ef2c870617 | 1499 | 33 |   def _optimal_path(input_sets, output_set, idx_dict, memory_limit):     """     Computes all possible pair contractions, sieves the results based |
| .venv/lib/python3.13/site-packages/numpy/_core/_exceptions.py | 5fc120d61ab5b94f0bf7088ec05a368d1aba4b4be78c27606051e3de1016f42a | 163 | 2 |  @_display_as_base class _ArrayMemoryError(MemoryError):     """ Thrown when an array cannot be allocated"""     def __init__(self, shape, dtype): |
| .venv/lib/python3.13/site-packages/numpy/_core/numerictypes.py | 98a3dbb0ecd7f6fc96404bf88e57f8c6794f7cfe086005de20b1c575bd854b42 | 634 | 1 |   ScalarType = [int, float, complex, bool, bytes, str, memoryview] ScalarType += sorted(set(sctypeDict.values()), key=_scalar_type_key) ScalarType = tuple(ScalarType) |
| .venv/lib/python3.13/site-packages/numpy/_core/strings.py | ca375e346d9ed30a658e99f01884a2ecd5d52c3e2db42339bc0612495d7223c9 | 1824 | 1 | """ This module contains a set of functions for vectorized string operations. """ |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_scalarmath.py | 8011c167949032bbb5039ec5504688324d7d1857552d345788ef6f561e175557 | 1177 | 2 |                 return self.arr          # Test for simple ArrayLike above and memoryviews (original report)         for arr_like in (ArrayLike(np.ones(3)), memoryview(np.ones(3))):             assert |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_array_coercion.py | 3c9decee9b27803334f38476c7b96e0075641e86b7d530e21f516266951649fb | 912 | 12 |     yield param(ArrayDunder, id="__array__")      # memory-view     yield param(memoryview, id="memoryview")  |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_unicode.py | aab43b502d329dd5c5608ecc889bbccbf2398c22b697139071e844dbcf4c1259 | 369 | 1 |             size = 4         return size * len(arr)     v = memoryview(arr)     if v.shape is None:         return len(v) * v.itemsize |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_scalarbuffer.py | da665b95a49cc2137c99d950bd450b00ab76ef707689afa68ed3662ffd94c5f4 | 154 | 12 |         x = scalar()         a = np.array([], dtype=np.dtype(scalar))         mv_x = memoryview(x)         mv_a = memoryview(a)         assert_equal(mv_x.format, mv_a.format) |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_mem_overlap.py | 206a511761a790b431122222cec553d1e594b65802709438c34f811234a94fff | 931 | 44 |  def test_overlapping_assignments():     # Test automatically generated assignments which overlap in memory.      inds = _indices(ndims) |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_shape_base.py | 9914abb98ed2f38ba56b6e59a0ebdb71183f79aff70b7df7f1ed6d99d9afd549 | 892 | 5 |     assert_raises_regex, ) from numpy.testing._private.utils import requires_memory   |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_array_interface.py | 977f55b95e2709d21e575454bccb638cfa2102022f24ff95dc643931a3eb54af | 223 | 2 |              if (!data) {                 PyErr_Format(PyExc_MemoryError,                     "Failed to malloc %lld bytes", n_bytes);  |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_records.py | 3c0307cc83e9d965839b8247150f9c8cf0567f8043b90ba6218a3b517fb31259 | 545 | 2 |             (2, 'xy', 6.6999998092651367, 1),             (0, ' ', 0.40000000596046448, 0)],                        names='c1, c2, c3, c4')         pa = np.rec.fromrecords([             (1, 'abc', 3.7 |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_mem_policy.py | a4bea404af1f82d4434df32e6c51865a79624cf5a74bae2e67d9751f9a88f219 | 453 | 3 | @pytest.fixture def get_module(tmp_path):     """ Add a memory policy that returns a false pointer 64 bytes into the     actual allocation, and fill the prefix with some text. Then check at each     m |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_simd.py | bbcc5267a1cd2c9f7eb2260d22ec9dd1103b15b0f504b1269d5e53194aedd455 | 1342 | 25 |     def _data(self, start=None, count=None, reverse=False):         """         Create list of consecutive numbers according to number of vector's lanes.         """         if start is None: |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_indexing.py | 954d233f852f11edbf314880872e3f183d73be9748c14ac7be2bb4309856ff04 | 1456 | 10 |         #assert_equal(a[:, True], a[:, None])         #         #assert_(not np.may_share_memory(a, a[True, :]))      def test_everything_returns_views(self): |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_umath.py | 0fbc125fb26f224f34ce7c1df06b31619233a7ad88b7be52073bca3991de3971 | 4917 | 3 |             for a in arrays:                 # In case of divmod, we need to flatten the result                 # column first as we get a column vector of quotient and                 # remainder and |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_numeric.py | 68cd937d3692544d9fcf46779cdef65e8c520ef67301d6adc16a4b616181070b | 4248 | 19 |         shape = (12, 2)          assert np.shares_memory(np.reshape(arr, shape), arr)         assert np.shares_memory(np.reshape(arr, shape, order="C"), arr)         assert np.shares_memory( |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test__exceptions.py | 96e313eaf3c875fe8bbb014d1b24fec4b31968a644618385cc5a4c69eb288e81 | 91 | 9 | from numpy.exceptions import AxisError  _ArrayMemoryError = np._core._exceptions._ArrayMemoryError _UFuncNoLoopError = np._core._exceptions._UFuncNoLoopError  |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_casting_unittests.py | 1c7f38f61e28c7575e8cb0786855f607db5219fd16855bcf6413c94f8c933800 | 818 | 1 |             # field cases (field to field is tested explicitly also):             # Not considered viewable, because a negative offset would allow             # may structured dtype to indirectly acce |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_ufunc.py | c8ed436d24f2a27656b33f07a1757413860de57960f9a2078bac67da04e2f76f | 3314 | 18 |     suppress_warnings, ) from numpy.testing._private.utils import requires_memory  UNARY_UFUNCS = [obj for obj in np._core.umath.__dict__.values() |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_dtype.py | 7b564b9f4c63f05ae5c4adc578738eb2843ec55d7bf8530cee687b569bae561b | 1996 | 3 | class TestStructuredDtypeSparseFields:     """Tests subarray fields which contain sparse dtypes so that     not all memory is used by the dtype work. Such dtype's should     leave the underlying memor |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_umath_accuracy.py | 4021407a23cdeab10ef1fc03c09ba7e09d6908a9b46cfb102bafb5a536023086 | 125 | 1 |   str_to_float = np.vectorize(convert)  class TestAccuracy: |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_simd_module.py | 2635c7e18abed0af91f051ea5438a735aa98fe0adbd5f4051725531c6434a418 | 104 | 4 |     def test_num_lanes(self, sfx):         nlanes = getattr(npyv, "nlanes_" + sfx)         vector = getattr(npyv, "setall_" + sfx)(1)         assert len(vector) == nlanes  |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_stringdtype.py | 411054a72837be9c040a6ce76ab9110b6593fcb4cb8a79a7fcb04e5a94317f72 | 1808 | 2 |     arr = np.array(string_list, dtype=StringDType())     # create another stringdtype array with an arena that has a different     # in-memory layout than the first array     arr_rev = np.array(string |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_strings.py | d7a84453194723cf7ef18b285bd45f23e578794f862b09c95c46a4f9d07b956f | 1455 | 12 | import numpy as np from numpy.testing import IS_PYPY, assert_array_equal, assert_raises from numpy.testing._private.utils import requires_memory  COMPARISONS = [ |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_dlpack.py | 2df8b75dddae9b12785bc7c986de5ea479585b04cac7b301e3b8bb75c388a6af | 191 | 3 |          y = np.from_dlpack(x)         assert np.may_share_memory(x, y)         y = np.from_dlpack(x, copy=False)         assert np.may_share_memory(x, y) |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_einsum.py | 4a2c73f99a202999a7173dede3dbe80fa02c0b19b1525fdcfc31f14fdaddb1c1 | 1318 | 3 |             sup.filter(np.exceptions.ComplexWarning)              # matvec(a,b) / a.dot(b) where a is matrix, b is vector             for n in range(1, 17):                 a = np.arange(4 * n, dtype= |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_api.py | 362aa5c58c8139994a54a216b3fbd04e0e999ce939884eb79dbcf51817475de2 | 622 | 8 |     assert_(hasattr(builtins, 'get'))      # test memoryview     dat = np.array(memoryview(b'1.0'), dtype=np.float64)     assert_equal(dat, [49.0, 46.0, 48.0]) |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_scalar_ctors.py | 2376a42a9e96770b131a273ca58402fdce80c4f5cf1174adcb058e1749ff8af5 | 208 | 2 |  def test_void_arraylike_trumps_byteslike():     # The memoryview is converted as an array-like of shape (18,)     # rather than a single bytes-like of that length.     m = memoryview(b"just one mintl |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_multiarray.py | 6aed8121cc571f5ad7315066e1528d0376a8809bb742d77c6c0c1ca19ce90dc3 | 10564 | 92 |     temppath, ) from numpy.testing._private.utils import _no_tracing, requires_memory   |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_nditer.py | ef2d70758ce919dc046c745ce71a69c7c159e3970ac4dae6dc92b350fbe486b1 | 3499 | 20 |     suppress_warnings, ) from numpy.testing._private.utils import requires_memory   |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_cpu_features.py | 952f622165b39ca66047cf86e00059ab39cc4c9182df8dfe1416821bd6475e64 | 433 | 1 |         else:             self.features_map = {                 # ELF auxiliary vector and /proc/cpuinfo on Linux kernel(armv8 aarch32)                 # doesn't provide information about ASIMD, so we |
| .venv/lib/python3.13/site-packages/numpy/_core/tests/test_regression.py | 7c92677ac2d15323f38826d854cf4b7cb492dea00c533d7e9b375d855f41afe5 | 2671 | 15 |     suppress_warnings, ) from numpy.testing._private.utils import _no_tracing, requires_memory   |
| .venv/lib/python3.13/site-packages/numpy/_typing/_dtype_like.py | f0ce517a42ea7617848d63089f84676e4133b12ee309ab42893d03e6183ee777 | 115 | 1 | _DTypeLikeStr: TypeAlias = type[str] \| _DTypeLike[np.str_] \| _StrCodes _DTypeLikeVoid: TypeAlias = (     type[memoryview] \| _DTypeLike[np.void] \| _VoidDTypeLike \| _VoidCodes ) _DTypeLikeObject: TypeAl |
| .venv/lib/python3.13/site-packages/numpy/_typing/_array_like.py | 10f6547c94a36a6bec589e91b39670c00ff916106961da227dc555b557163e7d | 107 | 1 |     @runtime_checkable     class _Buffer(Protocol):         def __buffer__(self, flags: int, /) -> memoryview: ...  ArrayLike: TypeAlias = _Buffer \| _DualArrayLike[dtype[Any], complex \| bytes \| str] |
| .venv/lib/python3.13/site-packages/numpy/typing/tests/data/pass/multiarray.py | 3311dac7a97de32aa54d5665780a86efb20b11b5bac14e68b0f707cf127ce67b | 77 | 4 | np.unpackbits(AR_u1)  np.shares_memory(1, 2) np.shares_memory(AR_f8, AR_f8, max_work=1)  |
| .venv/lib/python3.13/site-packages/numpy/typing/tests/data/pass/ndarray_misc.py | c016d00c772988894c97ecf94e854eac5a68c6ba9740c06ad5d15259fc0624d1 | 199 | 1 |  # this fails on numpy 2.2.1 # https://github.com/scipy/scipy/blob/a755ee77ec47a64849abe42c349936475a6c2f24/scipy/io/arff/tests/test_arffread.py#L41-L44 A_float = np.array([[1, 5], [2, 4], [np.nan, np |
| .venv/lib/python3.13/site-packages/numpy/typing/tests/data/pass/array_like.py | fb04e2c36a3facbc3569e4fb15287ad112a0ba1bf12b2aff56fe573574d8792e | 44 | 1 | x10: ArrayLike = (1, 2, 3) x11: ArrayLike = "foo" x12: ArrayLike = memoryview(b'foo')   |
| .venv/lib/python3.13/site-packages/numpy/f2py/cfuncs.py | e09e0fd76a06a725991dbd4054a025ed827741482783018c0a7075221ac99fb5 | 1564 | 3 | #define FAILNULL(p) do {                                            \\     if ((p) == NULL) {                                              \\         PyErr_SetString(PyExc_MemoryError, "NULL pointer f |
| .venv/lib/python3.13/site-packages/numpy/f2py/rules.py | 22b8fed77a0b1a8c0d1d8125155f93654b34544774350a51b27a269c8d4d4f1f | 1630 | 3 | #routdebugleave#     }     CFUNCSMESS(\"Freeing memory.\\n\"); #freemem# #ifdef F2PY_REPORT_ATEXIT |
| .venv/lib/python3.13/site-packages/numpy/f2py/tests/test_array_from_pyobj.py | 375449d3215c2ece9c1667714a38b38df2d14c485d29186b3bd571f1b706d065 | 679 | 26 |             if typ.elsize == Type(obj.dtype).elsize:                 if not intent.is_intent("copy") and self.arr_attr[1] <= 1:                     assert self.has_shared_memory()      def arr_equal(s |
| .venv/lib/python3.13/site-packages/numpy/f2py/tests/test_f2py2e.py | 686667647e5449df052691b91752fa6d67d4cee52a3fde78962b79f930cf6de1 | 965 | 1 | debug-capi:Building return value. debug-capi:Python C/API function blah.hi: successful. debug-capi:Freeing memory.         """)         assert rout.stdout == eout |
| .venv/lib/python3.13/site-packages/numpy/testing/_private/utils.py | 3d915b0314d238f150fd55cc6830a03c5052124da47041a1f06462049cbfc898 | 2760 | 18 |     def memusage(_proc_pid_stat=None):         """         Return virtual memory size in bytes of the running python.          """ |
| .venv/lib/python3.13/site-packages/numpy/lib/_polynomial_impl.py | 4d68aa946dd60daf7bb5acb1402125b590fd4cd854c85a6bccbfd499decbc6ca | 1466 | 3 |      Fit a polynomial ``p(x) = p[0] * x**deg + ... + p[deg]`` of degree `deg`     to points `(x, y)`. Returns a vector of coefficients `p` that minimises     the squared error in the order `deg`, `deg |
| .venv/lib/python3.13/site-packages/numpy/lib/recfunctions.py | 4f869ae715dabfd9ed7f0e589b33e2abf614921d76c06938d17c812d03c21335 | 1682 | 7 | def repack_fields(a, align=False, recurse=False):     """     Re-pack the fields of a structured array or dtype in memory.      The memory layout of structured datatypes allows fields at arbitrary |
| .venv/lib/python3.13/site-packages/numpy/lib/_arraysetops_impl.py | 545760a456497322616053dc4e4fcb403fd2aea5faa68cbfb21b0b2af662832d | 1261 | 23 |  Speed could be gained in some operations by an implementation of `numpy.sort`, that can provide directly the permutation vectors, thus avoiding calls to `numpy.argsort`.  |
| .venv/lib/python3.13/site-packages/numpy/lib/_stride_tricks_impl.py | cb7531a778c5cc3c26210d77ecddb36a9efebd6fe338d5109979db7eaaeceb40 | 550 | 7 |     and shape. This means it manipulates the internal data structure of     ndarray and, if done incorrectly, the array elements can point to     invalid memory and can corrupt results or crash your p |
| .venv/lib/python3.13/site-packages/numpy/lib/_arrayterator_impl.py | 1ed3800c81ee1bd0036db3138268783ff9ae91ed55fbc13e14d10eddb54e18f0 | 225 | 5 |  This module solves the problem of iterating over a big file-based array without having to read it into memory. The `Arrayterator` class wraps an array object, and when iterated it will return sub-arr |
| .venv/lib/python3.13/site-packages/numpy/lib/_histograms_impl.py | 52dbbb68041ced9a6c1e7ff4e288149d9ab565c7477e2a5cabd791abcd7ba155 | 1086 | 2 |      # We set a block size, as this allows us to iterate over chunks when     # computing histograms, to minimize memory usage.     BLOCK = 65536  |
| .venv/lib/python3.13/site-packages/numpy/lib/_arraypad_impl.py | cf9fbe5d3f344dc9c365ecc756b7716ae252637c82e2f30375dec994efa1df3c | 891 | 17 |         'maximum'             Pads with the maximum value of all or part of the             vector along each axis.         'mean'             Pads with the mean value of all or part of the |
| .venv/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py | 92e71acf00ae7e1e26370102c99c447abc6ca9afc6c50333d6462e65444323cb | 2597 | 11 |                     #   will read the string and then                     #   the format.read_array will copy the string                     #   to another place in memory.                     #   It  |
| .venv/lib/python3.13/site-packages/numpy/lib/_index_tricks_impl.py | 83b369e04f001bdb20ca2f474d482f38cd3ca489408ff72f5f0e1c73b36b5392 | 1068 | 3 |     --------     ogrid : like `mgrid` but returns open (not fleshed out) mesh grids     meshgrid: return coordinate matrices from coordinate vectors     r_ : array concatenator     :ref:`how-to-partit |
| .venv/lib/python3.13/site-packages/numpy/lib/_twodim_base_impl.py | de738bbc20fa71f33a303de8dfcd45e3c181f29a2ab1418308339094e0505e66 | 1202 | 4 |     order : {'C', 'F'}, optional         Whether the output should be stored in row-major (C-style) or         column-major (Fortran-style) order in memory.     device : str, optional         The devi |
| .venv/lib/python3.13/site-packages/numpy/lib/_format_impl.py | cdc437c57c4f7fb7a992db18adc7416c83ee38287d38f575837801ea085fe2b1 | 1037 | 10 |   documentation.  - Allows memory-mapping of the data. See `open_memmap`.  - Can be read from a filelike stream object instead of an actual file. |
| .venv/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py | 0191b2376f44730e0b46e5354cd51c3c2edc5473bdc9ee1b27d15023b9ff1b07 | 5845 | 64 |     'select', 'piecewise', 'trim_zeros', 'copy', 'iterable', 'percentile',     'diff', 'gradient', 'angle', 'unwrap', 'sort_complex', 'flip',     'rot90', 'extract', 'place', 'vectorize', 'asarray_chk |
| .venv/lib/python3.13/site-packages/numpy/lib/_nanfunctions_impl.py | 71d393edd6308ef52923d8841d3af0cdb6ed2a13fd65980e08c8ab4c17983d49 | 2025 | 5 |         but the type (of the output) will be cast if necessary.     overwrite_input : bool, optional        If True, then allow use of memory of input array `a` for        calculations. The input arra |
| .venv/lib/python3.13/site-packages/numpy/lib/_utils_impl.py | ec14ab791707348b1478c8f753519bab35632582afcae1161dd1bf0b84cce3a4 | 780 | 2 |             print(inspect.getdoc(object), file=output)          methods = pydoc.allmethods(object)          public_methods = [meth for meth in methods if meth[0] != '_'] |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_twodim_base.py | f9d8efda23f75b6b01e2b0208fd3ab97c6a51b00c57cfbdc56ee8236f94a21c8 | 560 | 1 |  class TestDiag:     def test_vector(self):         vals = (100 * arange(5)).astype('l')         b = zeros((5, 5)) |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_shape_base.py | 6561de582b3dc74b03f8bd3787a9139947511efc47542fbc28ebbc2a89a1c8a4 | 814 | 9 |   class TestMayShareMemory:     def test_basic(self):         d = np.ones((50, 60)) |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_index_tricks.py | 6e9e06163a90decfed6860d5b023a0b39614eeab4332142e3c6c2f702c63dac9 | 569 | 5 |      def test_repeated_input(self):         length_of_vector = 5         x = np.arange(length_of_vector)         out = ix_(x, x) |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test__version.py | 4b05e812a31aa7ad377368ddece36877464e550797e93fb302b31fd373821dbc | 65 | 1 |         assert_(NumpyVersion('1.8.0rc1') < ver)      for ver in ['1.8.0a2', '1.8.0b3', '1.7.2rc4']:         assert_(NumpyVersion('1.8.0rc1') > ver)  |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_io.py | f12b474dedfe5ecc8f341cb822f79fb5163565b6b62535b700b38783f6c47d1c | 2849 | 17 |     temppath, ) from numpy.testing._private.utils import requires_memory   |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_arraysetops.py | 18aa2d1546ca8047c7c9b82160fd7320cd1158ca96d696b871d62530bd6c7974 | 1075 | 1 |             b = np.asarray(b).flatten().tolist()             return a in b         isin_slow = np.vectorize(_isin_slow, otypes=[bool], excluded={1})          def assert_isin_equal(a, b): |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_function_base.py | cf64a478677da908d799ac64e9b8688b4eaa95fc5dac3cc912a46c0f122e1283 | 4574 | 76 |     unique,     unwrap,     vectorize, ) from numpy._core.numeric import normalize_axis_tuple |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_arraypad.py | 1b3a8c210d18f172d898fe68b17ce5e56d4f732c32fce2bedfd4932a809625ce | 1416 | 5 |   def test_legacy_vector_functionality():     def _padwithtens(vector, pad_width, iaxis, kwargs):         vector[:pad_width[0]] = 10 |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_packbits.py | 44492849787d1555538b3cb21d690ba9714b223b74af29d77a2c612bcfa00609 | 377 | 2 | @pytest.mark.parametrize('bitorder', ('little', 'big')) def test_packbits_large(bitorder):     # test data large enough for 16 byte vectorization     a = np.array([1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,  |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_stride_tricks.py | b4112ba69592a7c8c0724931ff337965b0217cac5927df5c390c4323d07fc61d | 657 | 5 |   def test_writeable_memoryview():     # The result of broadcast_arrays exports as a non-writeable memoryview     # because otherwise there is no good way to opt in to the new behaviour |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_recfunctions.py | c58b02fedfeda48a5626f4b5a515361cdc594ced5c277419d4e9d7b786a39b4b | 1053 | 8 |         dd = structured_to_unstructured(d)         ddd = unstructured_to_structured(dd, d.dtype)         assert_(np.shares_memory(dd, d))         assert_(np.shares_memory(ddd, d))  |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_nanfunctions.py | d461ad3d40fc6d2e6fd85c4bafc7b4054831f64e88bbef162d98ac6b03d8e18c | 1439 | 1 |  def test_memmap_takes_fast_route(tmpdir):     # We want memory mapped arrays to take the fast route through nanmax,     # which avoids creating a mask by using fmax.reduce (see gh-28721). So we     # |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_format.py | 05329dda552875df203739d6921fc7977986f0cbbc48e1400c4a86779902c3ae | 1055 | 3 |     assert_warns, ) from numpy.testing._private.utils import requires_memory  # Generate some basic arrays to test with. |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_histograms.py | 424700e3a949d58f93ddfe3e427ee49fa27d6c889ddd12caecd28cad4237469c | 856 | 2 |             histogram(arr, bins=10)      # @requires_memory(free_bytes=1e10)     # @pytest.mark.slow     @pytest.mark.skip(reason="Bad memory reports lead to OOM in ci testing") |
| .venv/lib/python3.13/site-packages/numpy/lib/tests/test_regression.py | 51446d9adc1faf1303177518d5930d6e020939adfc8d4cd82829a96180fc7b74 | 232 | 4 |         assert_array_equal([], np.unique(np.array([])))      def test_mem_vectorise(self):         # Ticket #325         vt = np.vectorize(lambda *args: args) |
| .venv/lib/python3.13/site-packages/numpy/doc/ufuncs.py | f71b7c1f7e0686b5eb16af5c585506bc915e3daf58b87f53ab50f30279b61361 | 139 | 1 | or otherwise corrupted in the downcast to the lower type. This usage is useful when one wants to avoid creating large temporary arrays and instead allows one to reuse the same array memory repeatedly  |
| .venv/lib/python3.13/site-packages/numpy/random/tests/test_generator_mt19937.py | 5f4004ce2df1cba173c93a5364d4ff957c974bf2d639615873d9d9e90b6420b4 | 2805 | 3 |         "seed": 384908324,         "steps": 312,         "initial": {"key_sha256": "16b791a1e04886ccbbb4d448d6ff791267dc458ae599475d08d5cced29d11614", "pos": 311},  # noqa: E501         "jumped":  {"k |
| .venv/lib/python3.13/site-packages/numpy/random/tests/test_randomstate.py | 59b641a59a6506582685629736c8fb774670d011c9da7c447ab3119eec326271 | 2131 | 7 |                        'geometric':         '0d764db64f5c3bad48c8c33551c13b4d07a1e7b470f77629bef6c985cac76fcf',  # noqa: E501                        'hypergeometric':    '7b59bf2f1691626c5815cdcd9a49e |
| .venv/lib/python3.13/site-packages/numpy/random/tests/test_smoke.py | 7a9914178ec76a7692655cfd35552deb152629984936894f201fb3e0c37aed0c | 820 | 11 |         cls.rg = Generator(cls.bit_generator(*cls.seed))         cls.initial_state = cls.rg.bit_generator.state         cls.seed_vector_bits = 64         cls._extra_setup()  |
| .venv/lib/python3.13/site-packages/numpy/random/tests/test_random.py | 6129474f0bbab7b0408c32d9ac1cf87bcfb29d2b95e9e3873fd370c43a1906f5 | 1758 | 3 |         # in the range [0, 6) for all but bool, where the range         # is [0, 2). Hashes are for little endian numbers.         tgt = {'bool':   '509aea74d792fb931784c4b0135392c65aec64beee12b0cc167 |
| .venv/lib/python3.13/site-packages/numpy/random/_examples/numba/extending_distributions.py | 7dd78f5de523e3ac972b430ad5cb33c541d088e4e236e36cadb66a3f0e00746b | 68 | 1 | normalsj = nb.jit(normals, nopython=True)  # Numba requires a memory address for void * # Can also get address from x.ctypes.bit_generator.value bit_generator_address = int(ffi.cast('uintptr_t', bit_g |
| .venv/lib/python3.13/site-packages/numpy/matrixlib/defmatrix.py | c29c3a95953d5faaa9f30009a240d7b76441acbd5e5ea96606dfa88c8c18ce55 | 1120 | 7 |     def __mul__(self, other):         if isinstance(other, (N.ndarray, list, tuple)):             # This promotes 1-D vectors to row vectors             return N.dot(self, asmatrix(other))         if  |
| .venv/lib/python3.13/site-packages/numpy/matrixlib/tests/test_defmatrix.py | 1bdbf8f9c1ae01b1d5543089dab0949d0ad24d40a13a287fe99315f99958b0d0 | 456 | 6 |         assert_equal(x.T.ravel(order='A'), [[1, 2, 3, 4, 5, 6]])      def test_array_memory_sharing(self):         assert_(np.may_share_memory(self.a, self.a.ravel()))         assert_(not np.may_share |
| .venv/lib/python3.13/site-packages/numpy/matrixlib/tests/test_regression.py | 5e77d9e11a134b8f57314c9494754c73ac1c58898d4636bb0d3d704dd124e36f | 32 | 1 |         assert_(type(d) is np.ndarray)      def test_matrix_multiply_by_1d_vector(self):         # Ticket #473         def mul(): |
| .venv/lib/python3.13/site-packages/numpy/polynomial/polyutils.py | 99011ade80b3f57f9dd4768d757929049cd7586ce0638d960cc8c93a7f7cf0ef | 760 | 3 |         raise ValueError("expected deg >= 0")     if x.ndim != 1:         raise TypeError("expected 1D vector for x")     if x.size == 0:         raise TypeError("expected non-empty vector for x") |
| .venv/lib/python3.13/site-packages/numpy/polynomial/tests/test_classes.py | 9c1b151dcb9b85ea35b3bb7e8d45d8f7ce29b42db1f9a5833e45840f571466de | 619 | 12 |     p3 = Poly(c3)     p4 = p1 * p2 + p3     c4 = list(p4.coef)     assert_poly_almost_equal(p4 // p2, p1)     assert_poly_almost_equal(p4 // c2, p1) |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/roboflow.json | 8c6e716dd99dec7afe6fcb845bb5a70c569a518784d1781b738cfa1cc7ad505b | 23 | 4 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Roboflow Embedding Function Schema",   "description": "Schema for the roboflow embedding function configuration",   "version": "1. |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/transformers.json | 514c5ac55a0e630218864221bcf02f1147bd5bbb18a8d26f3069ba6d6efa3870 | 28 | 2 | {     "$schema": "http://json-schema.org/draft-07/schema#",     "title": "Transformers Embedding Function Schema",     "description": "Schema for the Transformers embedding function configuration",    |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/openai.json | 48df2b9093a4738f5ef9ec006c1c5793ed148e4043ffa9ecc75a82a71fb1f806 | 72 | 4 | {     "$schema": "http://json-schema.org/draft-07/schema#",     "title": "OpenAI Embedding Function Schema",     "description": "Schema for the OpenAI embedding function configuration",     "version": |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/google_palm.json | f0e69382245a652f1c1483a25e944cae084de22c0843ec78adc2b0c0f8b7a4ab | 23 | 3 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Google PaLM Embedding Function Schema",   "description": "Schema for the Google PaLM embedding function configuration",   "version |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/jina.json | 92677527f5a7ca59f1a67a232d24a66f3b2f70cd61e0cf8b2c1e3e172062bc5c | 47 | 12 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Jina Embedding Function Schema",   "description": "Schema for the jina embedding function configuration",   "version": "1.0.0", |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/text2vec.json | d6a96415e1a2ad0798740e68418f58e9bd710cf4a189616a961269da85b503e4 | 18 | 3 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Text2vec Embedding Function Schema",   "description": "Schema for the text2vec embedding function configuration",   "version": "1. |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/morph.json | b0067ccab6f8fa7c6a5aae3b12ff8102106ecf9070f5ac558f2f11db7c05352f | 36 | 4 | {     "$schema": "http://json-schema.org/draft-07/schema#",     "title": "Morph Embedding Function Schema",     "description": "Schema for the Morph embedding function configuration",     "version": " |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/google_generative_ai.json | d631d9ecb0dc912b45d00666c51e6b7c8352856c7c104393d404ee83d3d6330a | 28 | 4 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Google Generative AI Embedding Function Schema",   "description": "Schema for the Google Generative AI embedding function configur |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/huggingface.json | a27aa319b0c6ae4ae51e42e77acbc88e430c3b6509fd1d501eda16d9197802e5 | 23 | 3 | {     "$schema": "http://json-schema.org/draft-07/schema#",     "title": "HuggingFace Embedding Function Schema",     "description": "Schema for the HuggingFace embedding function configuration",      |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/google_vertex.json | d198d0d0d953debbd063405ffe5f747329330cd2dcfe547a9f602c662955a1ea | 33 | 3 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Google Vertex Embedding Function Schema",   "description": "Schema for the Google Vertex embedding function configuration",   "ver |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/onnx_mini_lm_l6_v2.json | c6e0ff014832c6b98c26f78a2ef0d0d2d031c37efaee495bc2b18716132f7024 | 19 | 3 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Onnx_mini_lm_l6_v2 Embedding Function Schema",   "description": "Schema for the onnx_mini_lm_l6_v2 embedding function configuratio |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/ollama.json | f395788dadd5dfe31db4b4a733bbeb9d1425a53bb7a1b6b6200ca4c12143f55a | 27 | 3 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Ollama Embedding Function Schema",   "description": "Schema for the Ollama embedding function configuration",   "version": "1.0.0" |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/cloudflare_workers_ai.json | 294ab220679d28a0f3b1ce6b924ca3fc36ab953821163939a2dcf141e41d30c2 | 32 | 3 | {     "$schema": "http://json-schema.org/draft-07/schema#",     "title": "Cloudflare Workers AI Embedding Function Schema",     "description": "Schema for the Cloudflare Workers AI embedding function  |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/mistral.json | 1f2c9a9497f29706338f144e72e6f7f49422b3eb6e8ac81fc92d603c6e747c64 | 22 | 4 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Mistral Embedding Function Schema",   "description": "Schema for the Mistral embedding function configuration",   "version": "1.0. |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/instructor.json | d9744a7eaa36900cb290d98fb321f808f6a1199ea88b12910a26fee13edb792c | 27 | 5 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Instructor Embedding Function Schema",   "description": "Schema for the instructor embedding function configuration",   "version": |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/README.md | 803f97695464b35b40f0b9c15434bf9fafbcc39949ad76d704a7884ac0af5551 | 57 | 11 | # Embedding Function Schemas  This directory contains JSON schemas for all embedding functions in Chroma. The purpose of having these schemas is to support cross-language compatibility and to validate |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/cohere.json | 238c36677f646319a95b0d5aaf1eaa70cdabec7a728a935cccdc402362979180 | 23 | 3 | {     "$schema": "http://json-schema.org/draft-07/schema#",     "title": "Cohere Embedding Function Schema",     "description": "Schema for the Cohere embedding function configuration",     "version": |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/together_ai.json | b091dc1ff43c527bc6917b9eab78c312d3b63017bf2ab612ac77ea0e01b24574 | 23 | 3 | {     "$schema": "http://json-schema.org/draft-07/schema#",     "title": "Together AI Embedding Function Schema",     "description": "Schema for the Together AI embedding function configuration",      |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/base_schema.json | 2ec701223879976953f38742506a88f6bc755fd81b8c9b1e255bba64d1cc5d6d | 27 | 5 | {     "$schema": "http://json-schema.org/draft-07/schema#",     "title": "Embedding Function Base Schema",     "description": "Base schema for all embedding functions in Chroma",     "type": "object", |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/sentence_transformer.json | 19022e4da4dc6ef0b0ca89dbd232b2e5bd3d46947a2e8f5bf0301fd655b64971 | 42 | 5 | {     "$schema": "http://json-schema.org/draft-07/schema#",     "title": "SentenceTransformer Embedding Function Schema",     "description": "Schema for the SentenceTransformer embedding function conf |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/huggingface_server.json | 0d22c4f0968932ef25f2d6bb9e13ca7196f6714e6d4dfc5e7eae274f02d9ab64 | 22 | 3 | {     "$schema": "http://json-schema.org/draft-07/schema#",     "title": "HuggingFace Embedding Server Schema",     "description": "Schema for the HuggingFace embedding server configuration",     "ver |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/open_clip.json | 0ac085a19ca2bd11559c8e98b89de761973539e42f903273dfff064271c29e9d | 28 | 5 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Open_clip Embedding Function Schema",   "description": "Schema for the open_clip embedding function configuration",   "version": " |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/chroma_langchain.json | daf452884c8c4198f5d6f29beb91d5da9cec6d1baf53bb4b493026d7489e0b8b | 18 | 6 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Langchain Embedding Function Schema",   "description": "Schema for the langchain embedding function configuration",   "version": " |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/amazon_bedrock.json | 241a23f324f84e1885f690dd49929410a4058d96c77e5818baebff6528123cf8 | 28 | 3 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Amazon Bedrock Embedding Function Schema",   "description": "Schema for the Amazon Bedrock embedding function configuration",   "v |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/voyageai.json | 2e6e9f6fe4b300576bad5ca0c14a00819c8e4bac78219041c0045ca595e63653 | 31 | 6 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Voyageai Embedding Function Schema",   "description": "Schema for the voyageai embedding function configuration",   "version": "1. |
| .venv/lib/python3.13/site-packages/schemas/embedding_functions/default.json | 2605b15ffd58750a7096806353bae96949a7baed118e461b91ac48fa36fb8746 | 11 | 2 | {   "$schema": "http://json-schema.org/draft-07/schema#",   "title": "Default Embedding Function Schema",   "description": "Schema for the default embedding function configuration",   "version": "1.0. |
| .venv/lib/python3.13/site-packages/PIL/PngImagePlugin.py | 8cf04da99e74b71147588b038a471d91e7817cb358d4fc53e70cdc3cc7267264 | 1552 | 12 | See :ref:`Text in PNG File Format<png-text>`. """ MAX_TEXT_MEMORY = 64 * MAX_TEXT_CHUNK """ Set the maximum total text chunk size. |
| .venv/lib/python3.13/site-packages/PIL/ImageFile.py | 1cb80aaa7e8af49e07967ca23c56544c07dcab15d88c4d3a7d978a3ba57e85ac | 923 | 7 | # 1997-01-11 fl   Use encode_to_file where possible # 1997-08-27 fl   Flush output in _save # 1998-03-05 fl   Use memory mapping for some modes # 1999-02-04 fl   Use memory mapping also for "I;16" and |
| .venv/lib/python3.13/site-packages/PIL/ImageColor.py | 20603d0b6ba67840ff1334b60af8fa2ac53456eb42f51b2d58860f7bcb83b159 | 321 | 4 |     "azure": "#f0ffff",     "beige": "#f5f5dc",     "bisque": "#ffe4c4",     "black": "#000000",     "blanchedalmond": "#ffebcd", |
| .venv/lib/python3.13/site-packages/PIL/GifImagePlugin.py | 4a45dba19c314e896ad2eb5e5d85f49dcad9894c72012cb0a80bab39c5408b75 | 1214 | 1 |  # Force optimization so that we can test performance against # cases where it took lots of memory and time previously. _FORCE_OPTIMIZE = False  |
| .venv/lib/python3.13/site-packages/PIL/ExifTags.py | cd6ea4562902a2c8b2a02a3b27b47ad9ebc3de1a318ca3dc867561f29a3b0997 | 383 | 1 |     CompositeImageExposureTimes = 0xA462     Gamma = 0xA500     PrintImageMatching = 0xC4A5     DNGVersion = 0xC612     DNGBackwardVersion = 0xC613 |
| .venv/lib/python3.13/site-packages/PIL/ImageCms.py | 0396556938e3c51e8078334dbcafa19aed10a8a38c4ec728bba0540532e86f48 | 1124 | 5 |     """Don't fix scum dot"""     HIGHRESPRECALC = 0x0400     """Use more memory to give better accuracy"""     LOWRESPRECALC = 0x0800     """Use less memory to minimize resources""" |
| .venv/lib/python3.13/site-packages/PIL/ImageDraw.py | 127af472d0472819d21d504396a7086c80321e0563e596cb2feb3055bf2cf15a | 1233 | 1 |     edge = {(x, y)}     # use a set to keep record of current and previous edge pixels     # to reduce memory consumption     full_edge = set()     while edge: |
| .venv/lib/python3.13/site-packages/PIL/ImageWin.py | 2d3d39c3cfef4df46b0b79fd4bda4cd1335b5ebcd92c424794226297b5eff349 | 248 | 2 |     def frombytes(self, buffer: bytes) -> None:         """         Load display memory contents from byte data.          :param buffer: A buffer containing display data (usually |
| .venv/lib/python3.13/site-packages/PIL/EpsImagePlugin.py | 44e5b00afd3c6c2fc1e3578c7f60057bc516e991f8fd7435f31d76281fda40b3 | 477 | 1 |          byte_arr = bytearray(255)         bytes_mv = memoryview(byte_arr)         bytes_read = 0         reading_header_comments = True |
| .venv/lib/python3.13/site-packages/PIL/ImageTk.py | 6f94a7b5c9065ecd040ac2363267498370925fa02d10bb168743a1c6ee35bbf9 | 267 | 1 |  def getimage(photo: PhotoImage) -> Image.Image:     """Copies the contents of a PhotoImage to a PIL image memory."""     im = Image.new("RGBA", (photo.width(), photo.height()))  |
| .venv/lib/python3.13/site-packages/PIL/TiffImagePlugin.py | 20aed4af5df534dc89113fb0939d2dccb912c9ded32359704844b837fb71cb9c | 2340 | 3 |         args = self.tile[0][3]          # To be nice on memory footprint, if there's a         # file descriptor, use that instead of reading         # into a string in python. |
| .venv/lib/python3.13/site-packages/PIL/McIdasImagePlugin.py | 6da388903f822087828011537fc928b3ddbc3ca06e094a9861adfcbb75844bff | 79 | 1 |             mode = rawmode = "I;16B"         elif w[11] == 4:             # FIXME: add memory map support             mode = "I"             rawmode = "I;32B" |
| .venv/lib/python3.13/site-packages/PIL/DdsImagePlugin.py | 7e375f64afde42d529ffe6e3a119adfb9c20393e464e6be0e9a23e8ad721e26a | 625 | 12 |     BC3_UNORM = 77     BC3_UNORM_SRGB = 78     BC4_TYPELESS = 79     BC4_UNORM = 80     BC4_SNORM = 81 |
| .venv/lib/python3.13/site-packages/PIL/Image.py | f7925e7e2d901487d960ec9f1cd0514f006dc2b9cd66c9f9a02b0b42c04b74af | 4246 | 12 | ]  # raw modes that may be memory mapped.  NOTE: if you change this, you # may have to modify the stride calculation in map.c too! _MAPMODES = ("L", "P", "RGBX", "RGBA", "CMYK", "I;16", "I;16L", "I;16 |
| .venv/lib/python3.13/site-packages/PIL/ImImagePlugin.py | c28e4e2f63c07105b63304642674be375eada19cd758bf798f1f4504cee5f689 | 390 | 1 | class ImImageFile(ImageFile.ImageFile):     format = "IM"     format_description = "IFUNC Image Memory"     _close_exclusive_fp_after_loading = False  |
| .venv/lib/python3.13/site-packages/PIL/JpegImagePlugin.py | 59a0994e9766cee08ce668b8e1b372378a751173ac9cacfadeabf85c46e6f0db | 903 | 1 |     0xFFC2: ("SOF2", "Progressive DCT", SOF),     0xFFC3: ("SOF3", "Spatial lossless", SOF),     0xFFC4: ("DHT", "Define Huffman table", Skip),     0xFFC5: ("SOF5", "Differential sequential DCT", SOF) |
| .venv/lib/python3.13/site-packages/PIL/ImageFont.py | ad5426df3c274c56751d2a7839e0394c72a34dece113c1ccae73a11f39aa7c43 | 1340 | 17 |                      .. versionadded:: 1.1.5          :return: An internal PIL storage memory instance as defined by the                  :py:mod:`PIL.Image.core` interface module.         """ |
| .venv/lib/python3.13/site-packages/requests/models.py | 32365d67893bb67c3ed67cf93ca4a18e63e6ab29342fa0dc8b09c59e06ff564e | 1040 | 3 |     def iter_content(self, chunk_size=1, decode_unicode=False):         """Iterates over the response data.  When stream=True is set on the         request, this avoids reading the content at once int |
| .venv/lib/python3.13/site-packages/requests/api.py | fd96fd39aeedcd5222cd32b016b3e30c463d7a3b66fce9d2444467003c46b10b | 158 | 1 |     # By using the 'with' statement we are sure the session is closed, thus we     # avoid leaving sockets open which can trigger a ResourceWarning in some     # cases, and look like a memory leak in  |
| .venv/lib/python3.13/site-packages/requests/utils.py | 5aa53ceab677c2f842fad42359c8ed1ff1c4299c1607789609957a496e4311d4 | 1087 | 5 |      if "application/json" in content_type:         # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset         return "utf-8"  |
| .venv/lib/python3.13/site-packages/safety/output_utils.py | b0973d8fdb25854d36c51264d4419b719689c3746755fddb2b9ce1cdd1a66795 | 1298 | 4 |             b = cve.cvssv2.get("base_score", "-")             s = cve.cvssv2.get("impact_score", "-")             v = cve.cvssv2.get("vector_string", "-")              cvssv2_line = {'words': [ |
| .venv/lib/python3.13/site-packages/safety/meta.py | 372a5310dbd3e58b2215a0d6a72d6b840eadb0e698c8d2bf58cd9ccab1defabb | 85 | 5 |   def get_user_agent() -> str:     """     Get the user agent string for HTTP requests. |
| .venv/lib/python3.13/site-packages/safety/init/constants.py | 4af8ffaca0cc5494591803fbdac86b8f0e4669f6f92d5e8e4a18fc04b2023eda | 128 | 1 | # Welcome Section MSG_WELCOME_TITLE = (     "\n\nWelcome to Safety, the AI-powered Software Supply Chain Firewall.\n\n" ) MSG_WELCOME_DESCRIPTION = [ |
| .venv/lib/python3.13/site-packages/safety/formatters/schemas/zero_five.py | 3d388da377eab60ae50a5b6445beda9643475578e8687573844112b5c675830e | 96 | 6 |         base_score (fields_.Int): Base score of the CVSSv2.         impact_score (fields_.Int): Impact score of the CVSSv2.         vector_string (fields_.Str): Vector string of the CVSSv2.     """  |
| .venv/lib/python3.13/site-packages/safety/scan/fun_mode/easter_eggs.py | d9376b5061c62f67cdecf02d174d63db5ab7d08b3558eb9ad2cd345ba609ab43 | 285 | 1 |             console.print(                 "It's a tie! Both reached the finish line at the same time!",                 style="bold magenta",             )             break |
| .venv/lib/python3.13/site-packages/safety/scan/fun_mode/celebration_effects.py | 9e5af3931b05998a644959f1865713ae2b3ffba5a0f01be104fc342e765b2edb | 228 | 4 |             y = random.randint(0, max(0, height - 2))             char = random.choice(chars)             color = random.choice(["red", "green", "yellow", "blue", "magenta", "cyan"])             conso |
| .venv/lib/python3.13/site-packages/safety/events/handlers/common.py | c8eb3113bc2b6817cf0d7a82b36d88b5e27875d38242dbaed136f2d7681094e1 | 334 | 6 | class SecurityEventsHandler(EventHandler[SecurityEventTypes]):     """     Handler that collects events in memory and flushes them when requested.     """  |
| .venv/lib/python3.13/site-packages/safety/tool/constants.py | b6e52e1042674ece8f211e10857aed3ff54f9414d538d3b59ef249d475aa11e6 | 1013 | 2 |     "azure-mgmt-policyinsights",     "azure-mgmt-nspkg",     "google-cloud-orchestration-airflow",     "apache-airflow-providers-cncf-kubernetes",     "azure-mgmt-batchai", |
| .venv/lib/python3.13/site-packages/safety/tool/interceptors/base.py | 51b6e2abde194c02c5bc316fee00a64d12cf203b6a4f7b12d05f9cd53a09979f | 91 | 1 |                                  objects.     Note:         All method implementations should be idempotent.     """  |
| .venv/lib/python3.13/site-packages/termcolor/termcolor.py | 073c8789f62859b92c5c517bc988dd81615282e19290004d35eb1f4a5ac74111 | 216 | 8 |     "on_yellow": 43,     "on_blue": 44,     "on_magenta": 45,     "on_cyan": 46,     "on_light_grey": 47, |
| .venv/lib/python3.13/site-packages/termcolor/__main__.py | def2ea0de65d7b2351586a4d152a15bfbfb3485797e7d4012a345008b14c7472 | 87 | 13 |     cprint("Yellow color", "yellow")     cprint("Blue color", "blue")     cprint("Magenta color", "magenta")     cprint("Cyan color", "cyan")     cprint("White color", "white") |
| .venv/lib/python3.13/site-packages/anyio/__init__.py | cf72325a0590bb10a2f8a53099afb52d2cace16079d2657637c16f4bdfc878f1 | 109 | 2 | from ._core._sockets import wait_socket_writable as wait_socket_writable from ._core._sockets import wait_writable as wait_writable from ._core._streams import create_memory_object_stream as create_me |
| .venv/lib/python3.13/site-packages/anyio/abc/_streams.py | d34e462920971a9af19e1b9c20b6e84aa736245a2f102664f66de9faaab15d57 | 240 | 2 |          You should not try to send any further data to this stream after calling this         method. This method is idempotent (does nothing on successive calls).         """  |
| .venv/lib/python3.13/site-packages/anyio/_backends/_trio.py | b51183b68b3ac66aa61a5b2d7c8f301231af859ab4cbf4984da3369bccdab515 | 1376 | 6 | ) from .._core._sockets import convert_ipv6_sockaddr from .._core._streams import create_memory_object_stream from .._core._synchronization import (     CapacityLimiter as BaseCapacityLimiter, |
| .venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py | 617a502740beb4d898bd97449556b7cc67e51bf25dbdfec5343886f7e4c784c8 | 2947 | 8 | ) from .._core._sockets import convert_ipv6_sockaddr from .._core._streams import create_memory_object_stream from .._core._synchronization import (     CapacityLimiter as BaseCapacityLimiter, |
| .venv/lib/python3.13/site-packages/anyio/_core/_streams.py | 3a768a8280c3f8570c4b02ef92801418fe75b06d99751bcca71b7dab6c358180 | 53 | 16 | from warnings import warn  from ..streams.memory import (     MemoryObjectReceiveStream,     MemoryObjectSendStream, |
| .venv/lib/python3.13/site-packages/anyio/_core/_tempfile.py | 9476fb096e05c8896991fe400c07f85662c708ac041c5f67c6a3720421455220 | 617 | 1 | class SpooledTemporaryFile(AsyncFile[AnyStr]):     """     An asynchronous spooled temporary file that starts in memory and is spooled to disk.      This class provides an asynchronous interface to a  |
| .venv/lib/python3.13/site-packages/anyio/_core/_asyncio_selector_thread.py | d8f77114cddcb34d8aa7a052a696ef9914fbabb6acade4d6e45801c44b1f941a | 168 | 1 |         self._send.setblocking(False)         self._receive.setblocking(False)         # This somewhat reduces the amount of memory wasted queueing up data         # for wakeups. With these settings,  |
| .venv/lib/python3.13/site-packages/anyio/streams/memory.py | 19c6c5ddc6a176c74566d71365a20aa595cf0d92a8823d7cc163cf984d0e9865 | 320 | 24 |   class MemoryObjectStreamStatistics(NamedTuple):     current_buffer_used: int  #: number of items stored in the buffer     #: maximum number of items that can be stored on this stream (or :data:`math |
| .venv/lib/python3.13/site-packages/anyio/streams/tls.py | b2249a691c97f979df0bb25b9fd563b48755cc9903b2f216ff6a5211585e0c54 | 418 | 4 |     standard_compatible: bool     _ssl_object: ssl.SSLObject     _read_bio: ssl.MemoryBIO     _write_bio: ssl.MemoryBIO  |
| .venv/lib/python3.13/site-packages/pip/_internal/configuration.py | 068990de90bce09eb30970d0a4d0ff3a6158ee6b9b13d70c05956884d53332f6 | 398 | 1 |      def save(self) -> None:         """Save the current in-memory state."""         self._ensure_have_load_only()  |
| .venv/lib/python3.13/site-packages/pip/_internal/exceptions.py | 6d14c49fa265c3ebf11e38b1b62bb42bbf635c9bb45f91550b42fad8175bd0a2 | 882 | 2 |                 self.note_stmt,                 console,                 prefix="[magenta bold]note[/]: ",                 indent="      ",             ) |
| .venv/lib/python3.13/site-packages/pip/_internal/wheel_builder.py | 3c3176c3aa7179e739b243f780b22b47f56b26b00ee291d1a549e435b27c4794 | 335 | 1 | """Orchestrator for building wheels from InstallRequirements."""  from __future__ import annotations |
| .venv/lib/python3.13/site-packages/pip/_internal/network/session.py | 784f9550824653d61e79a572eed540bcc4568a032ccae00ca7192395ba6d6e3a | 529 | 7 |  @functools.lru_cache(maxsize=1) def user_agent() -> str:     """     Return a string representing the user agent. |
| .venv/lib/python3.13/site-packages/pip/_internal/network/lazy_wheel.py | e47effb3efc02ba6ebd4ae4d15cc94b22a1c2bd13abf0ac9639933c2332fd043 | 214 | 2 | from pip._vendor.requests.models import CONTENT_CHUNK_SIZE, Response  from pip._internal.metadata import BaseDistribution, MemoryWheel, get_wheel_distribution from pip._internal.network.session import |
| .venv/lib/python3.13/site-packages/pip/_internal/utils/subprocess.py | af8f816bf61cdee6574298b42b8a5916c093fd0a9d4afb45dd727edb4e1059a0 | 249 | 2 |                 subprocess_logger.error("%s", error, extra={"rich": True})                 subprocess_logger.verbose(                     "[bold magenta]full command[/]: [blue]%s[/]",                  |
| .venv/lib/python3.13/site-packages/pip/_internal/utils/compatibility_tags.py | 0e23522eaa6eaee5d46a6190c0e2765990720c62d319a5e2f4ef977fc7ce8b7e | 202 | 1 |  def _android_platforms(arch: str) -> list[str]:     match = re.fullmatch(r"android_(\d+)_(.+)", arch)     if match:         api_level, abi = match.groups() |
| .venv/lib/python3.13/site-packages/pip/_internal/utils/unpacking.py | e2d6360feb1bb41b762dcc2cf7c126dcc3c03dd1e75d20579e9494d0ba065194 | 338 | 1 |                 ensure_dir(dir)                 # Don't use read() to avoid allocating an arbitrarily large                 # chunk of memory for the file's content                 fp = zip.open(name) |
| .venv/lib/python3.13/site-packages/pip/_internal/req/req_install.py | 3782f157d2c78a68257b9cc490d164f5649f8b9d4a5ef2bdcbbde6bd897dba28 | 938 | 1 |                 location = display_path(self.satisfied_by.location)             else:                 location = "<memory>"             s += f" in {location}"         if self.comes_from: |
| .venv/lib/python3.13/site-packages/pip/_internal/req/req_uninstall.py | 74298e1edfbd45a241abddb52f8b4c1f73e62010deb46a659db8d1297986b74d | 640 | 2 | from typing import Any, Callable  from pip._internal.exceptions import LegacyDistutilsInstall, UninstallMissingRecord from pip._internal.locations import get_bin_prefix, get_bin_user from pip._interna |
| .venv/lib/python3.13/site-packages/pip/_internal/req/constructors.py | 4252e3048839c4fc72431fe118607b173e76eebb805c2ea76d532819f5f33673 | 563 | 1 |     are given).     """     match: re.Match[str] \| None = re.fullmatch(         # see https://peps.python.org/pep-0508/#complete-grammar         r"([\w\t .-]+)(\[[^\]]*\])?(.*)", |
| .venv/lib/python3.13/site-packages/pip/_internal/locations/__init__.py | d920035f41abf41229c75f403bb15eabcf673a60501846e5d485a30699da13d1 | 442 | 1 | if not _USE_SYSCONFIG:     # Import distutils lazily to avoid deprecation warnings,     # but import it soon enough that it is in memory and available during     # a pip reinstall.     from . import _ |
| .venv/lib/python3.13/site-packages/pip/_internal/metadata/__init__.py | 6b5f41d3422c5f6e64841b7ca165b2ebf90a82308ce337a1f85a98b5e08e1700 | 165 | 2 | from pip._internal.utils.misc import strtobool  from .base import BaseDistribution, BaseEnvironment, FilesystemWheel, MemoryWheel, Wheel  __all__ = [ |
| .venv/lib/python3.13/site-packages/pip/_internal/metadata/pkg_resources.py | 34eefa66b7d1dbe2ca253c9a5eb990a0686624c02b00bbda72b9591d58920d3f | 299 | 3 |   class InMemoryMetadata:     """IMetadataProvider that reads metadata files from a dictionary.  |
| .venv/lib/python3.13/site-packages/pip/_internal/metadata/base.py | 046b8c7a795c413f22ee3f62725adf742def4b082f86bf208e7f79e5c0b2d7ab | 686 | 3 |         A string value is not necessarily a filesystem path, since distributions         can be loaded from other sources, e.g. arbitrary zip archives. ``None``         means the distribution is creat |
| .venv/lib/python3.13/site-packages/pip/_internal/metadata/importlib/_dists.py | 68e520097fc0b40f01fa558bbbe1df5c0fa2bcc2563711cf028855729423da0e | 224 | 2 |      This implementation eagerly reads the entire metadata directory into the     memory instead, and operates from that.     """  |
| .venv/lib/python3.13/site-packages/pip/_internal/distributions/wheel.py | fc76c6d0e7a117c7708f8517fb157ffed5cbc203eeb3d3a33047f635346a05b1 | 45 | 1 |      def get_metadata_distribution(self) -> BaseDistribution:         """Loads the metadata from the wheel file into memory and returns a         Distribution that uses it, not relying on the wheel fi |
| .venv/lib/python3.13/site-packages/pip/_vendor/packaging/version.py | a221eacd352ffe9d768698e0b0b0d571a179853ee90da48e56250d303e064d6d | 583 | 1 | A string containing the regular expression used to match a valid version.  The pattern is not anchored at either end, and is intended for embedding in larger expressions (for example, matching a versi |
| .venv/lib/python3.13/site-packages/pip/_vendor/packaging/licenses/_spdx.py | a009b5ced3c5c25b2608a7bb94002cbff38839f4b57160eef5b34191ebbeda7b | 760 | 2 |     'adobe-glyph': {'id': 'Adobe-Glyph', 'deprecated': False},     'adobe-utopia': {'id': 'Adobe-Utopia', 'deprecated': False},     'adsl': {'id': 'ADSL', 'deprecated': False},     'afl-1.1': {'id': ' |
| .venv/lib/python3.13/site-packages/pip/_vendor/truststore/_api.py | 69ff201191bfbe1b2e7626bdbf3e1eb37561f3102a873433e026e3b3afebc6eb | 334 | 2 |     def wrap_bio(         self,         incoming: ssl.MemoryBIO,         outgoing: ssl.MemoryBIO,         server_side: bool = False, |
| .venv/lib/python3.13/site-packages/pip/_vendor/truststore/_macos.py | 9d994b90e9accd413483aaf2470055198e423b33f2b9d72c889b4359aacce4b4 | 572 | 6 |     CoreFoundation.CFStringCreateWithCString.restype = CFStringRef      CoreFoundation.CFStringGetCStringPtr.argtypes = [CFStringRef, CFStringEncoding]     CoreFoundation.CFStringGetCStringPtr.restype |
| .venv/lib/python3.13/site-packages/pip/_vendor/truststore/__init__.py | db04525628e34733cb5575335aabdd64b36c10e8437e8a4a2ddd8428060bc0a5 | 37 | 1 |         raise ImportError("truststore requires the 'ssl' module")     else:         _sslmem = _ssl.MemoryBIO()         _sslobj = _ssl.create_default_context().wrap_bio(             _sslmem, |
| .venv/lib/python3.13/site-packages/pip/_vendor/truststore/_windows.py | ac01f22980fc33bb7e6d77c6f1580e55add3a5f85585bb78ad94253b8e58b8ff | 568 | 7 | X509_ASN_ENCODING = 0x00000001 PKCS_7_ASN_ENCODING = 0x00010000 CERT_STORE_PROV_MEMORY = b"Memory" CERT_STORE_ADD_USE_EXISTING = 2 USAGE_MATCH_TYPE_OR = 1 |
| .venv/lib/python3.13/site-packages/pip/_vendor/msgpack/fallback.py | d20d4fce9d2fb66044989e70f45decffe24c55444ff114b81b571ce5345a02c2 | 930 | 9 |          def write(self, s):             if isinstance(s, memoryview):                 s = s.tobytes()             elif isinstance(s, bytearray): |
| .venv/lib/python3.13/site-packages/pip/_vendor/pygments/console.py | 01a8035aac1e6b6c8159fd74282f69b4180ca4c8f12a9f3200102687e3503959 | 71 | 2 |  dark_colors = ["black", "red", "green", "yellow", "blue",                "magenta", "cyan", "gray"] light_colors = ["brightblack", "brightred", "brightgreen", "brightyellow", "brightblue",            |
| .venv/lib/python3.13/site-packages/pip/_vendor/pygments/style.py | 3e5399aa5b274d5779f111b2e74be403671743f94fe5b1791063040539e8e830 | 204 | 4 |     'ansiyellow': '7f7fe0',     'ansiblue': '00007f',     'ansimagenta': '7f007f',     'ansicyan': '007f7f',     'ansigray': 'e5e5e5', |
| .venv/lib/python3.13/site-packages/pip/_vendor/pygments/unistring.py | 6a5fbfac17a646e1af8a7b2b33a6ad36c1d3989e8351bc36e2ad8ed91bb57017 | 154 | 68 | Cf = '\xad\u0600-\u0605\u061c\u06dd\u070f\u08e2\u180e\u200b-\u200f\u202a-\u202e\u2060-\u2064\u2066-\u206f\ufeff\ufff9-\ufffb\U000110bd\U000110cd\U0001bca0-\U0001bca3\U0001d173-\U0001d17a\U000e0001\U00 |
| .venv/lib/python3.13/site-packages/pip/_vendor/pygments/filters/__init__.py | e14e23b40d17de23fcdee42707df9323e1c34b0f04f32f333181dad148db6da2 | 941 | 4 |         '\\varrho'               : '\U000003c1',         '\\sigma'                : '\U000003c3',         '\\tau'                  : '\U000003c4',         '\\upsilon'              : '\U000003c5',      |
| .venv/lib/python3.13/site-packages/pip/_vendor/pygments/lexers/python.py | bf18e7d5c38772520a24ac68ca206c41363ae461db919b5946e290d8054229ac | 1202 | 7 |                 'hasattr', 'hash', 'hex', 'id', 'input', 'int', 'isinstance',                 'issubclass', 'iter', 'len', 'list', 'locals', 'map', 'max',                 'memoryview', 'min', 'next',  |
| .venv/lib/python3.13/site-packages/pip/_vendor/pygments/lexers/_mapping.py | 978b425ccf1ef5a3c2d810fab2322bd1d793f89fb3e6d1e00b02fea757d2d0f1 | 603 | 12 |     'AgdaLexer': ('pip._vendor.pygments.lexers.haskell', 'Agda', ('agda',), ('*.agda',), ('text/x-agda',)),     'AheuiLexer': ('pip._vendor.pygments.lexers.esoteric', 'Aheui', ('aheui',), ('*.aheui',) |
| .venv/lib/python3.13/site-packages/pip/_vendor/distlib/scripts.py | 42fa7be84f49737220c98b9b9e9a88f5f4bb7ac78639ee058e97952aa2adf48c | 448 | 1 | # new version. If we try to fetch a wrapper *after* that rename, the finder # machinery will be confused as the package is no longer available at the # location where it was imported from. So we load  |
| .venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/filewrapper.py | da4b5734f1342aa9f2cc5db868eb0a080e7c1d0ab5c5e0ba97683aff3c238217 | 120 | 8 |     The data is stored in a temporary file until it is all available.  As long     as the temporary files directory is disk-based (sometimes it's a     memory-backed-``tmpfs`` on Linux), data will be  |
| .venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/cache.py | 397c2fec59f60309ca3626a12479e3b6f68a2e776f54bbfffb33be96d955f6a2 | 76 | 1 | """ The cache object API for implementing caches. The default is a thread safe in-memory dictionary. """  |
| .venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/caches/file_cache.py | 77cba9166cbfcf06829a56d61150652d715d76df19c3c739485a7178e66c75fc | 146 | 3 | class FileCache(_FileCacheMixin, BaseCache):     """     Traditional FileCache: body is stored in memory, so not suitable for large     downloads.     """ |
| .venv/lib/python3.13/site-packages/pip/_vendor/idna/idnadata.py | 5b7d067081afb4e598c008d98f8663ba8b94bad0ba7df80dbb28c9cbb7d9fa5a | 4244 | 36 |     0x5C1: 84,     0x5C2: 84,     0x5C4: 84,     0x5C5: 84,     0x5C7: 84, |
| .venv/lib/python3.13/site-packages/pip/_vendor/idna/uts46data.py | aedf742bd278d20512c29a433c2ae18e08b9000ea958ceb974419149feab2213 | 8682 | 50 |         (0xC2, "M", "â"),         (0xC3, "M", "ã"),         (0xC4, "M", "ä"),         (0xC5, "M", "å"),         (0xC6, "M", "æ"), |
| .venv/lib/python3.13/site-packages/pip/_vendor/requests/models.py | b5a963960eaf2786fec4cbb64da30d14591a8b031ec7f56c110eaa513377c336 | 1040 | 3 |     def iter_content(self, chunk_size=1, decode_unicode=False):         """Iterates over the response data.  When stream=True is set on the         request, this avoids reading the content at once int |
| .venv/lib/python3.13/site-packages/pip/_vendor/requests/api.py | fd96fd39aeedcd5222cd32b016b3e30c463d7a3b66fce9d2444467003c46b10b | 158 | 1 |     # By using the 'with' statement we are sure the session is closed, thus we     # avoid leaving sockets open which can trigger a ResourceWarning in some     # cases, and look like a memory leak in  |
| .venv/lib/python3.13/site-packages/pip/_vendor/requests/utils.py | 592df01d241a6847dc7aed6cca2168e637f87bf0962944dea7f21a6ce548fc9d | 1087 | 5 |      if "application/json" in content_type:         # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset         return "utf-8"  |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/logging.py | e4a68f3d230ff45c5c5cf05c28ce1c19dff35bbf0f3207fe61b3159ef7d2c34a | 298 | 1 |     divide()     sleep(1)     log.critical("Out of memory!")     log.info("Server exited with code=-1")     log.info("[bold]EXITING...[/bold]", extra=dict(markup=True)) |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/tree.py | c969d0eab02f446277a991aa06bc52d925b64ca05336b3f449d63c4313853eec | 258 | 4 |      table.add_column("Released", style="cyan", no_wrap=True)     table.add_column("Title", style="magenta")     table.add_column("Box Office", justify="right", style="green")  |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/console.py | b7d6b366999131553972985505949284db26071776f880167134e5868afe135b | 2681 | 1 |             >>> console = Console()             >>> with console.capture() as capture:             ...     console.print("[bold magenta]Hello World[/]")             >>> print(capture.get())  |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/box.py | 9266af05cfdd9fbdcbfe0ffcbf1592c18243daecc15ce5054ed24e7e96dccdc3 | 475 | 1 |         table.add_row("Cell", "Cell")         table.box = getattr(box, box_name)         table.title = Text(f"box.{box_name}", style="magenta")         columns.add_renderable(table)     console.print( |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/color.py | dc74942d50e3eea4245d47455afefc24e8926737f2e72d6791c6219dadbde95d | 622 | 7 |     "yellow": 3,     "blue": 4,     "magenta": 5,     "cyan": 6,     "white": 7, |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/default_styles.py | 921405aaa6a80ecddba6b32a5a91f0f273b95291b60cde90b6e4dde8bcd9c187 | 194 | 14 |     "green": Style(color="green"),     "yellow": Style(color="yellow"),     "magenta": Style(color="magenta"),     "cyan": Style(color="cyan"),     "white": Style(color="white"), |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/markup.py | ddeb8628fe6ce353424306928d39c9c6eb398993078f1a483345ba7c2c6b6b7f | 252 | 2 |     MARKUP = [         "[red]Hello World[/red]",         "[magenta]Hello [b]World[/b]",         "[bold]Bold[italic] bold and italic [/bold]italic[/italic]",         "Click [link=https://www.willmcguga |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/_inspect.py | 44e4f43cb0b618c5a26a559992a2488e662aec83518a34109284a89164da0222 | 269 | 1 |             yield Text.from_markup(                 f"[b cyan]{not_shown_count}[/][i] attribute(s) not shown.[/i] "                 f"Run [b][magenta]inspect[/]([not b]inspect[/])[/b] for options."    |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/text.py | 00eec93c2cfafa068dd6d8552d73019ed1260cf55816014d1b5a0ceb5fec6a75 | 1362 | 1 |      console.rule("justify='full'")     console.print(text, style="magenta", justify="full")     console.print() |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/live.py | b45dee90000967f37665b19c96a67e8b02e822867c7f41c7533efd8c0c89aa3f | 401 | 1 |         "Text may be printed while the progress bars are rendering.",         Panel("In fact, [i]any[/i] renderable will work"),         "Such as [magenta]tables[/]...",         table,         "Pretty |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/syntax.py | 78328847097ef9e6742f0a3675ad9146d7eeb5719abeb24eeb50a5e4e912e7d5 | 986 | 6 |     Keyword: Style(color="blue"),     Keyword.Type: Style(color="cyan"),     Operator.Word: Style(color="magenta"),     Name.Builtin: Style(color="cyan"),     Name.Function: Style(color="green"), |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/table.py | 6664fb57b30c08e60ac3b4c663d4992f26037fa25d33e5957f4ec5755b958532 | 1007 | 1 |             "Released", header_style="bright_cyan", style="cyan", no_wrap=True         )         table.add_column("Title", style="magenta")         table.add_column("Box Office", justify="right", styl |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/segment.py | a2d9ca78a18457e591950568b1f2557850dc0f100a1e9bc9fe12f34aee65ba63 | 753 | 2 |     code = """from rich.console import Console console = Console() text = Text.from_markup("Hello, [bold magenta]World[/]!") console.print(text)"""  |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/progress.py | 09473696453e5f9f6655d19f8cc0819197a218f2f7bb174e36384d245d93ef06 | 1716 | 2 |         return block      def readinto(self, b: Union[bytearray, memoryview, mmap]):  # type: ignore[no-untyped-def, override]         n = self.handle.readinto(b)  # type: ignore[attr-defined]         |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/cells.py | 2ab4248f9f8b821082a492d23502320198e775ce1b9c4a8e1268b962e67d5026 | 175 | 1 |     """Get the number of cells required to display text.      This method always caches, which may use up a lot of memory. It is recommended to use     `cell_len` over this method.  |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/_win32_console.py | 05268344833004b2139ff9b499344b3ea304e6afaab8675232e60ca587982707 | 662 | 2 |         6,  # yellow                      define FOREGROUND_RED             0x0004 -- 0000 0100         1,  # blue                        define FOREGROUND_INTENSITY       0x0008 -- 0000 1000          |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/__main__.py | 7bf6950beb43cdaad6416f52b9932e0a006be8e0d5fe20cd5765a1db19313a5c | 246 | 6 |             "✓ [bold green]4-bit color[/]\n"             "✓ [bold blue]8-bit color[/]\n"             "✓ [bold magenta]Truecolor (16.7 million)[/]\n"             "✓ [bold yellow]Dumb terminals[/]\n"    |
| .venv/lib/python3.13/site-packages/pip/_vendor/rich/status.py | 9243e987761e019068f97fb8c0fa7c813a99c94e3ae8d2f06410383d94d37b0a | 132 | 1 |      console = Console()     with console.status("[magenta]Covid detector booting up") as status:         sleep(3)         console.log("Importing advanced AI") |
| .venv/lib/python3.13/site-packages/pip/_vendor/urllib3/response.py | 7e60c9005906ef5b854e7fac5524e1d88c345a6717418aa46d18e286fc018d4f | 880 | 2 |             buffer = io.BytesIO()             # Besides `max_chunk_amt` being a maximum chunk size, it             # affects memory overhead of reading a response by this             # method in CPyth |
| .venv/lib/python3.13/site-packages/pip/_vendor/urllib3/connection.py | b6d200f74f41adb4d4cf092a11efd3cd9561e0938e8fb83ad58b1e8b69abc068 | 573 | 7 |             # Avoid modifying the headers passed into .request()             headers = headers.copy()         if "user-agent" not in (six.ensure_str(k.lower()) for k in headers):             headers[" |
| .venv/lib/python3.13/site-packages/pip/_vendor/urllib3/_collections.py | a72012249856ef074ea6a263f50240f05c8645fafc13cb94521a94be1174ef6f | 356 | 1 |     # Backwards compatibility for httplib     getheaders = getlist     getallmatchingheaders = getlist     iget = getlist  |
| .venv/lib/python3.13/site-packages/pip/_vendor/urllib3/connectionpool.py | 7b67a203035b14d08ac63e1bc0328d2bec3b1c8752cf73a633153f4c8b7e7af4 | 1141 | 1 |          :param headers:             Dictionary of custom headers to send, such as User-Agent,             If-None-Match, etc. If None, pool headers are used. If provided,             these headers co |
| .venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/ssltransport.py | 340faee6b313ac3143142f10cd129410a306d39eb584e0f8a814ebdd9e29bfa1 | 222 | 3 |         Create an SSLTransport around socket using the provided ssl_context.         """         self.incoming = ssl.MemoryBIO()         self.outgoing = ssl.MemoryBIO()  |
| .venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/request.py | 0b4394b76b5c53a2d189027b61834ff46bcfad2be5ef388805e910fb99e50599 | 138 | 10 | # emitting some HTTP headers that are added automatically. # The only headers that are supported are ``Accept-Encoding``, # ``Host``, and ``User-Agent``. SKIP_HEADER = "@@@SKIP_HEADER@@@" SKIPPABLE_HE |
| .venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/retry.py | e8436f399f0f043ce1f24822c69aa5f6522b6f67711fe93b66605a9c9176360e | 623 | 1 |          By default, we only retry on methods which are considered to be         idempotent (multiple requests with the same parameters end with the         same state). See :attr:`Retry.DEFAULT_ALLOW |
| .venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/securetransport.py | 15e7f5208514147aa97afcd78833db20690329c858d8554a79578b191d50ab78 | 921 | 2 | # We need to keep these two objects references alive: if they get GC'd while # in use then SecureTransport could attempt to call a function that is in freed # memory. That would be...uh...bad. Yeah, t |
| .venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/_securetransport/low_level.py | 076241076fcd44fd36c4ae8309ad4f6bd22ec6b3f0c730f365b8b14246fb53d3 | 398 | 9 | These are Python functions that are not directly related to the high-level APIs but are necessary to get them to work. They include a whole bunch of low-level CoreFoundation messing about and memory m |
| .venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/_securetransport/bindings.py | e1793ae2a2243c1b74f40e6af9120552e0e135cf665e29556a99bb5a7627cd1c | 520 | 2 |     CoreFoundation.CFStringCreateWithCString.restype = CFStringRef      CoreFoundation.CFStringGetCStringPtr.argtypes = [CFStringRef, CFStringEncoding]     CoreFoundation.CFStringGetCStringPtr.restype |
| .venv/lib/python3.13/site-packages/pip/_vendor/platformdirs/windows.py | 205a62a21501c313ed0b39722b036dc725b8264f2169ae96f28e7d99fac35d5a | 273 | 1 |         "CSIDL_LOCAL_APPDATA": "Local AppData",         "CSIDL_PERSONAL": "Personal",         "CSIDL_DOWNLOADS": "{374DE290-123F-4565-9164-39C4925E467B}",         "CSIDL_MYPICTURES": "My Pictures",    |
| .venv/lib/python3.13/site-packages/sklearn/conftest.py | 4c7ec65ce6af4d298b4f03862aa68695d7ad7c83863048dae1167c6dea42f63a | 376 | 5 | from sklearn.datasets import (     fetch_20newsgroups,     fetch_20newsgroups_vectorized,     fetch_california_housing,     fetch_covtype, |
| .venv/lib/python3.13/site-packages/sklearn/multiclass.py | 5fff24377edac83b5939ef64d40780873f13b5fbdcf5805baf68ac55339a6cf9 | 1288 | 8 | - error correcting output codes  The estimators provided in this module are meta-estimators: they require a base estimator to be provided in their constructor. For example, it is possible to use these |
| .venv/lib/python3.13/site-packages/sklearn/kernel_approximation.py | 0203398ea9789f2c6b4c3e73970d030b5a5138b46d94bdadb5439223407486ac | 1107 | 5 |      by efficiently computing a Count Sketch of the outer product of a     vector with itself using Fast Fourier Transforms (FFT). Read more in the     :ref:`User Guide <polynomial_kernel_approx>`.  |
| .venv/lib/python3.13/site-packages/sklearn/random_projection.py | f9a09de99a137fa891164661c2cf88126b7f3fb39cb65567f60410c93a3a49f9 | 825 | 16 |    In mathematics, the Johnson-Lindenstrauss lemma is a result   concerning low-distortion embeddings of points from high-dimensional   into low-dimensional Euclidean space. The lemma states that a sm |
| .venv/lib/python3.13/site-packages/sklearn/multioutput.py | 70669f4eabcfbe04cbad9a035d696d01f27ca7f793bc0d712a03ec3c9c76671b | 1329 | 2 | """Multioutput regression and classification.  The estimators provided in this module are meta-estimators: they require a base estimator to be provided in their constructor. The meta-estimator extends |
| .venv/lib/python3.13/site-packages/sklearn/kernel_ridge.py | 6fd7727a7b270b7be7261908252ce802d54ee7e40360fe1c97b1860ffd352141 | 241 | 4 |     function in the original space.      The form of the model learned by KRR is identical to support vector     regression (SVR). However, different loss functions are used: KRR uses     squared erro |
| .venv/lib/python3.13/site-packages/sklearn/_min_dependencies.py | 42f97ab4072f12a69b0c4eaacae39f46937103fb4414e0544e64f0cb31c31fe9 | 75 | 1 |     "pandas": ("1.4.0", "benchmark, docs, examples, tests"),     "seaborn": ("0.9.0", "docs, examples"),     "memory_profiler": ("0.57.0", "benchmark, docs"),     "pytest": (PYTEST_MIN_VERSION, "tests |
| .venv/lib/python3.13/site-packages/sklearn/naive_bayes.py | ee265c08217b2b4a0543bd984cb11a962b4d2f4c9a8150332e84f1364b5d37ec | 1541 | 23 |      def predict_joint_log_proba(self, X):         """Return joint log probability estimates for the test vector X.          For each row x of X and class y, the joint log probability is given by |
| .venv/lib/python3.13/site-packages/sklearn/pipeline.py | 0b2023ac29f73ebffe0d45fe2d26ca6aa64ed5e75209278ac47492e280962659 | 2189 | 22 | from .utils.metaestimators import _BaseComposition, available_if from .utils.parallel import Parallel, delayed from .utils.validation import check_is_fitted, check_memory  __all__ = ["FeatureUnion", " |
| .venv/lib/python3.13/site-packages/sklearn/discriminant_analysis.py | 4ad5403ad4b0fa4107816e14ba7c0ccab5b1e5a4dc6c3ce47eeaca1f9bb162c2 | 1130 | 14 |         ----------         X : {array-like, sparse matrix} of shape (n_samples, n_features)             Array of samples (test vectors).          Returns |
| .venv/lib/python3.13/site-packages/sklearn/_config.py | 6333fa37d0ed5924436cf9f0db117724a19dbc0c249795c349797e42a1c44d9b | 408 | 15 | _global_config = {     "assume_finite": bool(os.environ.get("SKLEARN_ASSUME_FINITE", False)),     "working_memory": int(os.environ.get("SKLEARN_WORKING_MEMORY", 1024)),     "print_changed_only": True, |
| .venv/lib/python3.13/site-packages/sklearn/dummy.py | 0469d968b0b08293d31d9672f6a8efcb63454935f8c50657aec061420755b499 | 705 | 8 |           frequent class label in the observed `y` argument passed to `fit`.           The `predict_proba` method returns the matching one-hot encoded           vector.         * "prior": the `predict |
| .venv/lib/python3.13/site-packages/sklearn/base.py | a2ad39c5ff6491d04c35738e942860def0e80d6800aeb1690cfd68bf46be8d91 | 1370 | 2 |      This mixin is empty, and only exists to indicate that the estimator is a     meta-estimator.      .. versionchanged:: 1.6 |
| .venv/lib/python3.13/site-packages/sklearn/calibration.py | 4e0fa65f478c628c3b962f461811fc5037d8beb9e2b8d31b8a2143f8fe28b6d5 | 1449 | 3 |            Probability Estimates, B. Zadrozny & C. Elkan, (KDD 2002)      .. [3] Probabilistic Outputs for Support Vector Machines and Comparisons to            Regularized Likelihood Methods, J. Plat |
| .venv/lib/python3.13/site-packages/sklearn/tree/_export.py | 067cf90582fe3175a05fd9d8418133510a966b32cb158c13f2f44a4c1db359f4 | 1168 | 1 |                 # and -min(impurity) instead of max(-impurity) on purpose, in                 # order to avoid what looks like an issue with SIMD on non                 # memory aligned arrays on 32bi |
| .venv/lib/python3.13/site-packages/sklearn/tree/_reingold_tilford.py | 2268a51c6bf5e532398a7c3205aafbf73132f95f93c43e40f4d524d2c04cf750 | 189 | 1 |     # "Improving Walker's Algorithm to Run in Linear Time" by Buchheim et al,     # (2002)     # https://citeseerx.ist.psu.edu/doc_view/pid/1f41c3c2a4880dc49238e46d555f16d28da2940d     if vil.ancestor |
| .venv/lib/python3.13/site-packages/sklearn/tree/_classes.py | 0f282a47534a1f144c1022e7f3cf0d4e717b297db51c9e64835070038b48bbd8 | 1998 | 5 |     (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and     unpruned trees which can potentially be very large on some data sets. To     reduce memory consumption, the complexity  |
| .venv/lib/python3.13/site-packages/sklearn/tree/tests/test_tree.py | 408abff3d754077d26f7d0fb5db4b612a862538f2ca8365dd7f414cffdfa261f | 2840 | 11 |             est.predict(T)          # predict on vector with different dims         est.fit(X, y)         t = np.asarray(T) |
| .venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py | 6fe88badb690ddf370f8c560a9286f60544ac50862576b33fa47576ab58d9e14 | 3731 | 2 |     targets, or for targets of different lengths.      Column vectors are squeezed to 1d, while multilabel formats are returned     as CSR sparse label indicators.  |
| .venv/lib/python3.13/site-packages/sklearn/metrics/pairwise.py | cd9b01f8b14f855bcd5821b6c3bc34d0c9e6bf5560c7b67dfa84f78612806e72 | 2676 | 43 |      For efficiency reasons, the euclidean distance between a pair of row     vector x and y is computed as::          dist(x, y) = sqrt(dot(x, x) - 2 * dot(x, y) + dot(y, y)) |
| .venv/lib/python3.13/site-packages/sklearn/metrics/_ranking.py | a1fc02f0b042a3945c37692c9377a746800dd2a90cdc227df5268f218bea3f74 | 2078 | 1 |     pos_label = _check_pos_label_consistency(pos_label, y_true)      # make y_true a boolean vector     y_true = y_true == pos_label  |
| .venv/lib/python3.13/site-packages/sklearn/metrics/cluster/_bicluster.py | 81bd17da53455530aa99d8b562eb56ddcfd6e19aa38812a68185ace7b9711147 | 115 | 1 |         May be the string "jaccard" to use the Jaccard coefficient, or         any function that takes four arguments, each of which is a 1d         indicator vector: (a_rows, a_columns, b_rows, b_col |
| .venv/lib/python3.13/site-packages/sklearn/metrics/_plot/confusion_matrix.py | 61f5d3a37898018d1fa24933efb8946d1829ef909fadb3bc71653da20eb3e16b | 500 | 1 |          For a detailed example of using a confusion matrix to evaluate a         Support Vector Classifier, please see         :ref:`sphx_glr_auto_examples_model_selection_plot_confusion_matrix.py`   |
| .venv/lib/python3.13/site-packages/sklearn/metrics/tests/test_common.py | d82a28e0786ae131773b2e02160fe7a41b2e6c90dd143a3cdb1fe9b6e5857138 | 2349 | 3 |     "name", sorted(set(ALL_METRICS) - METRIC_UNDEFINED_BINARY_MULTICLASS) ) def test_format_invariance_with_1d_vectors(name):     random_state = check_random_state(0)     y1 = random_state.randint(0,  |
| .venv/lib/python3.13/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py | b7e64d67b4725ce9326f216f0b19bb554d945a03a3636feba0e13c50ef3d6a28 | 1644 | 7 |             # relative differences.             raise AssertionError(                 f"Query vector with index {query_idx} lead to different distances"                 f" for common neighbor with ind |
| .venv/lib/python3.13/site-packages/sklearn/metrics/tests/test_pairwise.py | 7f956857a92ff85fa91333e999275a33f8dfb92b6ce17e116432d016b80fa0c1 | 1684 | 27 |     S = pairwise_distances(X)[:, :100]     S_chunks = pairwise_distances_chunked(         X, None, reduce_func=_reduce_func, working_memory=2**-16     )     assert isinstance(S_chunks, GeneratorType) |
| .venv/lib/python3.13/site-packages/sklearn/metrics/tests/test_classification.py | 4789d4d61491852f3658886112356427265de73b951164473b1319c41e561f91 | 3398 | 10 |  def test_cohen_kappa():     # These label vectors reproduce the contingency matrix from Artstein and     # Poesio (2008), Table 1: np.array([[20, 20], [10, 50]]).     y1 = np.array([0] * 40 + [1] * 6 |
| .venv/lib/python3.13/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py | 52c2ba059cab2a5988331272f3663ae477db12e7a03cb70e0ec67c2798a8ddea | 768 | 25 |  class ArgKmin(BaseDistancesReductionDispatcher):     """Compute the argkmin of row vectors of X on the ones of Y.      For each row vector of X, computes the indices of k first the rows |
| .venv/lib/python3.13/site-packages/sklearn/metrics/_pairwise_distances_reduction/__init__.py | b549194b6ebc3b10e95f8ad86dbc3c6b4cc6f16d37c6da71a3496a22f21d6662 | 113 | 3 | # #    This module provides routines to compute pairwise distances between a set #    of row vectors of X and another set of row vectors of Y and apply a #    reduction on top. The canonical example i |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/_forest.py | c5a4230e63753d964674363bdbc47179340f28433133172dce1ecef4e73b6ee4 | 3046 | 20 |     "RandomForestClassifier",     "RandomForestRegressor",     "RandomTreesEmbedding", ]  |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/_voting.py | 58beff3e35ad7fc5787dd7fd7cea48601efda80c5a4e9f14e2ad618dfaf1b2ee | 735 | 4 |         ----------         X : {array-like, sparse matrix} of shape (n_samples, n_features)             Training vectors, where `n_samples` is the number of samples and             `n_features` is the |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/_bagging.py | 8781697680db3434ff26309719b51ed3f086a43fe69ab45138aa17346239f3d1 | 1481 | 9 | """Bagging meta-estimator."""  # Authors: The scikit-learn developers |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/_gb.py | 028f08005071c5998eb6ef4414009fb391bcb2fc73f8e18584f6f1d0a9b4059d | 2197 | 13 |         # do oob?         if self.subsample < 1.0:             self.oob_improvement_ = np.zeros((self.n_estimators), dtype=np.float64)             self.oob_scores_ = np.zeros((self.n_estimators), dtyp |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py | 0a5d4fcf01f40c6e4219c387db611a71dfdc9a4cacca4001c202200fdf5a4d80 | 1174 | 10 |     """An AdaBoost classifier.      An AdaBoost [1]_ classifier is a meta-estimator that begins by fitting a     classifier on the original dataset and then fits additional copies of the     classifie |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/__init__.py | 7a6617f2ae1b3b0e121b139115b54a4b33ac459c219b61f4e0fa8569bd7ffa86 | 46 | 2 |     RandomForestClassifier,     RandomForestRegressor,     RandomTreesEmbedding, ) from ._gb import GradientBoostingClassifier, GradientBoostingRegressor |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/_iforest.py | a373daaadba5952982011c0623432c56e918ccc468a4375e56786f337556d8bc | 674 | 5 |         # ExtraTreeRegressor releases the GIL, so it's more efficient to use         # a thread-based backend rather than a process-based backend so as         # to avoid suffering from communication  |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/_stacking.py | 67c0fbc433408369f110cfc1e2eb3b468633effd4e705fa9f658f78b3adc33a5 | 1146 | 12 |         ----------         X : {array-like, sparse matrix} of shape (n_samples, n_features)             Training vectors, where `n_samples` is the number of samples and             `n_features` is the |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/tests/test_common.py | 914ca7ac93dbebb40799065a542d0a3d6bc99190214c428417958548ef293369 | 263 | 1 | ) # FIXME: we should move this test in `estimator_checks` once we are able # to construct meta-estimator instances def test_heterogeneous_ensemble_support_missing_values(Ensemble, Estimator, X, y):    |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/tests/test_forest.py | 3a4a38743320076cfa1fe51b19a0b12a2c06d9ecdb86a8862a33e77364322403 | 1866 | 21 |     RandomForestClassifier,     RandomForestRegressor,     RandomTreesEmbedding, ) from sklearn.ensemble._forest import ( |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/tests/test_gradient_boosting.py | ceb515abb2dad1046b037e0c71c4010aa6adacf2653b0cc7c72df8006fa1e580 | 1712 | 2 |     # later tests, and the tests that check for this warning fail     warn_msg = (         "A column-vector y was passed when a 1d array was expected. "         "Please change the shape of y to \\(n_s |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/_hist_gradient_boosting/binning.py | ed9b905ec280e056c7c3cc48e9d9bba6e5bfd318ec0854f3803765442d11c08d | 334 | 2 | from ...utils.validation import check_is_fitted from ._binning import _map_to_bins from ._bitset import set_bitset_memoryview from .common import ALMOST_INF, X_BINNED_DTYPE, X_BITSET_INNER_DTYPE, X_DT |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py | f88ec15b1f861d6ac8517b8e3e5348bb4522ebe3127c5d89127502078b427fdc | 2372 | 4 |         scale as good on datasets with a large number of samples.     sklearn.tree.DecisionTreeRegressor : A decision tree regressor.     RandomForestRegressor : A meta-estimator that fits a number of |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py | 40cd6ff1c19e5f074fde93949d0dcf8ca00f27d357ea0f53f8cb2e15205a72c9 | 822 | 3 |             )             # node.histograms is reused in largest_child.histograms. To break cyclic             # memory references and help garbage collection, we set it to None.             node.hist |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_bitset.py | e501e7cb91b7a7db7213106c76c515576bc52a03c8faf603b7ecef2e93011d74 | 65 | 8 |  from sklearn.ensemble._hist_gradient_boosting._bitset import (     in_bitset_memoryview,     set_bitset_memoryview,     set_raw_bitset_from_binned_bitset, |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_binning.py | 68d5c7c3bbbb21101d11f1ced9359d8c09a58fdcbf49d8498abfb0d3243e7e47 | 490 | 1 |     ], ) def test_bin_mapper_idempotence(max_bins_small, max_bins_large):     assert max_bins_large >= max_bins_small     data = np.random.RandomState(42).normal(size=30000).reshape(-1, 1) |
| .venv/lib/python3.13/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_predictor.py | c2ae6f5c833087b16bdf00de1c63b617ea0d357107fe151dc8ec92ed22065e91 | 188 | 2 | from sklearn.datasets import make_regression from sklearn.ensemble._hist_gradient_boosting._bitset import (     set_bitset_memoryview,     set_raw_bitset_from_binned_bitset, ) |
| .venv/lib/python3.13/site-packages/sklearn/cluster/_agglomerative.py | 462a5b67042876e02b6594c942609f16766bd8985e21b07436459de2bb944ca3 | 1334 | 21 | ) from ..utils.graph import _fix_connected_components from ..utils.validation import check_memory, validate_data  # mypy error: Module 'sklearn.cluster' has no attribute '_hierarchical_fast' |
| .venv/lib/python3.13/site-packages/sklearn/cluster/_optics.py | 13b2160471bdca06df83328eba64d0a3e7eddf79d2b5f4c3683ce88aebc5f31b | 1203 | 23 |     validate_params, ) from ..utils.validation import check_memory, validate_data   |
| .venv/lib/python3.13/site-packages/sklearn/cluster/_dbscan.py | db9b43ec585f2db81c0d4914fe3c4fefc957aa30aca84c7ae6fb47e960a358c8 | 481 | 19 |     n_jobs=None, ):     """Perform DBSCAN clustering from vector array or distance matrix.      Read more in the :ref:`User Guide <dbscan>`. |
| .venv/lib/python3.13/site-packages/sklearn/cluster/_bicluster.py | f3d8bf1f79b4c2b047bc3c35d6a336c8a43f74566a6bdfa6286a412041cb53fc | 622 | 22 |     def _svd(self, array, n_components, n_discard):         """Returns first `n_components` left and right singular         vectors u and v, discarding the first `n_discard`.         """         if se |
| .venv/lib/python3.13/site-packages/sklearn/cluster/_feature_agglomeration.py | db0a3cbed54cab3d29c0c6f87185544d772cc2378676415bb375cd95a24c267e | 77 | 2 |     def inverse_transform(self, X):         """         Inverse the transformation and return a vector of size `n_features`.          Parameters |
| .venv/lib/python3.13/site-packages/sklearn/cluster/_kmeans.py | 2e0da803f41cc870df45c59a24cd2da93c46d064785fef3e8d5c2e4912d9c803 | 2304 | 18 |     X : {array-like, sparse matrix} of shape (n_samples, n_features)         The observations to cluster. It must be noted that the data         will be converted to C ordering, which will cause a mem |
| .venv/lib/python3.13/site-packages/sklearn/cluster/_spectral.py | b224f57fcfbca65692d8bd1fdfa9c2d70aead62d4e4a153f28f7458d192cb8e0 | 806 | 69 |  from ..base import BaseEstimator, ClusterMixin, _fit_context from ..manifold._spectral_embedding import _spectral_embedding from ..metrics.pairwise import KERNEL_PARAMS, pairwise_kernels from ..neigh |
| .venv/lib/python3.13/site-packages/sklearn/cluster/_bisect_k_means.py | 67458275fd37ae94b79b55e4123c887c10bfafa721f1c36d009700eb7da77f3c | 544 | 6 |         )          # reset the indices attribute to save memory         self.indices = None  |
| .venv/lib/python3.13/site-packages/sklearn/cluster/_affinity_propagation.py | 6b1b13632584bf133c0eb73b84ef410d6296c068058bfc17aa6072220176d405 | 608 | 1 |     copy : bool, default=True         If copy is False, the affinity matrix is modified inplace by the         algorithm, for memory efficiency.      verbose : bool, default=False |
| .venv/lib/python3.13/site-packages/sklearn/cluster/_birch.py | d74617f048927db5e59c99e946e4ef0696fbf771e8479c1c2da82da459119133 | 750 | 3 |     linear_sum_ : ndarray         Linear sum of all the samples in a subcluster. Prevents holding         all sample data in memory.      squared_sum_ : float |
| .venv/lib/python3.13/site-packages/sklearn/cluster/tests/test_k_means.py | 9a64e96ad052f44cdf7242a2f382e086b2085f7d2d6dec2ce5d51d617e22aec5 | 1365 | 2 |     km.fit(X_new_type)      assert not np.may_share_memory(km.cluster_centers_, centers_new_type)   |
| .venv/lib/python3.13/site-packages/sklearn/cluster/tests/test_dbscan.py | f13e50387b0e23b66709870181c444d40313f4851a9e51489b1c6caf74ca8b51 | 435 | 1 |  def test_dbscan_feature():     # Tests the DBSCAN algorithm with a feature vector array.     # Parameters chosen specifically for this task.     # Different eps to other test, because distance is not |
| .venv/lib/python3.13/site-packages/sklearn/cluster/tests/test_birch.py | d1ce6d54159cee563847eee807017c729bc8dfeaa99683875a9e69a2a17d29a6 | 251 | 2 |      # Test that a small number of clusters raises a warning.     brc4 = Birch(threshold=10000.0)     with pytest.warns(ConvergenceWarning):         brc4.fit(X) |
| .venv/lib/python3.13/site-packages/sklearn/cluster/tests/test_optics.py | 70f8bb25a2e94d52d3ab7eedd27e9967268f94b97821c9074f2b8403a6931bcd | 869 | 7 | C2 = [4, -1] + 0.1 * rng.randn(n_points_per_cluster, 2) C3 = [1, -2] + 0.2 * rng.randn(n_points_per_cluster, 2) C4 = [-2, 3] + 0.3 * rng.randn(n_points_per_cluster, 2) C5 = [3, -2] + 1.6 * rng.randn(n |
| .venv/lib/python3.13/site-packages/sklearn/cluster/tests/test_hierarchical.py | ef436ac3ebad247bbcd22c6aa8e2f6342de7c5914e9bea010da576cb554866d5 | 890 | 6 |  def test_zero_cosine_linkage_tree():     # Check that zero vectors in X produce an error when     # 'cosine' affinity is used     X = np.array([[0, 1], [0, 0]]) |
| .venv/lib/python3.13/site-packages/sklearn/cluster/tests/test_bicluster.py | 2498da870fb9ad2bf235c2a9cf466d3358e5d3b8ef2c00790fdcddcdca8c5d4e | 265 | 5 | def test_fit_best_piecewise(global_random_seed):     model = SpectralBiclustering(random_state=global_random_seed)     vectors = np.array([[0, 0, 0, 1, 1, 1], [2, 2, 2, 3, 3, 3], [0, 1, 2, 3, 4, 5]])  |
| .venv/lib/python3.13/site-packages/sklearn/cluster/tests/test_hdbscan.py | c4b62756f034628d4a2ea87f6b15acd5e402a961a525b69288a5617f642cce90 | 583 | 1 |     first_with_label = {_y: np.where(y == _y)[0][0] for _y in list(set(y))}     y_to_labels = {_y: labels[first_with_label[_y]] for _y in list(set(y))}     aligned_target = np.vectorize(y_to_labels.ge |
| .venv/lib/python3.13/site-packages/sklearn/cluster/tests/test_spectral.py | 7c33f036b16003edcf2c5f5114dc6156fbb9b1e13973c6d30e9a19c6a1d2bd43 | 336 | 3 | def test_cluster_qr(global_random_seed):     # cluster_qr by itself should not be used for clustering generic data     # other than the rows of the eigenvectors within spectral clustering,     # but c |
| .venv/lib/python3.13/site-packages/sklearn/cluster/_hdbscan/hdbscan.py | a10b843050096568db7ce7f7e208658151269f9b5006d49ea72f74b1c0741d52 | 1001 | 3 |         Leaf size for trees responsible for fast nearest neighbour queries when         a KDTree or a BallTree are used as core-distance algorithms. A large         dataset size and small `leaf_size`  |
| .venv/lib/python3.13/site-packages/sklearn/feature_extraction/_hash.py | 47ce05ad5311e19bd0d6f220e0ffeb4a0fac2b6c1be307abac4c9f8aaff02852 | 209 | 8 |     Feature values must be (finite) numbers.      This class is a low-memory alternative to DictVectorizer and     CountVectorizer, intended for large-scale (online) learning and situations     where  |
| .venv/lib/python3.13/site-packages/sklearn/feature_extraction/__init__.py | 238e2cf9622335208a91a32f43a93ad0a1611c3dc97b7e24616e5e6d5e136139 | 19 | 3 |  from . import image, text from ._dict_vectorizer import DictVectorizer from ._hash import FeatureHasher from .image import grid_to_graph, img_to_graph |
| .venv/lib/python3.13/site-packages/sklearn/feature_extraction/_dict_vectorizer.py | 8e3319f203e38cf8a1a4ffac3a3335b0523fc6de567aa0de9b9e3e64b414671c | 460 | 16 |   class DictVectorizer(TransformerMixin, BaseEstimator):     """Transforms lists of feature-value mappings to vectors.  |
| .venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py | bfd7b87d4ae13cd8f8b0d7e418f49bac82a354aad62210d8d043ebe599a84881 | 2137 | 74 | """Utilities to build feature vectors from text documents."""  # Authors: The scikit-learn developers |
| .venv/lib/python3.13/site-packages/sklearn/feature_extraction/image.py | a40c79f72e60674583804c63ed29c7b2d5841d33af9990ff332aa81df757f816 | 688 | 1 |         for j in range(i_w):             # divide by the amount of overlap             # XXX: is this the most efficient way? memory-wise yes, cpu wise?             img[i, j] /= float(min(i + 1, p_h,  |
| .venv/lib/python3.13/site-packages/sklearn/feature_extraction/tests/test_dict_vectorizer.py | b097dcc3221ded78ebb3769a912f878e43efb74773b952ea22e0909a9c673795 | 262 | 50 |  from sklearn.exceptions import NotFittedError from sklearn.feature_extraction import DictVectorizer from sklearn.feature_selection import SelectKBest, chi2  |
| .venv/lib/python3.13/site-packages/sklearn/feature_extraction/tests/test_text.py | 621d70adc2abee5d80c6db9cf8ab05c20b80cc6e54ab1af2577fd5cd36dab216 | 1629 | 232 | from sklearn.feature_extraction.text import (     ENGLISH_STOP_WORDS,     CountVectorizer,     HashingVectorizer,     TfidfTransformer, |
| .venv/lib/python3.13/site-packages/sklearn/_loss/tests/test_link.py | 5cc1cc2e398f0354472eb0217b1a0ccd541196891c093f4b3216a35559e7792d | 112 | 2 |     assert_allclose(y_pred, out)     assert_array_equal(out, y_pred_2)     assert np.shares_memory(out, y_pred_2)      out = np.empty_like(y_pred) |
| .venv/lib/python3.13/site-packages/sklearn/_loss/tests/test_loss.py | 852805fc6e51d9cbf53f796b7589688b07436298a64fe0307d4d6385c67a15c4 | 1359 | 6 |     float64, and all output arrays are either all float32 or all float64.      Also check that input arrays can be readonly, e.g. memory mapped.     """     loss = loss() |
| .venv/lib/python3.13/site-packages/sklearn/semi_supervised/_label_propagation.py | 3416520f14de14fc066edfe3f2b08b820895537e690d9a6066ce24c4b7544a93 | 631 | 1 |  Kernel:   A function which projects a vector into some higher dimensional space. This   implementation supports RBF and KNN kernels. Using the RBF kernel generates   a dense matrix of size O(N^2). KN |
| .venv/lib/python3.13/site-packages/sklearn/semi_supervised/_self_training.py | c145e9fe2debbd82f0d5b3126ba33ed568edbd6f6e226327f2c33dbb56cf8c9a | 626 | 1 |      _parameter_constraints: dict = {         # We don't require `predic_proba` here to allow passing a meta-estimator         # that only exposes `predict_proba` after fitting.         # TODO(1.8) re |
| .venv/lib/python3.13/site-packages/sklearn/semi_supervised/tests/test_self_training.py | f4dc5d7a620248cdc13bd270efb3f386e6388905e6bf8273a1af7ff587c4c8ca | 396 | 3 | y_train_missing_labels[n_labeled_samples:] = -1 mapping = {0: "A", 1: "B", 2: "C", -1: "-1"} y_train_missing_strings = np.vectorize(mapping.get)(y_train_missing_labels).astype(     object ) |
| .venv/lib/python3.13/site-packages/sklearn/gaussian_process/_gpc.py | 88bf5ea647e70feab8fa7d1ca4b7f90a52e257fda9583343905ab11917e8c4cc | 974 | 11 |     ----------     X_train_ : array-like of shape (n_samples, n_features) or list of object         Feature vectors or other representations of training data (also         required for prediction).  |
| .venv/lib/python3.13/site-packages/sklearn/gaussian_process/kernels.py | 974b8b4a5022f8cadac747003d20cf67737ba2c215892dab490205afbaeb577a | 2409 | 16 |         The number of elements of the hyperparameter value. Defaults to 1,         which corresponds to a scalar hyperparameter. n_elements > 1         corresponds to a hyperparameter which is vector- |
| .venv/lib/python3.13/site-packages/sklearn/gaussian_process/_gpr.py | ce92905a94248df06d5edc31cf747f496486122c4ab232a832484e095b0033f5 | 676 | 6 |     ----------     X_train_ : array-like of shape (n_samples, n_features) or list of object         Feature vectors or other representations of training data (also         required for prediction).  |
| .venv/lib/python3.13/site-packages/sklearn/gaussian_process/tests/test_kernels.py | 8b37a5dc5aeee95760351187c67c15aa6544371cb4eac6230d3174de2448f664 | 404 | 9 | ) def test_kernel_theta(kernel):     # Check that parameter vector theta of kernel is set correctly.     kernel = clone(kernel)  # make tests independent of one-another     theta = kernel.theta |
| .venv/lib/python3.13/site-packages/sklearn/compose/_target.py | 36ccaba35f02facf9e5010da8ba4c8b4ec7de169acf4a1ff13fd14b7b4abce0a | 398 | 2 |  class TransformedTargetRegressor(RegressorMixin, BaseEstimator):     """Meta-estimator to regress on a transformed target.      Useful for applying a non-linear transformation to the target `y` in |
| .venv/lib/python3.13/site-packages/sklearn/compose/__init__.py | 5d4e23f1d77b485bb2e6bd007d32d9dfa5ec11c20ffc8aa34163460bb1abb348 | 24 | 1 | """Meta-estimators for building composite models with transformers.  In addition to its current contents, this module will eventually be home to |
| .venv/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py | 36395fd94f1aaff2f6980f9a5e4b6d4e5b9627bb6ed8794dddcc0a629b7da9e4 | 1600 | 5 |             positional columns, while strings can reference DataFrame columns             by name.  A scalar string or int should be used where             ``transformer`` expects X to be a 1d array-l |
| .venv/lib/python3.13/site-packages/sklearn/compose/tests/test_target.py | 55a5e4f6d01c9a4cdc91aa92e61ee2c2f5b7312fa170ecebecd852b19b379c31 | 413 | 1 |     # All transformer in scikit-learn expect 2D data. FunctionTransformer with     # validate=False lift this constraint without checking that the input is a     # 2D vector. We check the consistency  |
| .venv/lib/python3.13/site-packages/sklearn/compose/tests/test_column_transformer.py | 72ee4c10766829f608ddc6e7fe84da574e86ff838367c5dedfa24584e81e89a5 | 2800 | 2 | ) from sklearn.exceptions import NotFittedError from sklearn.feature_extraction import DictVectorizer from sklearn.feature_selection import VarianceThreshold from sklearn.preprocessing import ( |
| .venv/lib/python3.13/site-packages/sklearn/datasets/_base.py | 97c72551abc46c148c08ca0ecc885f4f95964a79c51888c6e06fc13eb61880cd | 1637 | 1 |     This function does not try to extract features into a numpy array or scipy     sparse matrix. In addition, if load_content is false it does not try to     load the files in memory.      To use tex |
| .venv/lib/python3.13/site-packages/sklearn/datasets/_samples_generator.py | d2d26a46ed9ca0907d13f2c07ad83354ad779dce0713fc37c7d68771ea6e0834 | 2384 | 7 |     n_targets : int, default=1         The number of regression targets, i.e., the dimension of the y output         vector associated with a sample. By default, the output is a scalar.      bias : fl |
| .venv/lib/python3.13/site-packages/sklearn/datasets/_olivetti_faces.py | fc981665d50bee3e7584d9eabaf670efacaf5c28458509d2fb048d0511280d46 | 185 | 3 |         faces = faces[order]         target = target[order]     faces_vectorized = faces.reshape(len(faces), -1)      fdescr = load_descr("olivetti_faces.rst") |
| .venv/lib/python3.13/site-packages/sklearn/datasets/_kddcup99.py | d5fd52b36a45a67b1599264e496186670ee9be92c807047ffe33debf27e0d0ba | 430 | 1 |     filename="kddcup99_10_data",     url="https://ndownloader.figshare.com/files/5976042",     checksum="8045aca0d84e70e622d1148d7df782496f6333bf6eb979a1b0837c42a9fd9561", )  |
| .venv/lib/python3.13/site-packages/sklearn/datasets/_california_housing.py | 5bc3f3449a4f6c0a7af5a31cb121069c8272c5eebbda3fe0bd6df098bba0df86 | 249 | 1 |     filename="cal_housing.tgz",     url="https://ndownloader.figshare.com/files/5976036",     checksum="aaa5c9a6afe2225cc2aed2723682ae403280c4a3695a2ddda4ffb5d8215ea681", )  |
| .venv/lib/python3.13/site-packages/sklearn/datasets/_species_distributions.py | 6498f3724b71c40ea11ce55bf32f429220e8959b4a9463b8182502400214d6a7 | 290 | 1 |     filename="samples.zip",     url="https://ndownloader.figshare.com/files/5976075",     checksum="abb07ad284ac50d9e6d20f1c4211e0fd3c098f7f85955e89d321ee8efe37ac28", )  |
| .venv/lib/python3.13/site-packages/sklearn/datasets/_covtype.py | 89c0bf47ed366fcde0216250ab9dc4e3fe90f27f148803b314a1f346c4981586 | 253 | 1 |     filename="covtype.data.gz",     url="https://ndownloader.figshare.com/files/5976039",     checksum="614360d0257557dd1792834a85a1cdebfadc3c4f30b011d56afee7ffb5b15771", )  |
| .venv/lib/python3.13/site-packages/sklearn/datasets/__init__.py | 38897ecc1b892641521f32fa64525f075109d6cfa3d5a74bb44c8569a910c72f | 167 | 2 |     load_svmlight_files, ) from ._twenty_newsgroups import fetch_20newsgroups, fetch_20newsgroups_vectorized  __all__ = [ |
| .venv/lib/python3.13/site-packages/sklearn/datasets/_arff_parser.py | b6364380dc88a90d48eb33c8c24c59c825dcad6d69fd0372f712d23bdfd930c6 | 544 | 1 |         first_df = pd.DataFrame([first_row], columns=columns_names, copy=False)          row_bytes = first_df.memory_usage(deep=True).sum()         chunksize = get_chunk_n_rows(row_bytes)  |
| .venv/lib/python3.13/site-packages/sklearn/datasets/_rcv1.py | a01a4bad28f810d710026281a5a901619226ec0a3eec21aa2844fb27a1db5b38 | 335 | 18 | from ._svmlight_format_io import load_svmlight_files  # The original vectorized data can be found at: #    http://www.ai.mit.edu/projects/jmlr/papers/volume5/lewis04a/a13-vector-files/lyrl2004_vectors |
| .venv/lib/python3.13/site-packages/sklearn/datasets/_lfw.py | c0e6d1d51ad3be2c07fcad110056bf1a3380959ef86baab6aecce1ad2ab6278a | 649 | 10 |  import numpy as np from joblib import Memory  from ..utils import Bunch |
| .venv/lib/python3.13/site-packages/sklearn/datasets/_svmlight_format_io.py | e75e4373a4cb4272aeff61db3504e766164ae681c7d82c011c0d37638f4429d6 | 586 | 10 |     Parsing a text based source can be expensive. When repeatedly     working on the same dataset, it is recommended to wrap this     loader with joblib.Memory.cache to store a memmapped backup of the |
| .venv/lib/python3.13/site-packages/sklearn/datasets/_twenty_newsgroups.py | 24e8cf244c77e0700c76372019f778af94b050e2fde4ea1e3d251dcdcc9f4dbb | 626 | 22 |  from .. import preprocessing from ..feature_extraction.text import CountVectorizer from ..utils import Bunch, check_random_state from ..utils._param_validation import Interval, StrOptions, validate_p |
| .venv/lib/python3.13/site-packages/sklearn/datasets/_openml.py | 656aed70447bc016fc9b5a85b7096f8247da0dca609368fb2a5cfcae74d429fe | 1161 | 3 |           pandas to be installed and can only open dense datasets.         - `"liac-arff"`: this is a pure Python ARFF parser that is much less           memory- and CPU-efficient. It deals with spars |
| .venv/lib/python3.13/site-packages/sklearn/datasets/tests/test_svmlight_format.py | 9aa2aeacadb5eaec9237a844f8301f1d1b7ee8d1c41a6e1f056c81207a4a0b1d | 614 | 1 |  @pytest.mark.skip(     "testing the overflow of 32 bit sparse indexing requires a large amount of memory" ) def test_load_large_qid(): |
| .venv/lib/python3.13/site-packages/sklearn/datasets/tests/test_20news.py | f8475e53a48b5654cf086b5ab4946995506f3ebb7a03281781e373ffd245fbc6 | 144 | 16 |   def test_20news_vectorized(fetch_20newsgroups_vectorized_fxt):     # test subset = train     bunch = fetch_20newsgroups_vectorized_fxt(subset="train") |
| .venv/lib/python3.13/site-packages/sklearn/datasets/tests/test_openml.py | 46b22ed172ffd4faa97a050dde96096b914cf50342c82317d248884bfe4362f4 | 1635 | 4 |   def test_convert_arff_data_dataframe_warning_low_memory_pandas(monkeypatch):     """Check that we raise a warning regarding the working memory when using     LIAC-ARFF parser.""" |
| .venv/lib/python3.13/site-packages/sklearn/externals/_arff.py | 61747cc60175231cae81057bd181cd8e6cdadb2bb3f3ace154cd62e8023e4520 | 1108 | 2 |         '''Do the job the ``encode``.'''          # Make sure this method is idempotent         self._current_line = 0  |
| .venv/lib/python3.13/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py | 666a005466ec8f4e2071f13b47457a37fec05c266b8584855d77f325f2793b86 | 377 | 2 |     --------     This function temporarily rechunks the array along `axis` to a single chunk.     This can be extremely inefficient and can lead to out-of-memory errors.      See the corresponding doc |
| .venv/lib/python3.13/site-packages/sklearn/externals/array_api_compat/dask/array/linalg.py | 02d9077ed27786e7eeb92959851c51d111fd22eade11eb77f3bae99f5877f175 | 73 | 3 |     return s  vector_norm = get_xp(da)(_linalg.vector_norm) diagonal = get_xp(da)(_linalg.diagonal)  |
| .venv/lib/python3.13/site-packages/sklearn/externals/array_api_compat/cupy/linalg.py | 9ca38cfbfc1c387cc7844795f4a07370c54d96f8892b89cfd6714152dbe78d33 | 50 | 5 | # These functions are completely new here. If the library already has them # (i.e., numpy 2.0), use the library version instead of our wrapper. if hasattr(cp.linalg, 'vector_norm'):     vector_norm =  |
| .venv/lib/python3.13/site-packages/sklearn/externals/array_api_compat/torch/linalg.py | 69c6dc83cd028da98c434243024ad62fb164c845b931f98657342cad14f4d233 | 122 | 5 |     # 2. x1.shape[:-1] == x2.shape     #     # See linalg_solve_is_vector_rhs in     # aten/src/ATen/native/LinearAlgebraUtils.h and     # TORCH_META_FUNC(_linalg_solve_ex) in |
| .venv/lib/python3.13/site-packages/sklearn/externals/array_api_compat/numpy/_aliases.py | 48a6827f3736798d5e02edd8ce6dc956e477b94a8becfa177fa1b26325e9730e | 191 | 1 | def _supports_buffer_protocol(obj: object) -> TypeIs[Buffer]:  # pyright: ignore[reportUnusedFunction]     try:         memoryview(obj)  # pyright: ignore[reportArgumentType]     except TypeError:     |
| .venv/lib/python3.13/site-packages/sklearn/externals/array_api_compat/numpy/linalg.py | 391bb8321b8de85e445cecbe9581f17cc1e4469551c765440b6f6b47007c070b | 144 | 8 |  # Note: unlike np.linalg.solve, the array API solve() only accepts x2 as a # vector when it is exactly 1-dimensional. All other cases treat x2 as a stack # of matrices. The np.linalg.solve behavior o |
| .venv/lib/python3.13/site-packages/sklearn/externals/array_api_compat/common/_linalg.py | 59d7f4173cf124d1221a138eb102a0f0f9ccbac3377d578de4203844122d17f6 | 233 | 5 | class EighResult(NamedTuple):     eigenvalues: Array     eigenvectors: Array  class QRResult(NamedTuple): |
| .venv/lib/python3.13/site-packages/sklearn/externals/_scipy/sparse/csgraph/_laplacian.py | 9756c06279ed963bc85dcf26c09a92a4b4ba1014e3ccc4dbd17ad6dbf4b50359 | 558 | 14 |     copy : bool, optional         If False, then change `csgraph` in place if possible,         avoiding doubling the memory use.         Default: True, for backward compatibility.     form : 'array', |
| .venv/lib/python3.13/site-packages/sklearn/externals/array_api_extra/testing.py | 9b0ff4cbf4f33264cfdb0515fe87c0c1c8a1d11ff29a1524401ac7063f64fe03 | 325 | 1 |     try:         func._lazy_xp_function = tags  # type: ignore[attr-defined]  # pylint: disable=protected-access  # pyright: ignore[reportFunctionMemberAccess]     except AttributeError:  # @cython.ve |
| .venv/lib/python3.13/site-packages/sklearn/externals/array_api_extra/_lib/_at.py | f993e29387da18ae83fd6bec0a0f55f76e82d2817fc7a0a6c3c8b7c9f8ef4f23 | 455 | 1 |         # namespace that Dask is wrapping.         # Note that da.minimum _incidentally_ works on NumPy, CuPy, and sparse         # thanks to all these meta-namespaces implementing the __array_ufunc__ |
| .venv/lib/python3.13/site-packages/sklearn/externals/array_api_extra/_lib/_lazy.py | 69bb7579ee3db85331dcdc2cf3e04a79eda3d6a2f05541b1dadac97d31eeb066 | 353 | 1 |         .. warning::             The whole operation needs to fit in memory all at once on a single worker.          The outputs will also be returned as a single chunk and you should consider |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_metaestimators.py | e8355db5428feebe72dd569f397e5295a4e29adc6e4fe3a540a6112c10fe1e71 | 338 | 13 | from sklearn.ensemble import BaggingClassifier from sklearn.exceptions import NotFittedError from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.feature_selection import RFE, RFEC |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_common.py | 2dceaa8fc1c9d6f390dba92ed8d6d7dac3e86846857a6640a68c4cab7cf5f968 | 407 | 1 |   # NOTE: When running `check_dataframe_column_names_consistency` on a meta-estimator that # delegates validation to a base estimator, the check is testing that the base estimator # is checking for co |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_public_functions.py | b023fce29708da8937dcd3369fc9259480f1c629c8a0399f7db8ee8fb72884dd | 404 | 3 |     "sklearn.datasets.dump_svmlight_file",     "sklearn.datasets.fetch_20newsgroups",     "sklearn.datasets.fetch_20newsgroups_vectorized",     "sklearn.datasets.fetch_california_housing",     "sklear |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_multioutput.py | dde9c09185cc86f105c42db37b20ff9d997969f8e117e785b4c44bc18628f772 | 881 | 1 | ) # FIXME: we should move this test in `estimator_checks` once we are able # to construct meta-estimator instances def test_support_missing_values(MultiOutputEstimator, Estimator):     # smoke test to |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_docstring_parameters.py | cdd14ad1af6a2cd19278f231e53dc2b05d620231c3052a20390a4388c6368907 | 329 | 6 |     skipped_attributes = {}      if Estimator.__name__.endswith("Vectorizer"):         # Vectorizer require some specific input data         if Estimator.__name__ in ( |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_dummy.py | 9124a6d2ff5bfab728191e5f0844c599ddaa60ea01718494c8d6754f89d871d6 | 716 | 1 |      clf = DummyClassifier(strategy="uniform", random_state=global_random_seed)     with pytest.warns(UserWarning, match="the uniform strategy would not save memory"):         clf.fit(X, y)  |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_discriminant_analysis.py | 55a5ae837098bbf38b4c5ac9fc03352002df5938e5758734de7b65a56cf27f1a | 671 | 1 |  def test_lda_explained_variance_ratio():     # Test if the sum of the normalized eigen vectors values equals 1,     # Also tests whether the explained_variance_ratio_ formed by the     # eigen solver |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_multiclass.py | c362e69b2981a3d2b86727c598c5f6ee7bc72258dea1a6654e2e96254c7e3e7b | 972 | 1 | ) # FIXME: we should move this test in `estimator_checks` once we are able # to construct meta-estimator instances def test_support_missing_values(MultiClassClassifier):     # smoke test to check that |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_config.py | 20e284318e8be00abd624a7dd1f8e8edcba3f517935aeec342e11478a4e1e262 | 169 | 3 |     assert get_config() == {         "assume_finite": False,         "working_memory": 1024,         "print_changed_only": True,         "display": "diagram", |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_metadata_routing.py | 9d65ae7f9c036ef8beafd6726075d418b98c5618e6e145ea61e2cdd976e39f3a | 1159 | 3 |     clf.fit(X, y)      # Meta-estimator consumes sample_weight, but doesn't forward it to the underlying     # estimator     clf = WeightedMetaClassifier(estimator=NonConsumingClassifier()) |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_calibration.py | 7e4753dba1d354de18310b6cac050126efccd163c8dd428315ceb896716c1d81 | 1137 | 4 | ) from sklearn.exceptions import NotFittedError from sklearn.feature_extraction import DictVectorizer from sklearn.frozen import FrozenEstimator from sklearn.impute import SimpleImputer |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_metaestimators_metadata_routing.py | 04a34003a0802a5cbb9f508f1ca75c7197511dc7f6b5a484b9b46dcdd1d36e5b | 928 | 4 | @config_context(enable_metadata_routing=True) def test_unsupported_estimators_get_metadata_routing(estimator):     """Test that get_metadata_routing is not implemented on meta-estimators for     which |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_naive_bayes.py | 49e3d33284da803a984339e316b734d6d2014e93225922bd30abdb7419cbf6b8 | 980 | 1 |   def test_alpha_vector():     X = np.array([[1, 0], [1, 1]])     y = np.array([0, 1]) |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_pipeline.py | 64a3a7748a29beb75881c1d0f8ac6aeec3834a041fcacf1b30fd8e97752ded00 | 2414 | 32 |     HistGradientBoostingClassifier,     RandomForestClassifier,     RandomTreesEmbedding, ) from sklearn.exceptions import NotFittedError, UnsetMetadataPassedError |
| .venv/lib/python3.13/site-packages/sklearn/tests/test_random_projection.py | 3c780cb63c6de6abf2e88334618e9e5a634b7a5c5d4f61f8905f0141b5017917 | 585 | 3 |  @pytest.mark.parametrize("coo_container", COO_CONTAINERS) def test_too_many_samples_to_find_a_safe_embedding(coo_container, global_random_seed):     data = make_sparse_random_data(         coo_contai |
| .venv/lib/python3.13/site-packages/sklearn/tests/metadata_routing_common.py | 4915d16446d32d8c2737ba0481104f57b9298c4495c142ee20e4a3d60b7a0dc4 | 585 | 4 |  class MetaRegressor(MetaEstimatorMixin, RegressorMixin, BaseEstimator):     """A meta-regressor which is only a router."""      def __init__(self, estimator): |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_quantile.py | 9487caf900846b4ccda9929e77a6b2adf53a41d282f5429e3c564fab8303e5a0 | 302 | 3 |         # p = n_features         # n = n_samples         # 1_n = vector of length n with entries equal one         # see https://stats.stackexchange.com/questions/384909/         # |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_base.py | 1d2ffdba0cb4509d11983fa87ba4187d4469c9c1ae9fd9193461281b20b35133 | 870 | 4 |     follows:         - if `X` is dense, center the data and         store the mean vector in `X_offset`.         - if `X` is sparse, store the mean in `X_offset`         without centering `X`. The cen |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_least_angle.py | e39e3a601f626299ebcaec625696f5a62417c93c5099b6ba2a2eea4bdd2fc3eb | 2347 | 7 |             if diag < 1e-7:                 # The system is becoming too ill-conditioned.                 # We have degenerate vectors in our active set.                 # We'll 'drop for good' the la |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py | e7a5fdd1d78f22f404406e930c3afa3d6327a0beb2614435d0d405e3d2621a15 | 371 | 11 |      The regularizer is a penalty added to the loss function that shrinks model     parameters towards the zero vector using the squared euclidean norm L2.      .. versionadded:: 0.17 |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_passive_aggressive.py | cc5ef39d76939f933970c4691ebeab358965668683e0e864e885ce13eb243411 | 574 | 1 |             Classes across all calls to partial_fit.             Can be obtained by via `np.unique(y_all)`, where y_all is the             target vector of the entire dataset.             This argumen |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py | fd333e0cc43cddcc72255424541691bdbc208685842917fd6f9e550bf4d300e5 | 2328 | 15 |         `[x, self.intercept_scaling]`,         i.e. a "synthetic" feature with constant value equal to         `intercept_scaling` is appended to the instance vector.         The intercept becomes     |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_omp.py | fbe78318b0d1bbfb3ca7fbde00b9c6a6b332cec206577032b5f4ae19771f1cf4 | 1122 | 6 |     idx : ndarray of shape (n_nonzero_coefs,)         Indices of the positions of the elements in gamma within the solution         vector.      coef : ndarray of shape (n_features, n_nonzero_coefs) |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_theil_sen.py | 92b4aaf07afd8a573810709d887e5f9b7a67fcddcf827747bbe2c26541c89421 | 468 | 5 |     ----------     X : array-like of shape (n_samples, n_features)         Training vector, where `n_samples` is the number of samples and         `n_features` is the number of features.  |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py | a90497f9bc58c802a4f1b436cf7ddbfe91c130ba75c175668f9673e5a0a01334 | 826 | 8 |         ).toarray()     else:         # np.einsum may use less memory but the following, using BLAS matrix         # multiplication (gemm), is by far faster.         WX = W[:, None] * X |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py | dc83a60d7ad30cabcd3dae7bd57ca860cae07846caf9987f8a30859fe5ad1a0e | 3404 | 35 |     X : {array-like, sparse matrix} of shape (n_samples, n_features)         Training data. Pass directly as Fortran-contiguous data to avoid         unnecessary memory duplication      y : ndarray of |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_ridge.py | a0a8c5e26611c1bc91a97ae85d6add59b98a2fa5c92ff7c25467ea88bd6e4ce3 | 2900 | 23 |             dual_coef = linalg.lstsq(K, y)[0]          # K is expensive to compute and store in memory so change it back in         # case it was user-given.         K.flat[:: n_samples + 1] -= alpha[ |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py | dcba13fcb0adff67ed224efc3498b0d3ccdea1915a6e4f35904426b7541dfd36 | 2605 | 8 |             Classes across all calls to partial_fit.             Can be obtained by via `np.unique(y_all)`, where y_all is the             target vector of the entire dataset.             This argumen |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_huber.py | ec28fa34877e4be8913d9b4ee95022c890ea73358a9007a4128ef0ab02e04ad3 | 364 | 5 |     ----------     w : ndarray, shape (n_features + 1,) or (n_features + 2,)         Feature vector.         w[:n_features] gives the coefficients         w[-1] gives the scale factor and if the inter |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_bayes.py | e6668da2ac9cf206420c7b3b87e3d58a979b15f416e3f7bb971916e847f9afe7 | 827 | 2 |     Vol. 4, No. 3, 1992.      M. E. Tipping, Sparse Bayesian Learning and the Relevance Vector Machine,     Journal of Machine Learning Research, Vol. 1, 2001.  |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py | eab88595bd9e2b08ef41463fa3faf86fc6ba5792c21cc32aa4d23030003bcb76 | 912 | 4 |             This solver is a good choice for `n_samples` >> `n_features`, especially             with one-hot encoded categorical features with rare categories. Be aware             that the memory us |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/tests/test_sgd.py | e0b73da63c3d13dc79040f0a9a498a92a00b719cd1d86165d0d08c41641465ba | 2196 | 1 |     # SGDClassifier.fit was called from a loky or multiprocessing backend. In     # this specific case, in-place modification of clf.coef_ would have caused     # a segmentation fault when trying to w |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/tests/test_bayes.py | 62b20d3e3a81d25688271a5cad53c8dee1bba94589904f8c9edce9f4fe977f42 | 315 | 3 |      Compute log marginal likelihood with equation (36) in Sparse Bayesian     Learning and the Relevance Vector Machine (Tipping, 2001):      - 0.5 * (log \|Id/alpha + X.X^T/lambda\| + |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/tests/test_theil_sen.py | 5087defe85bdf4c9e849e3597aa7f69dfcee31ddb3cc3ab96baae3c691d1925e | 304 | 1 |     assert_array_less(median, new_y)     assert_array_less(new_y, y)     # Check that a single vector is identity     X = np.array([1.0, 2.0, 3.0]).reshape(1, 3)     y = X[0] |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/tests/test_least_angle.py | 0eed6b9be5158f30d38f3b51c3f4befce69cc8eb1c020e72a809922b0b2b31ba | 870 | 1 |  def test_lars_path_readonly_data():     # When using automated memory mapping on large input, the     # fold data is in read-only mode     # This is a non-regression test for: |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/tests/test_sag.py | 92c51169a4838f3bc7076d37647e9b471775b3d7d490f85c01beb65c05e393ba | 862 | 10 |     weights = np.zeros(X.shape[1])     sum_gradient = np.zeros(X.shape[1])     gradient_memory = np.zeros((n_samples, n_features))      intercept = 0.0 |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/tests/test_base.py | 5cc4aedda58e16307aa3fd231baa65306e935a3a6e6a0d533ab41908e0f3d95a | 792 | 4 |      if to_copy and sparse_container is not None:         assert not np.may_share_memory(X_.data, X.data)     elif to_copy:         assert not np.may_share_memory(X_, X) |
| .venv/lib/python3.13/site-packages/sklearn/linear_model/tests/test_linear_loss.py | db33164557d840cfec56ebf34ce61e1bd2a5e0df57872c5249b002094fc1531e | 511 | 9 |         # y = rng.choice(np.arange(n_classes), p=proba) does not work.         # See https://stackoverflow.com/a/34190035/16761084         def choice_vectorized(items, p):             s = p.cumsum(axi |
| .venv/lib/python3.13/site-packages/sklearn/impute/_knn.py | d64be755da43107b26fa96414d885b356200b5c3335a80cf2642e921d789146a | 412 | 1 |                 X[receivers_idx, col] = value          # process in fixed-memory chunks         gen = pairwise_distances_chunked(             X[row_missing_idx, :], |
| .venv/lib/python3.13/site-packages/sklearn/impute/_iterative.py | 7202327f2263695e47c924394f1697f7b032c1af15a5292be54240b4d7758962 | 1031 | 1 |         """Validate the limits (min/max) of the feature values.          Converts scalar min/max limits to vectors of shape `(n_features,)`.          Parameters |
| .venv/lib/python3.13/site-packages/sklearn/impute/tests/test_knn.py | e052f4741c735bf168a14a45bb3811eae6031f663897da4b189d73920cbd6f84 | 571 | 10 |   @pytest.mark.parametrize("working_memory", [None, 0]) @pytest.mark.parametrize("na", [-1, np.nan]) # Note that we use working_memory=0 to ensure that chunking is tested, even |
| .venv/lib/python3.13/site-packages/sklearn/impute/tests/test_impute.py | a54a65210d13990476d65639489a10d25976d45986a17ad9b6a3d756ffc893d9 | 1936 | 2 |     "min_max_1, min_max_2",     [([None, None], [-np.inf, np.inf]), ([-10, 10], [[-10] * 4, [10] * 4])],     ids=["None-vs-inf", "Scalar-vs-vector"], ) def test_iterative_imputer_min_max_array_like_im |
| .venv/lib/python3.13/site-packages/sklearn/utils/optimize.py | 197dc7e1bcc254167516fe9e51c82f53677bcf1fb105c94d31114272a2ee5a7f | 390 | 1 |      fgrad : ndarray of shape (n_features,) or (n_features + 1,)         Gradient vector.      maxiter : int |
| .venv/lib/python3.13/site-packages/sklearn/utils/_arpack.py | 741e2b2589eec1251797bdc9a0b21241b60749779ca35d32de08cd2861840228 | 34 | 3 |  def _init_arpack_v0(size, random_state):     """Initialize the starting vector for iteration in ARPACK functions.      Initialize a ndarray with values sampled from the uniform distribution on |
| .venv/lib/python3.13/site-packages/sklearn/utils/_chunking.py | 7e99e36890d64cb9dd52fe1b1df225b76824d1898f61d02bb58963c150342ac3 | 179 | 13 |   def get_chunk_n_rows(row_bytes, *, max_n_rows=None, working_memory=None):     """Calculate how many rows can be processed within `working_memory`.  |
| .venv/lib/python3.13/site-packages/sklearn/utils/_array_api.py | 8494cbca7e64b8c0b0183e7e0b9a5ec831164768c4635959533358736127fba0 | 1007 | 3 |     """Helper to support the order kwarg only for NumPy-backed arrays      Memory layout parameter `order` is not exposed in the Array API standard,     however some input validation code in scikit-le |
| .venv/lib/python3.13/site-packages/sklearn/utils/estimator_checks.py | f5e97583755cfea5f2d839a8eac50695ca3896ff4d3072fcab0171eef65bb66e | 5349 | 6 |         "Isomap",         "KernelPCA",         "LocallyLinearEmbedding",         "LogisticRegressionCV",         "BisectingKMeans", |
| .venv/lib/python3.13/site-packages/sklearn/utils/multiclass.py | a40c0d0d78ae9784025ba5093f530918d2e0b0cf0904da3bbc3b55a627628501 | 585 | 3 |          * 'continuous': `y` is an array-like of floats that are not all           integers, and is 1d or a column vector.         * 'continuous-multioutput': `y` is a 2d array of floats that are      |
| .venv/lib/python3.13/site-packages/sklearn/utils/_mocking.py | 27bc131b324bdfae1c2c261e21fc4dc66b4f612bccfe029101c27b5aa16f46f8 | 420 | 2 |  class CheckingClassifier(ClassifierMixin, BaseEstimator):     """Dummy classifier to test pipelining and meta-estimators.      Checks some property of `X` and `y`in fit / predict. |
| .venv/lib/python3.13/site-packages/sklearn/utils/_set_output.py | 97cc4bf30925c92f2105d17ee8762bcb89bc1e54ab4508867b9f092236bbe7c0 | 461 | 1 |     """Safely call estimator.set_output and error if it not available.      This is used by meta-estimators to set the output for child estimators.      Parameters |
| .venv/lib/python3.13/site-packages/sklearn/utils/_metadata_requests.py | 6493985032fe623bc4966d632cbc132a7756cc85b59ffae2e7b4ea509ab1894d | 1629 | 19 | The only relevant public API for end users are the ``set_{method}_request`` methods, e.g. ``estimator.set_fit_request(sample_weight=True)``. However, third-party developers and users who implement cus |
| .venv/lib/python3.13/site-packages/sklearn/utils/metaestimators.py | 3af5cc6bab5ec7d1a8836c3368766aa0c7750d81c4a74dbe51baf3d9ccd75b21 | 164 | 1 | """Utilities for meta-estimators."""  # Authors: The scikit-learn developers |
| .venv/lib/python3.13/site-packages/sklearn/utils/extmath.py | 65f09dd40446f42d873f93acb36e3837dadfef26b0633fa148806c88f9055cf4 | 1396 | 33 |     ----------     x : array-like         The input array which could be either be a vector or a 2 dimensional array.      Returns |
| .venv/lib/python3.13/site-packages/sklearn/utils/_tags.py | 078c6634721d62555dac52359f98e2d7fa9961d55caff4967005fa0a4fd9367b | 356 | 2 |         `metric` or `affinity` or `kernel` parameter with value         'precomputed'. Its primary purpose is to support a         :term:`meta-estimator` or a cross validation procedure that         e |
| .venv/lib/python3.13/site-packages/sklearn/utils/validation.py | ae3c972e645e2d0ba00459e8f82ac540f0a670f474cc293875a95f4d63f0ccc2 | 2978 | 38 |   def check_memory(memory):     """Check that ``memory`` is joblib.Memory-like.  |
| .venv/lib/python3.13/site-packages/sklearn/utils/tests/test_pprint.py | 060f52bfcb8d3df3376c3b56ac879a8675da71dc864a396221e70fc870aa9937 | 696 | 14 |   class CountVectorizer(BaseEstimator):     def __init__(         self, |
| .venv/lib/python3.13/site-packages/sklearn/utils/tests/test_weight_vector.py | 79acb8fe67eb37bbe0d991a85e6674e9c53d08b41804928c47f74aeacd96ca27 | 26 | 12 | import pytest  from sklearn.utils._weight_vector import (     WeightVector32,     WeightVector64, |
| .venv/lib/python3.13/site-packages/sklearn/utils/tests/test_validation.py | f79068e17232df0e1f18c2caee86dcb3bdef58c147c158fc686613dc77f4a9dd | 2375 | 34 |     check_consistent_length,     check_is_fitted,     check_memory,     check_non_negative,     check_random_state, |
| .venv/lib/python3.13/site-packages/sklearn/utils/tests/test_chunking.py | e328238966eb2d6c6a81860a3d9d9a1ca47327ddcc0f7da411a8db8083b40bab | 74 | 13 |  @pytest.mark.parametrize(     ("row_bytes", "max_n_rows", "working_memory", "expected"),     [         (1024, None, 1, 1024), |
| .venv/lib/python3.13/site-packages/sklearn/utils/tests/test_class_weight.py | 2bebc2bd7cf91a5a8e97587a41d3d7446b3eb2f47cdaa9767c3ea77733e1b172 | 335 | 2 |     assert_array_almost_equal(sample_weight, [2.0, 2.0, 2.0, 1.0, 1.0, 1.0])      # Test with column vector of balanced classes     y = np.asarray([[1], [1], [1], [2], [2], [2]])     sample_weight = c |
| .venv/lib/python3.13/site-packages/sklearn/utils/tests/test_estimator_checks.py | ff93b361d8a380435041f2ffcc337c4d39ed0828d756af8c2edc2a1a7bc73a12 | 1666 | 1 |         np.sum(not_array)     # always returns True     assert np.may_share_memory(not_array, None)   |
| .venv/lib/python3.13/site-packages/sklearn/utils/tests/test_parallel.py | 95da87e8ca814d908ce842231f2492ce5c77c11c160f4fdc755e03cd0c2929c4 | 156 | 4 |   def get_working_memory():     return get_config()["working_memory"]  |
| .venv/lib/python3.13/site-packages/sklearn/utils/tests/test_extmath.py | ea5434de057ef020f4fb4dad254ede573e0e44d822d3459fc43b870e18f60f54 | 1122 | 9 | from sklearn.utils.extmath import (     _approximate_mode,     _deterministic_vector_sign_flip,     _incremental_mean_and_var,     _randomized_eigsh, |
| .venv/lib/python3.13/site-packages/sklearn/utils/_repr_html/tests/test_estimator.py | 12ec430d985c24347f5a56b0938bc532c5cf5e5a92d9752f648d685997dd0abe | 617 | 2 |         (dummy_function, "dummy_function"),         (partial(dummy_function, y=1), "dummy_function"),         (np.vectorize(partial(dummy_function, y=1)), re.escape("vectorize(...)")),     ], ) |
| .venv/lib/python3.13/site-packages/sklearn/utils/_test_common/instance_generator.py | dfa6fb92f1479ee0614725206f8f4e2cd61f51a1ca4746e173668fdcfc39e66f | 1294 | 39 |     RandomForestClassifier,     RandomForestRegressor,     RandomTreesEmbedding,     StackingClassifier,     StackingRegressor, |
| .venv/lib/python3.13/site-packages/sklearn/covariance/_shrunk_covariance.py | e25d87f453b331b75452c3956832dd7d68eadd7a22df97a970482e534b90cc9e | 823 | 2 |     block_size : int, default=1000         Size of blocks into which the covariance matrix will be split.         This is purely a memory optimization and does not affect results.      Returns |
| .venv/lib/python3.13/site-packages/sklearn/covariance/_robust_covariance.py | ab816ed7d7cb7eef4c238da27270f883543bdd06a9bf38f7d039e244486f276e | 875 | 1 |         try:             all_best_covariances = np.zeros((n_best_tot, n_features, n_features))         except MemoryError:             # The above is too big. Let's try with something much small       |
| .venv/lib/python3.13/site-packages/sklearn/covariance/tests/test_robust_covariance.py | 214b5a92459b2426ccef9de6a9b22cefae77e921d6678b8aeac817bfef6a2146 | 172 | 2 |     # The below line of code should raise an exception if the covariance matrix     # is singular. As a further test, since we have points in XYZ, the     # principle components (Eigenvectors) of thes |
| .venv/lib/python3.13/site-packages/sklearn/neural_network/_stochastic_optimizers.py | 95d656b882f5d15a47ab8b59d8fcc9ad3496cc04237696f3c7b88911b6c5c8cc | 288 | 4 |      beta_1 : float, default=0.9         Exponential decay rate for estimates of first moment vector, should be         in [0, 1)  |
| .venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py | ab529cbf71f881a411eaca3f3fbedea299e85869b6ebdc71b8233f2cf2c2222d | 1798 | 20 |  def _pack(coefs_, intercepts_):     """Pack the parameters into a single vector."""     return np.hstack([l.ravel() for l in coefs_ + intercepts_])  |
| .venv/lib/python3.13/site-packages/sklearn/neural_network/tests/test_mlp.py | 202613ca0d817f5e6ce273e1c41123ab9ad48f7f1df0382be5d036fcf0114c03 | 1095 | 4 |     y = y_digits_binary[:100]      alpha_vectors = []     alpha_values = np.arange(2)     absolute_sum = lambda x: np.sum(np.abs(x)) |
| .venv/lib/python3.13/site-packages/sklearn/feature_selection/_base.py | 97025ee90b9bef3c85e8b1c7ad3de36786366ac0b611bea83d60ba861da0c064 | 268 | 2 |         -------         support : array             An index that selects the retained features from a feature vector.             If `indices` is False, this is a boolean array of shape             [ |
| .venv/lib/python3.13/site-packages/sklearn/feature_selection/_variance_threshold.py | bb1ad359b2f3831fdbef85ca50698dc2b49630e8cfd0b0eaee45d40ff98b4316 | 142 | 1 |     See Also     --------     SelectFromModel: Meta-transformer for selecting features based on         importance weights.     SelectPercentile : Select features according to a percentile of the high |
| .venv/lib/python3.13/site-packages/sklearn/feature_selection/_rfe.py | 63cc34fca40b66d1402afbb643cb473401b014218037769b897ca3777f4747da | 1026 | 3 |      .. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., "Gene selection            for cancer classification using support vector machines",            Mach. Learn., 46(1-3), 389--422, 2002.  |
| .venv/lib/python3.13/site-packages/sklearn/feature_selection/_from_model.py | 85e43c88edfaeea28f518ac77f6320892c322176eda03bbf8b9ca1b76845f343 | 514 | 4 |  class SelectFromModel(MetaEstimatorMixin, SelectorMixin, BaseEstimator):     """Meta-transformer for selecting features based on importance weights.      .. versionadded:: 0.17 |
| .venv/lib/python3.13/site-packages/sklearn/feature_selection/_mutual_info.py | 7bcb49ebd19d66ee15829456f399e5c405eb63763823cc60ebcc5eefdcb6b834 | 581 | 5 |      y : array-like of shape (n_samples,)         Target vector.      discrete_features : {'auto', bool, array-like}, default='auto' |
| .venv/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py | 7678faccdbc62839671fb47e88e81ca3a6b45383a6081834ccbf13b49488e4ce | 1172 | 10 |         warnings.warn("Features %s are constant." % constant_features_idx, UserWarning)     f = msb / msw     # flatten matrix to vector in sparse case     f = np.asarray(f).ravel()     prob = special |
| .venv/lib/python3.13/site-packages/sklearn/feature_selection/_sequential.py | 73a76294f20704a3820184c66164964a0e1594212cc57ae0d8c60c3bb0df45a4 | 364 | 1 |         ----------         X : array-like of shape (n_samples, n_features)             Training vectors, where `n_samples` is the number of samples and             `n_features` is the number of predic |
| .venv/lib/python3.13/site-packages/sklearn/feature_selection/tests/test_chi2.py | 73a2f772cf4362e94c3544e39d9268ed5511b9c8e15072d8cc6d8469113d3757 | 94 | 2 | def test_chi2_coo(coo_container):     # Check that chi2 works with a COO matrix     # (as returned by CountVectorizer, DictVectorizer)     Xcoo = coo_container(X)     mkchi2(k=2).fit_transform(Xcoo, y |
| .venv/lib/python3.13/site-packages/sklearn/feature_selection/tests/test_mutual_info.py | 2320928e35cf9107b3f75e5c8edb211258fff714151d8f386b96a20893053f8b | 271 | 2 | def test_compute_mi_dd():     # In discrete case computations are straightforward and can be done     # by hand on given vectors.     x = np.array([0, 1, 1, 0, 0])     y = np.array([1, 0, 0, 0, 1]) |
| .venv/lib/python3.13/site-packages/sklearn/inspection/_permutation_importance.py | 5ea8e300144d0d2710500a09a2ce6186bb86b9113511d2cb653c9cd7904f6e5a | 314 | 1 |     # parallelism. Furthermore, making a copy is also useful when the joblib     # backend is 'loky' (default) or the old 'multiprocessing': in those cases,     # if X is large it will be automaticall |
| .venv/lib/python3.13/site-packages/sklearn/inspection/tests/test_permutation_importance.py | c03b7be7fb648e90cc7df91c627ee3cfa59e299ae45e0b0186d00eea701aed66 | 541 | 3 |      # The actually check that parallelism does not impact the results     # either with shared memory (threading) or without isolated memory     # via process-based parallelism using the default back |
| .venv/lib/python3.13/site-packages/sklearn/svm/_base.py | 2d464769a4e21d3010ff74cb3b4290543a63da3e32c82938b24090d3eaac5a69 | 1263 | 33 |   def _one_vs_one_coef(dual_coef, n_support, support_vectors):     """Generate primal coefficients from dual coefficients     for the one-vs-one multi class LibSVM in the case |
| .venv/lib/python3.13/site-packages/sklearn/svm/_bounds.py | fc1576d7adf2b3ce52617005c384a817cd2b902a72111a9dd1ddcbf23238696e | 99 | 4 |     ----------     X : {array-like, sparse matrix} of shape (n_samples, n_features)         Training vector, where `n_samples` is the number of samples and         `n_features` is the number of featur |
| .venv/lib/python3.13/site-packages/sklearn/svm/__init__.py | 50a8fc074ba81bbd61d1247999c14f4f13e9f38a5e68a1237f541641a530c120 | 22 | 1 | """Support vector machine algorithms."""  # See http://scikit-learn.sourceforge.net/modules/svm.html for complete |
| .venv/lib/python3.13/site-packages/sklearn/svm/_classes.py | edda43eaa18a5e11624c8c3526f03b9bff4e6f16d0654bf2ae82dfcb9ba1dfa6 | 1790 | 91 |  class LinearSVC(LinearClassifierMixin, SparseCoefMixin, BaseEstimator):     """Linear Support Vector Classification.      Similar to SVC with parameter kernel='linear', but implemented in terms of |
| .venv/lib/python3.13/site-packages/sklearn/svm/tests/test_sparse.py | ed47a58a9ea3acaab20e3dc14a2a3d456797ce820347b42db386c60782e37a89 | 497 | 7 |         X_test_dense = X_test     sparse_svm.fit(X_train, y_train)     assert sparse.issparse(sparse_svm.support_vectors_)     assert sparse.issparse(sparse_svm.dual_coef_)     assert_allclose(dense_s |
| .venv/lib/python3.13/site-packages/sklearn/svm/tests/test_svm.py | 8b40d0ad3fe0c895afb70cc9a41dd6ee72e48ae7c98daef144ebd64cdf28b6a7 | 1441 | 14 | """ Testing for Support Vector Machine module (sklearn.svm)  TODO: remove hard coded numerical results when possible |
| .venv/lib/python3.13/site-packages/sklearn/manifold/_locally_linear.py | a2d3f66b6e58e9381ff7922e85007eadf267654ceb30f1c262e3854ec86ee571 | 880 | 60 | """Locally Linear Embedding"""  # Authors: The scikit-learn developers |
| .venv/lib/python3.13/site-packages/sklearn/manifold/_t_sne.py | 55c7b6da7470db15837818842ea8c0faf335ee994f52a6d1165e242b3da96041 | 1185 | 31 |     distances : sparse matrix of shape (n_samples, n_samples)         Distances of samples to its n_neighbors nearest neighbors. All other         distances are left to zero (and are not materialized  |
| .venv/lib/python3.13/site-packages/sklearn/manifold/__init__.py | 825e1feeb3870edae9398ad06f7790794ad1453d98e53669c2b8037c6f9dd2e1 | 23 | 10 | """Data embedding techniques."""  # Authors: The scikit-learn developers |
| .venv/lib/python3.13/site-packages/sklearn/manifold/_isomap.py | 87e5fa6e23594b91b7dfed6d8544a7faa9c3b11c60d3d92a32ee610f8f56855e | 443 | 26 |  class Isomap(ClassNamePrefixFeaturesOutMixin, TransformerMixin, BaseEstimator):     """Isomap Embedding.      Non-linear dimensionality reduction through Isometric Mapping |
| .venv/lib/python3.13/site-packages/sklearn/manifold/_mds.py | fd469841529650016cfcdb864b7bd82ffe7c004ee0a85bd7d28a2c6f57a34857 | 715 | 21 |         Number of dimensions in which to immerse the dissimilarities. If an         ``init`` array is provided, this option is overridden and the shape of         ``init`` is used to determine the dim |
| .venv/lib/python3.13/site-packages/sklearn/manifold/_spectral_embedding.py | e5aad7372319c998445d075da09807eae6a15221f121ebb0f7eb741d985e9166 | 777 | 71 | """Spectral Embedding."""  # Authors: The scikit-learn developers |
| .venv/lib/python3.13/site-packages/sklearn/manifold/tests/test_isomap.py | 5a5e2fa04fbb651a4ae984ba24ac84a4085c700d11781946c8b354fa9e214167 | 349 | 11 |      if n_neighbors is not None:         G_iso = neighbors.kneighbors_graph(clf.embedding_, n_neighbors, mode="distance")     else:         G_iso = neighbors.radius_neighbors_graph( |
| .venv/lib/python3.13/site-packages/sklearn/manifold/tests/test_mds.py | 43beef19f1f5a41fcb022618a0a480b7b8da04669b014b47c82c2f307984cf49 | 235 | 2 | @pytest.mark.parametrize("normalized_stress", [True, False]) def test_returned_stress(normalized_stress):     # Test that the final stress corresponds to the final embedding     # (non-regression test |
| .venv/lib/python3.13/site-packages/sklearn/manifold/tests/test_t_sne.py | c593ceec9fbeaf69b7fdba8c3f839d9f3dff035ea69b1bb9036697fc1c788a7e | 1188 | 5 |     tsne = TSNE(n_components=1, perplexity=4)     X = random_state.randn(5, 2)     X_embedded = tsne.fit(X).embedding_     assert np.all(np.isfinite(X_embedded))  |
| .venv/lib/python3.13/site-packages/sklearn/manifold/tests/test_spectral_embedding.py | 62f9ac148bcb60666a9f61525e14b153cd0ffef998bf8915bfbb11e230e8b884 | 504 | 67 | from sklearn.cluster import KMeans from sklearn.datasets import make_blobs from sklearn.manifold import SpectralEmbedding, _spectral_embedding, spectral_embedding from sklearn.manifold._spectral_embed |
| .venv/lib/python3.13/site-packages/sklearn/manifold/tests/test_locally_linear.py | cb1b14b89eefce6d95c622e2d5fb998f32024bfd265ebc0889c2472c2efd7833 | 172 | 16 |      n_components = 2     clf = manifold.LocallyLinearEmbedding(         n_neighbors=5, n_components=n_components, random_state=rng     ) |
| .venv/lib/python3.13/site-packages/sklearn/mixture/_gaussian_mixture.py | c49e431bb0caac3fdcc7ad457a90996897ac6d6bae9a101700c8df06b4c5c6ad | 935 | 3 |  def _check_precision_positivity(precision, covariance_type):     """Check a precision vector is positive-definite."""     if np.any(np.less_equal(precision, 0.0)):         raise ValueError("'%s preci |
| .venv/lib/python3.13/site-packages/sklearn/preprocessing/_data.py | 1255040a0eb9c99f58775d55cf34f675cf61539f7c0a0dd0d6a36cb1f0da1e15 | 3707 | 14 |     This implementation will refuse to center scipy.sparse matrices     since it would make them non-sparse and would potentially crash the     program with memory exhaustion problems.      Instead th |
| .venv/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py | 182ad858c63cf28c26d6b332250006c052a502e483740b5b236a3c8e7493db97 | 1699 | 1 |       encoding of the categorical features.     TargetEncoder : Encodes categorical features using the target.     sklearn.feature_extraction.DictVectorizer : Performs a one-hot encoding of       dict |
| .venv/lib/python3.13/site-packages/sklearn/preprocessing/_label.py | f74cd79892e4f5c1504a46b92bdf9067a58ce22036fddc6d72d0645cc2f5803f | 964 | 2 |            [0, 0, 0, 1]])      Binary targets transform to a column vector      >>> lb = LabelBinarizer() |
| .venv/lib/python3.13/site-packages/sklearn/preprocessing/tests/test_data.py | be1e676eb56a0a37e0250367694cd46a7aa1cde01909969daaa433ce7a9d5e17 | 2694 | 1 | def test_quantile_transform_subsampling():     # Test that subsampling the input yield to a consistent results We check     # that the computed quantiles are almost mapped to a [0, 1] vector where     |
| .venv/lib/python3.13/site-packages/sklearn/frozen/_frozen.py | 84a1a7edc4d3884e836f4701a1e8540b244d6d170e39b44f78133b5745ff5c2e | 167 | 1 |     """Estimator that wraps a fitted estimator to prevent re-fitting.      This meta-estimator takes an estimator and freezes it, in the sense that calling     `fit` on it has no effect. `fit_predict` |
| .venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py | e1b92a446ca21961d2844f58ee8bad7e6bdbc732edb267039b663193f21fdd31 | 1997 | 8 |             Equal to list(self)[ind]         """         # This is used to make discrete sampling without replacement memory         # efficient.         for sub_grid in self.param_grid: |
| .venv/lib/python3.13/site-packages/sklearn/model_selection/_classification_threshold.py | 35a29aff27377e8deb9f8f67c529939b4fd9606ce7d172bd023226cfbf0fdb0b | 890 | 4 |         ----------         X : {array-like, sparse matrix} of shape (n_samples, n_features)             Training vectors, where `n_samples` is the number of samples and             `n_features` is the |
| .venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py | 8053f3d7ea3f9a43a6152b6f3110639ebe36123013b365ea0622cc8121b2bcde | 2531 | 7 |         Controls the number of jobs that get dispatched during parallel         execution. Reducing this number can be useful to avoid an         explosion of memory consumption when more jobs get dis |
| .venv/lib/python3.13/site-packages/sklearn/model_selection/_plot.py | 2762e7b4f4a0c259034d80e4921d569fffd965abd852ea7ec9faa483b6ff308c | 886 | 2 |         pre_dispatch : int or str, default='all'             Number of predispatched jobs for parallel execution (default is             all). The option can reduce the allocated memory. The str can   |
| .venv/lib/python3.13/site-packages/sklearn/model_selection/_search_successive_halving.py | 02e0d24797046cebebd6b00c3924f57f50ef3cd89b03e3f367208361dd17c11e | 1096 | 1 |          X : array-like, shape (n_samples, n_features)             Training vector, where `n_samples` is the number of samples and             `n_features` is the number of features.  |
| .venv/lib/python3.13/site-packages/sklearn/model_selection/tests/test_search.py | 23d2ae0afb7b377d0232211da2e7b706f322c6243a26d3d242427b5ff629f934 | 2967 | 2 | from sklearn.exceptions import FitFailedWarning from sklearn.experimental import enable_halving_search_cv  # noqa: F401 from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.impute  |
| .venv/lib/python3.13/site-packages/sklearn/model_selection/tests/test_classification_threshold.py | 759fdf5a20c9762cfd0c56b7646047d6ee7e7258de5eb398e43622c71c39acfe | 619 | 1 |     # create a dataset and repeat twice the sample of class #0     X_repeated, y_repeated = np.vstack([X, X[y == 0]]), np.hstack([y, y[y == 0]])     # create a sample weight vector that is equivalent  |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/_nmf.py | 558f6108e0fbdd7bc6d3a2bddf82e2699ca452918482efdc5e9fbef71274f840 | 2410 | 18 |     """Dot product-based Euclidean norm implementation.      See: http://fa.bianp.net/blog/2011/computing-the-vector-norm/      Parameters |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/_sparse_pca.py | 663870cdee5b9cd04e9e653e6812bc2847126c38f88510d267e07c082f947e26 | 549 | 5 |         ----------         X : array-like of shape (n_samples, n_features)             Training vector, where `n_samples` is the number of samples             and `n_features` is the number of feature |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/_kernel_pca.py | f9c1ec6604e5fb1102a1b9d882d5149d04369eb079a04b4556144717f8168d60 | 578 | 37 |         If True, input X is copied and stored by the model in the `X_fit_`         attribute. If no further changes will be done to X, setting         `copy_X=False` saves memory by storing a referenc |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/_incremental_pca.py | e9d5d7488e4eb264d7cbc3aef0a85ac90c1fea7eb06afa838856b8cfc0b67c38 | 427 | 10 |      Linear dimensionality reduction using Singular Value Decomposition of     the data, keeping only the most significant singular vectors to     project the data to a lower dimensional space. The in |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/_fastica.py | 6ab6916425578740701ec1afe2fa7da74ec3a1d0ea4d2ac63e12b3efba055b05 | 805 | 9 |     s = np.clip(s, a_min=np.finfo(W.dtype).tiny, a_max=None)      # u (resp. s) contains the eigenvectors (resp. square roots of     # the eigenvalues) of W * W.T     return np.linalg.multi_dot([u * ( |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/_pca.py | 563b9821194c63e2bbf616ab92d863cdc8052fbae59242cea00c0d7c4088959c | 858 | 11 |      whiten : bool, default=False         When True (False by default) the `components_` vectors are multiplied         by the square root of n_samples and then divided by the singular values          |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/_truncated_svd.py | 9fe23f1ebc98fc0bf27050d95adf30296119f2719433c05962e6011ed6faaa3d | 323 | 2 |      In particular, truncated SVD works on term count/tf-idf matrices as     returned by the vectorizers in :mod:`sklearn.feature_extraction.text`. In     that context, it is known as latent semantic  |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/_dict_learning.py | ac8cb881c2da638df8867f63c1c6105d30ef9b4101d402e027a701a33f260d0d | 2330 | 17 |      errors : array         Vector of errors at each iteration.      n_iter : int |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/_lda.py | a76eb1dd9366ce6d5b41e2242531b162b5a251180c748fade13d84dff9df5ce3 | 960 | 1 |     >>> from sklearn.datasets import make_multilabel_classification     >>> # This produces a feature matrix of token counts, similar to what     >>> # CountVectorizer would produce on text.     >>> X |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/tests/test_dict_learning.py | 6671bd662eed715924f2dd63c078e51d5a8cb76f996b1d3e47d0a8ef3818defa | 989 | 1 |     n_components, n_features = 40, 64     init_dict = rng.rand(n_components, n_features)     # Ensure that `data` is >2M. Joblib memory maps arrays     # if they are larger than 1MB. The 4 accounts fo |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/tests/test_truncated_svd.py | 65527f26ff875fedd8339b83678ac0fd4e923b10ba9114060887bebf1020623d | 213 | 1 |     )      # Compare to the 2-norms of the score vectors     assert_allclose(         pca.singular_values_, np.sqrt(np.sum(X_pca**2.0, axis=0)), rtol=1e-2 |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/tests/test_kernel_pca.py | f21d7b5b3cac798c70c8c6d1d4b23078fff217a09792821811b2c9058b68f53f | 567 | 2 |      # comparison between the non-centered and centered versions     assert_array_equal(kpca.eigenvectors_, kpca_c.eigenvectors_)     assert_array_equal(kpca.eigenvalues_, kpca_c.eigenvalues_)  |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/tests/test_incremental_pca.py | 39ada2c29779ddf9ce16c557fd4ebee780058d10d2f20b3ce1a9699aa30ac0e6 | 488 | 1 |     )      # Compare to the 2-norms of the score vectors     assert_array_almost_equal(         pca.singular_values_, np.sqrt(np.sum(X_pca**2.0, axis=0)), 12 |
| .venv/lib/python3.13/site-packages/sklearn/decomposition/tests/test_pca.py | 99a76292bfd975b6c6c4c251a15de66ccc66dc871a2dcbd7ada01ffb8baf305c | 1155 | 3 |     )     # Scale the data + vary the column means     scale_vector = random_state.random(X.shape[1]) * scale     X = X.multiply(scale_vector)  |
| .venv/lib/python3.13/site-packages/sklearn/cross_decomposition/_pls.py | 7cfc82a66785e862b344055ac3065ce057dae7a476eb9dba0c3f4e512dab49f2 | 1098 | 28 |   def _get_first_singular_vectors_power_method(     X, y, mode="A", max_iter=500, tol=1e-06, norm_y_weights=False ): |
| .venv/lib/python3.13/site-packages/sklearn/cross_decomposition/tests/test_pls.py | 34ae1b2ede18c1e8099f20d1ec5ed7b8dc0f790e1647e02a5d5bded48e6f9046 | 678 | 4 | from sklearn.cross_decomposition._pls import (     _center_scale_xy,     _get_first_singular_vectors_power_method,     _get_first_singular_vectors_svd,     _svd_flip_1d, |
| .venv/lib/python3.13/site-packages/sklearn/neighbors/_classification.py | 4d4194c408e712fc16ac5be0d9ba82f568fc7d66d092f227233f7068a68321ec | 920 | 6 |     leaf_size : int, default=30         Leaf size passed to BallTree or KDTree.  This can affect the         speed of the construction and query, as well as the memory         required to store the tr |
| .venv/lib/python3.13/site-packages/sklearn/neighbors/_base.py | 6686ee9f3f36ae7ab9b572a90931e689345e8d5ab6b1879361fb2ea15990d9e5 | 1405 | 1 |                         warnings.warn(                             (                                 "A column-vector y was passed when a "                                 "1d array was expected. Plea |
| .venv/lib/python3.13/site-packages/sklearn/neighbors/_graph.py | 4af5a9cdf907fb9c5c1bc4e39154f47153586d07ff903b413c1d460be88d7c3c | 705 | 6 |     leaf_size : int, default=30         Leaf size passed to BallTree or KDTree.  This can affect the         speed of the construction and query, as well as the memory         required to store the tr |
| .venv/lib/python3.13/site-packages/sklearn/neighbors/_regression.py | af974a83134d8f08dd7ee0f3b0e39e5ec43b4bbb6fdef88f5a31117818eb12a8 | 514 | 6 |     leaf_size : int, default=30         Leaf size passed to BallTree or KDTree.  This can affect the         speed of the construction and query, as well as the memory         required to store the tr |
| .venv/lib/python3.13/site-packages/sklearn/neighbors/_nearest_centroid.py | 6bce635f4b7acfae2d23a69f1f34aa8d6d2b074bb084005057d0d4d743b42c84 | 360 | 3 |     Notes     -----     When used for text classification with tf-idf vectors, this classifier is     also known as the Rocchio classifier.  |
| .venv/lib/python3.13/site-packages/sklearn/neighbors/_unsupervised.py | 39716b1a387c6a77e21047e5324e9f9998f4b19e887b827ecdf02b4c485542f3 | 180 | 3 |     leaf_size : int, default=30         Leaf size passed to BallTree or KDTree.  This can affect the         speed of the construction and query, as well as the memory         required to store the tr |
| .venv/lib/python3.13/site-packages/sklearn/neighbors/_lof.py | a05774d4db7d6ded41374f68b1b678c5f672d1e8454cddea9ebe7841aa4b4e63 | 519 | 4 |     leaf_size : int, default=30         Leaf is size passed to :class:`BallTree` or :class:`KDTree`. This can         affect the speed of the construction and query, as well as the memory         requ |
| .venv/lib/python3.13/site-packages/sklearn/neighbors/tests/test_neighbors_pipeline.py | 0b0965c52e13f5c3f6bad63ec6eba2dc6860b63441900efbe7d6f24b82dd4375 | 257 | 5 | from sklearn.cluster.tests.common import generate_clustered_data from sklearn.datasets import make_blobs from sklearn.manifold import TSNE, Isomap, SpectralEmbedding from sklearn.neighbors import (    |
| .venv/lib/python3.13/site-packages/sklearn/neighbors/tests/test_kd_tree.py | e1c1365c93b4ba6b969d63d096e38c47d8df7892835e61444e8c2c2c49702822 | 101 | 1 |     tree = BinarySearchTree(X, leaf_size=2)      # Call Parallel with max_nbytes=1 to trigger readonly memory mapping that     # use to raise "ValueError: buffer source array is read-only" in a previo |
| .venv/lib/python3.13/site-packages/sklearn/neighbors/tests/test_neighbors.py | 622e36937cf9dbf429f7a9c8527b801cf01b37885dd321e51eb64cd73a9a5c7d | 2504 | 1 |      def _weights(dist):         return np.vectorize(lambda x: 0 if x > 0.5 else 1)(dist)      est = neighbors.KNeighborsClassifier(n_neighbors=3, weights=_weights) |
| .venv/lib/python3.13/site-packages/sklearn/neighbors/tests/test_ball_tree.py | 869a09885a4cac6c70d0512177e2a084ef335ada276aa4abd4981b281eec74dd | 201 | 1 |      X = np.ones((5, 2))     msg = "Custom distance function must accept two vectors and return a float."     with pytest.raises(TypeError, match=msg):         BallTreeImplementation(X, metric=wrong_r |
| .venv/lib/python3.13/site-packages/importlib_resources/tests/util.py | 3cac9b184c82a39de632eec0fb9bc2ea7d1ede773d47c0d2d8db6f3be242cb16 | 309 | 15 |   class MemorySetup(ModuleSetup):     """Support loading a module in memory."""  |
| .venv/lib/python3.13/site-packages/importlib_resources/tests/test_functional.py | 077705585ced4a4321e18e7c33239ec7f95c128a083d1f9ecd3680f71cc8e98e | 268 | 2 |   class FunctionalAPITest_StringAnchor_Memory(     StringAnchorMixin,     FunctionalAPIBase, |
| .venv/lib/python3.13/site-packages/importlib_resources/tests/test_util.py | 568b4b35b9e03b2160d3714a553cc864a7781b3e143be74c12bd06faf1cc8ae2 | 30 | 8 | import unittest  from .util import MemorySetup, Traversable   |
| .venv/lib/python3.13/site-packages/importlib_resources/tests/test_path.py | a2b11361b986c983605c0f03b258fd30cdd78c6503456f2ee1d261201cb4a9d5 | 64 | 2 |   class PathMemoryTests(PathTests, unittest.TestCase):     def setUp(self):         file = io.BytesIO(b'Hello, UTF-8 world!\n') |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc8692.py | 78b2dba71ec275c0922f7320a20135ed6bcfa15dd55be2b56e8e9dab8991a1e8 | 80 | 3 | from pyasn1.type import univ  from pyasn1_modules import rfc4055 from pyasn1_modules import rfc5280 from pyasn1_modules import rfc5480 |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc6955.py | 14155bf0ba4728c663477c0e26d9be04f6e2e443224681ae516878d6bd6ca025 | 109 | 1 | # License: http://snmplabs.com/pyasn1/license.html # # Diffie-Hellman Proof-of-Possession Algorithms # # ASN.1 source from: |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4108.py | f88eb767472b9ff125bebf399d26bd06a025471edc2097c46fd22d3c392af096 | 351 | 2 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4108.txt # https://www.rfc-editor.org/errata_search.php?rfc=4108 # |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc7292.py | c0e4630c60ff6aa1e8ba3076c2eea736b123613c3754eff10e9f90c745562db7 | 358 | 4 | pkcs_12PbeIds = _OID(pkcs_12, 1)  pbeWithSHAAnd128BitRC4 = _OID(pkcs_12PbeIds, 1)  pbeWithSHAAnd40BitRC4 = _OID(pkcs_12PbeIds, 2) |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc3779.py | c7c1d828609a18edc1a2109110741411ad6860602b5880b62743dfb7188fae32 | 138 | 3 |   # Autonomous System Identifier Delegation Extension  id_pe_autonomousSysIds = univ.ObjectIdentifier('1.3.6.1.5.5.7.1.8') |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc1157.py | 24191b243ecb732187e2fcf16085e0030e7c5f5e56c7a46b2f9f4d3012ea6115 | 127 | 1 |     componentType = namedtype.NamedTypes(         namedtype.NamedType('enterprise', univ.ObjectIdentifier()),         namedtype.NamedType('agent-addr', rfc1155.NetworkAddress()),         namedtype.Nam |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc7191.py | b8cb01cc9f75ebbc31b223d80d052765015514d7e05319c2c1135e2a75f13463 | 262 | 1 |     ('unsupportedParameters', 15),     ('signatureFailure', 16),     ('insufficientMemory', 17),     ('incorrectTarget', 23),     ('missingSignature', 29), |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc8418.py | 79308f4ce9bab7e4721dde8f968c0ba200f350eef695175d11260b89288ea42d | 37 | 1 | # License: http://snmplabs.com/pyasn1/license.html # # Elliptic Curve Diffie-Hellman (ECDH) Key Agreement Algorithm #   with X25519 and X448 # |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc3560.py | dd477bb18ece015ff8286367fe1839c596e5124c44fc82c7d643f64c8f8a6d9c | 75 | 26 | #  from pyasn1_modules import rfc4055  id_sha1 = rfc4055.id_sha1 |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4211.py | 4c7aabf67e0f1a0d2354c9a3f24f5b84acdbe63ec86a9c2d0629e15900272fd9 | 397 | 1 | # # ASN.1 source from: # http://www.ietf.org/rfc/rfc4211.txt # from pyasn1.type import char |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4334.py | 43e7dc624b2bba7028d6dd3b1c4da39b95a54201407f9a37f6eb697a5d198dc2 | 76 | 1 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4334.txt #  |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc5934.py | efbcfde9278fe2233647a465e7e571ece684340f1942fceb7e10d5651cbd96a9 | 787 | 2 |     namedtype.NamedType('communities', CommunityIdentifierList().subtype(         implicitTag=tag.Tag(tag.tagClassContext, tag.tagFormatSimple, 2))),     namedtype.NamedType('allModules', univ.Null(). |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc3820.py | 855ef452989b99c4b31f8fd39dc1cf3c7b30e0eaed16331b7a94b812f89e40b9 | 66 | 1 | # License: http://snmplabs.com/pyasn1/license.html # # Diffie-Hellman Key Agreement # # ASN.1 source from: |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4043.py | 3963e05737cadc7b39b0d4094aa5019089e182292ffb1d79fb12d2837d31c0d1 | 44 | 1 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4043.txt #  |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4387.py | 0b296f11046957f53dbd58afcd32783d50e3644040292fba4eb555a1ea519361 | 24 | 1 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4387.txt #  |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4073.py | 6c756cb10137c97c1eb5eb354cf5804f7d1484e1229c78fcbc405a623582db88 | 60 | 1 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4073.txt #  |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4210.py | de7761b09e72171dd952f50ff040de26152295214075e2fc6da4f9b4a3f2222d | 804 | 1 | # License: http://snmplabs.com/pyasn1/license.html # # Certificate Management Protocol structures as per RFC4210 # # Based on Alex Railean's work |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc6031.py | 5f6723372567ad7dc6db31bb903e11abffe417af9fb669a7a879424090c2b8c5 | 470 | 5 |   id_pskc_timeDrift = _OID(id_pskc, 19)  class at_pskc_timeDrift(univ.Integer): |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc7906.py | 9837f5a56c1536509c1107ecc1486d4034ad027c12fb9c5b66d8cc95f9d62dd2 | 737 | 4 |  from pyasn1_modules import rfc2634 from pyasn1_modules import rfc4108 from pyasn1_modules import rfc5280 from pyasn1_modules import rfc5652 |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc5697.py | 696aa2f90059ac4afa2396c8a6945eb7875112a145f04d6d3b606f69904638e1 | 71 | 2 |  from pyasn1_modules import rfc5280 from pyasn1_modules import rfc4055   |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4357.py | b69659fbac43b7fbbc698af8a9bc1ee542714fe25518e8a1bb13da7a60750173 | 478 | 1 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4357.txt # https://www.rfc-editor.org/errata/eid5927 # https://www.rfc-editor.org/errata/eid5928 |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc3537.py | 2342d54a7b32c8c393349c8b75afbc4fdf094a162d0e4d77c8f77f6e6ad9dce4 | 35 | 1 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4010.txt #  |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc8360.py | 4f8b18ea8d952d53e767db38c89f0fcdf540f18eb49defb529c54db70e72b7eb | 45 | 3 |   # Autonomous System Identifier Delegation Extension V2  id_pe_autonomousSysIds_v2 = univ.ObjectIdentifier('1.3.6.1.5.5.7.1.29') |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4055.py | 7f6ae5c9a05e361976f3b6ffa8b2ec3698e0c316115730606ce1f6f149c96704 | 259 | 1 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4055.txt # from pyasn1.type import namedtype |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4010.py | 276169b4942fd37a3c37e9a8eef27dab9fc0f6faf0124d1cae9bc09179951fbe | 59 | 1 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4010.txt #  |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc5480.py | 1b305380a43af15f8bf90cb4481ac240c82a47998617b53bdee5e50737d5d899 | 191 | 2 |   # What can be imported from rfc4055.py ?  from pyasn1.type import namedtype |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc8017.py | a703d149c86f32d5ee6ad7022d42c7baf48bf2400f12a902e1a2098dde6f100a | 154 | 17 | from pyasn1_modules import rfc2437 from pyasn1_modules import rfc3447 from pyasn1_modules import rfc4055 from pyasn1_modules import rfc5280  |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc6664.py | 9eaf05e700de3b8f45a01195403c7c8afbe0fc6b2e6dd59ad5ba5933fe344e6b | 148 | 5 | from pyasn1_modules import rfc5751 from pyasn1_modules import rfc5480 from pyasn1_modules import rfc4055 from pyasn1_modules import rfc3279  |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4683.py | 5f43fa967df866c62409ea601891fc031521a06f394ee2e87f9e632080cc35e2 | 73 | 1 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4683.txt # https://www.rfc-editor.org/errata/eid1047 # |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4476.py | 9255a6305660fda32a9951ae6048d741adefde22a5a2992132e981a0b766613e | 94 | 1 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4476.txt #  |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc8410.py | 9ed78ac9329c230565821d6a525fbc904eb790a1be2a05ad2eb7c5f764d6cb24 | 44 | 2 | from pyasn1.type import univ from pyasn1_modules import rfc3565 from pyasn1_modules import rfc4055 from pyasn1_modules import rfc5280  |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4491.py | 2e97a3d7b4f931f176e459df5a8d4216a981616413252e164121a48b984282c3 | 45 | 10 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4491.txt #  |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc5035.py | c60c3dced00cfdb24a948502ce78b6cdc13fcf712b12e5e95913c9a57235284c | 200 | 2 |  from pyasn1_modules import rfc2634 from pyasn1_modules import rfc4055 from pyasn1_modules import rfc5652 from pyasn1_modules import rfc5280 |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc8018.py | f3fe3dc40def10e76519485ab30db14d4bf84e91c1be346ea289cc4ff9354d39 | 261 | 2 |   # Initialization Vector for AES: OCTET STRING (SIZE(16))  class AES_IV(univ.OctetString): |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4985.py | a160811b7b649c52d424e786e1a285ec9ae4038a8c8cfc891464e77fbc663ddf | 50 | 1 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4985.txt #  |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc3161.py | f64cff4ef439fcea413ee1d00c08765b2a8a78e4e18313eaf04e62041fac369f | 143 | 2 | from pyasn1.type import useful  from pyasn1_modules import rfc4210 from pyasn1_modules import rfc5280 from pyasn1_modules import rfc5652 |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc4490.py | 67d9e49ed49273d9e958706357d73ce90196fe2b6f1984389798c93b46b61820 | 114 | 9 | # # ASN.1 source from: # https://www.rfc-editor.org/rfc/rfc4490.txt #  |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc7030.py | b7eb36043c97dd9936b32fe331097e3f623635714e9fb86ebb4c0570cfb6b2ab | 67 | 1 | # License: http://snmplabs.com/pyasn1/license.html # # Enrollment over Secure Transport (EST) # # ASN.1 source from: |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc2631.py | 1deb789c73d5163ea8125a4400d624290ba29dc51ad26b3948eb7de0f87c8e1b | 38 | 1 | # License: http://snmplabs.com/pyasn1/license.html # # Diffie-Hellman Key Agreement # # ASN.1 source from: |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc6402.py | 92c83a62c69c4bdbc903339ba8538f442a1ef26a72bd10dbe37674bfe40a8673 | 629 | 4 | from pyasn1.type import useful  from pyasn1_modules import rfc4211 from pyasn1_modules import rfc5280 from pyasn1_modules import rfc5652 |
| .venv/lib/python3.13/site-packages/pyasn1_modules/rfc2876.py | c96c7ed12fcb9bea86684989e1edc3672ec62a9bf11537f4ad055f9f3fe47bef | 57 | 1 | class Skipjack_Parm(univ.Sequence):     componentType = namedtype.NamedTypes(         namedtype.NamedType('initialization-vector', univ.OctetString())     )  |
| .venv/lib/python3.13/site-packages/httpx/_api.py | aff660b388c8a5c3c92ea2b975b6d26b2aa8fe254c2856b164277ea0e1f12c4b | 439 | 1 |     """     Alternative to `httpx.request()` that streams the response body     instead of loading it into memory at once.      **Parameters**: See `httpx.request`. |
| .venv/lib/python3.13/site-packages/httpx/_multipart.py | 28e1c465997aa28860f663da2b2caedf8e6aab5ac92e0df94d41b7600cd70776 | 301 | 1 |         file_length = peek_filelike_length(self.file)          # If we can't determine the filesize without reading it into memory,         # then return `None` here, to indicate an unknown file lengt |
| .venv/lib/python3.13/site-packages/httpx/_client.py | c43f941baefe58c91e96d00039e1868fe719d91453026d7db1647194563bff8d | 2020 | 5 | logger = logging.getLogger("httpx")  USER_AGENT = f"python-httpx/{__version__}" ACCEPT_ENCODING = ", ".join(     [key for key in SUPPORTED_DECODERS.keys() if key != "identity"] |
| .venv/lib/python3.13/site-packages/httpx/_urlparse.py | 640987e3b38d7e4c6bae3f8f3d88467a21e36fa0232824be00d58837838bfca6 | 528 | 1 |              # Ensure that keyword arguments match as a valid regex.             if not COMPONENT_REGEX[key].fullmatch(value):                 raise InvalidURL(f"Invalid URL component '{key}'")  |
| .venv/lib/python3.13/site-packages/httpx/_models.py | e3ffc6bb2bf580bc6e6428708a6f247d036220e709f5a72b785392babbd97e6b | 1278 | 2 |             self._content = b"".join(self.stream)             if not isinstance(self.stream, ByteStream):                 # If a streaming request has been read entirely into memory, then              |
| .venv/lib/python3.13/site-packages/httpx/_utils.py | fd355ea802afc4990a1ddcfb74579be2cd0b66a41781e1645d281f88704aff5a | 243 | 1 |     """     Given a file-like stream object, return its length in number of bytes     without reading it into memory.     """     try: |
| .venv/lib/python3.13/site-packages/joblib/disk.py | d49e6184cb023f92c35bae65b93b40ad4c6c300251acf07ac314967fa19e067b | 132 | 1 |  def memstr_to_bytes(text):     """Convert a memory text to its value in bytes."""     kilo = 1024     units = dict(K=kilo, M=kilo**2, G=kilo**3) |
| .venv/lib/python3.13/site-packages/joblib/memory.py | bdaef3586f6cfd7e9e13e0a6d63ba7ac7f90c0a4e782e8a7e5c109221517a3df | 1243 | 17 | # the data store. # # This would enable creating 'Memory' objects with a different logic for # pickling that would simply span a MemorizedFunc with the same # store (or do we want to copy it to avoid  |
| .venv/lib/python3.13/site-packages/joblib/func_inspect.py | 6e19bf1a905edc7fc39b0e6b8a9ccfe416a503ac1babb645237484b8041b7de9 | 380 | 1 |   def format_call(func, args, kwargs, object_name="Memory"):     """Returns a nicely formatted statement displaying the function     call with the given arguments. |
| .venv/lib/python3.13/site-packages/joblib/__init__.py | 22ff5bb9707658f0c9a63093d64b910b37c34599005db2003966148da1843a58 | 164 | 6 |    computation to disk and rerun it only if necessary::        >>> from joblib import Memory       >>> location = 'your_cache_dir_goes_here'       >>> mem = Memory(location, verbose=1) |
| .venv/lib/python3.13/site-packages/joblib/numpy_pickle_compat.py | 24e9527cc4f5b83233b4ec90dddcd8829e5f1959f33d55810aa5e374866c8cb4 | 251 | 2 |     the meta information, rather than array representation routine     (tobytes) is that it enables us to use completely the strided     model to avoid memory copies (a and a.T store as fast). In      |
| .venv/lib/python3.13/site-packages/joblib/_store_backends.py | 84a30e8c07b7d3d8d429b7bef581c0c9f8639f191cc1a5ac770da6ee1168fabf | 496 | 3 | """Storage providers backends for Memory caching."""  import collections |
| .venv/lib/python3.13/site-packages/joblib/numpy_pickle_utils.py | 8f71a5236e5016fa3e0d33e7eee469b6ef8db56d7aced1ccd03ba09724321032 | 292 | 3 |         filename path corresponding to the fileobj parameter.     mmap_mode: str         memory map mode that should be used to open the pickle file. This         parameter is useful to verify that th |
| .venv/lib/python3.13/site-packages/joblib/numpy_pickle.py | 37fc1031febfbe023bd674582e77b475cda43ba75f8749644da3999fc4eae477 | 757 | 10 |     * determining if memmap is allowed on the array.     * reading the array bytes from a file.     * reading the array using memorymap from a file.     * writing the array bytes to a file.  |
| .venv/lib/python3.13/site-packages/joblib/compressor.py | 1830d526678e06a7ed73ab4c903ba9af2a231e193f8c857c5ab3683224f14dd4 | 573 | 1 |             self._check_can_write()             # Convert data type if called by io.BufferedWriter.             if isinstance(data, memoryview):                 data = data.tobytes()  |
| .venv/lib/python3.13/site-packages/joblib/_memmapping_reducer.py | 019e9da80e9f5e59b8f9e84109ff66d67ab8de350f2a66a7e3fdb086b381bad7 | 716 | 12 | """ Reducer using memory mapping for numpy arrays """ # Author: Thomas Moreau <thomas.moreau.2010@gmail.com> |
| .venv/lib/python3.13/site-packages/joblib/parallel.py | 4a425893e7131c2f2832f654efd4835d5eb5219d746081db05886b1c1e3bc8cf | 2076 | 10 |     supports_sharedmem = getattr(backend, "supports_sharedmem", False)     # Force to use thread-based backend if the provided backend does not     # match the shared memory constraint or if the backe |
| .venv/lib/python3.13/site-packages/joblib/pool.py | 253734d0f100c8f6b2a3c987764b666eeae9e4e06c9cdc70490238cf3bed298b | 363 | 13 |  This module provides efficient ways of working with data stored in shared memory with numpy.memmap arrays without inducing any memory copy between the parent and child processes.  |
| .venv/lib/python3.13/site-packages/joblib/_parallel_backends.py | 7e0cbf16066229e36f4d6af8c0a6d25f8914371d980fa9bba793b527deb185be | 754 | 3 |      def terminate(self):         """Shutdown the workers and free the shared memory."""      def compute_batch_size(self): |
| .venv/lib/python3.13/site-packages/joblib/hashing.py | dfc30cd33465d046e4efc223e9c31dad0f226d864fd29089c6edcbe18af0d6c7 | 271 | 3 |             self._getbuffer = np.getbuffer         else:             self._getbuffer = memoryview      def save(self, obj): |
| .venv/lib/python3.13/site-packages/joblib/executor.py | 7db56613f28acb08c97082a61cef64f0cdd591a32a65710fe185c1473fe9eb15 | 132 | 2 |  This module provides efficient ways of working with data stored in shared memory with numpy.memmap arrays without inducing any memory copy between the parent and child processes. """ |
| .venv/lib/python3.13/site-packages/joblib/test/test_memmapping.py | cf469a9db12cdf20832928725b721894b913011c1dbea5536f86de4cf4459a39 | 1281 | 37 |     _strided_from_memmap,     _WeakArrayKeyMap,     has_shareable_memory, ) from joblib.backports import make_memmap |
| .venv/lib/python3.13/site-packages/joblib/test/test_numpy_pickle.py | 404c429c1486f845dd54a9e80e426334593a91b5f4143786791e74c2d2c78aca | 1226 | 15 | from joblib.test import data from joblib.test.common import (     memory_used,     np,     with_lz4, |
| .venv/lib/python3.13/site-packages/joblib/test/test_memory_async.py | b54a0223d767811d80b898c000a5c4949222cf6426e002467572a7f5cf2559a3 | 181 | 28 | import pytest  from joblib.memory import (     AsyncMemorizedFunc,     AsyncNotMemorizedFunc, |
| .venv/lib/python3.13/site-packages/joblib/test/test_parallel.py | ff5de4962f06632725c21d90b31cac5eb4496b8e28de06f7144a5263ad5a83de | 2251 | 9 |             yield np.ones(10, dtype=np.float32) * i      # Use max_nbytes=1 to force the use of memory-mapping even for small     # arrays     results = Parallel(n_jobs=2, max_nbytes=1, backend=backen |
| .venv/lib/python3.13/site-packages/joblib/test/common.py | be98e970980c6e6afc1f7b24737aacaff282faef999e1545464daf031989aaf0 | 85 | 15 | # with_numpy = skipif(not np, reason='Test requires numpy.')  # we use memory_profiler library for memory consumption checks try:     from memory_profiler import memory_usage |
| .venv/lib/python3.13/site-packages/joblib/test/test_func_inspect.py | 46c39147e8f8f127d7acd0506dbe62f927667d4ef393632bd082af72ef26d6dc | 339 | 4 |     get_func_name, ) from joblib.memory import Memory from joblib.test.common import with_numpy from joblib.testing import fixture, parametrize, raises |
| .venv/lib/python3.13/site-packages/joblib/test/test_memory.py | bd394d001910cf31ed454fdc5c6afd78e12fac7030ec410199e80c6d7fa0a99c | 1578 | 261 | """ Test the memory module. """  |
| .venv/lib/python3.13/site-packages/joblib/test/test_hashing.py | c1979324c5fc0bcb9addf26c28023b30ab697ab51f65fd5f2edd1968e8ef48ac | 521 | 5 | from joblib.func_inspect import filter_args from joblib.hashing import hash from joblib.memory import Memory from joblib.test.common import np, with_numpy from joblib.testing import fixture, parametri |
| .venv/lib/python3.13/site-packages/joblib/externals/cloudpickle/cloudpickle.py | 70d10129d8c10e5cc571efedbd92fcf3dbafef50275d3cf55c1ce48ca012493a | 1546 | 5 |   def _memoryview_reduce(obj):     return bytes, (obj.tobytes(),)  |
| .venv/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py | 40f48a7add0e0805abea0ff67c7c0fb78ca341a009b237de25814f88a852f511 | 1345 | 33 | _CURRENT_DEPTH = 0  # Minimum time interval between two consecutive memory leak protection checks. _MEMORY_LEAK_CHECK_DELAY = 1.0  |
| .venv/lib/python3.13/site-packages/joblib/externals/loky/backend/queues.py | 7844c5bdb3c7c0a7dda18c8e80d402c8aabf6659be9731f77f0c2950887eff85 | 237 | 1 |                             finally:                                 wrelease()                         # Remove references early to avoid leaking memory                         del obj, obj_          |
| .venv/lib/python3.13/site-packages/joblib/externals/loky/backend/resource_tracker.py | 2736e66fca2d2d1edeb6a85e7cab99c40b3556f4f58d5f1de597aff2f51c57ab | 412 | 1 |      This feature is notably used by `joblib.Parallel` to share temporary     folders and memory mapped files between the main process and the worker     processes.  |
| .venv/lib/python3.13/site-packages/joblib/externals/loky/backend/context.py | 44f759bf390493b880d2bb5d0082d21cdce5eb0b07a66e970fa20bdf4a3000f1 | 406 | 1 |        (available on some Unix systems);      * Cgroup CPU bandwidth limit (available on Linux only, typically        set by docker and similar container orchestration systems);      * the value of th |
| .venv/lib/python3.13/site-packages/joblib/externals/loky/backend/spawn.py | b783f3109ded8f0a05f6df2a9d0505f51ed0f8b981a4304870751158dce7cfc3 | 245 | 3 |         # joblib/loky#242: allow loky processes to retrieve the resource         # tracker of their parent in case the child processes depickles         # shared_memory objects, that are still tracked |
| .venv/lib/python3.13/site-packages/prompt_toolkit/buffer.py | 56401b293255ef8e3568ee048bea33a9cf0806534f1272c602de6de36b41ea38 | 2030 | 2 | from .eventloop import aclosing from .filters import FilterOrBool, to_filter from .history import History, InMemoryHistory from .search import SearchDirection, SearchState from .selection import Paste |
| .venv/lib/python3.13/site-packages/prompt_toolkit/history.py | 4bd5bd4a02fcdd07ed31000d76376304c9bec8699e339d7fa824510b51f832bf | 307 | 4 |     "DummyHistory",     "FileHistory",     "InMemoryHistory", ]  |
| .venv/lib/python3.13/site-packages/prompt_toolkit/input/win32.py | f542a8f1ffd6e0053c3f82ee73b1b7bd60564826e9508403134c652a9efa987f | 887 | 1 |             result = KeyPress(Keys.ControlSpace, " ")          # Turn Control-Enter into META-Enter. (On a vt100 terminal, we cannot         # detect this combination. But it's really practical on Win |
| .venv/lib/python3.13/site-packages/prompt_toolkit/output/win32.py | 7792c6ff774b2dc1e8989fde2621407267527b55528e09de591f71836107cfe3 | 684 | 10 |     CYAN = 0x0003     RED = 0x0004     MAGENTA = 0x0005     YELLOW = 0x0006     GRAY = 0x0007 |
| .venv/lib/python3.13/site-packages/prompt_toolkit/output/vt100.py | 75be86f6ea120da35b1957a38e760d7df6789cfb030dc2ff5fbd32ac909bf43b | 758 | 6 |     "ansiyellow": 33,     "ansiblue": 34,     "ansimagenta": 35,     "ansicyan": 36,     "ansigray": 37, |
| .venv/lib/python3.13/site-packages/prompt_toolkit/completion/fuzzy_completer.py | 467444bc0ef2ea70bb2ca1aa65412fb6e4a6f1e5d541885e253b27854bd16e63 | 214 | 1 |      :param words: List of words or callable that returns a list of words.     :param meta_dict: Optional dict mapping words to their meta-information.     :param WORD: When True, use WORD characters. |
| .venv/lib/python3.13/site-packages/prompt_toolkit/completion/word_completer.py | 545d52ed80b162a237a4a9955c9683f3678c5b564cabcff3000212d572865393 | 95 | 1 |     :param words: List of words or callable that returns a list of words.     :param ignore_case: If True, case-insensitive completion.     :param meta_dict: Optional dict mapping words to their meta- |
| .venv/lib/python3.13/site-packages/prompt_toolkit/completion/base.py | 4fbdb5d9a49c35a18c692ac3230b092177972c833f79508871270d7033d96302 | 439 | 1 |     @property     def display_meta(self) -> StyleAndTextTuples:         "Return meta-text. (This is lazy when using a callable)."         from prompt_toolkit.formatted_text import to_formatted_text  |
| .venv/lib/python3.13/site-packages/prompt_toolkit/key_binding/digraphs.py | ad9be1f40758e537ba6d29481d140db2425854838d61a858baefb0f4fb62e723 | 1379 | 3 |     ("A", ">"): 0xC2,     ("A", "?"): 0xC3,     ("A", ":"): 0xC4,     ("A", "A"): 0xC5,     ("A", "E"): 0xC6, |
| .venv/lib/python3.13/site-packages/prompt_toolkit/key_binding/bindings/emacs.py | b6b21952ef1ee6424649aaba35d6fe131cf835d1d5f528d4b1fb30fd433c73aa | 564 | 1 |     def _insert_all_completions(event: E) -> None:         """         `meta-*`: Insert all possible completions of the preceding text.         """         buff = event.current_buffer |
| .venv/lib/python3.13/site-packages/prompt_toolkit/styles/style_transformation.py | 70668ea3e8ea84fefd4281072d0c6b399a3d40caf15b1b5781f5cab07971d498 | 375 | 4 |     "ansiyellow": "ansibrightyellow",     "ansiblue": "ansibrightblue",     "ansimagenta": "ansibrightmagenta",     "ansicyan": "ansibrightcyan",     "ansigray": "ansibrightblack", |
| .venv/lib/python3.13/site-packages/prompt_toolkit/styles/named_colors.py | c99df4a0a07e7c2464e9130049883cab7533db381d7f2fd835bb90598a7261ab | 163 | 4 |     "Azure": "#f0ffff",     "Beige": "#f5f5dc",     "Bisque": "#ffe4c4",     "Black": "#000000",     "BlanchedAlmond": "#ffebcd", |
| .venv/lib/python3.13/site-packages/prompt_toolkit/styles/base.py | f684e6bea834471cbd54455b471abfe3f3ff3673d656bf5079d2b9ea479ad91a | 185 | 4 |     "ansiyellow",     "ansiblue",     "ansimagenta",     "ansicyan",     "ansigray", |
| .venv/lib/python3.13/site-packages/prompt_toolkit/shortcuts/prompt.py | 21b6e94da57bd4447c73ddb453971ff424e4187b9d7c7b569d6baee00fd38cf1 | 1514 | 6 | from prompt_toolkit.auto_suggest import AutoSuggest, DynamicAutoSuggest from prompt_toolkit.buffer import Buffer from prompt_toolkit.clipboard import Clipboard, DynamicClipboard, InMemoryClipboard fro |
| .venv/lib/python3.13/site-packages/prompt_toolkit/eventloop/async_generator.py | 9e8ccb251e33d8c24a57b422d21b249c0da66f525ca7b5c9c7e01d5040e10e1c | 126 | 2 |  # By default, choose a buffer size that's a good balance between having enough # throughput, but not consuming too much memory. We use this to consume a sync # generator of completions as an async ge |
| .venv/lib/python3.13/site-packages/prompt_toolkit/application/application.py | a3388ab221cd98625084c8f538340890949e388dde8d159643d5ddb951d83801 | 1627 | 2 | from prompt_toolkit.buffer import Buffer from prompt_toolkit.cache import SimpleCache from prompt_toolkit.clipboard import Clipboard, InMemoryClipboard from prompt_toolkit.cursor_shapes import AnyCurs |
| .venv/lib/python3.13/site-packages/prompt_toolkit/clipboard/__init__.py | c8ad0ba2721f119472a17a9c80b761f248ce85e7218cef848f6f82d60dd57a04 | 18 | 3 |  from .base import Clipboard, ClipboardData, DummyClipboard, DynamicClipboard from .in_memory import InMemoryClipboard  # We are not importing `PyperclipClipboard` here, because it would require the |
| .venv/lib/python3.13/site-packages/prompt_toolkit/clipboard/base.py | aee704bf590a7ef6548fa6f0191cf4e2e4924d989eeebbe72949f25576f6befe | 110 | 1 |     """     Abstract baseclass for clipboards.     (An implementation can be in memory, it can share the X11 or Windows     keyboard, or can be persistent.)     """ |
| .venv/lib/python3.13/site-packages/prompt_toolkit/clipboard/in_memory.py | 53f898e9451ebe428c7d3be2aff5ccb03d2ac2e2d52aea137917639195be03a2 | 45 | 3 |  __all__ = [     "InMemoryClipboard", ]  |
| .venv/lib/python3.13/site-packages/attr/validators.py | 59a0751cb0071ea4475acaeffcaf47fac27b1128a5dc7dc29afd9df13b55671e | 711 | 4 |         func (typing.Callable):             Which underlying `re` function to call. Valid options are             `re.fullmatch`, `re.search`, and `re.match`; the default `None`             means `re. |
| .venv/lib/python3.13/site-packages/attr/_make.py | 94150f3e6c6203505e1f307a3a51e808487efad56f335a335cef1e5ce6ba8387 | 3124 | 2 |          # We only add the names of attributes that aren't inherited.         # Setting __slots__ to inherited attributes wastes memory.         slot_names = [name for name in names if name not in bas |
| .venv/lib/python3.13/site-packages/attr/_next_gen.py | ec54646ed97f374d7b4ae0617ff570de6c36736a46661b4218ecda760cfbb69e | 624 | 1 |         slots (bool):             Create a :term:`slotted class <slotted classes>` that's more             memory-efficient. Slotted classes are generally superior to the             default dict clas |
| .venv/lib/python3.13/site-packages/tiktoken/registry.py | edf92d65b27529c9bcb15c968047c8cbe6717d4bdc5eea4b50d5ca3df486c105 | 97 | 1 |                     ENCODING_CONSTRUCTORS[enc_name] = constructor         except Exception:             # Ensure we idempotently raise errors             ENCODING_CONSTRUCTORS = None             raise |
| .venv/lib/python3.13/site-packages/tiktoken/model.py | c438d91dcac59786ab343e41d773afa9b3fcccef64db0121852c6fb16a3c9e31 | 118 | 33 |     "o4-mini-": "o200k_base",     # chat     "gpt-5-": "o200k_base",     "gpt-4.5-": "o200k_base",     "gpt-4.1-": "o200k_base", |
| .venv/lib/python3.13/site-packages/tiktoken/_educational.py | 4d414ea7c43dd568eb4ef18a842344cab86dbdaf365257a75df84fcbdcd2ed54 | 224 | 2 |  def train_simple_encoding():     gpt2_pattern = (         r"""'s\|'t\|'re\|'ve\|'m\|'ll\|'d\| ?[\p{L}]+\| ?[\p{N}]+\| ?[^\s\p{L}\p{N}]+\|\s+(?!\S)\|\s+"""     ) |
| .venv/lib/python3.13/site-packages/transformers/optimization_tf.py | 2582fcb556cbc81de9b862746f68b58066a27421d2c66f3f8d89a6ef3f9927ee | 379 | 1 |         adam_global_clipnorm (`float`, *optional*, defaults to `None`)             If not `None`, clip gradient norm to this value. When using this argument, the norm is computed over all              |
| .venv/lib/python3.13/site-packages/transformers/modeling_outputs.py | b1d832a14ea24f63f181cbad7e410bd15a43082833221ff6980859a6c7fd357e | 1716 | 161 |             Sequence of hidden-states at the output of the last layer of the model.         hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed o |
| .venv/lib/python3.13/site-packages/transformers/configuration_utils.py | 05adf7e1e963c75771398b4b257bc35702328d9b51c9368856bf8481ec31cbbd | 1357 | 13 |      - **vocab_size** (`int`) -- The number of tokens in the vocabulary, which is also the first dimension of the       embeddings matrix (this attribute may be missing for models that don't have a te |
| .venv/lib/python3.13/site-packages/transformers/tokenization_utils.py | 91543bcbcda9cc62d08c15a6854c9c70efaf1d3135929c11a2950243e76bd6a6 | 1136 | 3 |         The special key `""` in `self._termination_char` is used to represent termination.          This function is idempotent, adding twice the same word will leave the trie unchanged          Examp |
| .venv/lib/python3.13/site-packages/transformers/convert_graph_to_onnx.py | 83e06f26e608ab6c03987c50d0d8360eba70a8db21c406d0364e338de817e27c | 552 | 1 |     input_dynamic_axes = {k: build_shape_dict(k, v, True, seq_len) for k, v in tokens.items()}      # flatten potentially grouped outputs (past for gpt2, attentions)     outputs_flat = []     for outp |
| .venv/lib/python3.13/site-packages/transformers/modeling_rope_utils.py | 4365a972bf6ac45729c33a4eb96850e1306221f36977c5dc9b207cb186dd93f9 | 635 | 82 |         """Longrope uses long factor if sequence is larger than original pretraining length, short otherwise."""         seq_len = torch.max(position_ids) + 1         if hasattr(self.config, "original |
| .venv/lib/python3.13/site-packages/transformers/convert_tf_hub_seq_to_seq_bert_to_pytorch.py | d367f044db222b7ce698bf4efe182c76ea2606e4c31d687cbdc4f293618e973f | 87 | 1 |         "google-bert/bert-large-cased",         vocab_size=vocab_size,         max_position_embeddings=512,         is_decoder=True,         add_cross_attention=True, |
| .venv/lib/python3.13/site-packages/transformers/video_utils.py | fe681e8e6635a7bf9aad31d29a4a59e87f6ac48c3d932fa80e15ab8ca4197b04 | 879 | 3 |             The padding mode to use. Can be one of:                 - `"constant"`: pads with a constant value.                 - `"reflect"`: pads with the reflection of the vector mirrored on the fi |
| .venv/lib/python3.13/site-packages/transformers/pytorch_utils.py | 73058fd3079c538eb9bcecb269604f43480cd6871f302d2bf790cad14b0b5df7 | 381 | 3 | class Conv1D(nn.Module):     """     1D-convolutional layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2).      Basically works like a linear layer but the weights are transpose |
| .venv/lib/python3.13/site-packages/transformers/modeling_flax_utils.py | 4db683065b03e80e2787dc647815b51fb6f161cc6c41703865eb1763645e2527 | 1275 | 8 |          This method can be used on TPU to explicitly convert the model parameters to bfloat16 precision to do full         half-precision training or to save weights in bfloat16 for inference in orde |
| .venv/lib/python3.13/site-packages/transformers/image_transforms.py | 163556a472733191afe8cd86e08348d599bd88eb2370a3747ca687b1c14a6691 | 978 | 3 |             The padding mode to use. Can be one of:                 - `"constant"`: pads with a constant value.                 - `"reflect"`: pads with the reflection of the vector mirrored on the fi |
| .venv/lib/python3.13/site-packages/transformers/modeling_flax_pytorch_utils.py | ae17b0b2a97b3adb973eaa4e4558a0ac6cf0f2c00f7132bb0f4cf8956c00633d | 492 | 3 |         return renamed_pt_tuple_key, pt_tensor      # embedding     renamed_pt_tuple_key = pt_tuple_key[:-1] + ("embedding",)     if pt_tuple_key[-1] == "weight" and is_key_or_prefix_key_in_dict(renam |
| .venv/lib/python3.13/site-packages/transformers/activations_tf.py | 4c699a87796832cfe9111c31a6359be7e0147872e8040c83c4561656e2c2ec55 | 148 | 2 |     """     Gaussian Error Linear Unit. Original Implementation of the gelu activation function in Google Bert repo when     initially created. For information: OpenAI GPT's gelu is slightly different |
| .venv/lib/python3.13/site-packages/transformers/feature_extraction_utils.py | 2e43fefc110a79880ad67f8f0cf9216fdd41140e2f04a3d961935009e3c13d79 | 690 | 4 |         from_auto_class = kwargs.pop("_from_auto", False)          user_agent = {"file_type": "feature extractor", "from_auto_class": from_auto_class}         if from_pipeline is not None:             |
| .venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py | 2e2dada865cce42b73387240716a12ff5c0a56977cfd680dc8fa937b0dc0ef51 | 4200 | 24 |         current vocabulary).          When adding new tokens to the vocabulary, you should make sure to also resize the token embedding matrix of the         model so that its embedding matrix matches |
| .venv/lib/python3.13/site-packages/transformers/testing_utils.py | 8ab96e0c4cc3c281e5e5622db376c0bf4e9ab4fd7ab8cbc8a1328a96cf6bab78 | 3519 | 75 |     is_aqlm_available,     is_auto_awq_available,     is_auto_gptq_available,     is_auto_round_available,     is_av_available, |
| .venv/lib/python3.13/site-packages/transformers/activations.py | 7b83cb02127676a22e6af6855aa7bd6baaa5db9bb5afcdaa843a271552f27773 | 325 | 7 | class NewGELUActivation(nn.Module):     """     Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT). Also see     the Gaussian Error Linear Units pap |
| .venv/lib/python3.13/site-packages/transformers/trainer_utils.py | 0227946b7ed10595354875fc3f6e8e38d094406eebdfc33f5600e68e23e165e4 | 911 | 63 | def neftune_post_forward_hook(module, input, output):     """     Implements the NEFTune forward pass for the model using forward hooks. Note this works only for torch.nn.Embedding     layers. This me |
| .venv/lib/python3.13/site-packages/transformers/safetensors_conversion.py | 2e39c54557d746c3a12077728b0ea97af0c970c76c2b073792f43a72c3ecf700 | 106 | 3 | from huggingface_hub import Discussion, HfApi, get_repo_discussions  from .utils import cached_file, http_user_agent, logging   |
| .venv/lib/python3.13/site-packages/transformers/processing_utils.py | 66c84b3c84ace91fb866e82c30b6d6cb2c3ed0da5fead19219e0ed7c45691d70 | 1715 | 13 |     methods that calculate and return useful data from processing     input multimodals (images/videos).     Note that this dataclass is aimed to be used only in vLLM     and we might change its API i |
| .venv/lib/python3.13/site-packages/transformers/image_processing_base.py | b030daecec544883e69566ffa9708753a56d353fdc8283c11cf6bc8d8c7553d0 | 537 | 4 |             token = use_auth_token          user_agent = {"file_type": "image processor", "from_auto_class": from_auto_class}         if from_pipeline is not None:             user_agent["using_pipeli |
| .venv/lib/python3.13/site-packages/transformers/modelcard.py | 2c64dfe621cf173e9b0b571e95b1a4db581a6c0afd6daa82d89a61fdb04c623b | 916 | 4 |         from_pipeline = kwargs.pop("_from_pipeline", None)          user_agent = {"file_type": "model_card"}         if from_pipeline is not None:             user_agent["using_pipeline"] = from_pipel |
| .venv/lib/python3.13/site-packages/transformers/optimization.py | 41b08ffb29c2691626b225ed389a694cc8e61480818214a35f215b5c39167bfb | 974 | 1 |     https://github.com/pytorch/fairseq/blob/master/fairseq/optim/adafactor.py      Paper: *Adafactor: Adaptive Learning Rates with Sublinear Memory Cost* https://huggingface.co/papers/1804.04235 Note  |
| .venv/lib/python3.13/site-packages/transformers/__init__.py | b39159ff9ee762ac46b877b3fa9e2230f1549473503d9eb272eae8c3955c2ad9 | 968 | 18 |         "DocumentQuestionAnsweringPipeline",         "FeatureExtractionPipeline",         "FillMaskPipeline",         "ImageClassificationPipeline",         "ImageFeatureExtractionPipeline", |
| .venv/lib/python3.13/site-packages/transformers/convert_slow_tokenizer.py | 8e57b627d42f34e0117d63090bc7ad8f5c66e8028c17887d3e4c7eae990bd92b | 1744 | 9 |   class OpenAIGPTConverter(Converter):     def converted(self) -> Tokenizer:         vocab = self.original_tokenizer.encoder |
| .venv/lib/python3.13/site-packages/transformers/feature_extraction_sequence_utils.py | 53ad1320349b74523f303d09c687bf6841abc23a2a11a7cfe9e18c60aa45f631 | 372 | 8 |             The sampling rate at which the audio files should be digitalized expressed in hertz (Hz).         padding_value (`float`):             The value that is used to fill the padding values / v |
| .venv/lib/python3.13/site-packages/transformers/training_args.py | f59195dc3f3d2dba7da87e85e60ea6b1907d0fa3ae6eba228a6f9a56cef1e836 | 3145 | 38 |             Number of predictions steps to accumulate the output tensors for, before moving the results to the CPU. If             left unset, the whole predictions are accumulated on the device accel |
| .venv/lib/python3.13/site-packages/transformers/modeling_gguf_pytorch_utils.py | 628eff2969c1c3fb19e1dd00f8be11b8188e305a706e6b91a3d164e58d9d9222 | 501 | 14 |     ) -> np.ndarray:         # Original permutation implementation         # https://github.com/ggerganov/llama.cpp/blob/a38b884c6c4b0c256583acfaaabdf556c62fabea/convert_hf_to_gguf.py#L1402-L1408      |
| .venv/lib/python3.13/site-packages/transformers/modeling_flax_outputs.py | d51421e954c8215821d8e304f8491474973635d062e531170470850aea45012b | 701 | 51 |             Sequence of hidden-states at the output of the last layer of the model.         hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when |
| .venv/lib/python3.13/site-packages/transformers/cache_utils.py | 9192c53314b5d6b31bd8ef91e56e559035961a764301fc82e6e7f64365405836 | 1517 | 18 |   class ChunkedSlidingLayer(SlidingWindowLayer):     """     An extended SlidingWindowLayer that supports prefill chunking, originally implemented for Llama 4. |
| .venv/lib/python3.13/site-packages/transformers/modeling_attn_mask_utils.py | a0810cef6b0d6093bfdaa349b3adde2e633fd3a6be5073d80b5e08b2f12c354b | 488 | 2 |         """         Attend to all tokens in masked rows from the expanded attention mask, for example the relevant first rows when         using left padding. This is required by F.scaled_dot_product_ |
| .venv/lib/python3.13/site-packages/transformers/modeling_tf_pytorch_utils.py | 43bfb9683788d9e737f8d6201fa169f4ea40326ca6ab2a75983646598bdefc8a | 677 | 2 |      # Convert standard TF2.0 names in PyTorch names     if tf_name[-1] == "kernel" or tf_name[-1] == "embeddings" or tf_name[-1] == "gamma":         tf_name[-1] = "weight"     if tf_name[-1] == "beta |
| .venv/lib/python3.13/site-packages/transformers/tokenization_utils_fast.py | 546f0bed7f7c97ef7fca2511424a6cfaa2ef39cd82941386b5429ba234d61f17 | 923 | 1 |             text_iterator (generator of `list[str]`):                 The training corpus. Should be a generator of batches of texts, for instance a list of lists of texts                 if you have  |
| .venv/lib/python3.13/site-packages/transformers/modeling_utils.py | 25906edd06eb4c409cad9f4a9d63dd5d0f55e13e604e73dac3827371ab5e8a71 | 6292 | 387 |         check_tied_parameters_on_same_device,         extract_model_from_parallel,         get_balanced_memory,         get_max_memory,         load_offloaded_weights, |
| .venv/lib/python3.13/site-packages/transformers/model_debugging_utils.py | f8e96ebb8c1d2a456a69514cb399bc59f49cd32d020482b6acfb62e767dd096b | 456 | 4 |   MEMORY_ADDRESS_REGEX = re.compile(r"object at 0x[0-9A-Fa-f]+")   |
| .venv/lib/python3.13/site-packages/transformers/file_utils.py | a865cb39152fdf17e557419c25d26bcabfda59ceb0f0f2784be790193698c694 | 132 | 1 |     get_torch_version,     has_file,     http_user_agent,     is_apex_available,     is_bs4_available, |
| .venv/lib/python3.13/site-packages/transformers/trainer.py | 67d86e8dddc37e6c6fc611d595166eb7956afb1faa07633008033e43ac04d095 | 5686 | 42 |     RemoveColumnsCollator,     SaveStrategy,     TrainerMemoryTracker,     TrainOutput,     check_target_module_exists, |
| .venv/lib/python3.13/site-packages/transformers/video_processing_utils.py | 3ed9b651be96eae817b4b7869ace543c9cf4ed2d53c29ea3c4957af112c50180 | 899 | 4 |             token = use_auth_token          user_agent = {"file_type": "video processor", "from_auto_class": from_auto_class}         if from_pipeline is not None:             user_agent["using_pipeli |
| .venv/lib/python3.13/site-packages/transformers/masking_utils.py | 5d883a0191406510008219e75b4c9c35ca36a534507286879525a0586f0eb9f8 | 1250 | 8 |         # Note that here the mask should ALWAYS be at least of the max `kv_index` size in the dimension 1. This is because         # we cannot pad it here in the mask_function as we don't know the fin |
| .venv/lib/python3.13/site-packages/transformers/convert_pytorch_checkpoint_to_tf2.py | c4d364b3bd15d6ce477ac938ff1afae5582ead019ddc9bfea51c3bd22b168d07 | 441 | 28 |     ElectraConfig,     FlaubertConfig,     GPT2Config,     LayoutLMConfig,     LxmertConfig, |
| .venv/lib/python3.13/site-packages/transformers/keras_callbacks.py | 33d66f41a279da4efd46580ced6368a2d897a03fe1362ae688c35a3f1237b629 | 414 | 1 |         output_dir="./model_save",         tokenizer=tokenizer,         hub_model_id="gpt5-7xlarge",     )  |
| .venv/lib/python3.13/site-packages/transformers/tf_utils.py | ba24bab923e607f6546b16d5faf3241b2d6ba034ed637ba3a48824c2eb241a67 | 295 | 4 |   def check_embeddings_within_bounds(tensor: tf.Tensor, embed_dim: int, tensor_name: str = "input_ids") -> None:     """     `tf.gather`, on which TF embedding layers are based, won't check positive o |
| .venv/lib/python3.13/site-packages/transformers/trainer_pt_utils.py | fd93951de5d2768b48afa929701b22c0c606ce153ae500404d91ed64cee1b04c | 1407 | 39 |             The metrics returned from train/evaluate/predictmetrics: metrics dict      Notes on memory reports:      In order to get memory usage report you need to install `psutil`. You can do that w |
| .venv/lib/python3.13/site-packages/transformers/modeling_layers.py | 376831a9448aa9b46f009b5e383329d629beaabb862987f40fa086ed2e861286 | 290 | 2 |         self.post_init()      def get_input_embeddings(self):         return getattr(self, self.base_model_prefix).embed_tokens  |
| .venv/lib/python3.13/site-packages/transformers/modeling_tf_utils.py | 46a73b0559630f1a1c4d14d7bb622e894b693001628e3b715f1e3a759203b1b1 | 3530 | 238 |                     saved_weight_value = saved_weights.get(symbolic_weight_name)                      # Retrocompatibility patch: some embeddings are stored with the weights name (e.g. Bart's          |
| .venv/lib/python3.13/site-packages/transformers/modeling_tf_outputs.py | e931c8356cde03e0d9cb101dbc4de5bb7a7787866978197cb23ace863f706fd6 | 991 | 69 |             Sequence of hidden-states at the output of the last layer of the model.         hidden_states (`tuple(tf.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or w |
| .venv/lib/python3.13/site-packages/transformers/onnx/features.py | cd184689883330c7ef761ed4bc23bd8ffcb42fd71b55b4d22fcf1c22d93f3c18 | 750 | 16 |     from transformers.models.auto import (         AutoModel,         AutoModelForCausalLM,         AutoModelForImageClassification,         AutoModelForImageSegmentation, |
| .venv/lib/python3.13/site-packages/transformers/loss/loss_utils.py | fa65f18b3167f45989d7a8ba86432a41d322338f9789cc89b08d5d7f20f110b7 | 170 | 5 |   def ForCausalLMLoss(     logits,     labels, |
| .venv/lib/python3.13/site-packages/transformers/quantizers/quantizer_fbgemm_fp8.py | 69692216971d24cb7cef43a4b296d964e6ea4b5a58431df63904b5c587efe5ef | 297 | 1 |             dtype = torch.bfloat16             logger.info(                 "Overriding dtype=%s with `dtype=torch.bloat16` due to "                 "requirements of `fbgemm-gpu` to enable model loadi |
| .venv/lib/python3.13/site-packages/transformers/quantizers/quantizer_bnb_4bit.py | 838ac986c3a7f61a07c41728d270e0868eb540aee5c8550716475b96ffe329ef | 366 | 17 |         super().__init__(quantization_config, **kwargs)          if self.quantization_config.llm_int8_skip_modules is not None:             self.modules_to_not_convert = self.quantization_config.llm_i |
| .venv/lib/python3.13/site-packages/transformers/quantizers/quantizer_torchao.py | 6f68055239e1dec3230c1d596ca4a575172299ed9577c381bf0f1154018f894c | 367 | 16 |             )      def adjust_max_memory(self, max_memory: dict[str, Union[int, str]]) -> dict[str, Union[int, str]]:         # need more space for the quantization parameters (e.g. scale). Tested wit |
| .venv/lib/python3.13/site-packages/transformers/quantizers/quantizer_gptq.py | f352830a15832c6fab0345774e4a59101d6150f561ab66ac83ff177dc2a85b05 | 125 | 47 |     from ..modeling_utils import PreTrainedModel  from ..utils import is_auto_gptq_available, is_gptqmodel_available, is_optimum_available, is_torch_available, logging from ..utils.quantization_config |
| .venv/lib/python3.13/site-packages/transformers/quantizers/quantizer_quanto.py | bd4dcd7beb72265bb181a8d4214e035c8747cc0a22c913264354621ba4a55183 | 202 | 5 |             return False      def adjust_max_memory(self, max_memory: dict[str, Union[int, str]]) -> dict[str, Union[int, str]]:         max_memory = {key: val * 0.90 for key, val in max_memory.items( |
| .venv/lib/python3.13/site-packages/transformers/quantizers/quantizer_mxfp4.py | ba610e86f74b4f91f12d9119116bda68e28e12ac6debeeb33794200fc5e2602c | 412 | 18 |         **kwargs,     ):         from ..integrations import Mxfp4GptOssExperts         from ..models.gpt_oss.modeling_gpt_oss import GptOssExperts  |
| .venv/lib/python3.13/site-packages/transformers/quantizers/quantizer_bitnet.py | f5c43a364f2a5ef82d81b33398f3f0a41bbd3037e6a99d7107aa67071e1a6905 | 125 | 5 |         )      def adjust_max_memory(self, max_memory: dict[str, Union[int, str]]) -> dict[str, Union[int, str]]:         max_memory = {key: val * 0.90 for key, val in max_memory.items()}         retu |
| .venv/lib/python3.13/site-packages/transformers/quantizers/quantizer_auto_round.py | 17672da67270954235a675784c6ba5e249b6fcf8a71e308d20069d959be4b8ba | 82 | 1 |      def is_serializable(self, safe_serialization=None):         ## for gptq/awq models, the quantization config will be changed         return True |
| .venv/lib/python3.13/site-packages/transformers/quantizers/quantizer_bnb_8bit.py | 5a3f7d68d06075255325c47b07894577098b38bf7333c947e476e4b48371e59a | 317 | 16 |         super().__init__(quantization_config, **kwargs)          if self.quantization_config.llm_int8_skip_modules is not None:             self.modules_to_not_convert = self.quantization_config.llm_i |
| .venv/lib/python3.13/site-packages/transformers/quantizers/base.py | 68551e4304fdd403e4545443f45a7319e0f758cb4110d8093a14c6fabefb20d7 | 402 | 6 |         }      def adjust_max_memory(self, max_memory: dict[str, Union[int, str]]) -> dict[str, Union[int, str]]:         """adjust max_memory argument for infer_auto_device_map() if extra memory is n |
| .venv/lib/python3.13/site-packages/transformers/quantizers/auto.py | d3712966c8b907411f830e5a9ea117c1a46abf081facf03d3580ce1febbeae04 | 335 | 10 |     FineGrainedFP8Config,     FPQuantConfig,     GPTQConfig,     HiggsConfig,     HqqConfig, |
| .venv/lib/python3.13/site-packages/transformers/pipelines/fill_mask.py | 63abcfc320f17dfc9af1ee8cb317192e846746b4a9fdd54405dbe38265cdfd7a | 287 | 1 |             Additional dictionary of keyword arguments passed along to the tokenizer.""", ) class FillMaskPipeline(Pipeline):     _load_processor = False     _load_image_processor = False |
| .venv/lib/python3.13/site-packages/transformers/pipelines/image_to_text.py | ae7f27beed4f6cac335d8a00f1084f7a13f8924f1ce59f2ead99d2d09ccd4d15 | 244 | 1 |     >>> from transformers import pipeline      >>> captioner = pipeline(model="ydshieh/vit-gpt2-coco-en")     >>> captioner("https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png")   |
| .venv/lib/python3.13/site-packages/transformers/pipelines/__init__.py | a5bbce6e2acdab973c92888cb7e29e94f16ad8a7c974de523bec2e17fc6b13a8 | 1231 | 15 | from .document_question_answering import DocumentQuestionAnsweringPipeline from .feature_extraction import FeatureExtractionPipeline from .fill_mask import FillMaskPipeline from .image_classification  |
| .venv/lib/python3.13/site-packages/transformers/pipelines/text_generation.py | 912f45f50f9dbc9b056b5568ecef1ff67a8984027b3a64050d2292879785ba61 | 547 | 7 | class TextGenerationPipeline(Pipeline):     """     Language generation pipeline using any `ModelWithLMHead` or `ModelForCausalLM`. This pipeline predicts the words     that will follow a specified te |
| .venv/lib/python3.13/site-packages/transformers/pipelines/automatic_speech_recognition.py | 13d9731500797985cf6f5f66c243715812a71b550a28a174f85fe40f9ff562e5 | 672 | 1 |         decoder (`pyctcdecode.BeamSearchDecoderCTC`, *optional*):             [PyCTCDecode's             BeamSearchDecoderCTC](https://github.com/kensho-technologies/pyctcdecode/blob/2fd33dc37c4111417 |
| .venv/lib/python3.13/site-packages/transformers/pipelines/mask_generation.py | af34cd4fe0cb846985fe81585d9a34a70e62bcb40b5f4a5cdfe7f1d2d803d317 | 342 | 16 |         points_per_batch (*optional*, int, default to 64):             Sets the number of points run simultaneously by the model. Higher numbers may be faster but use more GPU             memory.      |
| .venv/lib/python3.13/site-packages/transformers/pipelines/base.py | ae3f9aeefc745f6f7c436dcc94ca4955b22604defc44309a0c3ad1653a612c55 | 1591 | 3 |         if dim == 2:             if max_length == min_length:                 # Bypass for `ImageGPT` which doesn't provide a padding value, yet                 # we can consistently pad since the siz |
| .venv/lib/python3.13/site-packages/transformers/utils/metrics.py | 037d35afc318a193dc48c3bc95fa4e4893bf27c1851f186328705bc5acea4f15 | 417 | 19 |         )          self.kv_cache_free_memory_gauge = self.meter.create_gauge(             name="kv_cache_free_memory_bytes",             description="Free memory of the PagedAttentionCache in bytes", |
| .venv/lib/python3.13/site-packages/transformers/utils/dummy_pt_objects.py | 411d0080da338d8957dae8b83838d47f90257af92734e5ab9f9ce21b9c1bfd44 | 633 | 1 |   class NoBadWordsLogitsProcessor(metaclass=DummyObject):     _backends = ["torch"]  |
| .venv/lib/python3.13/site-packages/transformers/utils/__init__.py | 077677e28ad929a16debc7b7af1376a34d2ca8c26695101e614cfad41715d227 | 366 | 3 |     extract_commit_hash,     has_file,     http_user_agent,     is_offline_mode,     is_remote_url, |
| .venv/lib/python3.13/site-packages/transformers/utils/dummy_tf_objects.py | f193daeb0f21f95cd10f3c0e3bdc4adbabbd7afcf74fc6e4c522e183123e94a5 | 179 | 2 |   class TFNoBadWordsLogitsProcessor(metaclass=DummyObject):     _backends = ["tf"]  |
| .venv/lib/python3.13/site-packages/transformers/utils/chat_template_utils.py | 2fd24fee053c1965d97ae54d464b273780f63610d9fadcca642f674f356fc7ec | 557 | 2 |     >>>     >>> multiply_schema = get_json_schema(multiply)     >>> tokenizer = AutoTokenizer.from_pretrained("CohereForAI/c4ai-command-r-v01")     >>> messages = [{"role": "user", "content": "What is |
| .venv/lib/python3.13/site-packages/transformers/utils/auto_docstring.py | 6d63cde239e8cb5c2e6ae03c3151a81001cc3ae6eab4ce1e5de96ba49981f860 | 2051 | 31 |  HARDCODED_CONFIG_FOR_MODELS = {     "openai": "OpenAIGPTConfig",     "x-clip": "XCLIPConfig",     "kosmos2": "Kosmos2Config", |
| .venv/lib/python3.13/site-packages/transformers/utils/hub.py | 732ffb0e8dc13896a3c8efe509bd955020ce313d8c20c122b4e5d065de74b46c | 1198 | 22 |   def http_user_agent(user_agent: Union[dict, str, None] = None) -> str:     """     Formats a user-agent string with basic info about a request. |
| .venv/lib/python3.13/site-packages/transformers/utils/dummy_sentencepiece_objects.py | a41ca434d83d20f0deb2154e79ac38b311ef826b776f2f57e2b210b73d0e3588 | 255 | 1 |   class GPTSw3Tokenizer(metaclass=DummyObject):     _backends = ["sentencepiece"]  |
| .venv/lib/python3.13/site-packages/transformers/utils/doc.py | 2b93205d88b58f505de4e53e868e7ba23829d547ed1cde18bb69a98f7c779500 | 1583 | 22 |      This example uses a random model as the real ones are all very big. To get proper results, you should use     {real_checkpoint} instead of {fake_checkpoint}. If you get out-of-memory when loading |
| .venv/lib/python3.13/site-packages/transformers/utils/fx.py | 15499d780e9bf0e9fa2a488ed238ab728cf152858ff47f14d2fbe03b683829e8 | 1501 | 26 |     "donut-swin",     "electra",     "gpt2",     "gpt_neo",     "gptj", |
| .venv/lib/python3.13/site-packages/transformers/utils/import_utils.py | 8ce812a2fdc29d51351701e4e1d4f1ecc632af89b9463a46d1bf6ff3b103a64e | 2884 | 13 | _openai_available = _is_package_available("openai") _optimum_available = _is_package_available("optimum") _auto_gptq_available = _is_package_available("auto_gptq") _gptqmodel_available = _is_package_a |
| .venv/lib/python3.13/site-packages/transformers/utils/quantization_config.py | 8066355d8bf9fe4661c4bb7b44e1ed396e64265d8474952cbf9c01197adfeb83 | 2087 | 121 |     is_auto_awq_available,     is_compressed_tensors_available,     is_gptqmodel_available,     is_hqq_available,     is_quark_available, |
| .venv/lib/python3.13/site-packages/transformers/models/__init__.py | 8ba0830077043f431415948c6a2829bb6fe00362d5c5639ceae072e4aa885284 | 383 | 13 |     from .big_bird import *     from .bigbird_pegasus import *     from .biogpt import *     from .bit import *     from .bitnet import * |
| .venv/lib/python3.13/site-packages/transformers/models/dots1/configuration_dots1.py | e6c66047afa7ff099ba4477afc304d5dff86413ee168f41d12c818c9330b6c86 | 212 | 14 |     r"""     This is the configuration class to store the configuration of a [`Dots1Model`]. It is used to instantiate a     `dots.llm1` model according to the specified arguments, defining the model  |
| .venv/lib/python3.13/site-packages/transformers/models/dots1/modular_dots1.py | 337e74998b78def2f7ce5d96cf0c760f4f1e2ba9ab1997f232fe310e5db7c1a3 | 112 | 13 | # See the License for the specific language governing permissions and # limitations under the License. from ...modeling_outputs import CausalLMOutputWithPast from ...processing_utils import Unpack fro |
| .venv/lib/python3.13/site-packages/transformers/models/dots1/modeling_dots1.py | d06522f33d841150628da8a7f212f97b249ec7f62d04dca80b69cb3241dcf059 | 613 | 27 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWith |
| .venv/lib/python3.13/site-packages/transformers/models/metaclip_2/configuration_metaclip_2.py | dee8a7d96c0f5e5cbec1a21cbef43f6ecbeda03125d7aecfd7271f21a93993b1 | 347 | 4 |         num_attention_heads (`int`, *optional*, defaults to 8):             Number of attention heads for each attention layer in the Transformer encoder.         max_position_embeddings (`int`, *opti |
| .venv/lib/python3.13/site-packages/transformers/models/metaclip_2/modeling_metaclip_2.py | fa1e04a31a4e4e08d0f36062ee17982e27c3815847ca2d3f7457f8092095d73b | 1251 | 92 |   class MetaClip2TextEmbeddings(nn.Module):     def __init__(self, config: MetaClip2TextConfig):         super().__init__() |
| .venv/lib/python3.13/site-packages/transformers/models/metaclip_2/modular_metaclip_2.py | 30dcb8b7b16c0ffc013cc8cff08dd1096da246726d52e49fa08500202738362a | 247 | 14 |     CLIPForImageClassification,     CLIPModel,     CLIPTextEmbeddings,     CLIPTextModel,     CLIPTextModelWithProjection, |
| .venv/lib/python3.13/site-packages/transformers/models/nllb_moe/configuration_nllb_moe.py | 8c72a846919bae534470188e9376f67cf3a8d66e8e0fb4f1d7517dafc4927756 | 220 | 8 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/nllb_moe/modeling_nllb_moe.py | 9a149acaea66028479528a9639fbddde62b988713811a3dab67127c990d30374 | 1777 | 59 |   # Copied from transformers.models.m2m_100.modeling_m2m_100.M2M100ScaledWordEmbedding with M2M100->NllbMoe class NllbMoeScaledWordEmbedding(nn.Embedding):     """ |
| .venv/lib/python3.13/site-packages/transformers/models/sew_d/modeling_sew_d.py | f8b3b59d62ebcf2843010375ceaee72df086ba4901d81d6c9b51894a703c16c2 | 1658 | 66 | from ...integrations.deepspeed import is_deepspeed_zero3_enabled from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutput, CausalLMOutput, SequenceClas |
| .venv/lib/python3.13/site-packages/transformers/models/sew_d/configuration_sew_d.py | 5172d8a030088b1f5c5a149056e6afcf82e06d0da5bc2c4ee6f13f6c6b197a2d | 292 | 30 |         squeeze_factor (`int`, *optional*, defaults to 2):             Sequence length downsampling factor after the encoder and upsampling factor after the transformer.         max_position_embedding |
| .venv/lib/python3.13/site-packages/transformers/models/table_transformer/modeling_table_transformer.py | 4584b4c79de95a43e487c3a249f8412d37b68a8a6519eb64bd0bbe446f158f50 | 1331 | 67 | class TableTransformerConvModel(nn.Module):     """     This module adds 2D position embeddings to all intermediate feature maps of the convolutional encoder.     """  |
| .venv/lib/python3.13/site-packages/transformers/models/table_transformer/configuration_table_transformer.py | b1757d7c572a36acfd2bbcd83c2159c835df8ebe361a1a2d27bb61e5409d1f9e | 288 | 6 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/bark/generation_configuration_bark.py | 708e6fc1fde597d60804a897a5bec7299c2ed7ec03ae19e592da58cbc8bd5fde | 331 | 5 |                 Semantic vocab size.             max_input_semantic_length (`int`, *optional*, defaults to 256):                 Max length of semantic input vector.             semantic_rate_hz (`flo |
| .venv/lib/python3.13/site-packages/transformers/models/bark/processing_bark.py | d95bb82866b9ed1baac3173ad1f6185bfb8ab1843715f7d9694c089f7604557e | 299 | 60 |         tokenizer ([`PreTrainedTokenizer`]):             An instance of [`PreTrainedTokenizer`].         speaker_embeddings (`dict[dict[str]]`, *optional*):             Optional nested speaker embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/bark/configuration_bark.py | a7d5297e2f0d5dfe1b1e3f5dd82ef9aac7aea51ed7ec5dc96161404e454587b7 | 304 | 5 |             Dimensionality of the "intermediate" (often named feed-forward) layer in the architecture.         dropout (`float`, *optional*, defaults to 0.0):             The dropout probability for a |
| .venv/lib/python3.13/site-packages/transformers/models/bark/modeling_bark.py | eade1bd3912804234a3e5374f9ec3041c39f5da4bbd2c066e28a1ea1626b9df5 | 1631 | 100 | from ...modeling_flash_attention_utils import flash_attn_supports_top_left_mask, is_flash_attn_available from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import Causa |
| .venv/lib/python3.13/site-packages/transformers/models/convnextv2/modeling_tf_convnextv2.py | 2b08988d4738546123bab57d4ac18dfd5dbc4621983e7ee0eefd4c81180e4390 | 682 | 24 |   # Copied from transformers.models.convnext.modeling_tf_convnext.TFConvNextEmbeddings with ConvNext->ConvNextV2 class TFConvNextV2Embeddings(keras.layers.Layer):     """This class is comparable to (a |
| .venv/lib/python3.13/site-packages/transformers/models/convnextv2/modeling_convnextv2.py | e3680e5319a5c517a75fbbccbc85b5c7f41e2164d4cfce1c7eb2bd7e44ba5ea1 | 447 | 20 |     def forward(self, hidden_states: torch.FloatTensor) -> torch.FloatTensor:         # Compute and normalize global spatial feature maps         global_features = torch.linalg.vector_norm(hidden_stat |
| .venv/lib/python3.13/site-packages/transformers/models/convnextv2/configuration_convnextv2.py | 6d47a77a2ac92e187f78bd6b419d4c93f652082cc9960f82c1c34d124d1f5636 | 119 | 1 |             The number of input channels.         patch_size (`int`, *optional*, defaults to 4):             Patch size to use in the patch embedding layer.         num_stages (`int`, *optional*, defa |
| .venv/lib/python3.13/site-packages/transformers/models/llama4/configuration_llama4.py | dd81010cb344c19c783da112fb25eda0e65f5043d15b1d5d5309391496a9a6b8 | 467 | 30 |     with the defaults will yield a similar configuration to that of the Llama4 109B.      e.g. [meta-llama/Llama-4-Scout-17B-16E](https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E)      Configur |
| .venv/lib/python3.13/site-packages/transformers/models/llama4/modeling_llama4.py | dc1c72acbe950a9f2789d6d3b5c794632a85d88b08bca554e9582c0aa8f82587 | 1405 | 62 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutput, BaseModelOutputWithPast, C |
| .venv/lib/python3.13/site-packages/transformers/models/vitpose/modeling_vitpose.py | 3f467e2e49365ecefc69fa332c4b2f920a1506aea704cb136030d9889d9aa698 | 281 | 2 |         Heatmaps as predicted by the model.     hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):  |
| .venv/lib/python3.13/site-packages/transformers/models/mlcd/modeling_mlcd.py | d477406154cfefb07bfee703c36145ba9273135224b534523d7613a75045ba68 | 612 | 57 |   class MLCDRotaryEmbedding(nn.Module):     inv_freq: torch.Tensor  # fix linting for `register_buffer`  |
| .venv/lib/python3.13/site-packages/transformers/models/mlcd/modular_mlcd.py | a1ab13527c6786a0f7edaa258b0e578392bdc34e8824f9dd221335077cc5719c | 530 | 46 |     CLIPEncoder,     CLIPEncoderLayer,     CLIPVisionEmbeddings,     CLIPVisionModel,     CLIPVisionTransformer, |
| .venv/lib/python3.13/site-packages/transformers/models/pixtral/configuration_pixtral.py | f3a718ef8556ec9f17a94d496efa712ea3979e7ce83e1ec8ffdce36bc8f75a78 | 107 | 1 |             Dropout probability for the attention layers.         rope_theta (`float`, *optional*, defaults to 10000.0):             The base period of the RoPE embeddings.         initializer_range ( |
| .venv/lib/python3.13/site-packages/transformers/models/pixtral/modeling_pixtral.py | 03004386bd01f31c8198d459eff41804458698d91ee18f6c470410e18846c7eb | 524 | 25 |   class PixtralRotaryEmbedding(nn.Module):     """     The key with pixtral embedding is just that you have a frequency for each pixel positions. |
| .venv/lib/python3.13/site-packages/transformers/models/glpn/configuration_glpn.py | a6c1226ad0d945c79278b7b6e0287bedeb34fee80b123ce6ccff3542d8485dc2 | 136 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/glpn/modeling_glpn.py | a8e13bd1848a6ecaaec017528970f6127d6879fc14b5f65a34e59a55c1ff2283 | 726 | 22 |   # Copied from transformers.models.segformer.modeling_segformer.SegformerOverlapPatchEmbeddings class GLPNOverlapPatchEmbeddings(nn.Module):     """Construct the overlapping patch embeddings.""" |
| .venv/lib/python3.13/site-packages/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py | 28221d75f98b3cc35bdcb22b258f7148231ab148d11cfe9607e8e779d04e78d2 | 414 | 10 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py | 99a51824599c9bb848dce91b333d0b8167b5cce74d203423a6c8fc2fc0100ed9 | 3033 | 73 |     BaseModelOutput,     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     Seq2SeqLMOutput,     Seq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/biogpt/__init__.py | a59c558e6573b7b15796430eff97cc834d5ec8fbef1d85e60c0df730a869e989 | 29 | 3 |  if TYPE_CHECKING:     from .configuration_biogpt import *     from .modeling_biogpt import *     from .tokenization_biogpt import * |
| .venv/lib/python3.13/site-packages/transformers/models/biogpt/tokenization_biogpt.py | f0b87f2116b4d11fadcb3ea4005e334ebe3c625e807027ef1b9e32b2e786b155 | 332 | 5 | # See the License for the specific language governing permissions and # limitations under the License. """Tokenization classes for BioGPT."""  import json |
| .venv/lib/python3.13/site-packages/transformers/models/biogpt/modeling_biogpt.py | b6d09015bb88955b67429407ceebf12587546e7747124bc00aa4c23176fd4633 | 965 | 86 | #                🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨 #           This file was automatically generated from src/transformers/models/biogpt/modular_biogpt.py. #               Do NOT edit t |
| .venv/lib/python3.13/site-packages/transformers/models/biogpt/configuration_biogpt.py | b79e3849e3cddc03be0636379f3316e021fe94c01dc6cd53a266caebcdb3e1f2 | 135 | 28 | # See the License for the specific language governing permissions and # limitations under the License. """BioGPT model configuration"""  from ...configuration_utils import PretrainedConfig |
| .venv/lib/python3.13/site-packages/transformers/models/biogpt/modular_biogpt.py | 41fb1eed440ef14b175f7538372c38e8460411ed8e48a5b6c6f2ee2041b49b43 | 789 | 71 | # See the License for the specific language governing permissions and # limitations under the License. """PyTorch BioGPT model."""  import math |
| .venv/lib/python3.13/site-packages/transformers/models/visual_bert/configuration_visual_bert.py | e14d7b6279528db3a9cec00f7461ff11fbc18efee3a696c75a598b06b72118ce | 136 | 17 |         hidden_size (`int`, *optional*, defaults to 768):             Dimensionality of the encoder layers and the pooler layer.         visual_embedding_dim (`int`, *optional*, defaults to 512):      |
| .venv/lib/python3.13/site-packages/transformers/models/visual_bert/modeling_visual_bert.py | 36546365ab958fe932fd99399853e6b2603e55b3b5832367294fa68c0088affa | 1574 | 134 |   class VisualBertEmbeddings(nn.Module):     """Construct the embeddings from word, position and token_type embeddings and visual embeddings."""  |
| .venv/lib/python3.13/site-packages/transformers/models/video_llava/processing_video_llava.py | ab1d51bade7e54f6cde43c21592e60430aa7a345ec99831b1155d7983a3022f2 | 201 | 1 |             in a chat into a tokenizable string.         num_additional_image_tokens (`int`, *optional*, defaults to 1):             Number of additional tokens added to the image embeddings, such as  |
| .venv/lib/python3.13/site-packages/transformers/models/video_llava/modeling_video_llava.py | 601ff964a6c13b4019e59e91cde2e1928b8c0b9fd889326a10309565ba02be20 | 722 | 22 |     """ ) class VideoLlavaCausalLMOutputWithPast(ModelOutput):     r"""     loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided): |
| .venv/lib/python3.13/site-packages/transformers/models/video_llava/configuration_video_llava.py | cdeb660f672f7c7cc512253c3c99f5a965953f03204f4f18311deaf834cfba49 | 144 | 2 |             vision features.         image_seq_length (`int`, *optional*, defaults to 256):             Sequence length of one image embedding.         video_seq_length (`int`, *optional*, defaults to |
| .venv/lib/python3.13/site-packages/transformers/models/cohere/modular_cohere.py | 4485adfd063bb82b7f7571b34fc6584dc7ed640a69d9e68ec62d157a5999b01c | 357 | 34 | # Copyright 2024 Cohere team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It has been modified from its # o |
| .venv/lib/python3.13/site-packages/transformers/models/cohere/tokenization_cohere_fast.py | 48568035e2ebd0ac38cf1f88b4b4c0d77501199ba532505d3bb77d16a241c675 | 513 | 7 |  # fmt: off DEFAULT_SYSTEM_PROMPT = "You are Command-R, a brilliant, sophisticated, AI-assistant trained to assist human users by providing thorough responses. You are trained by Cohere." DEFAULT_RAG_ |
| .venv/lib/python3.13/site-packages/transformers/models/cohere/modeling_cohere.py | 65f34c2b40cddf4b0c96da4ef2adb6e20adeba5801cda65bbe3c5dda3993b031 | 535 | 36 | # Copyright 2024 Cohere team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It has been modified from its # o |
| .venv/lib/python3.13/site-packages/transformers/models/cohere/configuration_cohere.py | 72e34ea45166961f9aa966d8eccefbd60af511fa3849ca21cc9ec05cdd5c5c0b | 218 | 25 | # Copyright 2024 Cohere team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It has been modified from its # o |
| .venv/lib/python3.13/site-packages/transformers/models/udop/configuration_udop.py | c73687124ff52ed63802a1ebd74a8bd95b7b622f8246008ef7c362fcebd13e08 | 161 | 5 |         eos_token_id (`int`, *optional*, defaults to 1):             The id of the end-of-sequence token in the vocabulary.         max_2d_position_embeddings (`int`, *optional*, defaults to 1024):    |
| .venv/lib/python3.13/site-packages/transformers/models/udop/modeling_udop.py | 96dcc9bdd4c51a136da262cddf4c74fd2b68e982cda836c279dc782213accd42 | 2008 | 122 |         that can be used (see `past_key_values` input) to speed up sequential decoding.     hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed o |
| .venv/lib/python3.13/site-packages/transformers/models/blip_2/configuration_blip_2.py | 62c6ff771f2d7f94d1acdc37bc88f0a75c6e290178f8bfd4d93c9439975ea51f | 351 | 13 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/blip_2/modeling_blip_2.py | 7833f87757c1091a828780bcbe71134da03b8da366e9333813543203f4fe9117 | 2425 | 163 | from ...pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer from ...utils import ModelOutput, TransformersKwargs, auto_docstring, logging, torch_int fr |
| .venv/lib/python3.13/site-packages/transformers/models/flava/modeling_flava.py | 5ccef46bc2883a651ad0e57041026ed02f523383bd51a38eac67ce3b70d640ea | 2041 | 250 | @auto_docstring(     custom_intro="""     Output from FlavaModel containing embeddings and outputs from individual encoders.      Note that `image_embeddings` and `text_embeddigns` returned are simila |
| .venv/lib/python3.13/site-packages/transformers/models/flava/configuration_flava.py | 6d8685a446231f1629d3b261ad4bebf5db39905b9b7f0e750c0cbe0008c81b0a | 702 | 14 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/albert/configuration_albert.py | d63cfab109bf2a2fe8fc41c98fb9b350b6a746ddf11683efdedb7fad083a0ade | 171 | 17 |             Vocabulary size of the ALBERT model. Defines the number of different tokens that can be represented by the             `inputs_ids` passed when calling [`AlbertModel`] or [`TFAlbertModel`] |
| .venv/lib/python3.13/site-packages/transformers/models/albert/modeling_albert.py | 59f415c00cf5fc834e2813009e31392b4a8803ffc3515e8f1e99248b627b13ef | 1350 | 109 |          # Naming was changed to be more explicit         name = name.replace("embeddings/attention", "embeddings")         name = name.replace("inner_group_", "albert_layers/")         name = name.re |
| .venv/lib/python3.13/site-packages/transformers/models/albert/modeling_flax_albert.py | f90aea53cf6d338e2300d312fa1690952011a76bb156e5170a9527944f254f9f | 1133 | 50 |             before SoftMax).         hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):             Tuple |
| .venv/lib/python3.13/site-packages/transformers/models/albert/modeling_tf_albert.py | 9df2240d47f9774391ce4d6f1bedc5f8f593c8b4adfbbb8852c069751f6bff08 | 1573 | 79 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     ModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/cohere2_vision/modular_cohere2_vision.py | d3240a6405dd01fb1082784780b21510bc94ede39b9aea4b03fc2753b1feeb5d | 323 | 6 |  from transformers.models.aya_vision.modeling_aya_vision import (     AyaVisionCausalLMOutputWithPast,     AyaVisionForConditionalGeneration,     AyaVisionModel, |
| .venv/lib/python3.13/site-packages/transformers/models/cohere2_vision/configuration_cohere2_vision.py | f931107b89ffef9e12d7e900db6e02892a700dc70359ea8080145088deb3659f | 83 | 1 |             text_config = CONFIG_MAPPING[text_config["model_type"]](**text_config)         elif text_config is None:             text_config = CONFIG_MAPPING["cohere2"](tie_word_embeddings=True)       |
| .venv/lib/python3.13/site-packages/transformers/models/cohere2_vision/modeling_cohere2_vision.py | 1a75f456b1142c82f01eebde125c6a9f2988a544f7e444d879a73ba6f707aa93 | 428 | 14 |     """ ) class Cohere2VisionCausalLMOutputWithPast(ModelOutput):     r"""     loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided): |
| .venv/lib/python3.13/site-packages/transformers/models/videomae/modeling_videomae.py | ba1299df4fa8d54f08e085c143ca40a1fa4a31d78cd116485e8a8937fbffceed | 907 | 44 |   class VideoMAEEmbeddings(nn.Module):     """     Construct the patch and position embeddings. |
| .venv/lib/python3.13/site-packages/transformers/models/videomae/configuration_videomae.py | 3b4070a9866773d4392a97a699e97aacec5e0c14a3eca282c60a477cc5425461 | 149 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/starcoder2/configuration_starcoder2.py | c20b7158d532fe68e8972f07ca0e1e54124a16d732f71dab74ae79bb312b2178 | 208 | 18 |         hidden_act (`str` or `function`, *optional*, defaults to `"gelu_pytorch_tanh"`):             The non-linear activation function (function or string) in the decoder.         max_position_embedd |
| .venv/lib/python3.13/site-packages/transformers/models/starcoder2/modeling_starcoder2.py | 6c505f3cae72d2c8c5db7b675a499591dc297158b2313ce9be987f0abc635eb2 | 486 | 33 | # Copyright 2024 BigCode and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It has  |
| .venv/lib/python3.13/site-packages/transformers/models/starcoder2/modular_starcoder2.py | 0ae132c6fa57c80a022846dcb4dd2214f238dea09ff8d6ff10a440300a93ec1a | 240 | 19 | # Copyright 2024 BigCode and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It has  |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_oss/modeling_gpt_oss.py | 2e26e56ef6db8e78ef343f96331bbf6d8ab17a5bbc9c750f2d4f69208c1c12e0 | 721 | 78 | #                🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨 #           This file was automatically generated from src/transformers/models/gpt_oss/modular_gpt_oss.py. #               Do NOT edit |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_oss/__init__.py | 6b776754a80fe91c1bbb10495b79287582a3f28545e58ea92c98b132d84fd720 | 28 | 2 |  if TYPE_CHECKING:     from .configuration_gpt_oss import *     from .modeling_gpt_oss import * else: |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_oss/configuration_gpt_oss.py | 508e7cd2613ced06a0d65266c503680f4e81cdfcd1bc46ed3eada3880c3068e6 | 127 | 11 |   class GptOssConfig(PretrainedConfig):     r"""     This will yield a configuration to that of the BERT |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_oss/modular_gpt_oss.py | ccd997c3dd53226a86dea4953d100690275bcefe72a4cc8a9814ff4172e9fc65 | 468 | 53 |     LlamaPreTrainedModel,     LlamaRMSNorm,     LlamaRotaryEmbedding,     repeat_kv, ) |
| .venv/lib/python3.13/site-packages/transformers/models/vits/configuration_vits.py | 393e36ab68a17f643dafdaa6ec924ce202653aa412672547f0993742c6dc8e2d | 254 | 7 |             Number of attention heads for each attention layer in the Transformer encoder.         window_size (`int`, *optional*, defaults to 4):             Window size for the relative positional e |
| .venv/lib/python3.13/site-packages/transformers/models/vits/modeling_vits.py | a8d93f6562f1c7096fa0a684c7e1e492d16fa75c328323344d020b1754a372c9 | 1410 | 32 |             weight_norm = nn.utils.weight_norm          if config.speaker_embedding_size != 0:             cond_layer = torch.nn.Conv1d(config.speaker_embedding_size, 2 * config.hidden_size * num_laye |
| .venv/lib/python3.13/site-packages/transformers/models/olmoe/modeling_olmoe.py | 9f1b9746fe58e9349a31b32ca0fd656464bb60d2034b76ff70dad37c8e000307 | 1103 | 42 | from ...modeling_flash_attention_utils import flash_attn_supports_top_left_mask, is_flash_attn_available from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import MoeCa |
| .venv/lib/python3.13/site-packages/transformers/models/olmoe/configuration_olmoe.py | fcd109de7bee1ea10e24d0ff8d68e9a9f57e991efe081f6552754fa039a10a9e | 183 | 13 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/speech_to_text/feature_extraction_speech_to_text.py | afabf168c89933b281c608549ddfd69c32786eb9acf791e29864746e4cef825c | 316 | 2 |             Number of Mel-frequency bins.         padding_value (`float`, *optional*, defaults to 0.0):             The value that is used to fill the padding vectors.         dither (`float`, *option |
| .venv/lib/python3.13/site-packages/transformers/models/speech_to_text/modeling_speech_to_text.py | a91800afc593174dc4a9624f1220463d943965429f38c8da52e8ceebc62bcabb | 1337 | 41 |   class Speech2TextSinusoidalPositionalEmbedding(nn.Module):     """This module produces sinusoidal positional embeddings of any length."""  |
| .venv/lib/python3.13/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py | faa399b28ef989bd03243bc8184e0d72741d3f743deee00b22252a951779faa7 | 1601 | 51 |     TFModelInputType,     TFPreTrainedModel,     TFSharedEmbeddings,     keras,     keras_serializable, |
| .venv/lib/python3.13/site-packages/transformers/models/speech_to_text/configuration_speech_to_text.py | 61ace09a71d8b7f95b61a45036dd9d11802a82901f6259f7ea1425f3d58f2c5e | 200 | 8 |             Dimensionality of the layers and the pooler layer.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/gemma/modular_gemma.py | 44e875438f14fea3c3c65c58f66654ea6dddb9a7183f98945a48f00adf14eb9d | 477 | 20 | from ...utils import TransformersKwargs, logging from ..llama.modeling_llama import (     LlamaForCausalLM,     LlamaForSequenceClassification,     LlamaForTokenClassification, |
| .venv/lib/python3.13/site-packages/transformers/models/gemma/configuration_gemma.py | 2d69e8686cf9df1c4f21b653d56cd012e17b46dfcca653d543d36f3f9e5713d2 | 161 | 10 |             The non-linear activation function (function or string) in the decoder. Will default to `"gelu_pytorch_tanh"`             if not specified. `"gelu_pytorch_tanh"` uses an approximation of t |
| .venv/lib/python3.13/site-packages/transformers/models/gemma/modeling_flax_gemma.py | ad11a53da05723f971b4bcf8ec67f065a6eb77333c10772d3608ad957363cf84 | 778 | 40 | from jax import lax  from ...modeling_flax_outputs import FlaxBaseModelOutput, FlaxCausalLMOutput from ...modeling_flax_utils import ACT2FN, FlaxPreTrainedModel, append_call_sample_docstring from ...u |
| .venv/lib/python3.13/site-packages/transformers/models/gemma/modeling_gemma.py | bfe974d17db9c519b07d332495b73d6a2507bc3430edfca9357164eb9ffccc35 | 505 | 25 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/aimv2/modular_aimv2.py | 2f402f77b4ae2702f2afad2d7aab9c5394e49aa0a07cd709333baaa51a665a9a | 721 | 32 |     can_return_tuple, ) from ..clip.modeling_clip import CLIPModel, CLIPTextEmbeddings, _get_vector_norm from ..llama.modeling_llama import LlamaMLP, LlamaRMSNorm from ..siglip.configuration_siglip im |
| .venv/lib/python3.13/site-packages/transformers/models/aimv2/configuration_aimv2.py | 2b4c9a543a48941b65622f310df86953b9dd4c04aa4eef2757fac2a160000323 | 285 | 4 |         eos_token_id (`int`, *optional*, defaults to 49407):             The id of the end-of-sequence token in the vocabulary.         max_position_embeddings (`int`, *optional*, defaults to 77):     |
| .venv/lib/python3.13/site-packages/transformers/models/aimv2/modeling_aimv2.py | 369dd780e59298dfbffbc30f3357bd17ccdaea4a915a81291c82347cbc26b686 | 821 | 53 |         similarity scores.     text_embeds (`torch.FloatTensor` of shape `(batch_size, output_dim`):         The text embeddings obtained by applying the projection layer to the pooled output of [`Aim |
| .venv/lib/python3.13/site-packages/transformers/models/time_series_transformer/configuration_time_series_transformer.py | 8cdb3ea19d7bc950f2e20fac84dc8e2e803da6ea48b7d66505b5f905744bc98a | 230 | 10 |             of integers, having the same length as `num_static_categorical_features`. Cannot be `None` if             `num_static_categorical_features` is > 0.         embedding_dimension (`list[int]` |
| .venv/lib/python3.13/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py | 954510793669b5ced2d090775520525f2a0ef7afb4a2d5cd9a6488372c98e76b | 1906 | 49 |         cardinalities (`list[int]`):             List of cardinalities of the categorical features.         embedding_dims (`list[int]`):             List of embedding dimensions of the categorical fe |
| .venv/lib/python3.13/site-packages/transformers/models/mllama/image_processing_mllama.py | 2673032f34961f7e0aa988b54a09d23b95c4b95d5a4822661b24faac51c6b38f | 906 | 1 |      Given that the tiles you get depend on the chosen aspect ratio, you have to add     embedding in the modeling code to help it know if it got a 3x2 or a 1x6 or a 2x3     aspect ratio.  |
| .venv/lib/python3.13/site-packages/transformers/models/mllama/processing_mllama.py | 81d92a11497ab5e212dfc5568de6c2e9651b515628728bb22d88ca3ff3b637aa | 383 | 1 |         from PIL import Image          processor = MllamaProcessor.from_pretrained("meta-llama/Llama-3.2-11B-Vision")          processor( |
| .venv/lib/python3.13/site-packages/transformers/models/mllama/configuration_mllama.py | c4d4b07453c4e15d0c00ab220a58e82b75057a4c0bbd1bcc752acd8bf2f9a99d | 374 | 24 |     with the defaults will yield a similar configuration to that of the Mllama-11B.      e.g. [meta-llama/Llama-3.2-11B-Vision](https://huggingface.co/meta-llama/Llama-3.2-11B-Vision)      Configurati |
| .venv/lib/python3.13/site-packages/transformers/models/mllama/modeling_mllama.py | 4daabf0e396ca0ad18b39798f4f344b929ac40f7e9e12961d80e69243376a8b5 | 1758 | 116 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutput, BaseModelOutputWithPast, C |
| .venv/lib/python3.13/site-packages/transformers/models/omdet_turbo/modeling_omdet_turbo.py | c3cbb5c7b5207ca821e8fbf15af256b0100c4931782d70a9950abff786e4282a | 1644 | 99 |         The extracted states from the Feature Pyramid Network (FPN) and Path Aggregation Network (PAN) of the encoder.     decoder_hidden_states (`tuple[torch.FloatTensor]`, *optional*):         Tuple |
| .venv/lib/python3.13/site-packages/transformers/models/omdet_turbo/configuration_omdet_turbo.py | d97323b551b0227095e06a505be147aacbd70a871ed6bb2204c4fd8f60577afa | 305 | 3 |             The feedforward dimension for the task encoder.         class_embed_dim (`int`, *optional*, defaults to 512):             The dimension of the classes embeddings.         class_distance_ty |
| .venv/lib/python3.13/site-packages/transformers/models/clvp/tokenization_clvp.py | 1b93baca4a717ee24b69e8fc9a0923b72dd43449d32f8edee517ef55527b3fc4 | 368 | 22 |  @lru_cache # Copied from transformers.models.gpt2.tokenization_gpt2.bytes_to_unicode def bytes_to_unicode():     """ |
| .venv/lib/python3.13/site-packages/transformers/models/clvp/feature_extraction_clvp.py | 97a26bfb6dd506956bd5c6550132d5c5387dbcd7ae03770a664aab2fcdec48f2 | 242 | 1 |                 - `'np'`: Return Numpy `np.ndarray` objects.             padding_value (`float`, *optional*, defaults to 0.0):                 The value that is used to fill the padding values / vecto |
| .venv/lib/python3.13/site-packages/transformers/models/clvp/modeling_clvp.py | 1b03b4b72794404b60acd73158d525fd0d32cf6cba2c528b8a55bbb61e5e5a39 | 1963 | 88 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPooling,     CausalLMOutputWithCrossAttentions, ) from ...modeling_utils import PreTrainedModel |
| .venv/lib/python3.13/site-packages/transformers/models/clvp/configuration_clvp.py | f9ca01cc23c1e68e876f0750f9bd095b130447190058f14ce264c8e5f6b3710b | 440 | 19 |             Dimensionality of the "intermediate" (i.e., feed-forward) layer in the Transformer encoder.         projection_dim (`int`, *optional*, defaults to 768):             Dimensionality of the p |
| .venv/lib/python3.13/site-packages/transformers/models/m2m_100/modeling_m2m_100.py | 82c2345de66dbc3abbfaebc6ffac08b159400ad14046927cfa0f73eb36eda791 | 1447 | 64 |   # Copied from transformers.models.bart.modeling_bart.BartScaledWordEmbedding with Bart->M2M100 class M2M100ScaledWordEmbedding(nn.Embedding):     """ |
| .venv/lib/python3.13/site-packages/transformers/models/m2m_100/configuration_m2m_100.py | 8b047f78333f265a284f3d3c3c6770f33a9e1665cdab7ff7b6d35ed62bd08e3d | 285 | 8 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/olmo2/modeling_olmo2.py | 9524d330f6d36722eaf29dcf6deb29a9e812b4ce5298b30d94f6b616a4fcb6d1 | 471 | 26 | from ...masking_utils import create_causal_mask from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeli |
| .venv/lib/python3.13/site-packages/transformers/models/olmo2/configuration_olmo2.py | 92a0639c0b3493ea59f98f3334c45643eea06aff98a4ea60ea8cbd2d9f808691 | 181 | 12 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/olmo2/modular_olmo2.py | be3fd883341b551ac17dfc22893612212048fb6493cc092018ac9c8364f02d6b | 322 | 24 |     OlmoAttention,     OlmoDecoderLayer,     OlmoForCausalLM,     OlmoModel,     OlmoRotaryEmbedding, |
| .venv/lib/python3.13/site-packages/transformers/models/superglue/modeling_superglue.py | 6c155ff91077569d983b97679537de2c204b706908ee30944b1e6769de234c80 | 812 | 27 |  class SuperGlueSelfAttention(nn.Module):     def __init__(self, config, position_embedding_type=None):         super().__init__()         if config.hidden_size % config.num_attention_heads != 0 and n |
| .venv/lib/python3.13/site-packages/transformers/models/emu3/processing_emu3.py | 9f9596af33cca615cc0099d06d2f4ceee06993c8d52cab4c33a3a0632885edaf | 249 | 5 | class Emu3Processor(ProcessorMixin):     r"""     Constructs a Emu3 processor which wraps a Emu3 image processor and a GPT2 tokenizer into a single     processor.  |
| .venv/lib/python3.13/site-packages/transformers/models/emu3/configuration_emu3.py | 275b93db14c8e3ec3867ecfa8f13da1ae718d77b7dc0048a243ebf03e79edab2 | 329 | 18 |             Codebook size of the VQ model.         embed_dim (`int`, *optional*, defaults to 4):             Dimension of the quantized vector in codebook.         latent_channels (`int`, *optional*,  |
| .venv/lib/python3.13/site-packages/transformers/models/emu3/modular_emu3.py | bb562d9f4f87ffb6709fc24169240246b08716c6cb3a1d4610f4c24cd14b44a2 | 1224 | 44 | from ...cache_utils import Cache from ...generation import GenerationMixin from ...modeling_outputs import CausalLMOutputWithPast from ...modeling_utils import PreTrainedModel from ...processing_utils |
| .venv/lib/python3.13/site-packages/transformers/models/emu3/modeling_emu3.py | 5c2d74a40b7193122fc1f23186c2d1642a2870db9a64e1a36edde28e4967a344 | 1639 | 58 | from ...masking_utils import create_causal_mask from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeli |
| .venv/lib/python3.13/site-packages/transformers/models/got_ocr2/modeling_got_ocr2.py | 69d7578971557302dd5d7be2437497b4475ebf49b011e7e58acd6c07d9902f86 | 844 | 34 |  class GotOcr2VisionAttention(nn.Module):     """Multi-head Attention block with relative position embeddings."""      def __init__(self, config, window_size): |
| .venv/lib/python3.13/site-packages/transformers/models/got_ocr2/modular_got_ocr2.py | 58c89d6901de3ec130562da8172b864bd2b72ea83f53d10bd623829b86a62bd4 | 485 | 13 | from ..auto import CONFIG_MAPPING, AutoConfig from ..llava.modeling_llava import (     LlavaCausalLMOutputWithPast,     LlavaForConditionalGeneration,     LlavaModel, |
| .venv/lib/python3.13/site-packages/transformers/models/got_ocr2/configuration_got_ocr2.py | 9fd6b76e82c564dec7302c854ab6617191fe71e5a4dff52df57273d45fdc1242 | 212 | 5 |             Whether to add a bias to query, key, value projections.         use_abs_pos (`bool`, *optional*, defaults to `True`):             Whether to use absolute position embedding.         use_re |
| .venv/lib/python3.13/site-packages/transformers/models/diffllama/modeling_diffllama.py | e7eb3dfb892182911a20ba0cc3ad681c0255f08fd60d1b8188f3be8c47a60f98 | 768 | 36 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/diffllama/configuration_diffllama.py | 490afa14cf21e8440223e34d61892cbcad094b2d9637caba68640d0c56c90200 | 200 | 18 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/diffllama/modular_diffllama.py | bcba8c295566fcbbc8621928449d021cb704b49dedffb1572793a917000cc971 | 448 | 18 | from ...utils import logging from ...utils.deprecation import deprecate_kwarg from ..gemma.modeling_gemma import GemmaForCausalLM from ..llama.modeling_llama import (     LlamaDecoderLayer, |
| .venv/lib/python3.13/site-packages/transformers/models/squeezebert/modeling_squeezebert.py | 5cd7142f2f6ba30c627729a31dbf03dce596545693b02f6b1cb3e6250b1de6b4 | 963 | 55 |   class SqueezeBertEmbeddings(nn.Module):     """Construct the embeddings from word, position and token_type embeddings."""  |
| .venv/lib/python3.13/site-packages/transformers/models/squeezebert/configuration_squeezebert.py | f48e2652ea84c0a008adecd18e3b68dc705f27e6a25814e441c2195ae2451463 | 168 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/swin/modeling_swin.py | 7f73018459af6175c18ba018ff3306179167a5d91687e9ea1e54674889e35398 | 1280 | 73 |   # drop_path, SwinPatchEmbeddings, SwinPatchMerging and SwinDropPath are from the timm library.   |
| .venv/lib/python3.13/site-packages/transformers/models/swin/configuration_swin.py | 85c92c138e0c193f7fad660d5ef87297de23a94d34ad06375d74c33f34e5be6a | 180 | 9 |             The number of input channels.         embed_dim (`int`, *optional*, defaults to 96):             Dimensionality of patch embedding.         depths (`list(int)`, *optional*, defaults to `[2 |
| .venv/lib/python3.13/site-packages/transformers/models/swin/modeling_tf_swin.py | d6a9795b9ad8ea8c510dddb8763f911ac5b2fa89ca1906de375259dca68a763e | 1640 | 72 |   # drop_path, TFSwinPatchEmbeddings, TFSwinPatchMerging and TFSwinDropPath are tensorflow # implementations of PyTorch functionalities in the timm library.  |
| .venv/lib/python3.13/site-packages/transformers/models/convnext/modeling_tf_convnext.py | 7dfed330702d60dd08b286a2be3d53df8321cdbbf1ffde1844566a8bc0b7bb90 | 668 | 23 |   class TFConvNextEmbeddings(keras.layers.Layer):     """This class is comparable to (and inspired by) the SwinEmbeddings class     found in src/transformers/models/swin/modeling_swin.py. |
| .venv/lib/python3.13/site-packages/transformers/models/convnext/configuration_convnext.py | f66e685d8f55c7705d003c3493b11e3389f72ab9026f7240f9638f5256edafbe | 143 | 1 |             The number of input channels.         patch_size (`int`, *optional*, defaults to 4):             Patch size to use in the patch embedding layer.         num_stages (`int`, *optional*, defa |
| .venv/lib/python3.13/site-packages/transformers/models/convnext/modeling_convnext.py | e35713b24bd55647a023196cfcdd898b389997d121f6ac5c56a4eed3abb99c2b | 424 | 18 |   class ConvNextEmbeddings(nn.Module):     """This class is comparable to (and inspired by) the SwinEmbeddings class     found in src/transformers/models/swin/modeling_swin.py. |
| .venv/lib/python3.13/site-packages/transformers/models/arcee/modeling_arcee.py | 783fe68fa3050016f03f1505548e22f19641d18923506233cba3d42e38bbcaed | 507 | 26 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/arcee/modular_arcee.py | a5c505e48f537cf20f8eb26958929ffe8755a2b47fa4bc202a1bd2a8b3305a90 | 226 | 19 | from ..llama.configuration_llama import LlamaConfig from ..llama.modeling_llama import (     LlamaForCausalLM,     LlamaForQuestionAnswering,     LlamaForSequenceClassification, |
| .venv/lib/python3.13/site-packages/transformers/models/arcee/configuration_arcee.py | 4b839e882b0757f41ba30eaae97f993f0839505cfb8efa4aeabd3a19fdca099c | 202 | 16 |         hidden_act (`str` or `function`, *optional*, defaults to `"relu2"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`, |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_neox/tokenization_gpt_neox_fast.py | 8a2beb96e3f8393910941423ab3d64a67d0d848adaaea3da7c36c280719cf34a | 225 | 9 | # See the License for the specific language governing permissions and # limitations under the License. """Tokenization classes for GPTNeoX."""  from typing import Optional |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_neox/__init__.py | e822fdd82baa05320327e607fdda05c1bfa84729407dfc3ba70c5e76fddafb8d | 29 | 3 |  if TYPE_CHECKING:     from .configuration_gpt_neox import *     from .modeling_gpt_neox import *     from .tokenization_gpt_neox_fast import * |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_neox/configuration_gpt_neox.py | fb3f73b6b94e020ca8acf799293a7e7cebd25563a866eaa18807ead154c1b8d3 | 207 | 37 | # See the License for the specific language governing permissions and # limitations under the License. """GPTNeoX model configuration"""  from ...configuration_utils import PretrainedConfig |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py | 3d2a9f48992143d12d8cd24fe8c8a5975e1cd904c8fdbdde0045c735135e4e2c | 833 | 103 | #                🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨 #           This file was automatically generated from src/transformers/models/gpt_neox/modular_gpt_neox.py. #               Do NOT ed |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_neox/modular_gpt_neox.py | 9e9c4fc48cdd19503b22654d096dbca18ceff8e7664a1251fc65241e97739b7e | 705 | 84 | from ...modeling_outputs import (     BaseModelOutputWithPast,     CausalLMOutputWithPast,     QuestionAnsweringModelOutput,     SequenceClassifierOutputWithPast, |
| .venv/lib/python3.13/site-packages/transformers/models/poolformer/modeling_poolformer.py | 1f4858e6f937c5a01159e15e01f8de88ee57238993edcae94d2a7676b8ab017d | 402 | 20 |   class PoolFormerEmbeddings(nn.Module):     """     Construct Patch Embeddings. |
| .venv/lib/python3.13/site-packages/transformers/models/mimi/configuration_mimi.py | eede5bdaddcf5a953b17755ce0ec3abdf7b5ffc331c2962c1b7454972a9f2942 | 280 | 11 |             Number of discret codes in each codebooks.         codebook_dim (`int`, *optional*, defaults to 256):             Dimension of the unquantized codebook vectors. If not defined, uses `hidde |
| .venv/lib/python3.13/site-packages/transformers/models/mimi/modeling_mimi.py | d69cafb4bc0264853fa0ee37319e59d870a99c1e5f9dddc96193a3a283d6bbd5 | 1770 | 60 |     r"""     audio_codes (`torch.LongTensor`  of shape `(batch_size, num_quantizers, codes_length)`, *optional*):         Discret code embeddings computed using `model.encode`.     audio_values (`torc |
| .venv/lib/python3.13/site-packages/transformers/models/wavlm/modular_wavlm.py | e2c8005a198fe583c7cd8b8af93de08eb87e4eee158cebad11501ff24e270e04 | 589 | 54 |     Wav2Vec2ForCTC,     Wav2Vec2ForSequenceClassification,     Wav2Vec2ForXVector,     Wav2Vec2Model,     Wav2Vec2PositionalConvEmbedding, |
| .venv/lib/python3.13/site-packages/transformers/models/wavlm/configuration_wavlm.py | 1eb2b476db3171507e937c8eda9c7a452f935b59689efc7fc7cb91933ee226a4 | 338 | 51 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the  |
| .venv/lib/python3.13/site-packages/transformers/models/wavlm/modeling_wavlm.py | 3bdd46ce6ef62f49d2446f90f898823b402c2d3109a2c1f36b906c107879d384 | 1707 | 87 | from ...modeling_outputs import (     BaseModelOutput,     CausalLMOutput,     SequenceClassifierOutput,     TokenClassifierOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/marian/modeling_marian.py | f67ab0ada8e01a40b8f5f68125193b47e70273ed65dada3248f16988f4d994ff | 1703 | 145 |     BaseModelOutput,     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     Seq2SeqLMOutput,     Seq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/marian/configuration_marian.py | d92bf50b35586085ef2c19f2b5a2c6d13e24fa9b68ca98552c0264fb345cb32c | 396 | 13 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/marian/modeling_flax_marian.py | aa4514a4a0b830f1e6112b88d308c643de6ebb416cd2322340ca4a53fd3ec4c3 | 1501 | 36 |     FlaxBaseModelOutput,     FlaxBaseModelOutputWithPastAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxSeq2SeqLMOutput,     FlaxSeq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/marian/tokenization_marian.py | e0ec7547cd7c839738c7fa51e3526025f3a101939a2d74d10e03903d0ace9115 | 397 | 2 |      ```python     >>> from transformers import MarianForCausalLM, MarianTokenizer      >>> model = MarianForCausalLM.from_pretrained("Helsinki-NLP/opus-mt-en-de") |
| .venv/lib/python3.13/site-packages/transformers/models/marian/modeling_tf_marian.py | e5b759341d0057cd9158ebcf3067bcea151e947f7b5ab5503eda8823128ae2b4 | 1559 | 50 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     add_code_sample_docstrings, |
| .venv/lib/python3.13/site-packages/transformers/models/vilt/configuration_vilt.py | 07b96759057b402e427a58863d01794cfe428beb37e5bbfbfcb5f852f395354b | 148 | 9 |         modality_type_vocab_size (`int`, *optional*, defaults to 2):             The vocabulary size of the modalities passed when calling [`ViltModel`]. This is used after concatenating the           |
| .venv/lib/python3.13/site-packages/transformers/models/vilt/modeling_vilt.py | 8a653b8bf60bbf27e8ac935cecd3fa0f5773ef3778d777670fe46e83dfc23b53 | 1353 | 90 |     hidden_states (`list[tuple(torch.FloatTensor)]`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):         List of tuples of `torch.Float |
| .venv/lib/python3.13/site-packages/transformers/models/electra/modeling_flax_electra.py | 23c69ad3666408228be9c87f2f7f0117162640af845ae32748452c4ffa94c4f1 | 1615 | 71 |     FlaxBaseModelOutput,     FlaxBaseModelOutputWithPastAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxMaskedLMOutput,     FlaxMultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/electra/configuration_electra.py | 43cb9dcaafc0ca64339309e5acfbab8f899d97d7f8414da5d18383287e76dee7 | 188 | 19 |             Vocabulary size of the ELECTRA model. Defines the number of different tokens that can be represented by the             `inputs_ids` passed when calling [`ElectraModel`] or [`TFElectraMode |
| .venv/lib/python3.13/site-packages/transformers/models/electra/modeling_tf_electra.py | 756f840fa1d02ac2e9aff433432dcea8bfa7319073993fe586b951cf66e2734f | 1776 | 80 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     ModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/electra/modeling_electra.py | bb44e8e4c64e917cf3e0c7abf921b2691ad01c4734ab621d5bd15959f5dbb302 | 1587 | 113 |     BaseModelOutputWithCrossAttentions,     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/exaone4/modeling_exaone4.py | d045c85eac18b843c967c18094cd831297700ebaa0cce70189798bb6d391997b | 539 | 26 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/exaone4/configuration_exaone4.py | 07770f48889b6b15b79f7a8480f53279e2a9da12791e516cbf30aca190015095 | 224 | 19 |     This is the configuration class to store the configuration of a [`Exaone4Model`]. It is used to     instantiate a EXAONE 4.0 model according to the specified arguments, defining the model architec |
| .venv/lib/python3.13/site-packages/transformers/models/exaone4/modular_exaone4.py | 08bfa5f7627bea5038cc95b4a2354d919003b87897c557dabda1de0e5305ab16 | 522 | 38 | from ...modeling_outputs import (     BaseModelOutputWithPast,     CausalLMOutputWithPast, ) from ...modeling_utils import ALL_ATTENTION_FUNCTIONS |
| .venv/lib/python3.13/site-packages/transformers/models/evolla/modular_evolla.py | 0d9e05afe081c00f34be3527ac56a8c5215922b1bfaf6d4664836fc6a6a09a7d | 1022 | 53 |     BaseModelOutputWithPast,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithPast,     ModelOutput, ) |
| .venv/lib/python3.13/site-packages/transformers/models/evolla/configuration_evolla.py | 8f3f692a2766be7745215700025a63c3b0536f78be32ff7869cf7284ba6b3650 | 278 | 22 |         attention_probs_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout ratio for the attention probabilities in the protein sequence model.         max_position_embedding |
| .venv/lib/python3.13/site-packages/transformers/models/evolla/modeling_evolla.py | ba9cb8c919f63e0398743b42ceb455ead89537800af1d672eb05ba5518f40ece | 1583 | 113 |     BaseModelOutputWithPast,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithPast,     ModelOutput, ) |
| .venv/lib/python3.13/site-packages/transformers/models/evolla/processing_evolla.py | 97ffe58984abf8d99f0a5c334422fcf07a08014b354d9a45615ca7e1e758ce55 | 248 | 2 |      # overwrite to save the protein tokenizer in a separate folder     # Adapted from instructblip.processing_instructblip.py (https://github.com/huggingface/transformers/blob/9b479a245b793cac2a8b2e8 |
| .venv/lib/python3.13/site-packages/transformers/models/perception_lm/configuration_perception_lm.py | 3bc9bcfdb9b65b76ef1e32298ff1799caa33e242ec9c1ebd2b03b499c2d050ec | 89 | 1 |             The config object or dictionary of the text backbone.         vision_use_cls_token (`bool`, *optional*, defaults to `True`):             Whether CLS token is used in the vision backbone. I |
| .venv/lib/python3.13/site-packages/transformers/models/perception_lm/modular_perception_lm.py | e04772a169a40f1167bf514681186c23b3412bcb26f3588bd460ba11bf59478d | 396 | 8 | from ..auto import AutoModel from ..llava.modeling_llava import (     LlavaCausalLMOutputWithPast,     LlavaForConditionalGeneration,     LlavaModel, |
| .venv/lib/python3.13/site-packages/transformers/models/perception_lm/image_processing_perception_lm_fast.py | 4961eceb31857f08e12676fb075c5b8ed632bd23ecfb62dbf201726b8cb62273 | 320 | 2 |     vision_input_type (`str`, *optional*, defaults to `"thumb+tile"`):         Vision processing strategy. `"thumb+tile"` uses both thumbnails and multiple tiles for         multi-scale processing, ot |
| .venv/lib/python3.13/site-packages/transformers/models/perception_lm/modeling_perception_lm.py | 1d1b8c72270031015685ddd2edc2559f9c050a94187253bc4e1ac8ad177c68ed | 468 | 15 |     """ ) class PerceptionLMCausalLMOutputWithPast(ModelOutput):     r"""     loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided): |
| .venv/lib/python3.13/site-packages/transformers/models/bit/modeling_bit.py | a842b74702b16ca5491d0a4c7da40138eabd0fd98d88edcc2005943be1c19f3e | 842 | 21 |         padding = padding.lower()         if padding == "same":             # TF compatible 'SAME' padding, has a performance and GPU memory allocation impact             if stride == 1 and (dilation  |
| .venv/lib/python3.13/site-packages/transformers/models/bit/configuration_bit.py | c1914fefa089615ec79fe3386924665e7f92c5702c99450738b3473fa072ea52 | 137 | 10 |         num_channels (`int`, *optional*, defaults to 3):             The number of input channels.         embedding_size (`int`, *optional*, defaults to 64):             Dimensionality (hidden size)  |
| .venv/lib/python3.13/site-packages/transformers/models/luke/configuration_luke.py | abf40b1510eb25f001a1bf7febec6f4b2ec44b854c60a83d037fe01bc0ecc403 | 143 | 6 |             Dimensionality of the encoder layers and the pooler layer.         entity_emb_size (`int`, *optional*, defaults to 256):             The number of dimensions of the entity embedding.       |
| .venv/lib/python3.13/site-packages/transformers/models/luke/modeling_luke.py | ed97dac4f6812a6b0cd2a5930e5892bf6a4c2a1ab40f5b3d532b5300cecb6938 | 2181 | 160 |         Sequence of entity hidden-states at the output of the last layer of the model.     entity_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is pa |
| .venv/lib/python3.13/site-packages/transformers/models/luke/tokenization_luke.py | 487b67b009be8755707475a330f5d0d25787482a2a54555d2c0d8a1092364691 | 1732 | 1 | class LukeTokenizer(PreTrainedTokenizer):     """     Constructs a LUKE tokenizer, derived from the GPT-2 tokenizer, using byte-level Byte-Pair-Encoding.      This tokenizer has been trained to treat  |
| .venv/lib/python3.13/site-packages/transformers/models/deberta/modeling_deberta.py | 0cbb8e067599132470de9ef990ad5645a8335d35d1789b01dc4af501d3d0f3ba | 1206 | 129 |             self.max_relative_positions = getattr(config, "max_relative_positions", -1)             if self.max_relative_positions < 1:                 self.max_relative_positions = config.max_positio |
| .venv/lib/python3.13/site-packages/transformers/models/deberta/tokenization_deberta_fast.py | ba8244f40b2cc869ace6e44cc48cb76b02a3d16f2727bb18141d178995f3e3b9 | 210 | 9 |         return cls + token_ids_0 + sep + token_ids_1 + sep      # Copied from transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast._batch_encode_plus     def _batch_encode_plus(self, *arg |
| .venv/lib/python3.13/site-packages/transformers/models/deberta/configuration_deberta.py | 18592b3e7f53800dd046b45362cc459d046c151cc51cf9690c9c12fc70a8f46a | 201 | 10 |             are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddings, encoder, and pooler |
| .venv/lib/python3.13/site-packages/transformers/models/deberta/modeling_tf_deberta.py | eab1fc8dd096328c4a9eeac8b6ad6295667c29b68cf886d41a43c40ab50c47d3 | 1653 | 111 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import add_code_sample_docstrings, add_start_docstrings, add_start_docstrings_to_m |
| .venv/lib/python3.13/site-packages/transformers/models/deberta/tokenization_deberta.py | b046c1e09f05d01770cb17e43a79303dce005811dcc11c9513b425f4037c47e4 | 367 | 28 |   # Copied from transformers.models.gpt2.tokenization_gpt2.bytes_to_unicode def bytes_to_unicode():     """ |
| .venv/lib/python3.13/site-packages/transformers/models/granite/modeling_granite.py | 10bd5af1756c312534c8fd7526474f023ece05144d940fa3818d565e18f0e957 | 566 | 33 | from ...masking_utils import create_causal_mask from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeli |
| .venv/lib/python3.13/site-packages/transformers/models/granite/configuration_granite.py | 535090da0bd3606c7be77517d2de4839f70b9658a40d4ec9ba98fb365397dc39 | 198 | 20 | # Copyright 2024 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/granite/modular_granite.py | 51d89512d8ec57012da0843c42f685abfc5a7db646d1d18478a592e141cba442 | 287 | 20 | from ...cache_utils import Cache, DynamicCache from ...masking_utils import create_causal_mask from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...processing_utils  |
| .venv/lib/python3.13/site-packages/transformers/models/gemma2/modeling_gemma2.py | 89a79d05ff48f2bc672e34d60848b3cecb2c190ec15c328afa2e32d8f4543bc4 | 597 | 26 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/gemma2/configuration_gemma2.py | 77700a046ba5db470f02eabacc581495ec47ce358f2b91810d6d4871066ffc4f | 183 | 10 |             The non-linear activation function (function or string) in the decoder. Will default to `"gelu_pytorch_tanh"`             if not specified. `"gelu_pytorch_tanh"` uses an approximation of t |
| .venv/lib/python3.13/site-packages/transformers/models/gemma2/modular_gemma2.py | a65f0bcead95d1cd9d2886b68f592f750860a73c572cb5f5b5f1eadc50ef35b3 | 584 | 29 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWith |
| .venv/lib/python3.13/site-packages/transformers/models/mixtral/modeling_mixtral.py | 1f1362b3386195e7f9824ad118ac2e80dc3f0626bd16fab2df51bdc7a825de94 | 690 | 29 | # Copyright 2023 Mistral AI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/mixtral/configuration_mixtral.py | ece31b83ca5f694d167d89c6208aaae670f3c7df31f0d3ca8be34e6f7a1201d9 | 192 | 10 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/mixtral/modular_mixtral.py | f2f78df30766fd187dc9e46025d606260f8c54220e476bc15322b534f579d069 | 469 | 23 | # Copyright 2023 Mistral AI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/pix2struct/configuration_pix2struct.py | 787835f4acd25b96e1d9d55380c1fbbe164f66edb283a884a72f0334ee9b93c5 | 338 | 11 |             The maximum distance of the longer sequences for the bucket separation.         dropout_rate (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully conne |
| .venv/lib/python3.13/site-packages/transformers/models/pix2struct/modeling_pix2struct.py | 8fb1a54933ca2b9057970004535e34c1225241f0c4356d8531f72307e1549253 | 1614 | 58 |     BaseModelOutput,     BaseModelOutputWithPooling,     CausalLMOutputWithCrossAttentions,     Seq2SeqLMOutput,     Seq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py | 1d6120e467adea8580c866b392fd8a6fb1ca7aedbd1b672f0b2ff3daa7ef7ec6 | 1996 | 81 | class ConditionalDetrConvModel(nn.Module):     """     This module adds 2D position embeddings to all intermediate feature maps of the convolutional encoder.     """  |
| .venv/lib/python3.13/site-packages/transformers/models/conditional_detr/image_processing_conditional_detr.py | 8bf43abe925f2efe140cc1c2ac025a1d2d79a69d74660907ca2fea8b639145fc | 1859 | 4 |      # Keep track of instances of each class     stuff_memory_list: dict[str, int] = {}     for k in range(pred_labels.shape[0]):         pred_class = pred_labels[k].item() |
| .venv/lib/python3.13/site-packages/transformers/models/conditional_detr/configuration_conditional_detr.py | 27448c66ac8abd0d01bbfa20ef8595ab09b632ec6660e65015ed48c3e7d59621 | 287 | 6 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/vision_text_dual_encoder/modeling_tf_vision_text_dual_encoder.py | 36708e68062d8d0e3252ff74026edc1e7c4a53d5600c39d7190aa7252b2012ce | 624 | 7 |      This model inherits from [`TFPreTrainedModel`]. Check the superclass documentation for the generic methods the     library implements for all its model (such as downloading or saving, resizing th |
| .venv/lib/python3.13/site-packages/transformers/models/vision_text_dual_encoder/modeling_flax_vision_text_dual_encoder.py | 7a3561ea3bcd2617f15dcef4280cb2d146718ffc56a5cae5cbbb1b51c9418b9e | 602 | 7 |      This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the     library implements for all its model (such as downloading or saving, resizing the  |
| .venv/lib/python3.13/site-packages/transformers/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py | 7a5d87d26fbc1ce6952f87afe5a3b186754ef56fae0a2c3cfb6d5a2dc866db90 | 424 | 2 |         r"""         Returns:             text_features (`torch.FloatTensor` of shape `(batch_size, output_dim`): The text embeddings obtained by             applying the projection layer to the poole |
| .venv/lib/python3.13/site-packages/transformers/models/mvp/modeling_mvp.py | a136ad448d8232bfed613d2fb66550d6d839b62c7bacd5ffc9bcf2854416efdf | 1787 | 58 |     BaseModelOutput,     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     Seq2SeqLMOutput,     Seq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/mvp/tokenization_mvp_fast.py | c50acf888f75fc21bb208fa040426ceebb5348c45b28d011735f3930e6b9250b | 275 | 2 | class MvpTokenizerFast(PreTrainedTokenizerFast):     r"""     Construct a "fast" MVP tokenizer (backed by HuggingFace's *tokenizers* library), derived from the GPT-2 tokenizer,     using byte-level By |
| .venv/lib/python3.13/site-packages/transformers/models/mvp/configuration_mvp.py | 021fc41b49c8b4e0f7ff2fd60da77a72709c8066364d75ae273c6e2c943a7eae | 184 | 10 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/timesfm/modeling_timesfm.py | a16ffac9aa3b14ecdfbe55f119502c74ad806657d7ec7d5fd11efbc940d1fa84 | 846 | 13 |   class TimesFmPositionalEmbedding(nn.Module):     """Generates position embedding for a given 1-d sequence."""  |
| .venv/lib/python3.13/site-packages/transformers/models/timesfm/configuration_timesfm.py | 3812b1c2b35e79a93e6202ad28be334e0b3bd3913db68e0509b0fbc17d09d46b | 128 | 6 |             The length of the prediction horizon.         freq_size (`int`, *optional*, defaults to 3):             The number of frequency embeddings.         num_hidden_layers (`int`, *optional*, de |
| .venv/lib/python3.13/site-packages/transformers/models/timesfm/modular_timesfm.py | 444d72a66f29ca00a38d94369547c47f0aa2637bfcc187561c9ac4b0522475ea | 802 | 13 |   class TimesFmPositionalEmbedding(nn.Module):     """Generates position embedding for a given 1-d sequence."""  |
| .venv/lib/python3.13/site-packages/transformers/models/pvt_v2/configuration_pvt_v2.py | ecb30c4505206ffc58bd61641ad2f103a93f6b5d1c04552d4b1f2f7a326ea77f | 157 | 3 |             Dimension of each of the encoder blocks.         patch_sizes (`list[int]`, *optional*, defaults to `[7, 3, 3, 3]`):             Patch size for overlapping patch embedding before each encod |
| .venv/lib/python3.13/site-packages/transformers/models/pvt_v2/modeling_pvt_v2.py | 91576219b9bf47eef310a19f3572f0833d8d5dc80b37426b64529410afcbcb3b | 636 | 14 |   class PvtV2OverlapPatchEmbeddings(nn.Module):     """Image to Patch Embedding"""  |
| .venv/lib/python3.13/site-packages/transformers/models/donut/configuration_donut_swin.py | 9878343f8311c4c3b0fc8b07285b4122e4aeb98d2d20d18ddc599422632a493f | 136 | 9 |             The number of input channels.         embed_dim (`int`, *optional*, defaults to 96):             Dimensionality of patch embedding.         depths (`list(int)`, *optional*, defaults to `[2 |
| .venv/lib/python3.13/site-packages/transformers/models/donut/modeling_donut_swin.py | ce6642e672b4d24e2459903edeff71d608b3f37bd81550310e89c354f1b09f67 | 1033 | 62 |     r"""     reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):         Tuple of `torch.Fl |
| .venv/lib/python3.13/site-packages/transformers/models/sam/modeling_sam.py | 4f6639e4a052ed2791ea3172f3addfaa5986060874f513e802e22de5f5696ad1 | 1369 | 226 | @auto_docstring(     custom_intro="""     Base class for sam vision model's outputs that also contains image embeddings obtained by applying the projection     layer to the pooler_output.     """ |
| .venv/lib/python3.13/site-packages/transformers/models/sam/image_processing_sam_fast.py | e3d53740d56c2ccc25267355c2a058ca1eba1079a92089effdfd484f5c462033 | 830 | 1 | def _compute_stability_score(masks: "torch.Tensor", mask_threshold: float, stability_score_offset: int):     # One mask is always contained inside the other.     # Save memory by preventing unnecessar |
| .venv/lib/python3.13/site-packages/transformers/models/sam/image_processing_sam.py | 7fda7284bae8e8aa314f473d88b46fcab2e155d7f9bf3cb81de07fa24566fa52 | 1500 | 1 | def _compute_stability_score_pt(masks: "torch.Tensor", mask_threshold: float, stability_score_offset: int):     # One mask is always contained inside the other.     # Save memory by preventing unneces |
| .venv/lib/python3.13/site-packages/transformers/models/sam/modeling_tf_sam.py | a146332d41ddb4e8047284bac33915f4c0e6535d94c17c1318e88042257ed960 | 1724 | 215 | class TFSamVisionEncoderOutput(ModelOutput):     """     Base class for sam vision model's outputs that also contains image embeddings obtained by applying the projection     layer to the pooler_outpu |
| .venv/lib/python3.13/site-packages/transformers/models/sam/configuration_sam.py | aba0b5d0ec9874789c5917ee6ae76797fe4af48dcb1fc9cf423ff5c173c67a0c | 338 | 10 |         mask_input_channels (`int`, *optional*, defaults to 16):             The number of channels to be fed to the `MaskDecoder` module.         num_point_embeddings (`int`, *optional*, defaults to  |
| .venv/lib/python3.13/site-packages/transformers/models/mpt/modeling_mpt.py | fe22545b66ba03f5f684b4e74d26d3cc3a69274ab16eb1a54fc05c25c82e15c5 | 826 | 18 | from ...modeling_outputs import (     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     QuestionAnsweringModelOutput,     SequenceClassifierOutputWithPast, |
| .venv/lib/python3.13/site-packages/transformers/models/mpt/configuration_mpt.py | 4be021d6e02b1693481aff7b3c2d2635c5bf241bcce48f374d18cceb52a3359d | 230 | 9 |             token belongs to. Defaults to `False` meaning any provided *token_type_ids* will be ignored.         alibi (`bool`, *optional*, defaults to `True`):             Whether or not to use the a |
| .venv/lib/python3.13/site-packages/transformers/models/shieldgemma2/configuration_shieldgemma2.py | 0a3e0c338edfbe74151aacc45de89d6aaae44a6cf8fa2d75998bf3eb28f876f5 | 119 | 1 |             Custom vision config or dict.         mm_tokens_per_image (`int`, *optional*, defaults to 256):             The number of tokens per image embedding.         boi_token_index (`int`, *optio |
| .venv/lib/python3.13/site-packages/transformers/models/shieldgemma2/modeling_shieldgemma2.py | 52b9d461c0e37769eee86e0ff04030b092afd1da2f7d8a04faf2e1654def3f69 | 150 | 10 |         self.model = AutoModelForImageTextToText.from_config(config=config)      def get_input_embeddings(self):         return self.model.language_model.get_input_embeddings()  |
| .venv/lib/python3.13/site-packages/transformers/models/maskformer/modeling_maskformer_swin.py | ebd220323f944dfb73a50a28f76dbf20ac0d380d278e996517a46a247f53fd11 | 928 | 52 |   class MaskFormerSwinEmbeddings(nn.Module):     """     Construct the patch and position embeddings. |
| .venv/lib/python3.13/site-packages/transformers/models/maskformer/configuration_maskformer_swin.py | fbbd86b95ecec83794d30097ece96d50070c3d2a4a66ac25a89c1db0b5a58a31 | 154 | 9 |             The number of input channels.         embed_dim (`int`, *optional*, defaults to 96):             Dimensionality of patch embedding.         depths (`list[int]`, *optional*, defaults to `[2 |
| .venv/lib/python3.13/site-packages/transformers/models/maskformer/image_processing_maskformer.py | 872d04668ccf39e8610bd285ed7976962009c0fe31f20a034085218fb9c255a1 | 1324 | 4 |      # Keep track of instances of each class     stuff_memory_list: dict[str, int] = {}     for k in range(pred_labels.shape[0]):         pred_class = pred_labels[k].item() |
| .venv/lib/python3.13/site-packages/transformers/models/maskformer/modeling_maskformer.py | 4676194a2f4f87277bd568a74ea60d38293ceda3334248bd784211f7c51dcb90 | 1804 | 50 |      The `encoder_last_hidden_state` are referred on the paper as **images features**, while `decoder_last_hidden_state`     as **pixel embeddings**     """ ) |
| .venv/lib/python3.13/site-packages/transformers/models/deepseek_vl_hybrid/modeling_deepseek_vl_hybrid.py | 98252ac2bb56d34384b2d9856b24e42aaaca0e64c61d4930f9b3141a7fd8de20 | 506 | 17 |         input) to speed up sequential decoding.     image_hidden_states (`tuple(torch.FloatTensor)`, *optional*):         Tuple of `torch.FloatTensor` (one for the output of the image embeddings, `(ba |
| .venv/lib/python3.13/site-packages/transformers/models/deepseek_vl_hybrid/modular_deepseek_vl_hybrid.py | 82e7233075847fa334e4dc932bcc11cdf43d83922e0066a32f0e797e42c225e8 | 995 | 7 | ) from ..deepseek_vl.processing_deepseek_vl import DeepseekVLProcessor, DeepseekVLProcessorKwargs from ..idefics.modeling_idefics import IdeficsBaseModelOutputWithPast, IdeficsCausalLMOutputWithPast f |
| .venv/lib/python3.13/site-packages/transformers/models/markuplm/modeling_markuplm.py | 7446e41b3c86240ece491357ee4d0496cbd688c706f020749e4a53e87340b3a2 | 1053 | 76 |   class XPathEmbeddings(nn.Module):     """Construct the embeddings from xpath tags and subscripts.  |
| .venv/lib/python3.13/site-packages/transformers/models/markuplm/configuration_markuplm.py | d133ef32153bf79a7e8e668fc8179f56ec011126462681ce38844d93a360c977 | 171 | 26 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/cpmant/configuration_cpmant.py | 46f826407f2541acd1a29ce97cae7e1dfe1e78fb575dfbcc2776abd55402daf1 | 123 | 1 |             Number of layers of the Transformer encoder.         dropout_p (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in the embeddings, |
| .venv/lib/python3.13/site-packages/transformers/models/cpmant/modeling_cpmant.py | 60f3c8e70943730587219fe0051ca503df5511c3f1237eb4974afeb73176b922 | 809 | 35 | from ...cache_utils import Cache, DynamicCache from ...generation import GenerationMixin from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_utils import P |
| .venv/lib/python3.13/site-packages/transformers/models/led/modeling_tf_led.py | 58f44a54761f972b7969812f22e9beaeab3696b123eb6f4a09f1c530149078a3 | 2664 | 111 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     ModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/led/configuration_led.py | c2e2c3636c08cb0114ff6dd6b837dca065bcf9b83f5fc4a63fce37c67605c994 | 166 | 9 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/led/tokenization_led_fast.py | c8ed06d10eb21a6b0f0b210823db7e027610784689f874036cb8df01c188f42b | 323 | 2 | class LEDTokenizerFast(PreTrainedTokenizerFast):     r"""     Construct a "fast" LED tokenizer (backed by HuggingFace's *tokenizers* library), derived from the GPT-2 tokenizer,     using byte-level By |
| .venv/lib/python3.13/site-packages/transformers/models/led/modeling_led.py | 19699f7d90be75f24a77e34d5d0282f7906b99261194621c91db76304c68d2b9 | 2534 | 95 |   class LEDLearnedPositionalEmbedding(nn.Embedding):     """     This module learns positional embeddings up to a fixed maximum size. |
| .venv/lib/python3.13/site-packages/transformers/models/vjepa2/modeling_vjepa2.py | 37e1a11613fcd448e7492088a6f8f534d23a9969b9fb9b1fd7dd98656672ac2f | 1237 | 34 |   class VJEPA2PatchEmbeddings3D(nn.Module):     """     Image to Patch Embedding |
| .venv/lib/python3.13/site-packages/transformers/models/olmo/configuration_olmo.py | b3f628b68bd4b69f95981eeaf515780754ca823869de013a51caa0ef62371897 | 199 | 15 | # Copyright 2024 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/olmo/modeling_olmo.py | d2e98af440964388f95c3ea0301b75715e2ae6d475708b006337213faac0fe4a | 466 | 26 | from ...masking_utils import create_causal_mask from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeli |
| .venv/lib/python3.13/site-packages/transformers/models/olmo/modular_olmo.py | 699e2f3ade2d1c062253895e91a6930535f174abca8584d78fdeec9aa4f07486 | 175 | 14 |     LlamaAttention,     LlamaDecoderLayer,     LlamaForCausalLM,     LlamaMLP,     LlamaModel, |
| .venv/lib/python3.13/site-packages/transformers/models/chameleon/modeling_chameleon.py | 7a1a106cf0c6d7c7403d738c94483f1599e5fe9d490d48964cb4eeb84efa7a95 | 1171 | 61 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWith |
| .venv/lib/python3.13/site-packages/transformers/models/chameleon/configuration_chameleon.py | 859c19f293a328565afaeac8ec715ef8db24ff8ad60ca083c433fea37363cef1 | 283 | 19 |     Args:         embed_dim (`int`, *optional*, defaults to 256):             Dimensionality of each embedding vector.         num_embeddings (`int`, *optional*, defaults to 8192):             Number  |
| .venv/lib/python3.13/site-packages/transformers/models/chameleon/processing_chameleon.py | 8a6253310ffecbb43f10c204efaa3558d670aa8afb98a1ee785c87b8d8ab727e | 197 | 1 |             The tokenizer is a required input.         image_seq_length (`int`, *optional*, defaults to 1024):             Sequence length of one image embedding.         image_token (`str`, *optional |
| .venv/lib/python3.13/site-packages/transformers/models/longt5/modeling_longt5.py | 71c7d355406d41b8c31f52ab1bb54b0b5661419b8f1b87a1a8edc57d62726fe8 | 2198 | 64 |          if self.has_relative_attention_bias:             self.relative_attention_bias = nn.Embedding(self.relative_attention_num_buckets, self.n_heads)         self.pruned_heads = set()         self. |
| .venv/lib/python3.13/site-packages/transformers/models/longt5/modeling_flax_longt5.py | 94d3fe9783255eae3318d625a34832177a17bdc34293ef6a0cb418901125184f | 2450 | 39 |     FlaxBaseModelOutput,     FlaxBaseModelOutputWithPastAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxSeq2SeqLMOutput,     FlaxSeq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/phi3/modular_phi3.py | a272db9b67ed0d7136feeedf7dad797028faf32626de823fa1571f1d23b9fefc | 274 | 15 | from ..mistral.modeling_mistral import (     MistralDecoderLayer,     MistralForCausalLM,     MistralForSequenceClassification,     MistralForTokenClassification, |
| .venv/lib/python3.13/site-packages/transformers/models/phi3/modeling_phi3.py | 3b2e19b8396d472c6bad2cc86d10950c34aa5a13debcd9288daa8ee026f7c3bd | 548 | 28 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/phi3/configuration_phi3.py | 9739542422a4e27265daff11e4020adfa6f66e0af4b2d9069bd5583d992ead05 | 241 | 19 |             Dropout probability for mlp outputs.         embd_pdrop (`int`, *optional*, defaults to 0.0):             The dropout ratio for the embeddings.         attention_dropout (`float`, *optiona |
| .venv/lib/python3.13/site-packages/transformers/models/gemma3/modeling_gemma3.py | b4d552742a507de1b91770c347a79a9f35c535445f3c6b669274b6edc6dfebc9 | 1309 | 65 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWith |
| .venv/lib/python3.13/site-packages/transformers/models/gemma3/configuration_gemma3.py | 7d0e83a2bfb99ce0612da5d12abb8296489cea12b8089de87b53cc372b8940d7 | 348 | 19 |             The non-linear activation function (function or string) in the decoder. Will default to `"gelu_pytorch_tanh"`             if not specified. `"gelu_pytorch_tanh"` uses an approximation of t |
| .venv/lib/python3.13/site-packages/transformers/models/gemma3/modular_gemma3.py | c7104e7ae9d80590c23054a8b282a233a23a63b3073208c4c1a9a0d986e39fb3 | 1179 | 68 | from ..gemma2.modeling_gemma2 import (     Gemma2Attention,     Gemma2ForCausalLM,     Gemma2MLP,     Gemma2Model, |
| .venv/lib/python3.13/site-packages/transformers/models/colqwen2/processing_colqwen2.py | fc5a1334f3a9e4192df9809815d6c81f6c4a0ce439d6ed61bbba0e3e51dbe58c | 408 | 25 |     def score_retrieval(         self,         query_embeddings: Union["torch.Tensor", list["torch.Tensor"]],         passage_embeddings: Union["torch.Tensor", list["torch.Tensor"]],         batch_siz |
| .venv/lib/python3.13/site-packages/transformers/models/colqwen2/configuration_colqwen2.py | 3d52dfbbaeb071fa052acf4c06569f5436108d4af33b001b594a5fd98b198e78 | 95 | 6 |         vlm_config (`PretrainedConfig`, *optional*):             Configuration of the VLM backbone model.         embedding_dim (`int`, *optional*, defaults to 128):             Dimension of the multi |
| .venv/lib/python3.13/site-packages/transformers/models/colqwen2/modular_colqwen2.py | 98536774e9f2c152d8fd183473ee80a42984af2b21738afa258d3a6fc1438aca | 418 | 18 | @auto_docstring(     custom_intro="""     Base class for ColQwen2 embeddings output.     """ ) |
| .venv/lib/python3.13/site-packages/transformers/models/colqwen2/modeling_colqwen2.py | fde5683cc85d3cd5da72e8e271514d27ca9e718ba10954b8b0e53d52d9db4b67 | 255 | 40 |             if module.bias is not None:                 module.bias.data.zero_()         elif isinstance(module, nn.Embedding):             module.weight.data.normal_(mean=0.0, std=std)             if |
| .venv/lib/python3.13/site-packages/transformers/models/eomt/modular_eomt.py | a261ee94d12814f874c466119cc3763c1f176f295f3a007a4744759ea2dbad8f | 603 | 35 | from ...utils.generic import check_model_inputs from ..dinov2.modeling_dinov2 import (     Dinov2Embeddings,     Dinov2Layer,     Dinov2LayerScale, |
| .venv/lib/python3.13/site-packages/transformers/models/eomt/modeling_eomt.py | 877122847c52ddf5c46267abb3e69da39e2c417005fcf52113e8288d45148e37 | 1228 | 34 |         Last hidden states (final feature map) of the last layer.     hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_ |
| .venv/lib/python3.13/site-packages/transformers/models/eomt/image_processing_eomt.py | c50882c5847a4c797e9313738a18b2c2ac71c0f7b16e7e57d5d5c95233092a1b | 975 | 4 |     # Keep track of instances of each class     current_segment_id = 0     stuff_memory_list: dict[str, int] = {}      for k in range(pred_labels.shape[0]): |
| .venv/lib/python3.13/site-packages/transformers/models/eomt/configuration_eomt.py | 9ef1faaa36abd2bede8c7f7233f596bf3f1a8954091b5f3c65d2de746313394c | 169 | 1 |             The non-linear activation function (function or string) in the encoder.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all full |
| .venv/lib/python3.13/site-packages/transformers/models/esm/modeling_tf_esm.py | e46b100f2f0d9a81f3934b3daebd4f84141798691eec582d298c5de9737493f9 | 1575 | 124 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, stable_softmax from ...utils import logging from .configuration_esm import EsmConfig |
| .venv/lib/python3.13/site-packages/transformers/models/esm/configuration_esm.py | 7a1c24a7d51c5dc5d7a7a76984c3bb72a767f86d41bf52d4078b2884ebd6cba6 | 366 | 13 |             Dimensionality of the "intermediate" (often named feed-forward) layer in the Transformer encoder.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropou |
| .venv/lib/python3.13/site-packages/transformers/models/esm/modeling_esm.py | ab66fcf66c276097f0cbeb09d8b0f086df362815d097af289c8dff07477b2a65 | 1060 | 98 |      avg = a1 * a2     avg.div_(a12)  # in-place to reduce memory     normalized = x - avg     return normalized |
| .venv/lib/python3.13/site-packages/transformers/models/esm/modeling_esmfold.py | e9476f5b8d1bf46972a4bc74b11a250cd405f58e045b107d67d61753012ed8ca | 2310 | 39 |         Hidden states from the protein folding trunk.     s_s (`torch.FloatTensor`):         Per-residue embeddings derived by concatenating the hidden states of each layer of the ESM-2 LM stem.     s |
| .venv/lib/python3.13/site-packages/transformers/models/esm/openfold_utils/rigid_utils.py | a0cd6ae60181ba40eda50aab268b1399f0125044118ccecba3ebb63d1f96e82b | 1244 | 8 | def rot_vec_mul(r: torch.Tensor, t: torch.Tensor) -> torch.Tensor:     """     Applies a rotation to a vector. Written out by hand to avoid transfer to avoid AMP downcasting.      Args: |
| .venv/lib/python3.13/site-packages/transformers/models/esm/openfold_utils/chunk_utils.py | 4d30e2a0c7e244583bdbdbe529da499cd117dbde00252ed14b120695fd1a4e53 | 399 | 1 |         t.reshape((-1,) + t.shape[no_batch_dims:])[flat_start:flat_end]      but without the need for the initial reshape call, which can be memory-intensive in certain situations. The only     reshap |
| .venv/lib/python3.13/site-packages/transformers/models/esm/openfold_utils/feats.py | 40262ea6c548368e6326ec18937f137a335890f9469ba29f735629354c6923cb | 254 | 6 |     max_bin: torch.types.Number,     no_bins: int,     use_unit_vector: bool = False,     eps: float = 1e-20,     inf: float = 1e8, |
| .venv/lib/python3.13/site-packages/transformers/models/univnet/modeling_univnet.py | 2d35f85b90f807c07dccadbd6daf0ce73e571ada8705b8f69fc9fc3893fa7e2b | 619 | 2 |         output_hidden_states = torch.einsum("bildsk,biokl->bolsd", hidden_states, kernel)          output_hidden_states = output_hidden_states.to(memory_format=torch.channels_last_3d)         bias = b |
| .venv/lib/python3.13/site-packages/transformers/models/glm4/configuration_glm4.py | 94545690ad64c3f1839e18b4c3405588a9d0f45069469d2e304ca32f1356edd6 | 153 | 10 |         attention_dropout (`float`, *optional*, defaults to 0.0):             The dropout ratio for the attention probabilities.         max_position_embeddings (`int`, *optional*, defaults to 131072) |
| .venv/lib/python3.13/site-packages/transformers/models/glm4/modular_glm4.py | a5c87e70dad149bfaea16ce9eb32b2a54fae9f645ff32bf34e8a6135c93cc860 | 140 | 11 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import CausalLMOutputWithPast from ...processing_u |
| .venv/lib/python3.13/site-packages/transformers/models/glm4/modeling_glm4.py | a37f4a34d721b1a77af1232e9477584aff42fcadf0f8bd1de75e193d5a9a7efa | 522 | 25 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/big_bird/configuration_big_bird.py | a9bfe5cb37baa2a83e3d219a00e4944241f27a0f00a4b18fd1cefa959f9a14c2 | 177 | 10 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/big_bird/modeling_flax_big_bird.py | 64da3fd1d0765343d65b6b17fec6e0dcf042ec3a50bf944c7dda444be6734d43 | 2649 | 78 |     FlaxBaseModelOutputWithPooling,     FlaxBaseModelOutputWithPoolingAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxMaskedLMOutput,     FlaxMultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/big_bird/modeling_big_bird.py | 94f5bfd3fc22cf4874a657cfb231e6663754b6173ea17cd58e7793d9fa847d1a | 2960 | 94 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/hunyuan_v1_moe/modeling_hunyuan_v1_moe.py | 9aacb1c4e48435a1210cf249bb1455ee844778b3f8448cc2570fd64555442b02 | 585 | 27 | from ...masking_utils import create_causal_mask from ...modeling_layers import GenericForSequenceClassification, GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, Cau |
| .venv/lib/python3.13/site-packages/transformers/models/hunyuan_v1_moe/configuration_hunyuan_v1_moe.py | 21000938c1020ad064db6e3ed8ef56dde9c292c55096e5c8016ec6bb4b17e894 | 205 | 12 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/hunyuan_v1_moe/modular_hunyuan_v1_moe.py | 3f5afbf4c076c033a13fd1f7303ef4bac99169d13abda0d4a134664d269c7406 | 275 | 10 |     LlamaAttention,     LlamaDecoderLayer,     LlamaForCausalLM,     LlamaForSequenceClassification,     LlamaMLP, |
| .venv/lib/python3.13/site-packages/transformers/models/auto/modeling_flax_auto.py | 8e58f26781ffc168dcc6e55b2d40ed3b469c075d38c26efc697c9535e1aefd99 | 414 | 36 |         ("big_bird", "FlaxBigBirdModel"),         ("blenderbot", "FlaxBlenderbotModel"),         ("blenderbot-small", "FlaxBlenderbotSmallModel"),         ("bloom", "FlaxBloomModel"),         ("clip", |
| .venv/lib/python3.13/site-packages/transformers/models/auto/modeling_tf_auto.py | 6166865949ab18d8397a27ae9f53931bf126b735b2f0253f11bb7d830ea6c72c | 777 | 69 |         ("bert", "TFBertModel"),         ("blenderbot", "TFBlenderbotModel"),         ("blenderbot-small", "TFBlenderbotSmallModel"),         ("blip", "TFBlipModel"),         ("camembert", "TFCamember |
| .venv/lib/python3.13/site-packages/transformers/models/auto/configuration_auto.py | 5ae3551d7ba745e899af5664286e5f3ca2346a415f6390153cc112984f23c6e7 | 1354 | 70 |         ("big_bird", "BigBirdConfig"),         ("bigbird_pegasus", "BigBirdPegasusConfig"),         ("biogpt", "BioGptConfig"),         ("bit", "BitConfig"),         ("bitnet", "BitNetConfig"), |
| .venv/lib/python3.13/site-packages/transformers/models/auto/image_processing_auto.py | 34a4639959e6513d8471bb62a3d8b51cf0d1e10d95c29f8cbeb2fa027f4b94f2 | 688 | 4 |             ("idefics3", ("Idefics3ImageProcessor", "Idefics3ImageProcessorFast")),             ("ijepa", ("ViTImageProcessor", "ViTImageProcessorFast")),             ("imagegpt", ("ImageGPTImageProce |
| .venv/lib/python3.13/site-packages/transformers/models/auto/modeling_auto.py | a25d5b7c28aa8f2b79a4334323f8759416b4afb8ad0271a8c87bf3f2360de8d5 | 2341 | 313 |         ("big_bird", "BigBirdModel"),         ("bigbird_pegasus", "BigBirdPegasusModel"),         ("biogpt", "BioGptModel"),         ("bit", "BitModel"),         ("bitnet", "BitNetModel"), |
| .venv/lib/python3.13/site-packages/transformers/models/auto/feature_extraction_auto.py | a46c2a04e5658a9155e7008c380c7b97a1d37562426111d8a8048852ff596b8d | 421 | 2 |         ("groupvit", "CLIPFeatureExtractor"),         ("hubert", "Wav2Vec2FeatureExtractor"),         ("imagegpt", "ImageGPTFeatureExtractor"),         ("kyutai_speech_to_text", "KyutaiSpeechToTextFea |
| .venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py | b0cd25702a99bfdf1cd93edcb1f3793a7d422ed5b4f053d4a9e71cf678b79fa0 | 1205 | 60 |         ),         ("bigbird_pegasus", ("PegasusTokenizer", "PegasusTokenizerFast" if is_tokenizers_available() else None)),         ("biogpt", ("BioGptTokenizer", None)),         ("bitnet", (None, "P |
| .venv/lib/python3.13/site-packages/transformers/models/bert_generation/configuration_bert_generation.py | 287b1eee4320a1781c95dcf42cca2791bea698da1545b436534ed0dffa7afdf2 | 128 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/bert_generation/modeling_bert_generation.py | b8ce5d9469519affeeea044982432df559909b1fe4c6cbee6dc367f0ebd8bf3c | 881 | 73 | from ...generation import GenerationMixin from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPastAndCrossAttentions, CausalLMOutputWithCrossAt |
| .venv/lib/python3.13/site-packages/transformers/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py | 7310a4b04d1d97e1ce3690961a0cd5fe07ebf921e20cc86e65aa0f07e2d39794 | 660 | 2 |         Args:             logits (`np.ndarray`):                 The logits output vector of the model representing the log probabilities for each token.             pool (`multiprocessing.Pool`, *opt |
| .venv/lib/python3.13/site-packages/transformers/models/vit_msn/configuration_vit_msn.py | 1de534525a2b6a721253dccb88fb0ad02ca8a0c69caa8813366c04e31a7637ea | 116 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/vit_msn/modeling_vit_msn.py | 29d7755d4e660c448ae2ffc9b29ea5520ac7557c2635eaec94e0ee8f894d7235 | 568 | 47 |   class ViTMSNEmbeddings(nn.Module):     """     Construct the CLS token, position and patch embeddings. Optionally, also the mask token. |
| .venv/lib/python3.13/site-packages/transformers/models/rt_detr/configuration_rt_detr_resnet.py | 9016e682515992ad1ca8bb33d556704d754b1d09e39cb8ed15b91f30c6d53a63 | 115 | 5 |         num_channels (`int`, *optional*, defaults to 3):             The number of input channels.         embedding_size (`int`, *optional*, defaults to 64):             Dimensionality (hidden size)  |
| .venv/lib/python3.13/site-packages/transformers/models/rt_detr/modeling_rt_detr.py | 5bbaf160f380c0acc8014d5bd60d052c85bdf766e8c2bca9d5ae073b361a9a7c | 2014 | 55 |         hidden_states: torch.Tensor,         attention_mask: torch.Tensor,         position_embeddings: Optional[torch.Tensor] = None,         output_attentions: bool = False,         **kwargs, |
| .venv/lib/python3.13/site-packages/transformers/models/rt_detr/modeling_rt_detr_resnet.py | c65113f1d7516f10732f3dae1f892cffdc2ea8d3dba63fae6a739dd203a9f438 | 400 | 16 |   class RTDetrResNetEmbeddings(nn.Module):     """     ResNet Embeddings (stem) composed of a deep aggressive convolution. |
| .venv/lib/python3.13/site-packages/transformers/models/rt_detr/configuration_rt_detr.py | 2a19e8d3a34f0623ffd8dabbfeecb9ebd3a8891eac6fbbddc49d633153ad9020 | 373 | 3 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         eval_size (`tuple[int, int]`, *optional*):             Height and width used to computes the effective height and width of the po |
| .venv/lib/python3.13/site-packages/transformers/models/dab_detr/configuration_dab_detr.py | 2cea4964fda726d612f72536b6c86eaa0b44596348a2363ffe997a56e7a49208 | 269 | 8 |             This parameter is a general dimension parameter, defining dimensions for components such as the encoder layer and projection parameters in the decoder layer, among others.         dropout  |
| .venv/lib/python3.13/site-packages/transformers/models/dab_detr/modeling_dab_detr.py | 9c0b8c5c6885977e57746cb2019174791670b8e1c60c9f2a00791b7d53d4a0c3 | 1600 | 74 | class DabDetrConvModel(nn.Module):     """     This module adds 2D position embeddings to all intermediate feature maps of the convolutional encoder.     """  |
| .venv/lib/python3.13/site-packages/transformers/models/kosmos2_5/configuration_kosmos2_5.py | 2b05416b30dc0229f147d4d0d99eb07a36f0fc4f4bd85e5271f93e7056829bd6 | 255 | 12 |             Vocabulary size of the Kosmos2_5 model. Defines the number of different tokens that can be represented by the             `inputs_ids` passed when calling [`Kosmos2_5Model`].         max_p |
| .venv/lib/python3.13/site-packages/transformers/models/kosmos2_5/modeling_kosmos2_5.py | bdfd9f20df50fb04cf981e45b0072e57b4a7b326e44022b2a6d158da11fa5a59 | 1842 | 105 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPooling,     CausalLMOutputWithCrossAttentions, ) from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel |
| .venv/lib/python3.13/site-packages/transformers/models/zamba2/configuration_zamba2.py | 0cd64040d9c1c0f69c4c9cb5ca9ec377ccbd696ec72f7cc5c1ad316a6d45a29f | 242 | 8 |             Vocabulary size of the Zamba2 model. Defines the number of different tokens that can be represented by the             `inputs_ids` passed when calling [`Zamba2Model`]         max_position |
| .venv/lib/python3.13/site-packages/transformers/models/zamba2/modeling_zamba2.py | 865e1a69ce63e2773f7d822f512fc03854fedf484cca9151d72101fe50211fc9 | 1735 | 51 | from ...modeling_attn_mask_utils import AttentionMaskConverter from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutpu |
| .venv/lib/python3.13/site-packages/transformers/models/zamba2/modular_zamba2.py | 6ac9b410b285cf79f0fb9ee16ed022ba5f8a8943e59e98b182e6b6c100f6e64f | 1156 | 38 |     is_mamba_ssm_available, ) from ..llama.modeling_llama import LlamaRotaryEmbedding, apply_rotary_pos_emb from ..mamba2.modeling_mamba2 import pad_tensor_by_size, reshape_into_chunks, segment_sum fr |
| .venv/lib/python3.13/site-packages/transformers/models/jetmoe/modeling_jetmoe.py | d474f46fb5169514372f719a957571c55fb0a9feb8e9a8488feeb13f7ce90d8b | 1218 | 32 |     GradientCheckpointingLayer, ) from ...modeling_outputs import MoeCausalLMOutputWithPast, MoeModelOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ... |
| .venv/lib/python3.13/site-packages/transformers/models/jetmoe/configuration_jetmoe.py | 8d5bcd79f20b889a439c7d1070c77848ff0bff9fb4c52d5e5006be4b8ddd346d | 153 | 10 |         intermediate_size (`int`, *optional*, defaults to 5632):             Dimension of the MLP representations.         max_position_embeddings (`int`, *optional*, defaults to 4096):             Th |
| .venv/lib/python3.13/site-packages/transformers/models/lxmert/configuration_lxmert.py | 7adafe9eb623a1b8223d6e07f7e3d30bd56e1a039d475dc3462aa27d71649dae | 170 | 5 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/lxmert/modeling_lxmert.py | 686e46604e832f6c4514b38c7bf83ab7c612975654496da46d6f2c480acf427b | 1416 | 61 |         pointer = model         for m_name in name:             if re.fullmatch(r"[A-Za-z]+_\d+", m_name):                 scope_names = re.split(r"_(\d+)", m_name)             else: |
| .venv/lib/python3.13/site-packages/transformers/models/lxmert/modeling_tf_lxmert.py | 68660fe13d6e4f365c8499216593595cc8000ae15ee5314d9079bc8d3217e12e | 1661 | 64 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, stable_softmax from ...utils import (     ModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/clip/configuration_clip.py | 9b12196d1416ef327485c093bc8fbde6d32e26caebaf4f9ef3039e91f9437d7c | 412 | 4 |         num_attention_heads (`int`, *optional*, defaults to 8):             Number of attention heads for each attention layer in the Transformer encoder.         max_position_embeddings (`int`, *opti |
| .venv/lib/python3.13/site-packages/transformers/models/clip/modeling_tf_clip.py | 31c735347d22c26eacaac7f39e18cd0a95f3697d74e429c2ecf203d465a7755d | 1461 | 70 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     ModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/clip/modeling_flax_clip.py | 2eb64f9ce021e7b8c4670844317cd7d61b0f7ff46588d3d8b63b2731893f4ce8 | 1307 | 45 |     - [Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)     - [Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#autom |
| .venv/lib/python3.13/site-packages/transformers/models/clip/modeling_clip.py | 114eae3c33eaa8ba83a758c16f1216c241ad22327d8fb8275acce99d24f9cc65 | 1283 | 93 |   def _get_vector_norm(tensor: torch.Tensor) -> torch.Tensor:     """     This method is equivalent to tensor.norm(p=2, dim=-1, keepdim=True) and used to make |
| .venv/lib/python3.13/site-packages/transformers/models/clip/tokenization_clip_fast.py | 67dff0f21a56d0dc18a45f8764f3fafa02ee2b0aeafeb70761c9623f9114dd53 | 165 | 1 | # See the License for the specific language governing permissions and # limitations under the License. """Tokenization classes for OpenAI GPT."""  from typing import Optional |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2/modular_qwen2.py | 3c4322b9274595f8f9174c9b0b4340c949bc9037869642e65ead31292c224f31 | 246 | 10 |     LlamaAttention,     LlamaDecoderLayer,     LlamaForCausalLM,     LlamaForQuestionAnswering,     LlamaForSequenceClassification, |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2/tokenization_qwen2.py | 23f05697fcaf26fe5e328abaf524f010510a2b9f4ba2e2edc9dca0a4015a09a2 | 343 | 29 |  @lru_cache # Copied from transformers.models.gpt2.tokenization_gpt2.bytes_to_unicode def bytes_to_unicode():     """ |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2/configuration_qwen2.py | a67d3a7e99c2168186263ec3558d706512063ab7e79fbc2d740268275efd6fd8 | 219 | 18 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2/modeling_qwen2.py | a59fa06524227361fb401baf4d177124a27aec146bc01ec931235a9abbab17cb | 499 | 27 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2/tokenization_qwen2_fast.py | 1025a3b86526283bd86a447f0fe2d991d09775b32d3fdcc233c9e447b0611049 | 138 | 5 |     Byte-Pair-Encoding.      Same with GPT2Tokenizer, this tokenizer has been trained to treat spaces like parts of the tokens so a word will     be encoded differently whether it is at the beginning  |
| .venv/lib/python3.13/site-packages/transformers/models/ctrl/modeling_ctrl.py | 6be9aeef26ed5502a27265f09be7e32eae107ddae222a76d5b19105bfc0ffafd | 778 | 16 | from ...cache_utils import DynamicCache from ...generation import GenerationMixin from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast, SequenceClassifierOutput from ...mode |
| .venv/lib/python3.13/site-packages/transformers/models/ctrl/configuration_ctrl.py | 560e9916a6a5e4c0abfadd8ae69a799ad3764c949ea2380a2fc2206d991df359 | 117 | 4 |             just in case (e.g., 512 or 1024 or 2048).         n_embd (`int`, *optional*, defaults to 1280):             Dimensionality of the embeddings and hidden states.         dff (`int`, *optiona |
| .venv/lib/python3.13/site-packages/transformers/models/ctrl/modeling_tf_ctrl.py | ec2f79e12ce6905ea6e2eada5ae910d90fef843dec971eeeb27f405c8dba62c1 | 921 | 33 | import tensorflow as tf  from ...modeling_tf_outputs import TFBaseModelOutputWithPast, TFCausalLMOutputWithPast, TFSequenceClassifierOutput from ...modeling_tf_utils import (     TFCausalLanguageModel |
| .venv/lib/python3.13/site-packages/transformers/models/hubert/modeling_tf_hubert.py | 103f69272d8f2b4f02fdd45a3ce7568242ef774f4167ab1098a4aea906ce6289 | 1672 | 25 |  from ...activations_tf import get_tf_activation from ...modeling_tf_outputs import TFBaseModelOutput, TFCausalLMOutput from ...modeling_tf_utils import (     TFPreTrainedModel, |
| .venv/lib/python3.13/site-packages/transformers/models/hubert/modular_hubert.py | 7e10e8c7e97b57dd1d99198e5a82746c6c219096473661330253cb3f905d0fe1 | 303 | 11 |   class HubertPositionalConvEmbedding(nn.Module):     def __init__(self, config):         super().__init__() |
| .venv/lib/python3.13/site-packages/transformers/models/hubert/configuration_hubert.py | 5c587bd2d50bf884d8b67f9132dfa5665fc48f6a90db8bc92d96720581773f00 | 266 | 24 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout(`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the e |
| .venv/lib/python3.13/site-packages/transformers/models/hubert/modeling_hubert.py | 0f45986cef311941cc627b49ed937239bcad35ce03a2c0dcfc0dc4ef70726203 | 1286 | 29 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutput, CausalLMOutput, SequenceCl |
| .venv/lib/python3.13/site-packages/transformers/models/sam_hq/modeling_sam_hq.py | 2b05f24c06e0974d0fe8bdc53cd9a2821bd5873a7e1a441a63fa2a09058a1e0a | 1494 | 261 | @auto_docstring(     custom_intro="""     Base class for sam_hq vision model's outputs that also contains image embeddings obtained by applying the projection     layer to the pooler_output.     """ |
| .venv/lib/python3.13/site-packages/transformers/models/sam_hq/configuration_sam_hq.py | 5379cf730f6587633a31d04c7bbacaff19e22953d5a112b382abcf814fbb933a | 314 | 10 |         mask_input_channels (`int`, *optional*, defaults to 16):             The number of channels to be fed to the `MaskDecoder` module.         num_point_embeddings (`int`, *optional*, defaults to  |
| .venv/lib/python3.13/site-packages/transformers/models/sam_hq/modular_sam_hq.py | 4e366d8011cde481e72e31dd0afe467a869f146484c271bcfba64c4cce4428ef | 654 | 137 |         mask_input_channels (`int`, *optional*, defaults to 16):             The number of channels to be fed to the `MaskDecoder` module.         num_point_embeddings (`int`, *optional*, defaults to  |
| .venv/lib/python3.13/site-packages/transformers/models/groupvit/configuration_groupvit.py | 5f306560a167c87195986750376da981674f7abd0e19bbcf5a7099be8b902ff3 | 408 | 6 |         num_attention_heads (`int`, *optional*, defaults to 4):             Number of attention heads for each attention layer in the Transformer encoder.         max_position_embeddings (`int`, *opti |
| .venv/lib/python3.13/site-packages/transformers/models/groupvit/modeling_groupvit.py | 7156030d5314911019a97917d9734e8bf8a43f5c17b80f3d4e159a7c80462d14 | 1465 | 77 |     # Straight through.     index = y_soft.max(dim, keepdim=True)[1]     y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, 1.0)     ret = y_hard - y_ |
| .venv/lib/python3.13/site-packages/transformers/models/groupvit/modeling_tf_groupvit.py | 9bae69353d2445354967249dead59ea98e99c7b29acb1b9c3474a3fc1dc1480e | 2142 | 88 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     ModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/granitemoe/modeling_granitemoe.py | db9858ac0c9666a22d460e8a798df8086394e9084e45df93129d1474df1db40a | 1004 | 53 | from ...modeling_attn_mask_utils import AttentionMaskConverter from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, MoeCausalLMOutputWithP |
| .venv/lib/python3.13/site-packages/transformers/models/granitemoe/configuration_granitemoe.py | 6d930c9775bc203cfd55f6cdf7c637f4ad762bb0b6326d03d7ee35be7832c5f5 | 197 | 22 | # Copyright 2024 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/pvt/configuration_pvt.py | 362bc944a5e0310f85e123aa7fb6779c5356c4929db15ea2a89d98755bebb63d | 164 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/pvt/modeling_pvt.py | 0611b5b51a739d73527c43e42747205822e5ab83a902131b84bb9693ba3d8991 | 613 | 40 |   class PvtPatchEmbeddings(nn.Module):     """     This class turns `pixel_values` of shape `(batch_size, num_channels, height, width)` into the initial |
| .venv/lib/python3.13/site-packages/transformers/models/helium/modular_helium.py | e9a164aa6af23005aa042f43df915e3c02443dd8fa4ae3586ef4f7802de3e2d1 | 151 | 12 |  from ...utils import logging from ..gemma.modeling_gemma import GemmaForCausalLM, GemmaForSequenceClassification, GemmaForTokenClassification from ..granite.modeling_granite import GraniteAttention f |
| .venv/lib/python3.13/site-packages/transformers/models/helium/configuration_helium.py | 91cb57a904dc7a285fb2a471d2f22673fbab537222e61ca9f9c506cbc4d44f41 | 155 | 10 |         attention_dropout (`float`, *optional*, defaults to 0.0):             The dropout ratio for the attention probabilities.         max_position_embeddings (`int`, *optional*, defaults to 4096):  |
| .venv/lib/python3.13/site-packages/transformers/models/helium/modeling_helium.py | 323c2a53b3a3894c5dad358ec5ab992885e2d33b91311a9cbdd118fba7143cbb | 498 | 24 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/superpoint/modeling_superpoint.py | 8aa37a8386b662df08fad6a7b4e77ae9a8d1ba4882ce5d4f70b15420c0efef52 | 478 | 2 |     hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or     when `config.output_hidden_states=True`):         Tuple of `torch.FloatTensor` (on |
| .venv/lib/python3.13/site-packages/transformers/models/reformer/modeling_reformer.py | 76b82e2654b3eb40495fc18645c232ba5585badb823d103ba42e25ed8083123e | 2774 | 312 | from ...activations import ACT2FN from ...generation import GenerationMixin from ...modeling_outputs import CausalLMOutput, MaskedLMOutput, QuestionAnsweringModelOutput, SequenceClassifierOutput from  |
| .venv/lib/python3.13/site-packages/transformers/models/reformer/configuration_reformer.py | 3274e996880a3679163881901cb471e6a9ab64e06a22a5df7b22f364fcbcf480 | 236 | 25 |     Args:         attention_head_size (`int`, *optional*, defaults to 64):             Dimensionality of the projected key, query and value vectors         attn_layers (`list[str]`, *optional*, defaul |
| .venv/lib/python3.13/site-packages/transformers/models/t5gemma/configuration_t5gemma.py | 55cbd61b5750012b7301996cbe3619ea68507de23629132049394b2b4a0309ea | 332 | 15 |             The non-linear activation function (function or string) in the decoder. Will default to `"gelu_pytorch_tanh"`             if not specified. `"gelu_pytorch_tanh"` uses an approximation of t |
| .venv/lib/python3.13/site-packages/transformers/models/t5gemma/modular_t5gemma.py | c548c078c945abdcfc95e3f769a66b3349ebc481832e8501c7b9ca62e13cfffe | 1251 | 55 |     Gemma2PreTrainedModel,     Gemma2RMSNorm,     Gemma2RotaryEmbedding,     create_causal_mask,     create_sliding_window_causal_mask, |
| .venv/lib/python3.13/site-packages/transformers/models/t5gemma/modeling_t5gemma.py | dfa7e6df7670c617fb5304dccadac81a7e6d77575e0ce4fe5b9eac338bc957f1 | 1392 | 58 |   class T5GemmaRotaryEmbedding(nn.Module):     inv_freq: torch.Tensor  # fix linting for `register_buffer`  |
| .venv/lib/python3.13/site-packages/transformers/models/sew/configuration_sew.py | 949223bf62adaf73dec4d77d13c43671bddec338785b5d1e0a4e4ce1df893b27 | 257 | 24 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the  |
| .venv/lib/python3.13/site-packages/transformers/models/sew/modular_sew.py | 23f6511151375cd87c04c2b82cb9eef6c1ab64fad4cdb9d2a19ccb84e06c42bf | 462 | 17 |   class SEWPositionalConvEmbedding(nn.Module):     def __init__(self, config):         super().__init__() |
| .venv/lib/python3.13/site-packages/transformers/models/sew/modeling_sew.py | 9183e526340cfa17d4afd50282ccf5464f31948b88b542afba5be8f77080e5eb | 1104 | 28 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutput, CausalLMOutput, SequenceCl |
| .venv/lib/python3.13/site-packages/transformers/models/oneformer/image_processing_oneformer_fast.py | 1bf9cdcdc05fca47cd162202a7653bd6dd8d5d83ae184e7b45a5f9095910ab52 | 1007 | 4 |     mask_labels = mask_probs.argmax(0)  # [height, width]      stuff_memory_list: dict[str, int] = {}     for k in range(pred_labels.shape[0]):         pred_class = pred_labels[k].item() |
| .venv/lib/python3.13/site-packages/transformers/models/oneformer/image_processing_oneformer.py | 62447f9bc7169f634e0ad31106876a7ffc05915d809162d3ec9f1c2d09fc6c01 | 1344 | 4 |      # Keep track of instances of each class     stuff_memory_list: dict[str, int] = {}     for k in range(pred_labels.shape[0]):         pred_class = pred_labels[k].item() |
| .venv/lib/python3.13/site-packages/transformers/models/oneformer/modeling_oneformer.py | 43b315cd2b322cc0929efd56802177c05285b0b1176fd0281ef8a4da72b2a4b2 | 3211 | 149 |     r"""     encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):         Tuple of `torch.Flo |
| .venv/lib/python3.13/site-packages/transformers/models/oneformer/configuration_oneformer.py | 19e55ae348fc3f65da29b539f09584f42d84617361814263635de45335e588c5 | 286 | 1 |                 window_size=7,                 drop_path_rate=0.3,                 use_absolute_embeddings=False,                 out_features=["stage1", "stage2", "stage3", "stage4"],             ) |
| .venv/lib/python3.13/site-packages/transformers/models/llava_next_video/configuration_llava_next_video.py | 5c6fb030a405986c0685b41213c6e2beb7d54b644f4204aa996d0f11b651a025 | 167 | 7 |             A list of possible resolutions to use for processing high resolution images. Each item in the list should be a tuple or list             of the form `(height, width)`.         tie_word_emb |
| .venv/lib/python3.13/site-packages/transformers/models/llava_next_video/modular_llava_next_video.py | a07f1dd68c40db37392d888f3b38e4a2c314deb673c75bca56f8237a9d793667 | 724 | 15 |  from transformers.models.llava_next.modeling_llava_next import (     LlavaNextCausalLMOutputWithPast,     LlavaNextForConditionalGeneration,     LlavaNextModel, |
| .venv/lib/python3.13/site-packages/transformers/models/llava_next_video/processing_llava_next_video.py | e25bb8ac03c88d393976af196ce31a3b48385129e78a39036f5e45c064ab9f7e | 307 | 1 |             Special token used to denote image location.         num_additional_image_tokens (`int`, *optional*, defaults to 0):             Number of additional tokens added to the image embeddings,  |
| .venv/lib/python3.13/site-packages/transformers/models/llava_next_video/modeling_llava_next_video.py | 06516b38f1a717886b9beadd7f037a249073b7d5f4142bb3d2a2ac4a34e87067 | 988 | 19 |     """ ) class LlavaNextVideoCausalLMOutputWithPast(ModelOutput):     r"""     loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided): |
| .venv/lib/python3.13/site-packages/transformers/models/falcon_mamba/modular_falcon_mamba.py | f7669e75ae714e5d5a48ebf6cd34219424367d99580248913d5a30e1a1edc2d4 | 547 | 11 |     MambaBlock,     MambaCache,     MambaCausalLMOutput,     MambaForCausalLM,     MambaMixer, |
| .venv/lib/python3.13/site-packages/transformers/models/falcon_mamba/configuration_falcon_mamba.py | c5b44c438647469266347c55261dad218b67309580304d1a0db29ed68318ff7e | 171 | 2 |             `inputs_ids` passed when calling [`FalconMambaModel`].         hidden_size (`int`, *optional*, defaults to 768):             Dimensionality of the embeddings and hidden states.         sta |
| .venv/lib/python3.13/site-packages/transformers/models/falcon_mamba/modeling_falcon_mamba.py | 2a08bcc04ddbb6e455a9de3661555b620057377bd24d8e09ce8a7223eb4b678c | 911 | 29 |          ```python         >>> from transformers import AutoTokenizer, FalconMambaForCausalLM, FalconMambaCache          >>> model = FalconMambaForCausalLM.from_pretrained("state-spaces/falcon_mamba-1 |
| .venv/lib/python3.13/site-packages/transformers/models/focalnet/configuration_focalnet.py | 2fa092de670b2c36532057a24eac1ebbc5b532880d42af1932b2220fffa0d71e | 165 | 6 |             The size (resolution) of each image.         patch_size (`int`, *optional*, defaults to 4):             The size (resolution) of each patch in the embeddings layer.         num_channels (` |
| .venv/lib/python3.13/site-packages/transformers/models/focalnet/modeling_focalnet.py | b60868b006a31bfe2fcf5f5a9144431368191f63e33ff4e1706bff48a65256d5 | 959 | 43 |     r"""     reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):         Tuple of `torch.Fl |
| .venv/lib/python3.13/site-packages/transformers/models/resnet/modeling_tf_resnet.py | 152d15359a9432aeec5c0055f86137b2d714a587766d550654d876c562c976ba | 597 | 7 |   class TFResNetEmbeddings(keras.layers.Layer):     """     ResNet Embeddings (stem) composed of a single aggressive convolution. |
| .venv/lib/python3.13/site-packages/transformers/models/resnet/modeling_flax_resnet.py | dabe62b0121a29021c19e0ca585b706ec81ab466434d7bb4ae910a55b793e711 | 705 | 13 |     - [Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)     - [Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#autom |
| .venv/lib/python3.13/site-packages/transformers/models/resnet/modeling_resnet.py | 7a92b5b347152332cb1d00179eb73f6a25e57df1f68e66049c7e4906d53698dd | 456 | 15 |   class ResNetEmbeddings(nn.Module):     """     ResNet Embeddings (stem) composed of a single aggressive convolution. |
| .venv/lib/python3.13/site-packages/transformers/models/resnet/configuration_resnet.py | 454596bf3fcac229412553a5698d5c2b408dd3bf153d73f0ce53acda366677a2 | 137 | 5 |         num_channels (`int`, *optional*, defaults to 3):             The number of input channels.         embedding_size (`int`, *optional*, defaults to 64):             Dimensionality (hidden size)  |
| .venv/lib/python3.13/site-packages/transformers/models/mask2former/modeling_mask2former.py | 5ad48e36302fc6fee459a855f3f6796b9ddbbdd02bfdbde0b2e9e06900bc3533 | 2489 | 117 |     r"""     hidden_states (`tuple(torch.FloatTensor)`, *optional*):         Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer) of         shape `(b |
| .venv/lib/python3.13/site-packages/transformers/models/mask2former/image_processing_mask2former.py | 80b268e6389849cafdf045d6942e0b155162d95eac2cd0753dc81db4d6c1a720 | 1287 | 4 |      # Keep track of instances of each class     stuff_memory_list: dict[str, int] = {}     for k in range(pred_labels.shape[0]):         pred_class = pred_labels[k].item() |
| .venv/lib/python3.13/site-packages/transformers/models/mask2former/configuration_mask2former.py | e9f27c19b0c89d70760a5cbf41bad8c79c54e2136ff93f1357ff609555220ad3 | 265 | 2 |             Number of attention heads for each attention layer.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embedd |
| .venv/lib/python3.13/site-packages/transformers/models/grounding_dino/configuration_grounding_dino.py | bf48ec785c4ec1f99d3b17acde82fbe5ef869887632049e09c974c34f0844bf4 | 310 | 18 |             Dimension of the layers.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.  |
| .venv/lib/python3.13/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py | 06b3972eb77c885d1ac7f39fc12baa16a725b96404a5b6accab28f34ee6ddd37 | 2640 | 144 |         Sequence of hidden-states at the output of the last layer of the text encoder.     vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is pa |
| .venv/lib/python3.13/site-packages/transformers/models/grounding_dino/image_processing_grounding_dino.py | b9afd20053a984c85018d272af5ef68a26d3e58862ba7f121be6c037b2fa0010 | 1622 | 4 |      # Keep track of instances of each class     stuff_memory_list: dict[str, int] = {}     for k in range(pred_labels.shape[0]):         pred_class = pred_labels[k].item() |
| .venv/lib/python3.13/site-packages/transformers/models/lfm2/configuration_lfm2.py | ea327690176cf0f620e83c801c115da4c21c256eeb06ff9b90caccd4b2d58082 | 166 | 13 |             paper](https://huggingface.co/papers/2305.13245). If it is not specified, will default to             `num_attention_heads`.         max_position_embeddings (`int`, *optional*, defaults to |
| .venv/lib/python3.13/site-packages/transformers/models/lfm2/modular_lfm2.py | 5eaae162ce8d9767e3454a875a538e64d5a31d3c2e4626bd7f88ce145ebf9091 | 521 | 18 | from ..llama.modeling_llama import (     LlamaAttention,     LlamaForCausalLM,     LlamaModel,     LlamaPreTrainedModel, |
| .venv/lib/python3.13/site-packages/transformers/models/lfm2/modeling_lfm2.py | a8126098ed0f2a3f4f2d00c04912b97314f90d101d1957f56237830a58a637de | 755 | 29 | from ...masking_utils import create_causal_mask from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeli |
| .venv/lib/python3.13/site-packages/transformers/models/tapas/modeling_tapas.py | 1597e2412b2ccbaeeded9a28466b1717cb6045990ae70dad1e79526e0bde3bfa | 2348 | 87 |      - add cell selection and aggregation heads     - take into account additional token type embedding layers     """     try: |
| .venv/lib/python3.13/site-packages/transformers/models/tapas/modeling_tf_tapas.py | 1e91b708bc29db564a677f4a7b0e856a489a5ae0aebf46455e615d32cd96165c | 2462 | 87 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     ModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/tapas/tokenization_tapas.py | b4de4f72f384fc64fd34e620801e06608d24465de68ff832a941c34346e31971 | 2794 | 7 |         return len(question_tokens) + 2      def _get_token_budget(self, question_tokens, max_length=None):         """         Computes the number of tokens left for the table after tokenizing a ques |
| .venv/lib/python3.13/site-packages/transformers/models/tapas/configuration_tapas.py | 8b5fdafc002b2e34bc4a45aed03bbc4c2ec96417ef3144a4bb642d79275f9c2e | 230 | 7 |             `"relu"`, `"swish"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers i |
| .venv/lib/python3.13/site-packages/transformers/models/qwen3/configuration_qwen3.py | 12bfdce91ba4f836a254755ef3e876678f41818b5e8c9b9232c36ebb53456320 | 227 | 18 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/qwen3/modular_qwen3.py | 580fed2220bc50ecabc729f091b3d097e6bccd14dde9b3db5640f98caf62ad5b | 175 | 10 | from ...cache_utils import Cache from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_outputs import CausalLMOutputWithPast from ...modeling_utils import ALL_ATTENTION_F |
| .venv/lib/python3.13/site-packages/transformers/models/qwen3/modeling_qwen3.py | 4b95c371fd26d40c69083dab36ac1eafd8cf82b415a0bb827275097c5ad2305b | 529 | 25 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/data2vec/configuration_data2vec_text.py | 109455cbab89715a0315574c25f19a20ec7f708216d37039f0de57f38f62ec6e | 155 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/data2vec/modeling_data2vec_vision.py | 38741593d746cd74ced47b0f1ba9159e53a53f0c1c2020b265b532069ecafd9f | 1368 | 59 |   # Copied from transformers.models.beit.modeling_beit.BeitEmbeddings with Beit->Data2VecVision class Data2VecVisionEmbeddings(nn.Module):     """ |
| .venv/lib/python3.13/site-packages/transformers/models/data2vec/modeling_tf_data2vec_vision.py | 18ee5c2bc0bb3f58ed50b97cf05630d13f1385aa3b134f48331e30853ceae87d | 1724 | 50 |             will be returned.         hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):             Tuple  |
| .venv/lib/python3.13/site-packages/transformers/models/data2vec/modular_data2vec_audio.py | cbfbb1fe832c3b41ae97da324e5fca2661b00bc9df2a43573d013f9dfbe2b9a0 | 268 | 8 |     Wav2Vec2ForCTC,     Wav2Vec2ForSequenceClassification,     Wav2Vec2ForXVector,     Wav2Vec2Model,     Wav2Vec2PreTrainedModel, |
| .venv/lib/python3.13/site-packages/transformers/models/data2vec/configuration_data2vec_vision.py | f0bb063e33e115a057a4c17a2ebb6774ca174c4df7a539df675a7d2f3d3a73b9 | 195 | 8 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/data2vec/modeling_data2vec_text.py | 40b075b057a02b1381878c65c0b26d111653b2773ad94a7f1c482671f7d9b8eb | 1379 | 97 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/data2vec/configuration_data2vec_audio.py | 4a624c6b4b41a1066e765c4f7b546fa52ab4630075d068d30a27f2d0dc0bea68 | 289 | 34 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the  |
| .venv/lib/python3.13/site-packages/transformers/models/data2vec/modeling_data2vec_audio.py | ab644a36eaad76cc5309add228fa2aee31bf2756715f4579030e6df1bbddbc00 | 1398 | 39 | from ...modeling_outputs import (     BaseModelOutput,     CausalLMOutput,     SequenceClassifierOutput,     TokenClassifierOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/dinat/modeling_dinat.py | a6ea823cf249a0a28b0fa725e8453496f1ff238f2254ef5f518cadb9a585dfac | 877 | 39 |     r"""     reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):         Tuple of `torch.Fl |
| .venv/lib/python3.13/site-packages/transformers/models/dinat/configuration_dinat.py | 7e119752a4421244e058beaba4f505ec9f96eeeb04e1eee09770d2fc9f7dc0c7 | 153 | 3 |             The number of input channels.         embed_dim (`int`, *optional*, defaults to 64):             Dimensionality of patch embedding.         depths (`list[int]`, *optional*, defaults to `[3 |
| .venv/lib/python3.13/site-packages/transformers/models/zamba/configuration_zamba.py | d2c1eb34204768c5a84cb7a07414a5d96150050b72323e2a6ff5cd3b971433ae | 228 | 14 |             Vocabulary size of the Zamba model. Defines the number of different tokens that can be represented by the             `inputs_ids` passed when calling [`ZambaModel`]         tie_word_embed |
| .venv/lib/python3.13/site-packages/transformers/models/zamba/modeling_zamba.py | 06138aa0503ade57306e2ea362b1da5541724648fd3c2656cf6aefe3e01944fb | 1312 | 22 | # Copyright 2024 Zyphra Technologies and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this libr |
| .venv/lib/python3.13/site-packages/transformers/models/mamba/modeling_mamba.py | ad28b5f1a464a64d1eabf96b42394f41ef322dbe5f4276e85d4f27368b61a796 | 849 | 32 |          ```python         >>> from transformers import AutoTokenizer, MambaForCausalLM, MambaCache          >>> model = MambaForCausalLM.from_pretrained("state-spaces/mamba-130m-hf") |
| .venv/lib/python3.13/site-packages/transformers/models/mamba/configuration_mamba.py | 92b86ded08fed727d8c5d32bdf307d5a1055a942a220db76a3906f0c2f2ff972 | 161 | 2 |             `inputs_ids` passed when calling [`MambaModel`].         hidden_size (`int`, *optional*, defaults to 768):             Dimensionality of the embeddings and hidden states.         state_siz |
| .venv/lib/python3.13/site-packages/transformers/models/stablelm/configuration_stablelm.py | 1aa28be777608a3966c103202ecbb0e2307a826d6cb54e126821138eaba6295b | 203 | 19 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string).         max_position_embeddings (`int`, *optional*, def |
| .venv/lib/python3.13/site-packages/transformers/models/stablelm/modeling_stablelm.py | 6493e369adbe7a0e958aad9dd008216f2a02f1b03e55f81743d84bc6de467c8b | 1002 | 58 | # Copyright 2024 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py | 282c879d8bd0765a450a10330c2803b3651f639e3a0348b4d54f1ed586064f44 | 931 | 17 | from jax.random import PRNGKey  from ...modeling_flax_outputs import FlaxBaseModelOutput, FlaxCausalLMOutputWithCrossAttentions, FlaxSeq2SeqLMOutput from ...modeling_flax_utils import FlaxPreTrainedMo |
| .venv/lib/python3.13/site-packages/transformers/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py | f35c13726aedd39b98c7b5fae8b6ddff7c478fb65c5791a2ba454ee3ae679d02 | 505 | 23 | from ...utils import auto_docstring, logging from ..auto.configuration_auto import AutoConfig from ..auto.modeling_auto import AutoModel, AutoModelForCausalLM from .configuration_speech_encoder_decode |
| .venv/lib/python3.13/site-packages/transformers/models/zoedepth/image_processing_zoedepth.py | 8d4cca78dc78551fa5f69b3f544b2185f442f9907ba4b1d6c3ae994534a25f8b | 563 | 3 |                 The padding mode to use. Can be one of:                     - `"constant"`: pads with a constant value.                     - `"reflect"`: pads with the reflection of the vector mirror |
| .venv/lib/python3.13/site-packages/transformers/models/zoedepth/configuration_zoedepth.py | 811436b91aa685f6a060d1d4dc59162783cf8ab6087bd55eec627b10d5b5ee69 | 246 | 5 |         num_attractors (`list[int], *optional*, defaults to `[16, 8, 4, 1]`):             The number of attractors to use in each stage.         bin_embedding_dim (`int`, *optional*, defaults to 128): |
| .venv/lib/python3.13/site-packages/transformers/models/zoedepth/modeling_zoedepth.py | 635b4ff03010370d867fd774c5f093a03e654533d5ce90888a80db84d81ecd7d | 1354 | 86 |     def forward(self, x):         """         Returns tensor of bin_width vectors (centers). One vector b for every pixel         """         x = self.conv1(x) |
| .venv/lib/python3.13/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py | 177151a374fc53f61da9ad360b674ea9c639bfac49abc1299aaaf950ad5fa8fe | 4072 | 188 |     inputs_embeds (`torch.FloatTensor` of shape`(batch_size, sequence_length, hidden_size)`, *optional*):         Optionally, instead of passing `input_ids` you can choose to directly pass an embedded |
| .venv/lib/python3.13/site-packages/transformers/models/seamless_m4t/feature_extraction_seamless_m4t.py | 55e30e0f2c5b99d1c2eceda06ff54ecd73bcfdccfb824b4258460854f9ac7164 | 310 | 5 |             Number of Mel-frequency bins.         padding_value (`float`, *optional*, defaults to 0.0):             The value that is used to fill the padding vectors.         stride (`int`, *optional |
| .venv/lib/python3.13/site-packages/transformers/models/seamless_m4t/configuration_seamless_m4t.py | cef0a1eebf8a3882f03a5ba301a24bb6fd7e67b07c5e06447f1a98b8132318ad | 417 | 40 |         use_cache (`bool`, *optional*, defaults to `True`):             Whether or not the model should return the last key/values attentions (not used by all models).         max_position_embeddings  |
| .venv/lib/python3.13/site-packages/transformers/models/umt5/configuration_umt5.py | 5bad1f6614f6ba944b6cd4dab914acd7e2b41d20796825789bbf531525ced552 | 182 | 3 |         use_cache=True,         tokenizer_class="T5Tokenizer",         tie_word_embeddings=True,         pad_token_id=0,         eos_token_id=1, |
| .venv/lib/python3.13/site-packages/transformers/models/umt5/modeling_umt5.py | 5a9483c5be779034e5bba4f1509763ebca2c520fa9395eb00148157888e939c0 | 1950 | 73 |          if self.has_relative_attention_bias:             self.relative_attention_bias = nn.Embedding(self.relative_attention_num_buckets, self.n_heads)         self.pruned_heads = set()  |
| .venv/lib/python3.13/site-packages/transformers/models/cohere2/modeling_cohere2.py | 4b109d9ba42fa73ea80f4108da906b5b1339b02d87b480c4b6e71fcd596707b2 | 514 | 33 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWith |
| .venv/lib/python3.13/site-packages/transformers/models/cohere2/modular_cohere2.py | ff8862f7189313e4b7ad1b35b6357202aecdd088e79556f195d73e182ad2f19c | 458 | 38 |     CohereAttention,     CohereDecoderLayer,     CohereForCausalLM,     CohereLayerNorm,     CoherePreTrainedModel, |
| .venv/lib/python3.13/site-packages/transformers/models/cohere2/configuration_cohere2.py | eed1d6951e452e1396c11f5dfc94cc06cd6c6c5ba0abe34ce9437851e3aad6a9 | 247 | 22 |     Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the     documentation from [`PretrainedConfig`] for more information. Instantiating a con |
| .venv/lib/python3.13/site-packages/transformers/models/apertus/modular_apertus.py | 3df65f278098dd45eaec9c713f26180cd111a323a2fc4bb5605359596553732d | 372 | 32 |     LlamaAttention,     LlamaDecoderLayer,     LlamaForCausalLM,     LlamaForTokenClassification,     LlamaModel, |
| .venv/lib/python3.13/site-packages/transformers/models/apertus/configuration_apertus.py | d4772e7a5ab7af6d056080b1b44ab2101bade8594ef013147466b6d370c57e1b | 215 | 19 |         hidden_act (`str` or `function`, *optional*, defaults to `"xielu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`, |
| .venv/lib/python3.13/site-packages/transformers/models/apertus/modeling_apertus.py | de912b576e520c3959594f3ab8f1ab3201622916bec41718e0184acdb00c14bc | 489 | 24 | from ...masking_utils import create_causal_mask from ...modeling_layers import GenericForTokenClassification, GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, Causal |
| .venv/lib/python3.13/site-packages/transformers/models/pegasus_x/modeling_pegasus_x.py | 080fc34587539253cc12ed9f738c32925d65a7a4c9376cfbc5eb377ea7422946 | 1720 | 123 |   # Copied from transformers.models.bart.modeling_bart.BartScaledWordEmbedding with Bart->PegasusX class PegasusXScaledWordEmbedding(nn.Embedding):     """ |
| .venv/lib/python3.13/site-packages/transformers/models/pegasus_x/configuration_pegasus_x.py | 45ab0a1ca3f5374644bec97cd49d98de384d009a34ce996700a23666a60976fe | 178 | 8 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/layoutlmv2/modeling_layoutlmv2.py | c770d459705a6115c368e94aa0b7c79446ce8fca6523267a52dd258df44e4e6b | 1396 | 148 |   class LayoutLMv2Embeddings(nn.Module):     """Construct the embeddings from word, position and token_type embeddings."""  |
| .venv/lib/python3.13/site-packages/transformers/models/layoutlmv2/configuration_layoutlmv2.py | 2e685b10151eb26f770c83435d945f5882ab074020cb771f961321ed408cb6a6 | 223 | 17 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/dinov3_vit/modeling_dinov3_vit.py | 00652d90ff8c7ae32b047ebe2acd2271f97e03f768cf570ac051045a4e0d5cf5 | 539 | 39 |   class DINOv3ViTEmbeddings(nn.Module):     """     Construct the CLS token, mask token, position and patch embeddings. |
| .venv/lib/python3.13/site-packages/transformers/models/dinov3_vit/configuration_dinov3_vit.py | 1ac7cb889e2314e8cadf9b0bed43d42cfb05dce6d730f719be4380c8a10a8a46 | 167 | 4 |             The epsilon used by the layer normalization layers.         rope_theta (`float`, *optional*, defaults to 100.0):             The base period of the RoPE embeddings.         image_size (`in |
| .venv/lib/python3.13/site-packages/transformers/models/dinov3_vit/modular_dinov3_vit.py | 862be64938db41de67c0273ae3a29abebc312489d63f59873e58dda0912e94a2 | 430 | 39 |   class DINOv3ViTEmbeddings(nn.Module):     """     Construct the CLS token, mask token, position and patch embeddings. |
| .venv/lib/python3.13/site-packages/transformers/models/granitemoehybrid/configuration_granitemoehybrid.py | 78f9706127b1a4a83cad70a5dd7eba71c9ec7a34520102eb22c41c291da6dba5 | 257 | 24 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/granitemoehybrid/modular_granitemoehybrid.py | 00c71ed9d734701f3f2406b532e803be0aded0bdd7cc5bbe9868375393cdfffa | 390 | 16 |     GraniteMoeSharedAttention,     GraniteMoeSharedDecoderLayer,     GraniteMoeSharedForCausalLM,     GraniteMoeSharedMLP,     GraniteMoeSharedModel, |
| .venv/lib/python3.13/site-packages/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py | 59db4d7a796320b8438ffa3349a06579b250b2a06e106303d145893616c03e17 | 1838 | 47 | from ...modeling_attn_mask_utils import AttentionMaskConverter from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, MoeCausalLMOutputWithP |
| .venv/lib/python3.13/site-packages/transformers/models/unispeech_sat/configuration_unispeech_sat.py | dc276e3d54d846a55059a65b0ffa00df0b0297feeff79167e11b96a4f8ba5614 | 328 | 55 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the  |
| .venv/lib/python3.13/site-packages/transformers/models/unispeech_sat/modular_unispeech_sat.py | 52c169c042e17331494d718da070a58061733fe6455811554391d047a4b92906 | 458 | 66 |     Wav2Vec2ForCTC,     Wav2Vec2ForSequenceClassification,     Wav2Vec2ForXVector,     Wav2Vec2GumbelVectorQuantizer,     Wav2Vec2Model, |
| .venv/lib/python3.13/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py | 462ea847f796f36522956f2667450c2054b1e8e3cad8a57e67d8b3c50680dc8d | 1827 | 105 | from ...modeling_outputs import (     BaseModelOutput,     CausalLMOutput,     ModelOutput,     SequenceClassifierOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/t5/modeling_flax_t5.py | 97eb98b7d65ed0e7a663e785d815680a66289a441e26279132ea3382bee9aa4f | 1802 | 29 |     FlaxBaseModelOutput,     FlaxBaseModelOutputWithPastAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxSeq2SeqLMOutput,     FlaxSeq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py | 20bc3475af4368e4e1a4a1d1b925755be061d7e1c7591a29d42dc08d0505c78c | 2407 | 71 |          for m_name in name:             if re.fullmatch(r"[A-Za-z]+_\d+", m_name):                 scope_names = re.split(r"_(\d+)", m_name)             else: |
| .venv/lib/python3.13/site-packages/transformers/models/t5/modeling_tf_t5.py | 956e3f795299637d7bc463e75edd4bfaad1f029e38c125e245bf39bce2448d8f | 1677 | 34 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     add_start_docstrings, |
| .venv/lib/python3.13/site-packages/transformers/models/granite_speech/processing_granite_speech.py | a4c4ff07264f5590b7c419027c5a16f0248b918fae31d356ff8b9f3db4f114fd | 105 | 1 |             # text / audio inputs here because some inference engines will             # trigger the conditions due to the way they call multimodal             # processors, e.g., vLLM.             au |
| .venv/lib/python3.13/site-packages/transformers/models/granite_speech/feature_extraction_granite_speech.py | 0ab428425585958dc1def33498375908533cb7fc69db5be31a279997ae6012b1 | 187 | 1 |         # and qwen2audio and refactor this to ensure input_feature_mask         # has the same dimensionality as input_features, or compute it in         # the model based on the audio embedding sizes |
| .venv/lib/python3.13/site-packages/transformers/models/granite_speech/modeling_granite_speech.py | 4556235578cceb9aa8b0bdbcbf8a5d21c7a3f39d99a9ad6fc93a032523204389 | 579 | 41 | from ...modeling_utils import PreTrainedModel from ...utils import auto_docstring, is_peft_available, logging from ..auto import AutoModel, AutoModelForCausalLM from .configuration_granite_speech impo |
| .venv/lib/python3.13/site-packages/transformers/models/dpr/modeling_dpr.py | 2f42a5fc4d82bbbe34cc640f6424fbc2998b044099346692dd5dc3cd13766bb0 | 593 | 15 | class DPRContextEncoderOutput(ModelOutput):     r"""     pooler_output (`torch.FloatTensor` of shape `(batch_size, embeddings_size)`):         The DPR encoder outputs the *pooler_output* that correspo |
| .venv/lib/python3.13/site-packages/transformers/models/dpr/modeling_tf_dpr.py | 569cc1ebb802d2c3279ee55c0315211f1c63f8bc639dfeb9f0b20e16f84a2d17 | 800 | 31 |      Args:         pooler_output (`tf.Tensor` of shape `(batch_size, embeddings_size)`):             The DPR encoder outputs the *pooler_output* that corresponds to the context representation. Last la |
| .venv/lib/python3.13/site-packages/transformers/models/dpr/configuration_dpr.py | f831841a2eeb1f46d29564a1d96085bc1e9c759e9b27c90edeef31be10d2f269 | 132 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/recurrent_gemma/configuration_recurrent_gemma.py | c34983d6b9e8904901baf0cd096d2630994ed03b05d13b86d89c894a676a1a62 | 162 | 3 |             Dimension of the hidden representations of the RG-LRU. If `None`             this will be set to `hidden_size`.             Whether to scale the output of the embeddings by `sqrt(hidden_si |
| .venv/lib/python3.13/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py | 1d6ecf6a63e77d0324e5b2299f4bed575821dbb87c1b07cec7c132d3652346ec | 786 | 19 | from ...modeling_attn_mask_utils import AttentionMaskConverter from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithNoAttention, CausalLMOutput  |
| .venv/lib/python3.13/site-packages/transformers/models/minimax/modular_minimax.py | 5f2f1f98a1b34fb1fe262914be78c5da9cb844030647109f5595d60e5a2ba8d0 | 605 | 21 |     MixtralAttention,     MixtralDecoderLayer,     MixtralForCausalLM,     MixtralForQuestionAnswering,     MixtralForSequenceClassification, |
| .venv/lib/python3.13/site-packages/transformers/models/minimax/configuration_minimax.py | c39d4265335c30b374b7a00d55721bf8ff6ddc9d2e3ff4a4831b0e4254fc67d8 | 231 | 10 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/minimax/modeling_minimax.py | 94e54e633f073211f5fdc6b47fa641c584cb56605421c425739cafb9af87700b | 934 | 30 |     GradientCheckpointingLayer, ) from ...modeling_outputs import MoeCausalLMOutputWithPast, MoeModelOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ... |
| .venv/lib/python3.13/site-packages/transformers/models/rwkv/modeling_rwkv.py | 1b8b2c99abcdf72685f1d846b668f3b59fc839789b767758fae0d72e870eab18 | 799 | 28 |         "-O3",         "-Xptxas -O3",         "--extra-device-vectorization",         f"-DTmax={context_length}",     ] |
| .venv/lib/python3.13/site-packages/transformers/models/rwkv/configuration_rwkv.py | d21c2212168b3427a4c4e8980ff0fe7bde5fb6aeff69acf1f48991b5fd327567 | 121 | 10 |             lets use any sequence length).         hidden_size (`int`, *optional*, defaults to 4096):             Dimensionality of the embeddings and hidden states.         num_hidden_layers (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/jamba/configuration_jamba.py | fed02758507b0f11afe0c17776adab4a6cc9dd8b3ef236a6904b4debb9933d64 | 237 | 14 |             Vocabulary size of the Jamba model. Defines the number of different tokens that can be represented by the             `inputs_ids` passed when calling [`JambaModel`]         tie_word_embed |
| .venv/lib/python3.13/site-packages/transformers/models/jamba/modeling_jamba.py | 4d6f89e08a6bf6fa2836e18e39882253fdf0d1e180ad2141318441311b3eb5f0 | 1458 | 19 | # Copyright 2024 AI21 Labs Ltd. and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library.  |
| .venv/lib/python3.13/site-packages/transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py | 40c620637d4d5151139420da5fd588c129cf6706f965f1e5f0dd097f05481097 | 1768 | 160 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds from ...utils import add_start_docstrings, add_start_docstrings_to_model_forward, replace_return_docstrings from .configurat |
| .venv/lib/python3.13/site-packages/transformers/models/layoutlmv3/modeling_layoutlmv3.py | 02cf3796a45443fc302bc6c1cbe45331c8de0957dfb2cf82cd9a32c854fa168f | 1255 | 138 |   class LayoutLMv3PatchEmbeddings(nn.Module):     """LayoutLMv3 image (patch) embeddings. This class also automatically interpolates the position embeddings for varying     image sizes.""" |
| .venv/lib/python3.13/site-packages/transformers/models/layoutlmv3/configuration_layoutlmv3.py | f8569aa4cf2a90452b9647ec1401b6eefe613c987e4a69109174986f93a20635 | 295 | 13 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/bloom/tokenization_bloom_fast.py | 56242c361b2c2bfd2016d107ada2572d12721d582301b069d2d9916c8b2f8958 | 153 | 1 |     model_input_names = ["input_ids", "attention_mask"]     slow_tokenizer_class = None     # No `max_model_input_sizes` as BLOOM uses ALiBi positional embeddings      def __init__( |
| .venv/lib/python3.13/site-packages/transformers/models/bloom/modeling_flax_bloom.py | 2518fee3625c35ae345a35919d0e90f9a02c655c5dd73b8d379f657f53068a73 | 738 | 36 |     FlaxBaseModelOutput,     FlaxBaseModelOutputWithPastAndCrossAttentions,     FlaxCausalLMOutput, ) from ...modeling_flax_utils import FlaxPreTrainedModel, append_call_sample_docstring |
| .venv/lib/python3.13/site-packages/transformers/models/bloom/configuration_bloom.py | 3bd5ff8eebcd3ea12ec65c0940dfa33c9aa3f1dd1244e4c711162548211ffc2e | 239 | 1 |             `vocab_size` has been defined.         hidden_size (`int`, *optional*, defaults to 64):             Dimensionality of the embeddings and hidden states.         n_layer (`int`, *optional*,  |
| .venv/lib/python3.13/site-packages/transformers/models/bloom/modeling_bloom.py | e506d39d4f2fdf24c2667400fc7358cff27753faaec6d0652d5137905f60776b | 1252 | 35 | from ...modeling_outputs import (     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     QuestionAnsweringModelOutput,     SequenceClassifierOutputWithPast, |
| .venv/lib/python3.13/site-packages/transformers/models/phimoe/modeling_phimoe.py | 8846b47dabaad17203b55ca24a408ce0e023d8a9e3f1c1f4a91a55ebb145eb56 | 1360 | 44 |     GradientCheckpointingLayer, ) from ...modeling_outputs import MoeCausalLMOutputWithPast, MoeModelOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS from ...modeling_utils import |
| .venv/lib/python3.13/site-packages/transformers/models/phimoe/configuration_phimoe.py | 6e65f6341abcf6814a4393e716691c927c39753e80f70d83f69b12f23b9b96dc | 202 | 16 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py | c14ea2475eb27826f52d47706f940094196db14bb1f68b5abd251fc0f2f53877 | 1562 | 110 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/xlm_roberta/modeling_tf_xlm_roberta.py | a4551778d9dc1262fc80d18a837330921e81f9d6f6c8a5e09dfe59beb94df86a | 1791 | 68 |     TFBaseModelOutputWithPastAndCrossAttentions,     TFBaseModelOutputWithPoolingAndCrossAttentions,     TFCausalLMOutputWithCrossAttentions,     TFMaskedLMOutput,     TFMultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/xlm_roberta/configuration_xlm_roberta.py | 03fbf3d26a4dd0a855e9d6ee38ef05479a850975d8792012927052fe454b5cf3 | 158 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/xlm_roberta/modeling_flax_xlm_roberta.py | 9dd62e5f2a23fc8e71556d93581e52ad7b7f0f7865a9286f6ce63eb56d1e3a43 | 1512 | 58 |     FlaxBaseModelOutputWithPooling,     FlaxBaseModelOutputWithPoolingAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxMaskedLMOutput,     FlaxMultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/clipseg/configuration_clipseg.py | 571ce44af8404ac6b154dccce18a69e57ca02a20cef9ea36121ce721556c4487 | 385 | 6 |         num_attention_heads (`int`, *optional*, defaults to 8):             Number of attention heads for each attention layer in the Transformer encoder.         max_position_embeddings (`int`, *opti |
| .venv/lib/python3.13/site-packages/transformers/models/clipseg/modeling_clipseg.py | 709dc238395e5f830f436e433321d873a3ba670108057059a85c0c617430e5ce | 1386 | 107 |         similarity scores.     text_embeds (`torch.FloatTensor` of shape `(batch_size, output_dim`):         The text embeddings obtained by applying the projection layer to the pooled output of [`CLI |
| .venv/lib/python3.13/site-packages/transformers/models/code_llama/tokenization_code_llama.py | 04b129ef6593ddf37ca71eb9cf3067f5b730bf7d138680df944db6ebb4c9f179 | 455 | 1 |      The default configuration match that of     [codellama/CodeLlama-7b-Instruct-hf](https://huggingface.co/meta-llama/CodeLlama-7b-Instruct-hf/blob/main/tokenizer_config.json)     which supports pro |
| .venv/lib/python3.13/site-packages/transformers/models/code_llama/tokenization_code_llama_fast.py | d5c6baf5bf2289cfd0eb5172f5fae6b7a99ac3c0e7431c5206105ec482e496dc | 375 | 2 |     This tokenizer inherits from [`PreTrainedTokenizerFast`] which contains most of the main methods. Users should     refer to this superclass for more information regarding those methods. The defaul |
| .venv/lib/python3.13/site-packages/transformers/models/efficientnet/modeling_efficientnet.py | cedd88448a6f5946c9b17f41f5cd1e61d6c4c74ba7823d26394e959f6e7983fa | 583 | 12 |   class EfficientNetEmbeddings(nn.Module):     r"""     A module that corresponds to the stem module of the original work. |
| .venv/lib/python3.13/site-packages/transformers/models/mgp_str/configuration_mgp_str.py | 3efc23ea804814fa76d7d364295ddbe248aca7bed4ce43762420b2df5cf64594 | 138 | 3 |             The number of classes for wordpiece head .         hidden_size (`int`, *optional*, defaults to 768):             The embedding dimension.         num_hidden_layers (`int`, *optional*, defa |
| .venv/lib/python3.13/site-packages/transformers/models/mgp_str/processing_mgp_str.py | 318b6a1c9a08222f5f3c094b4177a83ec04d3acf2a135d477286881e8ece69c6 | 236 | 2 |          self.char_tokenizer = tokenizer         self.bpe_tokenizer = AutoTokenizer.from_pretrained("openai-community/gpt2")         self.wp_tokenizer = AutoTokenizer.from_pretrained("google-bert/bert |
| .venv/lib/python3.13/site-packages/transformers/models/mgp_str/modeling_mgp_str.py | e271f5623020c0d7da8d4de0fc1aab31e50c7cdd0f43825c23f385b3402b0be6 | 461 | 21 | @auto_docstring(     custom_intro="""     Base class for vision model's outputs that also contains image embeddings of the pooling of the last hidden states.     """ ) |
| .venv/lib/python3.13/site-packages/transformers/models/mobilebert/modeling_tf_mobilebert.py | 9136bfa04ebf02761f1a859e7eecc74f53d7cc1ec62ccc159a4c2870ade40cdc | 1980 | 76 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     ModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/mobilebert/modeling_mobilebert.py | 89cad5cce0e6f84a7cde192a43316aca014428a2e9079cb196d5618b5057736f | 1483 | 78 |         pointer = model         for m_name in name:             if re.fullmatch(r"[A-Za-z]+_\d+", m_name):                 scope_names = re.split(r"_(\d+)", m_name)             else: |
| .venv/lib/python3.13/site-packages/transformers/models/mobilebert/configuration_mobilebert.py | 9128d4657440b60bc48e9e02da9c42f0fa39312eab3388b8bffc40cefaaa1d59 | 185 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/informer/configuration_informer.py | c3f4a2e64e596a418b5c035e98f0c163b457fe3deb7dc2d0aff35ac1d55445c0 | 251 | 11 |             of integers, having the same length as `num_static_categorical_features`. Cannot be `None` if             `num_static_categorical_features` is > 0.         embedding_dimension (`list[int]` |
| .venv/lib/python3.13/site-packages/transformers/models/informer/modeling_informer.py | 0162b0fdc3936f394d3fa9aed32fc16b1a0ca32df4d53028fa5bc1d5dcf12979 | 2161 | 48 |         cardinalities (`list[int]`):             List of cardinalities of the categorical features.         embedding_dims (`list[int]`):             List of embedding dimensions of the categorical fe |
| .venv/lib/python3.13/site-packages/transformers/models/informer/modular_informer.py | 8f5dce91f82d1b8e78a4b00ccde57acd19062a50a5dab91c932b0358d746cf47 | 981 | 32 |     TimeSeriesMeanScaler,     TimeSeriesNOPScaler,     TimeSeriesSinusoidalPositionalEmbedding,     TimeSeriesStdScaler,     TimeSeriesTransformerDecoder, |
| .venv/lib/python3.13/site-packages/transformers/models/kosmos2/modeling_kosmos2.py | f51b44a5451e2b8ffff4a324cb6c34ca80f79cdfeed87da0f1327e433720bbf8 | 1865 | 99 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPooling,     CausalLMOutputWithCrossAttentions, ) from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel |
| .venv/lib/python3.13/site-packages/transformers/models/kosmos2/configuration_kosmos2.py | 27c30227c4b30c9d37ffc0e248c362632538ea2d2d97a2c47362bfbb5767518f | 265 | 10 |             Vocabulary size of the Kosmos2 model. Defines the number of different tokens that can be represented by the             `inputs_ids` passed when calling [`Kosmos2Model`].         max_posit |
| .venv/lib/python3.13/site-packages/transformers/models/blip/modeling_tf_blip_text.py | 6ac12620d968a37206856629c333ec8fb2318cc94e9717b970318edf26691d75 | 1123 | 82 |     TFBaseModelOutputWithPastAndCrossAttentions,     TFBaseModelOutputWithPoolingAndCrossAttentions,     TFCausalLMOutputWithCrossAttentions, ) from ...modeling_tf_utils import ( |
| .venv/lib/python3.13/site-packages/transformers/models/blip/configuration_blip.py | fe2fc429e6b8fe1ff5e9acfcfe8d232fdf8eb349d76cfea237041aaab967cf8e | 318 | 5 |         num_attention_heads (`int`, *optional*, defaults to 8):             Number of attention heads for each attention layer in the Transformer encoder.         max_position_embeddings (`int`, *opti |
| .venv/lib/python3.13/site-packages/transformers/models/blip/modeling_tf_blip.py | 335075459c4bf490d922f84cd3940c23454be98ded2aac1976f4fd149339f311 | 1710 | 74 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, stable_softmax from ...utils import (     ModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/blip/modeling_blip_text.py | 5c2e5d21d7d9c2e9d97ddfd43be57ae7132d94b8c4de379835668acc88e3eeeb | 969 | 75 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions, ) from ...modeling_utils import PreTrainedModel |
| .venv/lib/python3.13/site-packages/transformers/models/blip/modeling_blip.py | 6150d988bb18a79e8d29a234e717162a09a79d9f7965dc922c823feac441c2de | 1448 | 88 | @auto_docstring(     custom_intro="""     Adapted from the base class for vision model's outputs that also contains image embeddings of the pooling of the     last hidden states. This class also adds  |
| .venv/lib/python3.13/site-packages/transformers/models/rag/modeling_rag.py | f1654a4003ca46062e4afa96568bdb8cbfbd5294a91538f3db9ee1c5f8ab2241 | 1670 | 27 |         each vocabulary token.     doc_scores (`torch.FloatTensor` of shape `(batch_size, config.n_docs)`):         Score between each retrieved document embeddings (see `retrieved_doc_embeds`) and    |
| .venv/lib/python3.13/site-packages/transformers/models/rag/configuration_rag.py | 7456d03b4aa14fe98a6284c4999017969c07487684e02556346718ec3effc86a | 187 | 5 |         max_combined_length (`int`, *optional*, defaults to 300):             Max length of contextualized input returned by [`~RagRetriever.__call__`].         retrieval_vector_size (`int`, *optional |
| .venv/lib/python3.13/site-packages/transformers/models/rag/modeling_tf_rag.py | 6d5c2b8af644c2d6807ae7a0cd720fa020bab16718bb3601e0b1888946832e44 | 1777 | 22 |             (see `past_key_values` input) to speed up sequential decoding.         doc_scores (`tf.Tensor` of shape `(batch_size, config.n_docs)`):             Score between each retrieved document em |
| .venv/lib/python3.13/site-packages/transformers/models/rag/retrieval_rag.py | 7da744844a5b9961c1721666be6a7234ad46118a80a9bab47db5f0fd3b91d3a1 | 683 | 76 |          Args:             question_hidden_states (`np.ndarray` of shape `(batch_size, vector_size)`):                 An array of query vectors.             n_docs (`int`): |
| .venv/lib/python3.13/site-packages/transformers/models/mobilevitv2/modeling_mobilevitv2.py | 317a5641e5de9eebd6503422d7332bbc48568a2076220a021f2c01b45e71ae1b | 968 | 8 |         context_scores = self.attn_dropout(context_scores)          # Compute context vector         # [batch_size, embed_dim, num_pixels_in_patch, num_patches] x [batch_size, 1, num_pixels_in_patch,  |
| .venv/lib/python3.13/site-packages/transformers/models/modernbert/configuration_modernbert.py | 1d02b4b9c5fb8adea0d22958def1d353246ea731cecf9d0aa4b372356b0ff768 | 225 | 11 |             The non-linear activation function (function or string) in the decoder. Will default to `"gelu"`             if not specified.         max_position_embeddings (`int`, *optional*, defaults  |
| .venv/lib/python3.13/site-packages/transformers/models/modernbert/modeling_modernbert.py | 5aa58d059af7f391328e0448a4d47d587fe33d1600b72475852aeeb3610ae7ba | 1543 | 55 | if is_flash_attn_2_available():     from flash_attn.flash_attn_interface import flash_attn_varlen_qkvpacked_func     from flash_attn.layers.rotary import RotaryEmbedding     from flash_attn.ops.triton |
| .venv/lib/python3.13/site-packages/transformers/models/modernbert/modular_modernbert.py | cffa14c6425a2da814d704ec999decba13173b915b4bbc6b8e76ad4dc58c6fbf | 1670 | 62 | from ...utils import auto_docstring, is_flash_attn_2_available, logging from ...utils.import_utils import is_triton_available from ..gemma.modeling_gemma import GemmaRotaryEmbedding, apply_rotary_pos_ |
| .venv/lib/python3.13/site-packages/transformers/models/codegen/modeling_codegen.py | 5987e8ab9444a855f8e6fbe094243b7daacaf2427286dbdb99472a778c7d942a | 674 | 41 | from ...modeling_attn_mask_utils import AttentionMaskConverter from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast |
| .venv/lib/python3.13/site-packages/transformers/models/codegen/configuration_codegen.py | 7342accb204d2ac3c531fd932ffe65392fc3ceda12f9c3a98516ac34e2367b92 | 232 | 15 |             This attribute is used in `CodeGenModel.__init__` without any real effect.         n_embd (`int`, *optional*, defaults to 4096):             Dimensionality of the embeddings and hidden sta |
| .venv/lib/python3.13/site-packages/transformers/models/codegen/tokenization_codegen_fast.py | c221f16a6edca02c904792f52c081c602060c0251485a2d9c3217696bed62bbc | 236 | 3 | # See the License for the specific language governing permissions and # limitations under the License. """Tokenization classes for OpenAI GPT."""  import re |
| .venv/lib/python3.13/site-packages/transformers/models/deit/modeling_deit.py | 2475cdfc6ce1012c1ca2923bf8e06a7ef059cd4f4944e61596294980317899b6 | 793 | 47 |   class DeiTEmbeddings(nn.Module):     """     Construct the CLS token, distillation token, position and patch embeddings. Optionally, also the mask token. |
| .venv/lib/python3.13/site-packages/transformers/models/deit/modeling_tf_deit.py | 886564d663ea76d3806ddea3a398f781bb9ea97037d09572ed706cdad13d9116 | 1233 | 53 |             distillation token).         hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):             Tup |
| .venv/lib/python3.13/site-packages/transformers/models/deit/configuration_deit.py | a9de29b1c7c928f59bc6199d0b38f515dbf5f68f0a3c8b97c09a54234e0fb9fe | 153 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/dpt/configuration_dpt.py | 8c26d21054ef119e55ee21e68cbfd2c5367d6b34c8e0ddaa11c77d09c1b13c6a | 305 | 4 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/dpt/modeling_dpt.py | eefa8cb47bd18b01e3b040f5f8374cd140ba8c2895dfca8f2d38c1a77f98f6cf | 1227 | 55 |   class DPTViTHybridEmbeddings(nn.Module):     """     This class turns `pixel_values` of shape `(batch_size, num_channels, height, width)` into the initial |
| .venv/lib/python3.13/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py | 3939510ca5498e433627dde737e3d15bcc567ad14ee90ed3b284472ef7b0da90 | 244 | 4 |             normed_input_values = []              for vector, length in zip(input_values, attention_mask.sum(-1)):                 normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:le |
| .venv/lib/python3.13/site-packages/transformers/models/wav2vec2/modeling_tf_wav2vec2.py | 08bce2d5c52ea3d9b40db8bdc9d2b8b12ec4e33dfd661548eed154388b313093 | 1856 | 31 |  from ...activations_tf import get_tf_activation from ...modeling_tf_outputs import TFBaseModelOutput, TFCausalLMOutput, TFSequenceClassifierOutput from ...modeling_tf_utils import (     TFPreTrainedM |
| .venv/lib/python3.13/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py | e0bbe7b22c0f6064727649e7c5422c09adb988f5e62a2378f7ad73766993dab5 | 2359 | 119 | from ...modeling_outputs import (     BaseModelOutput,     CausalLMOutput,     MaskedLMOutput,     SequenceClassifierOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/wav2vec2/modeling_flax_wav2vec2.py | c0d834a097fa3c6e93f820de31b7272018c4e4a6a6a3c46adcbca6382682596e | 1424 | 77 | from jax import lax  from ...modeling_flax_outputs import FlaxBaseModelOutput, FlaxCausalLMOutput from ...modeling_flax_utils import (     ACT2FN, |
| .venv/lib/python3.13/site-packages/transformers/models/wav2vec2/configuration_wav2vec2.py | 0385c6b925696547d6bddf9924f91c1a1212b0148db5281408d53680dd26668b | 348 | 55 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the  |
| .venv/lib/python3.13/site-packages/transformers/models/voxtral/modeling_voxtral.py | da04b46a9a5b552a531180ff7fd16536e08719c695fb5ad3bbe093c045d63586 | 543 | 23 | from ...generation import GenerationMixin from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutput, BaseModelOutputWithPast, CausalLMOutputWithPast fro |
| .venv/lib/python3.13/site-packages/transformers/models/voxtral/modular_voxtral.py | 396193ba9a06ff634db2b5c969b2231ee8c7bb76e5924f2f08836f8e5b2d9fd6 | 278 | 18 | from ...cache_utils import Cache from ...generation import GenerationMixin from ...modeling_outputs import BaseModelOutput, BaseModelOutputWithPast, CausalLMOutputWithPast from ...processing_utils imp |
| .venv/lib/python3.13/site-packages/transformers/models/voxtral/configuration_voxtral.py | cbff3fb9d0cdb0ae59b32e890246c827b4213180832f01cdc29d50850718983b | 202 | 6 |         num_attention_heads (`int`, *optional*, defaults to 20):             Number of attention heads for each attention layer in the Transformer encoder.         scale_embedding (`bool`, *optional*, |
| .venv/lib/python3.13/site-packages/transformers/models/fastspeech2_conformer/modeling_fastspeech2_conformer.py | 1f5cac58da1743f9e8175db5aa87b245af67e60941af01b1dab4468738936574 | 1572 | 49 |   def length_regulator(encoded_embeddings, duration_labels, speaking_speed=1.0):     """     Length regulator for feed-forward Transformer. |
| .venv/lib/python3.13/site-packages/transformers/models/fastspeech2_conformer/configuration_fastspeech2_conformer.py | 4d9e9adab4961378a4ba0381c7fb2be2d50b9b61695fc42d8f64bb30b05d9cd4 | 481 | 5 |             The dropout rate in the speech decoder postnet.         max_source_positions (`int`, *optional*, defaults to 5000):             if `"relative"` position embeddings are used, defines the ma |
| .venv/lib/python3.13/site-packages/transformers/models/siglip/configuration_siglip.py | dc6561226cda5b758217243721f0be64cdd9036aa6bc0fc1123999c8d390c9f9 | 258 | 4 |         num_attention_heads (`int`, *optional*, defaults to 12):             Number of attention heads for each attention layer in the Transformer encoder.         max_position_embeddings (`int`, *opt |
| .venv/lib/python3.13/site-packages/transformers/models/siglip/modeling_siglip.py | b55dace22508dcdaa4d3dc370c1e302a835b5dd4e0a83a858162c8d9e08aa1f1 | 1223 | 71 | @auto_docstring(     custom_intro="""     Base class for vision model's outputs that also contains image embeddings of the pooling of the last hidden states.     """ ) |
| .venv/lib/python3.13/site-packages/transformers/models/moonshine/modeling_moonshine.py | d0db54cd4982c984a8c06bdf67d2dc28775ef885bc81ffec027e0fe0ddf63af5 | 1098 | 44 |  def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):     """Applies Rotary Position Embedding to the query and key tensors.      Args: |
| .venv/lib/python3.13/site-packages/transformers/models/moonshine/configuration_moonshine.py | 1428aab3d05ac86977a14185878148005cfedde64a969a90386bac66f845059f | 231 | 14 |         decoder_hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings  |
| .venv/lib/python3.13/site-packages/transformers/models/moonshine/modular_moonshine.py | 5c18f69b8a22cf0783c980030777900454e615cc7d48323c6891efffc4433f38 | 922 | 44 | from ...utils import TransformersKwargs, auto_docstring, can_return_tuple, logging from ...utils.deprecation import deprecate_kwarg from ..glm.modeling_glm import GlmAttention, GlmRotaryEmbedding, app |
| .venv/lib/python3.13/site-packages/transformers/models/colpali/modular_colpali.py | 5133014bf51af0619f40bc1bd49c2038167c1a532bee67dbe155306dd2c8e721 | 346 | 25 |     def score_retrieval(         self,         query_embeddings: Union["torch.Tensor", list["torch.Tensor"]],         passage_embeddings: Union["torch.Tensor", list["torch.Tensor"]],         batch_siz |
| .venv/lib/python3.13/site-packages/transformers/models/colpali/configuration_colpali.py | f36de3f6416414e64255f8b45550bb01cb6db2d5e42b62c37c3fd16bdc15bfd7 | 105 | 6 |         text_config (`PretrainedConfig`, *optional*):             Configuration of the text backbone model. Overrides the `text_config` attribute of the `vlm_config` if provided.         embedding_dim |
| .venv/lib/python3.13/site-packages/transformers/models/colpali/processing_colpali.py | d9304e352ac0b619b3682afd3d8f59fc967b883167b5fb494e9efe988a66fdb4 | 415 | 25 |     def score_retrieval(         self,         query_embeddings: Union["torch.Tensor", list["torch.Tensor"]],         passage_embeddings: Union["torch.Tensor", list["torch.Tensor"]],         batch_siz |
| .venv/lib/python3.13/site-packages/transformers/models/colpali/modeling_colpali.py | 23e90ab9a8544d9d4702597d4235e9d9ff948310c7626e44065bdf9e70dea7ab | 215 | 39 |             if module.bias is not None:                 module.bias.data.zero_()         elif isinstance(module, nn.Embedding):             module.weight.data.normal_(mean=0.0, std=std)             if |
| .venv/lib/python3.13/site-packages/transformers/models/pegasus/modeling_flax_pegasus.py | 464734f7ae032aeaa060f326cca35c671e3f83784ea95f240f9b9da6acbec111 | 1533 | 36 |     FlaxBaseModelOutput,     FlaxBaseModelOutputWithPastAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxSeq2SeqLMOutput,     FlaxSeq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/pegasus/configuration_pegasus.py | efcf9631516d5218a05175c9e0f69b60903c4b75697d05bdfb635c339b7c1e5a | 165 | 10 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/pegasus/modeling_tf_pegasus.py | fd647ebdf1f15011b305425512cc3ba5a8da98325001e65962c32f114fc757fe | 1574 | 51 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     add_code_sample_docstrings, |
| .venv/lib/python3.13/site-packages/transformers/models/pegasus/modeling_pegasus.py | 8cf1590dc215a8aa8ec0ff0c6dd2a2d51fce9d225401c7289d8f57680bae8e83 | 1674 | 174 |     BaseModelOutput,     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     Seq2SeqLMOutput,     Seq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_5_vl/processing_qwen2_5_vl.py | 3e99f9303cfb53f3f57956d7266a9e5b30ef736284679de9f4e9aa3d67a86886 | 279 | 5 | # Copyright 2025 The Qwen Team and The HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. I |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py | ace34ffe3b98347665ba05b3e260a24370e9c8f66f0210ff0bc41100e1c8087f | 1735 | 132 | # Copyright 2025 The Qwen Team and The HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. I |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_5_vl/configuration_qwen2_5_vl.py | 74bb8f742be8777fcf7921cfd1459adc13a4c989beb92b63c839d22e1cd14f75 | 337 | 23 | # Copyright 2025 The Qwen Team and The HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. I |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py | 3b26a7c9c28db9a59b8e3bd5e9b66b351660b25e5480df7986d73ba170abaa4a | 1040 | 78 | # Copyright 2025 The Qwen Team and The HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. I |
| .venv/lib/python3.13/site-packages/transformers/models/bart/modeling_bart.py | 0c8b6c24e33b16f7c38511a921b4ac1c9f958176934e720ee3085f951e8d29eb | 1950 | 73 |     BaseModelOutput,     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     Seq2SeqLMOutput,     Seq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/bart/tokenization_bart_fast.py | 293d0849b2e50149fc8bbef3b62fce7b7c9e6f155233ae605c63054b73da794f | 272 | 2 | class BartTokenizerFast(PreTrainedTokenizerFast):     r"""     Construct a "fast" BART tokenizer (backed by HuggingFace's *tokenizers* library), derived from the GPT-2 tokenizer,     using byte-level  |
| .venv/lib/python3.13/site-packages/transformers/models/bart/configuration_bart.py | d017a607d0ca9338e90d5fb7f62202f7a3a440763db1ebf399852659d1b97c78 | 407 | 10 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/bart/modeling_tf_bart.py | 29bfcd81fa88e0b76f68b138262eafcd3a9cf4fef3758ee28e3af4a2c0ddd254 | 1714 | 56 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     add_code_sample_docstrings, |
| .venv/lib/python3.13/site-packages/transformers/models/bart/modeling_flax_bart.py | 4fc7520c74d811904e85ce4c0209ad09a97f9ecfe11423a7f7c6fd74f4b74e1a | 2007 | 59 |     FlaxBaseModelOutput,     FlaxBaseModelOutputWithPastAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxSeq2SeqLMOutput,     FlaxSeq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/doge/modular_doge.py | de7913ef1dcc3c9d0f8055ddaa9e213984bb2b93fad9abe1803f52a40f991148 | 801 | 38 | from ...integrations.flex_attention import compile_friendly_flex_attention from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import MoeCausalLMOutputWithPast, MoeModel |
| .venv/lib/python3.13/site-packages/transformers/models/doge/modeling_doge.py | 5f7d09a2d9fa0db25c61925bf212ca056545ce4cb45a49792d576a60dedb8073 | 813 | 27 | from ...masking_utils import create_causal_mask, create_sliding_window_causal_mask from ...modeling_layers import GenericForSequenceClassification, GradientCheckpointingLayer from ...modeling_outputs  |
| .venv/lib/python3.13/site-packages/transformers/models/doge/configuration_doge.py | 9e7b865eaac3542f68d73b75836b06a8dcb69e5c221f5852bfc1d41d041517e7 | 242 | 19 |             Whether or not the model should return the last key/values attentions (not used by all models). Only             relevant if `config.is_decoder=True`.         tie_word_embeddings (`bool`,  |
| .venv/lib/python3.13/site-packages/transformers/models/deepseek_vl/modeling_deepseek_vl.py | 0b2775d4eff23c61bde2b97300a8b27c872f500c8b82506d9b842c3604d36df6 | 362 | 15 |         input) to speed up sequential decoding.     image_hidden_states (`tuple(torch.FloatTensor)`, *optional*):         Tuple of `torch.FloatTensor` (one for the output of the image embeddings, `(ba |
| .venv/lib/python3.13/site-packages/transformers/models/deepseek_vl/modular_deepseek_vl.py | 2cd93f11537d68c5a0d139d773342885816154543f63c4d23d7a273474c29862 | 336 | 5 | ) from ..auto import CONFIG_MAPPING, AutoConfig, AutoModel from ..idefics.modeling_idefics import IdeficsBaseModelOutputWithPast, IdeficsCausalLMOutputWithPast from ..janus.image_processing_janus impo |
| .venv/lib/python3.13/site-packages/transformers/models/yoso/modeling_yoso.py | 6967e059a4ed419bd7fb0f4e7ff989b35e20732e760f92491c739a8a0e0d6552 | 1223 | 64 |   # Copied from transformers.models.nystromformer.modeling_nystromformer.NystromformerEmbeddings class YosoEmbeddings(nn.Module):     """Construct the embeddings from word, position and token_type emb |
| .venv/lib/python3.13/site-packages/transformers/models/yoso/configuration_yoso.py | e8f42ab743a31d00533679e10c4efad6c77096af7fb6a1b8f1427ea41577ac13 | 145 | 10 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/deepseek_v2/modeling_deepseek_v2.py | 335b4954f33ddfa8eb96bc9e679457c5bbd722935be0eba617ee5e7196a54ca5 | 641 | 24 | from ...masking_utils import create_causal_mask from ...modeling_layers import GenericForSequenceClassification, GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, Cau |
| .venv/lib/python3.13/site-packages/transformers/models/deepseek_v2/modular_deepseek_v2.py | bdaae4b242189de5a8e68e81d2e808bd74756aefc5f1e9c32835ed9934845909 | 534 | 19 | from ..llama.modeling_llama import (     LlamaDecoderLayer,     LlamaForCausalLM,     LlamaForSequenceClassification,     LlamaMLP, |
| .venv/lib/python3.13/site-packages/transformers/models/deepseek_v2/configuration_deepseek_v2.py | f2c9ea63da97ede45231ddbc51fbce7557bca35f40071704db56a4d565b55c2c | 240 | 13 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/janus/modeling_janus.py | 41c41c9d1e241e40d4243e2bb2d54b71ead4cb5f3c8a3d305a358be3d09da21d | 1436 | 81 |     decoded_pixel_values (`torch.FloatTensor` of shape `(batch_size, num_channels, image_size, image_size)`):         Reconstructed pixel values after encoding and decoding the input.     embedding_lo |
| .venv/lib/python3.13/site-packages/transformers/models/janus/configuration_janus.py | edf2f9f3f90573e856c21a6afba37f0491bcdb5f78037b87cfd4049912b4035e | 323 | 10 |             `"relu"`, `"selu"`, and `"gelu_new"` are supported.         mlp_ratio (`float`, *optional*, defaults to 4.0):             Ratio of MLP hidden dimensionality to embedding dimensionality.    |
| .venv/lib/python3.13/site-packages/transformers/models/janus/modular_janus.py | 29856a6b52d78c4ee13f952c12b435ff3e1fdf204aeed5a802c1464063ff49cb | 1612 | 58 |     ChameleonVQVAEEncoderConvDownsample,     ChameleonVQVAEEncoderResnetBlock,     ChameleonVQVAEVectorQuantizer, ) from ..idefics.modeling_idefics import IdeficsBaseModelOutputWithPast, IdeficsCausal |
| .venv/lib/python3.13/site-packages/transformers/models/mamba2/configuration_mamba2.py | 61627b63ff9c1224cbbf8e5be680a129dcc7161eb555615431d0d985c8cdca05 | 191 | 8 |             `inputs_ids` passed when calling [`Mamba2Model`].         hidden_size (`int`, *optional*, defaults to 4096):             Dimensionality of the embeddings and hidden states.         state_s |
| .venv/lib/python3.13/site-packages/transformers/models/mamba2/modeling_mamba2.py | 52fbd9d3e9f7cee9347a36577d761e84127f276eb9b4044d8b84d1ba7bb1a9dc | 1059 | 31 |          # S4D real initialization. These are not discretized!         # The core is to load them, compute the discrete states, then write the updated state. Keeps the memory bounded         A = torch |
| .venv/lib/python3.13/site-packages/transformers/models/switch_transformers/modeling_switch_transformers.py | e9edda497493683f39d0bddef2706b73545ad61070cc19e06cebcb3a6acc925e | 1820 | 52 |          if self.has_relative_attention_bias:             self.relative_attention_bias = nn.Embedding(self.relative_attention_num_buckets, self.n_heads)         self.pruned_heads = set()         self. |
| .venv/lib/python3.13/site-packages/transformers/models/autoformer/configuration_autoformer.py | 8529fa59aaba0aec8314ec4079cafd22115aab87c40041e7d2e89a0bfb6c6b7b | 246 | 10 |             of integers, having the same length as `num_static_categorical_features`. Cannot be `None` if             `num_static_categorical_features` is > 0.         embedding_dimension (`list[int]` |
| .venv/lib/python3.13/site-packages/transformers/models/autoformer/modeling_autoformer.py | 4abce72426a0cac678109fb1013b38ba4acc973b7e15d29db0fab5c8ad6180a5 | 2121 | 50 |         cardinalities (`list[int]`):             List of cardinalities of the categorical features.         embedding_dims (`list[int]`):             List of embedding dimensions of the categorical fe |
| .venv/lib/python3.13/site-packages/transformers/models/camembert/modeling_tf_camembert.py | a278d67c8b366cbd76069b274549239819465026c327fdb3b0561df3dabab844 | 1801 | 68 |     TFBaseModelOutputWithPastAndCrossAttentions,     TFBaseModelOutputWithPoolingAndCrossAttentions,     TFCausalLMOutputWithCrossAttentions,     TFMaskedLMOutput,     TFMultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/camembert/modeling_camembert.py | fe92a8dc4070ceb8e6ca0d891f81668915d2c3a1ef13c159db317956040a536e | 1576 | 108 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/camembert/configuration_camembert.py | 91ff75cc724b2f9fc2ff53a72703ed84a0e3ffadfa08d7df0a171f46cf9ea6a8 | 156 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/gemma3n/modular_gemma3n.py | edef45b1931fbf6993a4c866bfd5c0de59d714171ca88b1417ea200d3c63676a | 2687 | 93 |     Gemma2MLP,     Gemma2PreTrainedModel,     Gemma2RotaryEmbedding,     eager_attention_forward,     rotate_half, |
| .venv/lib/python3.13/site-packages/transformers/models/gemma3n/configuration_gemma3n.py | d356df876954c0bcd8de0aa51a7e4f6acfcbeb0ee84906e1868f989d47d98b9b | 685 | 21 |             the `inputs_ids` passed when calling [`Gemma3nTextModel`]         vocab_size_per_layer_input (`int`, *optional*, defaults to 262144):             Vocabulary size of the per-layer text embe |
| .venv/lib/python3.13/site-packages/transformers/models/gemma3n/modeling_gemma3n.py | d01eafe0e868078cddb7b973dec3e415c2a75e4c09be8ff93d2323f6a7ca652e | 2402 | 88 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWith |
| .venv/lib/python3.13/site-packages/transformers/models/roformer/modeling_roformer.py | 415c06fd2719d3af66bdc377a9db37ef0eefbd3c7dfbb483bd06e64ffda4d907 | 1506 | 87 | from ...modeling_outputs import (     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/roformer/modeling_flax_roformer.py | 47069b907c40756e230290546c9c235c448a0a0fb171ecfdb8d040cf26bfc4fe | 1092 | 37 |     - [Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)     - [Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#autom |
| .venv/lib/python3.13/site-packages/transformers/models/roformer/configuration_roformer.py | db68cca5de3e9c194fee4240959003c459abeface8afb05105df28ad45b6de0a | 151 | 11 |             Vocabulary size of the RoFormer model. Defines the number of different tokens that can be represented by             the `inputs_ids` passed when calling [`RoFormerModel`] or [`TFRoFormerM |
| .venv/lib/python3.13/site-packages/transformers/models/roformer/modeling_tf_roformer.py | c1ebcb565686aefe8feac3fccd8dcca60f5f52c651a9bf8f2d174e013fcea56a | 1547 | 105 |     TFBaseModelOutput,     TFBaseModelOutputWithPooling,     TFCausalLMOutput,     TFMaskedLMOutput,     TFMultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/timesformer/modeling_timesformer.py | 69407d77a802a4a4b27b2d0263fc07964f7fc50b02073e074f9616c3d7b19baa | 771 | 93 |  # Adapted from https://github.com/facebookresearch/TimeSformer/blob/a5ef29a7b7264baff199a30b3306ac27de901133/timesformer/models/vit.py#L155 class TimesformerPatchEmbeddings(nn.Module):     """Image t |
| .venv/lib/python3.13/site-packages/transformers/models/timesformer/configuration_timesformer.py | 1a29422a297fe3407f86a8e1d3ed36096ac1ba96f011f1e1399ddbe5b5294cf2 | 130 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py | b98ec7ee18a357dd1ac05e4b496ee5686b5d0697cb9b027465c712ffe889d12d | 1898 | 90 | class DeformableDetrConvModel(nn.Module):     """     This module adds 2D position embeddings to all intermediate feature maps of the convolutional encoder.     """  |
| .venv/lib/python3.13/site-packages/transformers/models/deformable_detr/image_processing_deformable_detr.py | 1ffba87177164e2f932457245fab3e21ea7032c396ee60aae17959d69e62b8cd | 1635 | 4 |      # Keep track of instances of each class     stuff_memory_list: dict[str, int] = {}     for k in range(pred_labels.shape[0]):         pred_class = pred_labels[k].item() |
| .venv/lib/python3.13/site-packages/transformers/models/deformable_detr/configuration_deformable_detr.py | e42455e1c74c4bfe4de0d4bc41af729802a870468621e802434c459b003e223c | 291 | 9 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/depth_pro/modeling_depth_pro.py | d5a49b5083a040c1bd16e36bded185bfc4de316f064bc7bc77d09839619eb7a1 | 1133 | 3 |         intermediate_features = []         for i in range(self.n_intermediate_hooks):             # +1 to correct index position as hidden_states contain embedding output as well             hidden_st |
| .venv/lib/python3.13/site-packages/transformers/models/align/modeling_align.py | 08968a55128f172611bb61d2f1f84c5a725ce75076655bf59dcebb1418de1dd2 | 1320 | 66 | @auto_docstring(     custom_intro="""     Base class for vision model's outputs that also contains image embeddings of the pooling of the last hidden states.     """ ) |
| .venv/lib/python3.13/site-packages/transformers/models/align/configuration_align.py | 4f7ca2696ff90bd54d1e8bb077e1462e0c0525df0cf21f9af60048a1dd18b367 | 332 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/modernbert_decoder/configuration_modernbert_decoder.py | d3ca5aaa12a15dbc3eb136ac772e6f36cba3385739c06542cb15899ad02a9079 | 209 | 11 |             The non-linear activation function (function or string) in the decoder. Will default to `"gelu"`             if not specified.         max_position_embeddings (`int`, *optional*, defaults  |
| .venv/lib/python3.13/site-packages/transformers/models/modernbert_decoder/modeling_modernbert_decoder.py | e3b135122efa19f60b6e6761f26610255e35bf6c54ff71f74601cfe178989a14 | 734 | 65 | from ...masking_utils import create_causal_mask, create_sliding_window_causal_mask from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, Ca |
| .venv/lib/python3.13/site-packages/transformers/models/modernbert_decoder/modular_modernbert_decoder.py | a62f83bea6a5233d4c4ae199be001a1a36db57c46f9e2a33e126d132ad2892cb | 806 | 66 | from ...masking_utils import create_causal_mask, create_sliding_window_causal_mask from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, Ca |
| .venv/lib/python3.13/site-packages/transformers/models/d_fine/modular_d_fine.py | 2e6884901b80a09047c6ab40b62f38cdb6e39d9e80672994e67ce72e13cf30b5 | 1222 | 13 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         eval_size (`tuple[int, int]`, *optional*):             Height and width used to computes the effective height and width of the po |
| .venv/lib/python3.13/site-packages/transformers/models/d_fine/configuration_d_fine.py | 98583fc5c0f6b7bf9ebe26d7e5110a7822a0dd129921d050b1246d1969d837a1 | 434 | 3 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         eval_size (`tuple[int, int]`, *optional*):             Height and width used to computes the effective height and width of the po |
| .venv/lib/python3.13/site-packages/transformers/models/d_fine/modeling_d_fine.py | f0d05693550a30d0fe049d9c5bdd77f4363df5be06c8ab3cf6f7bd07fd6a74f0 | 2189 | 47 |     Multi-headed attention from 'Attention Is All You Need' paper.      Here, we add position embeddings to the queries and keys (as explained in the Deformable DETR paper).     """  |
| .venv/lib/python3.13/site-packages/transformers/models/vit/modeling_vit.py | 93a2e6668b3e962092b78902b07c5c2d016d69b05a081cfd7859398b004caa29 | 693 | 51 |   class ViTEmbeddings(nn.Module):     """     Construct the CLS token, position and patch embeddings. Optionally, also the mask token. |
| .venv/lib/python3.13/site-packages/transformers/models/vit/modeling_flax_vit.py | f7948169bdc2008a03ddbc2059f37a63bbf8e1f47a107349543b8faa2f85397f | 678 | 26 |     - [Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)     - [Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#autom |
| .venv/lib/python3.13/site-packages/transformers/models/vit/modeling_tf_vit.py | afffd2f0617b012ef16cea67569fc939d1380721f51f55819efd4265d18b4e61 | 907 | 48 |   class TFViTEmbeddings(keras.layers.Layer):     """     Construct the CLS token, position and patch embeddings. |
| .venv/lib/python3.13/site-packages/transformers/models/vit/configuration_vit.py | ab38ea9ddb1173a3f277c6224c5bc06def8e2082724523ce75414a552241d858 | 152 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/segformer/configuration_segformer.py | 0b2bc44545fb432591a34986ee3c2cb7ede322accec83e9843665d0a4a1363f8 | 172 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/segformer/modeling_segformer.py | 888632682e36f597cb685ce949aba99a784fd3cea9233fa413eb51e6dfbdaef4 | 779 | 26 |             Classification (or regression if config.num_labels==1) scores (before SoftMax).         hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is  |
| .venv/lib/python3.13/site-packages/transformers/models/segformer/modeling_tf_segformer.py | f7d33cec59c77f10e29195e7fb63e60a71a23c47135b8931429582d6d4da430f | 1045 | 29 |   class TFSegformerOverlapPatchEmbeddings(keras.layers.Layer):     """Construct the overlapping patch embeddings."""  |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py | 52fb6ee75523c431b092c347523cd45831257c179bfd1264903e578bf07e8b40 | 1198 | 83 | # See the License for the specific language governing permissions and # limitations under the License. """PyTorch GPT Neo model."""  import os |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_neo/__init__.py | 6f6e6ac626a7bee72001ddcec6e234d11af9df6e28f8245eb34ceb70420e0992 | 29 | 3 |  if TYPE_CHECKING:     from .configuration_gpt_neo import *     from .modeling_flax_gpt_neo import *     from .modeling_gpt_neo import * |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_neo/modeling_flax_gpt_neo.py | 7c3e178a378ababbb97af995ecd70f400b60bd085af07fa8132266dae3651386 | 688 | 76 | from jax import lax  from ...modeling_flax_outputs import FlaxBaseModelOutput, FlaxCausalLMOutput from ...modeling_flax_utils import ACT2FN, FlaxPreTrainedModel, append_call_sample_docstring from ...u |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_neo/configuration_gpt_neo.py | cd189d283f0cef37fe61b683594630f1272341eb0ee41488e9ded8a079f28f05 | 274 | 28 | # See the License for the specific language governing permissions and # limitations under the License. """GPT Neo model configuration"""  from collections import OrderedDict |
| .venv/lib/python3.13/site-packages/transformers/models/vitmatte/modeling_vitmatte.py | 5f0fc0e0cbe3b0cdf83c3cb95f1919dba99b626ed63fcc226216d57383ba9346 | 297 | 6 |         Estimated alpha values.     hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):         Tupl |
| .venv/lib/python3.13/site-packages/transformers/models/paligemma/modeling_paligemma.py | 659f30ac3f46851c1fad41ceb85fcf73fc6a37f367d9addf8b6558b0282a8c75 | 630 | 24 |     """ ) class PaliGemmaCausalLMOutputWithPast(ModelOutput):     r"""     loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided): |
| .venv/lib/python3.13/site-packages/transformers/models/dbrx/modeling_dbrx.py | ef25d2948200f6b112aa165cd41c10db4ed7ccae6658d803d587d4e3ed886e3f | 1254 | 45 | from ...modeling_flash_attention_utils import flash_attn_supports_top_left_mask, is_flash_attn_available from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import MoeCa |
| .venv/lib/python3.13/site-packages/transformers/models/dbrx/configuration_dbrx.py | 5118a11f6d56565c9f54bfa1470d58850d8fb48bd05d8efb220d408964ec4f4a | 233 | 9 |     Args:         d_model (`int`, *optional*, defaults to 2048):             Dimensionality of the embeddings and hidden states.         n_heads (`int`, *optional*, defaults to 16):             Number |
| .venv/lib/python3.13/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py | a92f1c63d146b946c56a3c3be62e3deb35413c92487f5ed9c552a43007dc290f | 662 | 35 | ) from ..auto.configuration_auto import AutoConfig from ..auto.modeling_tf_auto import TFAutoModel, TFAutoModelForCausalLM from .configuration_encoder_decoder import EncoderDecoderConfig  |
| .venv/lib/python3.13/site-packages/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py | 5376c780e909c5941152a5ce69c5bb9c4c578388f6cc8f7ce74ad20c25a81435 | 902 | 37 | from jax.random import PRNGKey  from ...modeling_flax_outputs import FlaxBaseModelOutput, FlaxCausalLMOutputWithCrossAttentions, FlaxSeq2SeqLMOutput from ...modeling_flax_utils import FlaxPreTrainedMo |
| .venv/lib/python3.13/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py | 85b09fdabe3c12a4a86ad869becc999a168db6333168a875de5b438ed0e6d71a | 609 | 20 | from ...utils import auto_docstring, logging from ..auto.configuration_auto import AutoConfig from ..auto.modeling_auto import AutoModel, AutoModelForCausalLM from .configuration_encoder_decoder impor |
| .venv/lib/python3.13/site-packages/transformers/models/xlm/modeling_tf_xlm.py | 9043cda93eaf113f456860d4a28f3ec1f9829261483277d4dd754f53201537c1 | 1357 | 56 |     TFSequenceClassificationLoss,     TFSequenceSummary,     TFSharedEmbeddings,     TFTokenClassificationLoss,     get_initializer, |
| .venv/lib/python3.13/site-packages/transformers/models/xlm/configuration_xlm.py | 936d7acf22c8debdb41d7b057deb23d1042217ee280b18d433738d0b1259b736 | 242 | 19 |             Number of attention heads for each attention layer in the Transformer encoder.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully con |
| .venv/lib/python3.13/site-packages/transformers/models/xlm/modeling_xlm.py | 6a3e0e8209020578746e6338829e7a17b428cccf699350f89531b44c4f8bcc1a | 1636 | 41 |   def create_sinusoidal_embeddings(n_pos, dim, out):     position_enc = np.array([[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)])     out.requires_grad = Fals |
| .venv/lib/python3.13/site-packages/transformers/models/bert/modeling_tf_bert.py | 7bb1d3d3952890a43c7e1a4ec2f92c11c4866341c3b2804073b3736fae313a29 | 2126 | 74 |     TFBaseModelOutputWithPastAndCrossAttentions,     TFBaseModelOutputWithPoolingAndCrossAttentions,     TFCausalLMOutputWithCrossAttentions,     TFMaskedLMOutput,     TFMultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/bert/configuration_bert.py | 76fe8eb30215a4d52b5ad23b5a63375da000f02f1907e4b72f3b39265f4b9159 | 155 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/bert/modeling_flax_bert.py | c618c355fb070c7b1d14d1f08cd4708c7abdc105b9bac1fe88aa48363050ed24 | 1728 | 71 |     FlaxBaseModelOutputWithPooling,     FlaxBaseModelOutputWithPoolingAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxMaskedLMOutput,     FlaxMultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py | 824426a8c8e2b3c77bc55f14260964b5268cb5d05cba591389b2cb88ba77a21d | 1801 | 109 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/xlstm/configuration_xlstm.py | 8d70aea08617e1c6f86ad800323828bdee3bc269ba7644d2b58e210050b7c192 | 303 | 18 |         vocab_size (int, optional, *optional*, defaults to 50304):             Vocabulary size of the xLSTM model. Defines the number of different tokens that can be represented by the             `in |
| .venv/lib/python3.13/site-packages/transformers/models/xlstm/modeling_xlstm.py | 067a2dad2f5afdb6dfccc48ec9c369f06edc136066489a138b69026fc2b4bcea | 1625 | 36 |         vecF = fgate.view(batch_size, nh, nc, chunk_size)          # compute the gates, the g and the a and b vectors         vecF_logsig = fgate.logsigmoid(vecF)         vecB = vecF_logsig.cumsum(-1) |
| .venv/lib/python3.13/site-packages/transformers/models/mistral3/modular_mistral3.py | f7663e7ba5b14654fd7ae2df5d790916e71196a09eb285bb4197b54ae20e29cf | 339 | 7 | from ...utils import logging from ..llava.modeling_llava import (     LlavaCausalLMOutputWithPast,     LlavaForConditionalGeneration,     LlavaModel, |
| .venv/lib/python3.13/site-packages/transformers/models/mistral3/modeling_mistral3.py | dfc9bd6c681496a50cdb5f694e60c782007748e5fabeb36529d8c275826403c6 | 540 | 15 |     """ ) class Mistral3CausalLMOutputWithPast(ModelOutput):     r"""     loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided): |
| .venv/lib/python3.13/site-packages/transformers/models/mistral3/configuration_mistral3.py | fff5f4b9a56deb87e5ff0ace9572e231b83b454323d0f6a5c32a78e3ecdd0307 | 142 | 1 |                 initializer_range=0.02,                 intermediate_size=32768,                 max_position_embeddings=131072,                 model_type="mistral",                 num_attention_hea |
| .venv/lib/python3.13/site-packages/transformers/models/musicgen/configuration_musicgen.py | 629b2b851684a9100e618964c79bb27a5cf98aad9dc2f53cfe69249d120df403 | 249 | 15 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/musicgen/modeling_musicgen.py | bd4c88c7a952a6a3863f3c51a0fcb6daab74f6a262621f6cb6e0d4d074ff71b1 | 2453 | 58 |     BaseModelOutput,     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     ModelOutput,     Seq2SeqLMOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/plbart/configuration_plbart.py | 3774f895b08218fde760d20761a875c8cbc3cb516226a82974720028915f7134 | 198 | 10 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/plbart/modeling_plbart.py | 1c2b6313bc5c6b26d6e8dbe21f35a0f89615cb0fc4fe150e59759d03ab22b020 | 1724 | 70 |     BaseModelOutput,     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     Seq2SeqLMOutput,     Seq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/plbart/modular_plbart.py | 69f036bbaffd155701c60d0515575a5f476f7305ede1ba90561d2c0c931e9085 | 661 | 27 |     BartDecoder,     BartEncoder,     BartForCausalLM,     BartScaledWordEmbedding, ) |
| .venv/lib/python3.13/site-packages/transformers/models/deepseek_v3/modeling_deepseek_v3.py | dbf82133c74081c5c1e7d6853dc59d847d03789cfc2447ee9c0007403f4418be | 685 | 30 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GenericForSequenceClassification, GradientCheckpointingLayer from ...modeling_outputs import BaseModel |
| .venv/lib/python3.13/site-packages/transformers/models/deepseek_v3/modular_deepseek_v3.py | 8f34ee535539bef45703cf68de873f2dc9676818ab622e3085d11e91cc987eb3 | 370 | 13 | from ..llama.modeling_llama import (     LlamaDecoderLayer,     LlamaForCausalLM,     LlamaModel,     LlamaPreTrainedModel, |
| .venv/lib/python3.13/site-packages/transformers/models/deepseek_v3/configuration_deepseek_v3.py | 54472b0090ce5019f83663c3a805c3678ee00911868d939a2ac18bd2a487e711 | 254 | 16 |             Rank of the LoRA matrices for query projections.         qk_rope_head_dim (`int`, *optional*, defaults to 64):             Dimension of the query/key heads that use rotary position embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/ovis2/modeling_ovis2.py | a7583819925cc817b388c4aa9d216a08475ce4c75e3dcf3a7c330f5cc4014815 | 891 | 40 |     """ ) class Ovis2CausalLMOutputWithPast(ModelOutput):     r"""     loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided): |
| .venv/lib/python3.13/site-packages/transformers/models/ovis2/modular_ovis2.py | 86c07118a70cb2cd7a4842494740fc303e787add29e735da353818be5f84e6b8 | 432 | 29 | from ..llama.modeling_llama import LlamaMLP, LlamaRMSNorm from ..llava.modeling_llava import LlavaForConditionalGeneration, LlavaModel from ..llava_next.modeling_llava_next import LlavaNextCausalLMOut |
| .venv/lib/python3.13/site-packages/transformers/models/wav2vec2_conformer/modular_wav2vec2_conformer.py | 70dd3a86dc702fc4f3bec38d5d51b90bb48015b1277e6522a3176d0fe1deff5b | 731 | 98 |     Wav2Vec2ForPreTraining,     Wav2Vec2ForSequenceClassification,     Wav2Vec2ForXVector,     Wav2Vec2GumbelVectorQuantizer,     Wav2Vec2Model, |
| .venv/lib/python3.13/site-packages/transformers/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py | 07aa61af35d0e9d46a7a2e2261810741f2ee40a95efcc873ce4d5c50a20f35e3 | 1935 | 178 | from ...modeling_outputs import (     BaseModelOutput,     CausalLMOutput,     SequenceClassifierOutput,     TokenClassifierOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/wav2vec2_conformer/configuration_wav2vec2_conformer.py | 80179bfdc642e570833a68359653d443410b0d2fb5bb4fde19946b03df2d2f13 | 361 | 68 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the  |
| .venv/lib/python3.13/site-packages/transformers/models/aria/modular_aria.py | dcff0ba0a4fdf7bb36e519487183fed59093e9443fd672e0f2bb33d5fc25acd7 | 1614 | 26 |     LlamaAttention,     LlamaDecoderLayer,     LlamaForCausalLM,     LlamaMLP,     LlamaModel, |
| .venv/lib/python3.13/site-packages/transformers/models/aria/modeling_aria.py | 87ee09a7392ec31728ebbd5a9cc1e7c1abbeeb7d88f10a0ece82076778e39bea | 1281 | 42 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWith |
| .venv/lib/python3.13/site-packages/transformers/models/aria/image_processing_aria.py | b687069a05c6c4d30560d5b59d4279531834e4a46ce2f93276ea2dd7c3e8ef72 | 528 | 3 |                 The padding mode to use. Can be one of:                     - `"constant"`: pads with a constant value.                     - `"reflect"`: pads with the reflection of the vector mirror |
| .venv/lib/python3.13/site-packages/transformers/models/aria/configuration_aria.py | 39f03bdb6b53426e0412c63199933e5a6d76727a07f2c43bd366c7412052044c | 308 | 18 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/owlvit/configuration_owlvit.py | 2b129dce9eb10593801010d21aefcb4466012a18c483bb54f1d7ea2d05efeb0a | 337 | 4 |         num_attention_heads (`int`, *optional*, defaults to 8):             Number of attention heads for each attention layer in the Transformer encoder.         max_position_embeddings (`int`, *opti |
| .venv/lib/python3.13/site-packages/transformers/models/owlvit/modeling_owlvit.py | 9f6af3ad21c79975738e374c767a31d0947f1cd15797f62ab335b578c8602f26 | 1652 | 88 |         similarity scores.     text_embeds (`torch.FloatTensor` of shape `(batch_size * num_max_text_queries, output_dim`):         The text embeddings obtained by applying the projection layer to the |
| .venv/lib/python3.13/site-packages/transformers/models/vipllava/modeling_vipllava.py | 725e6999c84cfcce56d179d69277a44d8df3abde89d675e94b5c71eaa60a9602 | 465 | 14 |     """ ) class VipLlavaCausalLMOutputWithPast(ModelOutput):     r"""     loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided): |
| .venv/lib/python3.13/site-packages/transformers/models/vipllava/modular_vipllava.py | a4e05351b5d685788988061ed28a8eb86891e1815f9f6b3aa9ddea56a36b4bcd | 279 | 6 |  from transformers.models.llava.modeling_llava import (     LlavaCausalLMOutputWithPast,     LlavaForConditionalGeneration,     LlavaModel, |
| .venv/lib/python3.13/site-packages/transformers/models/vipllava/configuration_vipllava.py | 054bef755d82822129e61fa959bb84522eedf1b9e497a85aaa58cdb5fdde9fa7 | 123 | 1 |             The vision feature layer, or list of layers to select the vision features from.         image_seq_length (`int`, *optional*, defaults to 576):             Sequence length of one image embe |
| .venv/lib/python3.13/site-packages/transformers/models/ernie4_5_moe/modeling_ernie4_5_moe.py | 34bf5fe31baf33df2f4df9f46dfb7d19baa96daf655633f5a1515ca7d0dba4d5 | 750 | 27 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import MoeCausalLMOutputWithPast, MoeModelOutputWi |
| .venv/lib/python3.13/site-packages/transformers/models/ernie4_5_moe/configuration_ernie4_5_moe.py | 1e9716c10772405a6f630173301a6d22c52af749910f13550d0117a4918951cf | 255 | 18 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/ernie4_5_moe/modular_ernie4_5_moe.py | f950763967f12b84e7c85c0fd5f1aa0299b511860c1981c1758cee612dcbe542 | 347 | 14 | from ...utils import TransformersKwargs, auto_docstring, can_return_tuple, logging from ...utils.generic import OutputRecorder, check_model_inputs from ..ernie4_5.modeling_ernie4_5 import Ernie4_5Rota |
| .venv/lib/python3.13/site-packages/transformers/models/ijepa/modeling_ijepa.py | 8b052f8ebc4c8e881267ca9c373d2d0ff0471931bdb7381eba2202b07a092d71 | 541 | 48 |   class IJepaPatchEmbeddings(nn.Module):     """     This class turns `pixel_values` of shape `(batch_size, num_channels, height, width)` into the initial |
| .venv/lib/python3.13/site-packages/transformers/models/ijepa/configuration_ijepa.py | f253b7eb4512591527ae70573b649e899374a3328724d6f62b60f4fef08a797f | 122 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/ijepa/modular_ijepa.py | 600f4c30040de1610c241bb023cbcde3a1d2f1ccfd3e3c8c451af2c7f893ed62 | 187 | 33 | from ...processing_utils import Unpack from ...utils import TransformersKwargs, auto_docstring, torch_int from ..vit.modeling_vit import ViTEmbeddings, ViTForImageClassification, ViTModel, ViTPreTrain |
| .venv/lib/python3.13/site-packages/transformers/models/idefics3/image_processing_idefics3.py | 780adaf0acae8a208c40957d91ade4aff6fd4d22199c8b171959fd84411f7a2b | 900 | 1 |                     frames.append(cropped_image)              # For the global image at the end, we resize it to match the max_image_size, for cpu memory efficiency             global_image_height, gl |
| .venv/lib/python3.13/site-packages/transformers/models/idefics3/image_processing_idefics3_fast.py | 6a085bdc5671e6965b9fe6c517a61847cc08c099fe475df60ab3a628cbfe71c5 | 547 | 1 |             )  # batch_size x n_frames x num_channels x height x width              # For the global image at the end, we resize it to match the max_image_size, for cpu memory efficiency             g |
| .venv/lib/python3.13/site-packages/transformers/models/idefics3/configuration_idefics3.py | 7d0619d04a3eabb2275633456add918cbf51650991fbd9c02252bdbff5cd9191 | 191 | 9 |         image_token_id (`int`, *optional*, defaults to 128257):             The id of the "image" token.         tie_word_embeddings (`bool`, *optional*, defaults to `False`):             Whether or n |
| .venv/lib/python3.13/site-packages/transformers/models/idefics3/modeling_idefics3.py | 6bcee771eed5647a537da76349b3a1fc28209cfc6896b77e246fd4d7b58bffcc | 1048 | 60 |         input) to speed up sequential decoding.     image_hidden_states (`tuple(torch.FloatTensor)`, *optional*):         Tuple of `torch.FloatTensor` (one for the output of the image embeddings, `(ba |
| .venv/lib/python3.13/site-packages/transformers/models/patchtst/configuration_patchtst.py | 15d8877d81621efa3b908b8e57fcd218f1d9d90f9061b3c4075664a8b39ce6a1 | 257 | 7 |         num_attention_heads (`int`, *optional*, defaults to 4):             Number of attention heads for each attention layer in the Transformer encoder.         share_embedding (`bool`, *optional*,  |
| .venv/lib/python3.13/site-packages/transformers/models/patchtst/modeling_patchtst.py | 7d85640b45f540508c126345f7244ca7e85816985240f8eec2065341afb8461d | 1958 | 96 |   class PatchTSTEmbedding(nn.Module):     def __init__(self, config: PatchTSTConfig):         super().__init__() |
| .venv/lib/python3.13/site-packages/transformers/models/blenderbot/modeling_blenderbot.py | 13c59f9f271b1a776316ce912603f770e12644f11749e9ac9c2aeccba964f746 | 1598 | 67 |     BaseModelOutput,     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     Seq2SeqLMOutput,     Seq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/blenderbot/modeling_tf_blenderbot.py | cf366de2b94a89f0c4844ec7f84b120db6afcc1442665d97244ea642039eefee | 1558 | 41 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     add_code_sample_docstrings, |
| .venv/lib/python3.13/site-packages/transformers/models/blenderbot/configuration_blenderbot.py | 351ab1a1f723f1576d228cc183bc6788f3a2c85cb57dbdcc5f8493a613d507c0 | 397 | 10 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/blenderbot/modeling_flax_blenderbot.py | 113b36f63b4a7c38d204bfb2ed525c7671cf1eefce1acbebe14e6f99e56d468f | 1509 | 38 |     FlaxBaseModelOutput,     FlaxBaseModelOutputWithPastAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxSeq2SeqLMOutput,     FlaxSeq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/blenderbot/tokenization_blenderbot.py | b1fa92189125fa8c1bf7e307c46f7b1b8050741eab4aff5dd7bcbbc656cb242c | 411 | 1 | class BlenderbotTokenizer(PreTrainedTokenizer):     """     Constructs a Blenderbot tokenizer, derived from the GPT-2 tokenizer, using byte-level Byte-Pair-Encoding.      This tokenizer has been train |
| .venv/lib/python3.13/site-packages/transformers/models/blenderbot/tokenization_blenderbot_fast.py | 067e8a65a52bdbe2f09af1d098e328e937eac0bc5b9bff805daad0c3888ff5b4 | 285 | 1 | class BlenderbotTokenizerFast(PreTrainedTokenizerFast):     """     Construct a "fast" Blenderbot tokenizer (backed by HuggingFace's *tokenizers* library), derived from the GPT-2     tokenizer, using  |
| .venv/lib/python3.13/site-packages/transformers/models/musicgen_melody/configuration_musicgen_melody.py | c259d906a250d171254d1bc8db33dcd4f18b6abcccb160506872989a47a7b269 | 262 | 15 |             Vocabulary size of the MusicgenMelodyDecoder model. Defines the number of different tokens that can be             represented by the `inputs_ids` passed when calling [`MusicgenMelodyDecod |
| .venv/lib/python3.13/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py | bf838d3245284f37b6a401a9d9cbe46c439299ee5f92ed0fbc0b7c99782add42 | 2289 | 57 |   # Copied from transformers.models.musicgen.modeling_musicgen.MusicgenSinusoidalPositionalEmbedding with Musicgen->MusicgenMelody class MusicgenMelodySinusoidalPositionalEmbedding(nn.Module):     """ |
| .venv/lib/python3.13/site-packages/transformers/models/clap/modeling_clap.py | f26cdff24c78121603b147f49206a2d59b25aef6fafca03b7cf02e491472ca45 | 1955 | 72 |   # Adapted from: https://github.com/LAION-AI/CLAP/blob/6ad05a971ba0622f6acee8c41993e0d02bbed639/src/open_clip/utils.py#L191 def interpolate(hidden_states, ratio):     """ |
| .venv/lib/python3.13/site-packages/transformers/models/clap/configuration_clap.py | 8d39dfb8942fdc51ecd2b3fb9df24f3119386f3e8cb6c8c75dd4b564bfee9be2 | 383 | 16 |             `"relu"`, `"silu"` and `"relu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/mobilevit/modeling_mobilevit.py | 73dd86d9a428978ec78c05c336b5a02e5d2887cacf7e58de452d7082f8713fa7 | 1019 | 2 |             raise ValueError("You have to specify pixel_values")          embedding_output = self.conv_stem(pixel_values)          encoder_outputs = self.encoder( |
| .venv/lib/python3.13/site-packages/transformers/models/mobilevit/modeling_tf_mobilevit.py | 556fa25ef7709607e562b9a65bfb5f81bfd0284e00481d48ff971bae312f4143 | 1377 | 3 |         pixel_values = tf.transpose(pixel_values, perm=(0, 2, 3, 1))          embedding_output = self.conv_stem(pixel_values, training=training)          encoder_outputs = self.encoder( |
| .venv/lib/python3.13/site-packages/transformers/models/idefics/vision.py | 02b2a15160569023f57d59fc1d57315da21567fac736e0ec3a6001525c4ae96d | 484 | 32 | class IdeficsVisionModelOutput(ModelOutput):     """     Base class for vision model's outputs that also contains image embeddings of the pooling of the last hidden states.      Args: |
| .venv/lib/python3.13/site-packages/transformers/models/idefics/modeling_idefics.py | 9a0d9c7da2e991fb17806cd026dc78bc895426fe9c8a0c8fdc1f63c7e1e7e5e7 | 1541 | 176 | # Copyright 2022 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/idefics/perceiver.py | 324277e17e1d81534975d727f30516c837f4ad38a8565e161b774fe462d74744 | 190 | 11 |  Generic interface to various configurations of the Perceiver Resampler, that simply takes in a series of (potentially time-indexed) contextual embeddings, and "resamples" (compresses) them down to a  |
| .venv/lib/python3.13/site-packages/transformers/models/idefics/vision_tf.py | fcd9b172b24f7c55470b9992978a0f23620c6b8e19aca8efa238a57eac8f78bc | 573 | 43 | class TFIdeficsVisionModelOutput(ModelOutput):     """     Base class for vision model's outputs that also contains image embeddings of the pooling of the last hidden states.      Args: |
| .venv/lib/python3.13/site-packages/transformers/models/idefics/perceiver_tf.py | 5c644fdc569871b1dbc506bdfcda1a2e48a915fcbdb62ca681fc76c351814fa1 | 196 | 11 |  Generic interface to various configurations of the Perceiver Resampler, that simply takes in a series of (potentially time-indexed) contextual embeddings, and "resamples" (compresses) them down to a  |
| .venv/lib/python3.13/site-packages/transformers/models/idefics/modeling_tf_idefics.py | cc45377533718bed8611e0660f39eab8e0df0ffff3f3d6df6c1d437f1081c947 | 1779 | 169 | # Copyright 2022 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/idefics/configuration_idefics.py | e23eec02e97be1a76cbb77d73e2ab7e0578f0aa24969a7c28367661d4f61fc65 | 326 | 11 | # Copyright 2022 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/convbert/modeling_tf_convbert.py | 9af47df74d63a392fe18ebe9e90b686349ce451a70454450a52c44b374f95f97 | 1475 | 77 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     add_code_sample_docstrings, |
| .venv/lib/python3.13/site-packages/transformers/models/convbert/configuration_convbert.py | 325f14cad1d80afe3e0407b23d3533518e729e75fc748902206a2e98f4ea6827 | 161 | 8 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/convbert/modeling_convbert.py | 1f690a1aec26d20f888876b8bd1ed34518192df9c174b7d44b2d5c55e08dd260 | 1336 | 84 |      param_mapping = {         "embeddings.word_embeddings.weight": "electra/embeddings/word_embeddings",         "embeddings.position_embeddings.weight": "electra/embeddings/position_embeddings",     |
| .venv/lib/python3.13/site-packages/transformers/models/moshi/configuration_moshi.py | cd5a8045da39c101c4469ba7f99d5fd66c35fdd74b4e7d1f42cbecd928c4e49f | 334 | 19 |             Vocabulary size of the audio part of model. Defines the number of different tokens that can be             represented by the `audio_codes` passed when calling the Moshi models.         ma |
| .venv/lib/python3.13/site-packages/transformers/models/moshi/modeling_moshi.py | 231748dfbe9b47e7e7f9f989850f6401fbc9a22ba9da2367b6aeef5ee4afcd87 | 2501 | 54 | from ...modeling_flash_attention_utils import flash_attn_supports_top_left_mask, is_flash_attn_available from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseM |
| .venv/lib/python3.13/site-packages/transformers/models/hiera/configuration_hiera.py | 41b1764bbde90daa4c0b4fc0a105673d94ea5a0b34b57bd65a0480be33711051 | 195 | 5 |     Args:         embed_dim (`int`, *optional*, defaults to 96):             Dimensionality of patch embedding.         image_size (`list(int)`, *optional*, defaults to `[224, 224]`):             The  |
| .venv/lib/python3.13/site-packages/transformers/models/hiera/modeling_hiera.py | 260104ef2e325024fd2ad7ee6a1bff0eae77a8e225e904ea81779c42dd8aafe6 | 1463 | 65 |     r"""     reshaped_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):         Tuple of `torch.Fl |
| .venv/lib/python3.13/site-packages/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py | 2bfbf0bc2d96ed2cff8f8821dc36e7a65c1d207df344d0394e593dbfea9bc41c | 865 | 33 | from jax.random import PRNGKey  from ...modeling_flax_outputs import FlaxBaseModelOutput, FlaxCausalLMOutputWithCrossAttentions, FlaxSeq2SeqLMOutput from ...modeling_flax_utils import FlaxPreTrainedMo |
| .venv/lib/python3.13/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py | b7bcc73be84118c9bec2531040def1fa7081a947254973fddd4fbe22e9fc886f | 697 | 28 | ) from ..auto.configuration_auto import AutoConfig from ..auto.modeling_tf_auto import TFAutoModel, TFAutoModelForCausalLM from .configuration_vision_encoder_decoder import VisionEncoderDecoderConfig  |
| .venv/lib/python3.13/site-packages/transformers/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py | bff341eccbcf056e37bb0e2ef7f7e68b2687c54be5e28bf86311066d264a45f3 | 602 | 22 | from ...utils import auto_docstring, logging from ..auto.configuration_auto import AutoConfig from ..auto.modeling_auto import AutoModel, AutoModelForCausalLM from .configuration_vision_encoder_decode |
| .venv/lib/python3.13/site-packages/transformers/models/chinese_clip/modeling_chinese_clip.py | 672c4ee9adb638f43010c932c273083fc847624b1dc5a100b5e074a60183bedc | 1235 | 99 |         similarity scores.     text_embeds (`torch.FloatTensor` of shape `(batch_size, output_dim`):         The text embeddings obtained by applying the projection layer to the pooled output of       |
| .venv/lib/python3.13/site-packages/transformers/models/chinese_clip/configuration_chinese_clip.py | 6aeb78b4e76682f595e4b3770fbe4b25184a4cd0d11ccb7d289e9b989403ac4c | 424 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/vivit/configuration_vivit.py | 4d5b239b3a1769cd97874cdc1d2f1fcb4466162bdba25dd6b0eee48fe80a6629 | 120 | 1 |             `"relu"`, `"selu"`, `"gelu_fast"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully conn |
| .venv/lib/python3.13/site-packages/transformers/models/vivit/modeling_vivit.py | dfd9b0ac0c7b6d19c8b1e1535b48c16613d40b394e6bb8c2fb473563d6514d24 | 691 | 45 |   class VivitTubeletEmbeddings(nn.Module):     """     Construct Vivit Tubelet embeddings. |
| .venv/lib/python3.13/site-packages/transformers/models/csm/modular_csm.py | d2dd6a997091836079208a1f35a3a4ae52e2ef9bd711cc9afd444f0d4e9af01d | 769 | 26 | from ...generation import GenerationMixin from ...masking_utils import create_causal_mask from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_utils import  |
| .venv/lib/python3.13/site-packages/transformers/models/csm/configuration_csm.py | c6144176065b73be95dce30901c17810bf704048bd155415f20ddffd9bb0c46a | 441 | 39 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/csm/modeling_csm.py | 54cfc9d6d20daefb81203181f0d4550466dca7c355dd5b2d8c98430ac6b2c80f | 1091 | 38 | from ...masking_utils import create_causal_mask from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeli |
| .venv/lib/python3.13/site-packages/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py | dce7b4cfbe7fd12412338391fa146d1ffc36e0b9a1495f4082ccb3c0a03647d6 | 926 | 46 | from packaging import version  from transformers import AutoTokenizer, GPT2Config from transformers.modeling_utils import WEIGHTS_INDEX_NAME, WEIGHTS_NAME from transformers.utils import check_torch_lo |
| .venv/lib/python3.13/site-packages/transformers/models/trocr/configuration_trocr.py | 9a6f203b515a80e33b3a943d4bb4d9f54acd73ba2bd3cd72999cfeab7bacb37b | 147 | 25 | class TrOCRConfig(PretrainedConfig):     r"""     This is the configuration class to store the configuration of a [`TrOCRForCausalLM`]. It is used to instantiate an     TrOCR model according to the sp |
| .venv/lib/python3.13/site-packages/transformers/models/trocr/modeling_trocr.py | 5b7458314291234e71b15ac777595df66839a21b8aa74496bc29692707ab3b5b | 865 | 68 | ) from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPastAndCrossAttentions, CausalLMOutputWithCrossAttentions from ...modeling_utils import P |
| .venv/lib/python3.13/site-packages/transformers/models/hunyuan_v1_dense/modeling_hunyuan_v1_dense.py | 37f7f2b3168f089a14c0253a2878813311f3feeb92aa04c3a7d9209dab3bba1d | 515 | 27 | from ...masking_utils import create_causal_mask from ...modeling_layers import GenericForSequenceClassification, GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, Cau |
| .venv/lib/python3.13/site-packages/transformers/models/hunyuan_v1_dense/configuration_hunyuan_v1_dense.py | c5fc1e1a5ebe3dc609f7de9581b2339cec509f8070ac5bd0f61c6bb49a4d2d63 | 190 | 12 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/hunyuan_v1_dense/modular_hunyuan_v1_dense.py | 3cc97fe5fce2340c4ae23ca4ad194d07189048e591a9db2f31f9a5e40c21e0ca | 195 | 10 |     LlamaAttention,     LlamaDecoderLayer,     LlamaForCausalLM,     LlamaForSequenceClassification,     LlamaMLP, |
| .venv/lib/python3.13/site-packages/transformers/models/efficientloftr/modeling_efficientloftr.py | 9afa8d66065bffaa171869baf1154e492aa69fc31824ceba5edb38f14b76e08b | 1326 | 23 |  @compile_compatible_method_lru_cache(maxsize=32) def compute_embeddings(inv_freq: torch.Tensor, embed_height: int, embed_width: int, hidden_size: int) -> torch.Tensor:     i_indices = torch.ones(embe |
| .venv/lib/python3.13/site-packages/transformers/models/efficientloftr/configuration_efficientloftr.py | d77e625d8081c21f785f2aa42524852e8855359a1116d82b6bf75f4a5341950e | 200 | 5 |             The epsilon used by the batch normalization layers.         rope_theta (`float`, *optional*, defaults to 10000.0):             The base period of the RoPE embeddings.         partial_rotar |
| .venv/lib/python3.13/site-packages/transformers/models/xcodec/modeling_xcodec.py | 3360f3d04eaf83c083cd48154858acd58f93ef8f408da83afe29003a92c95b95 | 562 | 15 |      def decode(self, embed_ind):         quantized = F.embedding(embed_ind, self.embed)         return quantized  |
| .venv/lib/python3.13/site-packages/transformers/models/xcodec/configuration_xcodec.py | f15feefa9e49bf19e9bc7d5a8d3d0617991be5887f14facff6dc9d12eb1f1ea4 | 187 | 1 |             Number of entries in each residual quantizer's codebook.         codebook_dim (`int`, *optional*):             Dimensionality of each codebook vector. Defaults to sum of hidden size of aco |
| .venv/lib/python3.13/site-packages/transformers/models/smolvlm/modeling_smolvlm.py | b81038070b5a489728ff38e2775e77c9bdbe2f4fa82bca47c88385f9b4b92bda | 1029 | 53 |             if module.bias is not None:                 module.bias.data.zero_()         elif isinstance(module, nn.Embedding):             module.weight.data.normal_(mean=0.0, std=std)             if |
| .venv/lib/python3.13/site-packages/transformers/models/smolvlm/image_processing_smolvlm.py | cb6990fe3e41560301c8e0eaf31e1e424c5dd9ef0f12992f53f1e95b4fcdfb20 | 897 | 1 |                     frames.append(cropped_image)              # For the global image at the end, we resize it to match the max_image_size, for cpu memory efficiency             global_image_height, gl |
| .venv/lib/python3.13/site-packages/transformers/models/smolvlm/modular_smolvlm.py | ceadf93800d5e050c424f1bc2f3d5115e3fb19f461e58d851cdb386160b7418b | 411 | 6 |         image_token_id (`int`, *optional*, defaults to 128257):             The id of the "image" token.         tie_word_embeddings (`bool`, *optional*, defaults to `False`):             Whether or n |
| .venv/lib/python3.13/site-packages/transformers/models/smolvlm/image_processing_smolvlm_fast.py | cd3f2375e09cf87c2fc3d42c25f28c2c3c1fea80b192e3ff58a40b971e9c1624 | 537 | 1 |             )  # batch_size x n_frames x num_channels x height x width              # For the global image at the end, we resize it to match the max_image_size, for cpu memory efficiency             g |
| .venv/lib/python3.13/site-packages/transformers/models/smolvlm/configuration_smolvlm.py | e171e43fa6871de04e18ea0b367f3b02e029e5cb1f6295a8f10296f13adab982 | 197 | 9 |         image_token_id (`int`, *optional*, defaults to 128257):             The id of the "image" token.         tie_word_embeddings (`bool`, *optional*, defaults to `False`):             Whether or n |
| .venv/lib/python3.13/site-packages/transformers/models/unispeech/configuration_unispeech.py | 4c7713bd934e56c0f2a159220d9e64286bb986636ed2a33695a97e3fe58f0e8b | 310 | 44 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the  |
| .venv/lib/python3.13/site-packages/transformers/models/unispeech/modular_unispeech.py | 03bb436a8f4ad903d1772ed6a4b18a24b5a6605c69a7d7f87aa03390216fb5d1 | 446 | 57 |     Wav2Vec2ForCTC,     Wav2Vec2ForSequenceClassification,     Wav2Vec2GumbelVectorQuantizer,     Wav2Vec2Model,     Wav2Vec2PositionalConvEmbedding, |
| .venv/lib/python3.13/site-packages/transformers/models/unispeech/modeling_unispeech.py | f29650dc75f37175f3829f07a639339e258a29f1110a61870ed4298c88bb84e5 | 1519 | 83 | from ...modeling_outputs import (     BaseModelOutput,     CausalLMOutput,     ModelOutput,     SequenceClassifierOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/idefics2/configuration_idefics2.py | 4d4a4583ef5667f2125987ca5e55574f7679a13874831438058fb87db1dc45fd | 269 | 11 |             The epsilon used by the rms normalization layers.         resampler_n_latents (`int`, *optional*, defaults to 64):             Number of latent embeddings to resample ("compress") the inpu |
| .venv/lib/python3.13/site-packages/transformers/models/idefics2/modeling_idefics2.py | f195a0a5fbf469d2394ef1f6798d63359942ed0b6a07418b8e5787872a15df63 | 1307 | 55 |         input) to speed up sequential decoding.     image_hidden_states (`tuple(torch.FloatTensor)`, *optional*):         Tuple of `torch.FloatTensor` (one for the output of the image embeddings, `(ba |
| .venv/lib/python3.13/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py | 04bb87a21a0f918d7c2e09220a430f689977e2a68687b003768db100c6b0a2f5 | 1523 | 113 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/xlm_roberta_xl/configuration_xlm_roberta_xl.py | 7fc730f77f319f356b34c640f42e80d302109bf9a6b54afa10c40081a98df52c | 154 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/llava_next/processing_llava_next.py | dcee9ddb4bc47d452987bc029076f6429908b7013857efc72ba44a6d17aef7b4 | 267 | 1 |             Special token used to denote image location.         num_additional_image_tokens (`int`, *optional*, defaults to 0):             Number of additional tokens added to the image embeddings,  |
| .venv/lib/python3.13/site-packages/transformers/models/llava_next/modeling_llava_next.py | 87ab7bc53a7120d05c8160191cb3f91a54e63930d7cdd71ab0f008b21a94ef90 | 798 | 21 |     """ ) class LlavaNextCausalLMOutputWithPast(ModelOutput):     r"""     loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided): |
| .venv/lib/python3.13/site-packages/transformers/models/llava_next/image_processing_llava_next.py | 3387ce9337b16aa993b5365a9109f90b5707dfd2d3a444c14283aaa783f011c3 | 726 | 3 |                 The padding mode to use. Can be one of:                     - `"constant"`: pads with a constant value.                     - `"reflect"`: pads with the reflection of the vector mirror |
| .venv/lib/python3.13/site-packages/transformers/models/llava_next/configuration_llava_next.py | f0bbe78e60e02ac351becae5a99464376350b2e1d95e43e6128f87fbc3f39142 | 151 | 6 |             A list of possible resolutions to use for processing high resolution images. Each item in the list should be a tuple or list             of the form `(height, width)`.         tie_word_emb |
| .venv/lib/python3.13/site-packages/transformers/models/seed_oss/modeling_seed_oss.py | d4746e78a8b1d296cd2f17598e6fdab1c4121fcc9631830445e9019d6418c4f7 | 514 | 24 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/seed_oss/modular_seed_oss.py | 91a3c44960ab9355448cc7eccba0686510eefc9395b395b0911661e2090fc0c0 | 207 | 10 | from ...activations import ACT2FN from ...cache_utils import Cache from ...modeling_outputs import CausalLMOutputWithPast from ...modeling_utils import ALL_ATTENTION_FUNCTIONS from ...processing_utils |
| .venv/lib/python3.13/site-packages/transformers/models/seed_oss/configuration_seed_oss.py | 57f5e3b9a3ab4d4ee1c8032faec01083e56f9a6ddec46afe217f6e3e010b747d | 225 | 18 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/altclip/configuration_altclip.py | 52c6f6f445a3a5db590135be8f167c5419a6b39ec7dafe14b681ad43f9af601e | 373 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/altclip/modeling_altclip.py | 5166c26636dff48f6f6cfb1098ccbef43432860ac971216322583df6b792f6ab | 1415 | 128 |         similarity scores.     text_embeds (`torch.FloatTensor` of shape `(batch_size, output_dim`):         The text embeddings obtained by applying the projection layer to the pooled output of [`Alt |
| .venv/lib/python3.13/site-packages/transformers/models/imagegpt/image_processing_imagegpt.py | 63fc24ee1cf7130e8c99d4427acacfbbae1c5b6558217dc3ca16fc0866e87224 | 305 | 5 | # See the License for the specific language governing permissions and # limitations under the License. """Image processor class for ImageGPT."""  from typing import Optional, Union |
| .venv/lib/python3.13/site-packages/transformers/models/imagegpt/feature_extraction_imagegpt.py | b14ec768747d6c68731d82ee4439ef7074429f19491e47d3548b50627ed94b91 | 39 | 8 | # See the License for the specific language governing permissions and # limitations under the License. """Feature extractor class for ImageGPT."""  import warnings |
| .venv/lib/python3.13/site-packages/transformers/models/imagegpt/__init__.py | 5f1c08e14695cb2bd3706b89406aeebcb8be7471e5f0c74ebe102e9b7157686a | 30 | 4 |  if TYPE_CHECKING:     from .configuration_imagegpt import *     from .feature_extraction_imagegpt import *     from .image_processing_imagegpt import * |
| .venv/lib/python3.13/site-packages/transformers/models/imagegpt/configuration_imagegpt.py | 6e9e88e36b213595283e6c294ce5848b2507dfe510903ccaec09122e0b0c642a | 201 | 29 | # See the License for the specific language governing permissions and # limitations under the License. """OpenAI ImageGPT configuration"""  from collections import OrderedDict |
| .venv/lib/python3.13/site-packages/transformers/models/imagegpt/modeling_imagegpt.py | 2b52be455cc761ea7b8f48029ab286b36b60058cae3d7228a3757f89c3391d75 | 1044 | 77 | # See the License for the specific language governing permissions and # limitations under the License. """PyTorch OpenAI ImageGPT model."""  import math |
| .venv/lib/python3.13/site-packages/transformers/models/dia/modular_dia.py | 9170d5248147ddc286e46012c244bebc0f9a1ef65240f21475bc13921ea577ba | 774 | 40 |     LlamaAttention,     LlamaRMSNorm,     LlamaRotaryEmbedding,     eager_attention_forward, ) |
| .venv/lib/python3.13/site-packages/transformers/models/dia/configuration_dia.py | 1ba06735fe79dfa812b2684b209728dc432e96fd2d93bbbcf550d02e4169dc7c | 377 | 26 |      Args:         max_position_embeddings (`int`, *optional*, defaults to 1024):             The maximum sequence length that this model might ever be used with.         num_hidden_layers (`int`, *op |
| .venv/lib/python3.13/site-packages/transformers/models/dia/modeling_dia.py | d7dab604c0e2ab9745d930fea77819c2ad0b2bc6965badf93dbf4a327c7d5f5c | 959 | 46 |   class DiaMultiChannelEmbedding(nn.Module):     """In order to efficiently compute the audio embedding from the 9 different channels,     we vectorize the embedding process by using a single embeddin |
| .venv/lib/python3.13/site-packages/transformers/models/dia/generation_dia.py | 74cf1847d41bf68a81bf46b4da3d4c80446fc761ea0fa08ea320cb8858a94885 | 465 | 1 |          # If the model supports `logits_to_keep` in forward(), set it to 1 to avoid computing the whole         # logit matrix. This can save a lot of memory during the first forward pass. Note that  |
| .venv/lib/python3.13/site-packages/transformers/models/splinter/modeling_splinter.py | 74c25884735bb859935b37b92bf4133b635cf2b33c3df6180e480b1f722f9390 | 864 | 50 |   class SplinterEmbeddings(nn.Module):     """Construct the embeddings from word, position and token_type embeddings."""  |
| .venv/lib/python3.13/site-packages/transformers/models/splinter/configuration_splinter.py | 65a8d93d7e9ff4aee006aa763db3ad98983efdf014f21ef6b4a753363c905743 | 124 | 5 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/longformer/configuration_longformer.py | d80c1cc4f027089c3909b09d8135e77580539494d68b84330e78a5806ffadd3d | 208 | 5 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/longformer/modeling_longformer.py | aa78c91381fe379272e3398dc738aa0560b135ee1e0114f25990c88c7666ac00 | 2224 | 102 |   class LongformerEmbeddings(nn.Module):     """     Same as BertEmbeddings with a tiny tweak for positional embeddings indexing. |
| .venv/lib/python3.13/site-packages/transformers/models/longformer/modeling_tf_longformer.py | bbe9f6356e443c1ed404cc88156779266fecb693bb3bd9e557be101cd06cfb81 | 2784 | 127 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     ModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/longformer/tokenization_longformer_fast.py | 1a0f33be3af4330aa2e1a1eea4964bca40a296a13b8de5d11176cca39f738aa4 | 266 | 1 | class LongformerTokenizerFast(PreTrainedTokenizerFast):     """     Construct a "fast" Longformer tokenizer (backed by HuggingFace's *tokenizers* library), derived from the GPT-2     tokenizer, using  |
| .venv/lib/python3.13/site-packages/transformers/models/longformer/tokenization_longformer.py | 70af247ba70b7cc4565e55f0ffc1698d32332e86818b7898ecc81fe1bacc46ef | 403 | 1 | class LongformerTokenizer(PreTrainedTokenizer):     """     Constructs a Longformer tokenizer, derived from the GPT-2 tokenizer, using byte-level Byte-Pair-Encoding.      This tokenizer has been train |
| .venv/lib/python3.13/site-packages/transformers/models/yolos/modeling_yolos.py | 8c679ee317d5285698d7c41e7ee4ee8df5100da2eebfab864d64c06d096475e0 | 706 | 46 |   class YolosEmbeddings(nn.Module):     """     Construct the CLS token, detection tokens, position and patch embeddings. |
| .venv/lib/python3.13/site-packages/transformers/models/yolos/configuration_yolos.py | dcca2c59c34e5204c9d694c1902413f39d9fb272031e8988493c824a138aa369 | 179 | 5 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/yolos/image_processing_yolos.py | a99d08008fb36cb345b786ccf753a67987eeaf2f46c4581a36d76dd79719c871 | 1538 | 4 |      # Keep track of instances of each class     stuff_memory_list: dict[str, int] = {}     for k in range(pred_labels.shape[0]):         pred_class = pred_labels[k].item() |
| .venv/lib/python3.13/site-packages/transformers/models/opt/configuration_opt.py | 9c41cdee70428218c27dc53fbee7a84cbe537c231ce89504e9c507ea49e19f13 | 147 | 6 |             The non-linear activation function (function or string) in the encoder and pooler. If string, `"gelu"`,             `"relu"`, `"silu"` and `"gelu_new"` are supported.         max_position_ |
| .venv/lib/python3.13/site-packages/transformers/models/opt/modeling_tf_opt.py | 819f311c021a643626b2f1dbc4d23ae884c1d1021a62861d6cb17bb8d56e4c48 | 1093 | 46 |  from ...activations_tf import get_tf_activation from ...modeling_tf_outputs import TFBaseModelOutputWithPast, TFCausalLMOutputWithPast  # Public API |
| .venv/lib/python3.13/site-packages/transformers/models/opt/modeling_flax_opt.py | 6b538220d1d54e3fa8b23b895317d86604d2fb58fbafa10f4fe4e0003f653fbe | 803 | 31 | OPT_START_DOCSTRING = r"""     This model inherits from [`FlaxPreTrainedModel`]. Check the superclass documentation for the generic methods the     library implements for all its model (such as downlo |
| .venv/lib/python3.13/site-packages/transformers/models/opt/modeling_opt.py | e53d60ba9b5d8d41a83c0f56dfcbb08bd767633549a5ada60f7c84cc7d21a080 | 1111 | 41 | from ...modeling_outputs import (     BaseModelOutputWithPast,     CausalLMOutputWithPast,     QuestionAnsweringModelOutput,     SequenceClassifierOutputWithPast, |
| .venv/lib/python3.13/site-packages/transformers/models/nystromformer/modeling_nystromformer.py | 4809fc18b2a342e751357c4176d8063846f84c67e810db3cd7016a5e3bd6bcb9 | 1019 | 62 |   class NystromformerEmbeddings(nn.Module):     """Construct the embeddings from word, position and token_type embeddings."""  |
| .venv/lib/python3.13/site-packages/transformers/models/nystromformer/configuration_nystromformer.py | 5322e63c5da58b7fc00d3cfdb52d61e6de020d8e5de46cec7de0bd846e364732 | 133 | 5 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/decision_transformer/modeling_decision_transformer.py | 9d13fa8bdf8c9f1fdf4285e89adf96c92f8d74395a027060deb9ef109025fe5c | 945 | 78 |   # Copied from transformers.models.gpt2.modeling_gpt2.load_tf_weights_in_gpt2 def load_tf_weights_in_gpt2(model, config, gpt2_checkpoint_path):     """Load tf checkpoints in a pytorch model""" |
| .venv/lib/python3.13/site-packages/transformers/models/decision_transformer/configuration_decision_transformer.py | 84a38e6ff4ee3345d4edf0d0bbdb25da8ea235862dd7a0e597725408a79c141e | 158 | 5 |     instantiate a Decision Transformer model according to the specified arguments, defining the model architecture.     Instantiating a configuration with the defaults will yield a similar configurati |
| .venv/lib/python3.13/site-packages/transformers/models/beit/modeling_beit.py | 60b423d355bcaf9cd4c84710271c7c87071c9fc7c1f32e9cd5be71b6e93f0e41 | 1567 | 69 | # Based on timm implementation, which can be found here: # https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py class BeitEmbeddings(nn.Module):     """      |
| .venv/lib/python3.13/site-packages/transformers/models/beit/modeling_flax_beit.py | 83a43040e05d61de6485e588cda3bb5e9a24e0c14f256c2da29a23563e632df5 | 957 | 39 |             will be returned.         hidden_states (`tuple(jnp.ndarray)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):             Tupl |
| .venv/lib/python3.13/site-packages/transformers/models/beit/configuration_beit.py | cd3f5a72da53f84fa9ff92cb6fa683bd833cc4296fbb6a5d74958aeb09487e05 | 230 | 8 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/bamba/modular_bamba.py | c4cfce9d41a40baeef6b81512a39bbb1d6073187b7200216022a8acf83675c0d | 1220 | 35 | # Copyright 2024 IBM and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It has been |
| .venv/lib/python3.13/site-packages/transformers/models/bamba/configuration_bamba.py | ce8fb0bd7e70cfcc167a97492f04279b6cb265da47c7494cb04f3942e7fc4581 | 211 | 15 |             Vocabulary size of the Bamba model. Defines the number of different tokens that can be represented by the             `inputs_ids` passed when calling [`BambaModel`]         tie_word_embed |
| .venv/lib/python3.13/site-packages/transformers/models/bamba/modeling_bamba.py | afab3d6d4e49adfec636e68cd631fc6b5b4a5e7dd775de931e78ef710762729e | 1501 | 35 | # Copyright 2024 IBM and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It has been |
| .venv/lib/python3.13/site-packages/transformers/models/x_clip/modeling_x_clip.py | e469e18ad8e53e9ef6df08f946e258cc770e79df36cf451cfde4960c0e5e8c5b | 1548 | 82 |         similarity scores.     text_embeds (`torch.FloatTensor` of shape `(batch_size, output_dim`):         The text embeddings obtained by applying the projection layer to the pooled output of [`XCL |
| .venv/lib/python3.13/site-packages/transformers/models/x_clip/configuration_x_clip.py | b376865ef7b08692f99eb639ee3f4a8a1b86658658eb6c652570a6b49d406238 | 370 | 4 |         num_attention_heads (`int`, *optional*, defaults to 8):             Number of attention heads for each attention layer in the Transformer encoder.         max_position_embeddings (`int`, *opti |
| .venv/lib/python3.13/site-packages/transformers/models/cvt/modeling_tf_cvt.py | 732b414cca9c50cbf209b26712d658ddab6de8b92826a0e500dfa25fcb9cc804 | 1096 | 23 |             Classification token at the output of the last layer of the model.         hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `confi |
| .venv/lib/python3.13/site-packages/transformers/models/cvt/configuration_cvt.py | cd55f41edebd3879bcb6d9db0186f3c6d57490d0ca57faa96d20f04e8a8930a2 | 147 | 4 |             The number of input channels.         patch_sizes (`list[int]`, *optional*, defaults to `[7, 3, 3]`):             The kernel size of each encoder's patch embedding.         patch_stride (` |
| .venv/lib/python3.13/site-packages/transformers/models/cvt/modeling_cvt.py | fa03ef61893c3407e13e22c40957f5cabcd8d05bfd96a09dfccc798fc3c5bd1a | 672 | 10 |   class CvtEmbeddings(nn.Module):     """     Construct the CvT embeddings. |
| .venv/lib/python3.13/site-packages/transformers/models/depth_anything/modeling_depth_anything.py | caed665924cc58639f5e09171738c69f4e2ff98c26e1e6211eb92bd7bf7ba109 | 429 | 2 |      This happens in 3 stages:     1. Take the patch embeddings and reshape them to image-like feature representations.     2. Project the channel dimension of the hidden states according to `config.n |
| .venv/lib/python3.13/site-packages/transformers/models/siglip2/modular_siglip2.py | a50256c951d3ca201be3fc23a33e8abc4a54f3f662642d2303cb0f7beaf827a7 | 638 | 53 |   class Siglip2VisionEmbeddings(nn.Module):     def __init__(self, config: Siglip2VisionConfig):         super().__init__() |
| .venv/lib/python3.13/site-packages/transformers/models/siglip2/configuration_siglip2.py | cecd33a99f53a20f62c0b2bac8437aa5e244ad8087379374881075d4ba741690 | 266 | 4 |         num_attention_heads (`int`, *optional*, defaults to 12):             Number of attention heads for each attention layer in the Transformer encoder.         max_position_embeddings (`int`, *opt |
| .venv/lib/python3.13/site-packages/transformers/models/siglip2/modeling_siglip2.py | 8e67f2be7027c4f60ffb231b6a92dbb552f8928a195e99d614d183e942dc3d67 | 1304 | 100 | @auto_docstring(     custom_intro="""     Base class for vision model's outputs that also contains image embeddings of the pooling of the last hidden states.     """ ) |
| .venv/lib/python3.13/site-packages/transformers/models/roberta/tokenization_roberta.py | 16d29ac791790a0e2e251eda5aceb697d4e9d2e0dc54b5b675929fad87daaeb8 | 403 | 1 | class RobertaTokenizer(PreTrainedTokenizer):     """     Constructs a RoBERTa tokenizer, derived from the GPT-2 tokenizer, using byte-level Byte-Pair-Encoding.      This tokenizer has been trained to  |
| .venv/lib/python3.13/site-packages/transformers/models/roberta/modeling_tf_roberta.py | e7076860ed1a6837dde6eea2c0462348bba1a7732d8bc8ce0e1f4e75759142dd | 1783 | 66 |     TFBaseModelOutputWithPastAndCrossAttentions,     TFBaseModelOutputWithPoolingAndCrossAttentions,     TFCausalLMOutputWithCrossAttentions,     TFMaskedLMOutput,     TFMultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/roberta/modeling_flax_roberta.py | 856ed3c6e8106a69833a92c24d95b75f74e3709bb2f35008743ced39cc73b3e0 | 1501 | 56 |     FlaxBaseModelOutputWithPooling,     FlaxBaseModelOutputWithPoolingAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxMaskedLMOutput,     FlaxMultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/roberta/configuration_roberta.py | 0584e37f5968d0c93dc58a998cd1ec6529713c6ef324f70597cb6dafa2caf04c | 156 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/roberta/modeling_roberta.py | 27813e44b38ff4ea7b78021e7f252cfccc3e6929ade72429fcd2d98acab231ad | 1562 | 108 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/roberta/tokenization_roberta_fast.py | 2587b696666e814dc9ecf10a9ff49e81a15445200f2d47a333a7241ff4aa5a66 | 265 | 1 | class RobertaTokenizerFast(PreTrainedTokenizerFast):     """     Construct a "fast" RoBERTa tokenizer (backed by HuggingFace's *tokenizers* library), derived from the GPT-2     tokenizer, using byte-l |
| .venv/lib/python3.13/site-packages/transformers/models/vitdet/configuration_vitdet.py | 08cd7c9151668230c4a7b95e40f1b42fad1528d98179b9b162f10664de0abe58 | 157 | 13 |             Number of attention heads for each attention layer in the Transformer encoder.         mlp_ratio (`int`, *optional*, defaults to 4):             Ratio of mlp hidden dim to embedding dim.   |
| .venv/lib/python3.13/site-packages/transformers/models/vitdet/modeling_vitdet.py | b46265e7fe412753fc3643240c689c439303a075947478c347651f0622e65af4 | 821 | 73 |   class VitDetEmbeddings(nn.Module):     """     This class turns `pixel_values` of shape `(batch_size, num_channels, height, width)` into the initial |
| .venv/lib/python3.13/site-packages/transformers/models/prompt_depth_anything/modeling_prompt_depth_anything.py | 929236332237d85faf237238d7643290e5df34824705aaa9549d77bae6da68e8 | 496 | 2 |      This happens in 3 stages:     1. Take the patch embeddings and reshape them to image-like feature representations.     2. Project the channel dimension of the hidden states according to `config.n |
| .venv/lib/python3.13/site-packages/transformers/models/tvp/modeling_tvp.py | 7695bb3d4966c9154393c69dc0c97a0c8c3e46041c38c2e7ffce4a99bcb899d7 | 925 | 109 |   class TvpVisualInputEmbedding(nn.Module):     """     Takes input of both image and video (multi-frame) |
| .venv/lib/python3.13/site-packages/transformers/models/tvp/configuration_tvp.py | 0e982b3ea6067e303a39236487952c7642f0f1158517aaa1f7466bcfa53da67e | 210 | 12 |         num_attention_heads (`int`, *optional*, defaults to 12):             Number of attention heads for each attention layer in the Transformer encoder.         max_position_embeddings (`int`, *opt |
| .venv/lib/python3.13/site-packages/transformers/models/aya_vision/modular_aya_vision.py | aac5a36e8e66ef16ffb3167532f9c15d64e0e3bcd50d5cdc9f135ab8bc1cae66 | 307 | 6 |  from transformers.models.llava.modeling_llava import (     LlavaCausalLMOutputWithPast,     LlavaForConditionalGeneration,     LlavaModel, |
| .venv/lib/python3.13/site-packages/transformers/models/aya_vision/modeling_aya_vision.py | e1a7b8681c707833b11482523e144362d361b381ba4ea7e17f0b8edb524b1cf6 | 535 | 15 |     """ ) class AyaVisionCausalLMOutputWithPast(ModelOutput):     r"""     loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided): |
| .venv/lib/python3.13/site-packages/transformers/models/audio_spectrogram_transformer/configuration_audio_spectrogram_transformer.py | 1c084bba09ff13a023af7fb79f7aa8846e627c03ea35f4aeb9c4340764bbb423 | 132 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py | c04a18386f6e087495a4333ddbd95579ec4ca3fcca176eea6bc0434085fb7da5 | 483 | 31 |   class ASTEmbeddings(nn.Module):     """     Construct the CLS token, position and patch embeddings. |
| .venv/lib/python3.13/site-packages/transformers/models/fuyu/processing_fuyu.py | 7c0637ce9a6e3958732e31990da6413dc4f97fb730169e361a9ce12434af09ee | 794 | 11 |     scale_factors: Optional[list[list["torch.Tensor"]]],     max_tokens_to_generate: int,     max_position_embeddings: int,     add_BOS: bool,  # Same issue with types as above     add_beginning_of_an |
| .venv/lib/python3.13/site-packages/transformers/models/fuyu/image_processing_fuyu.py | 5a2b77c411c9548d7ea6ab1d5c7ab11dad64bfc2e545a3f80c1aefb69f19f5ed | 725 | 1 | class FuyuImageProcessor(BaseImageProcessor):     """     This class should handle the image processing part before the main FuyuForCausalLM. In particular, it should     handle:  |
| .venv/lib/python3.13/site-packages/transformers/models/fuyu/configuration_fuyu.py | ee381d3378e7cf2f99f886468f1dd580086e4b9fdb9c46bb1483bccba9154dac | 216 | 20 | class FuyuConfig(PretrainedConfig):     r"""     This is the configuration class to store the configuration of a [`FuyuForCausalLM`]. It is used to instantiate an     Fuyu model according to the speci |
| .venv/lib/python3.13/site-packages/transformers/models/fuyu/modeling_fuyu.py | 69d92fb61b8938811849e56b6a6eb4cc164b9beb681d4c0c53e6876ae9d5bb1c | 407 | 60 | from ...cache_utils import Cache from ...generation import GenerationMixin from ...modeling_outputs import CausalLMOutputWithPast from ...modeling_utils import PreTrainedModel from ...models.auto.mode |
| .venv/lib/python3.13/site-packages/transformers/models/gptj/modeling_gptj.py | fa36a3b1f0d1740b75b641316bb015779686616c6aa84e8a49dd4d588358dc94 | 1239 | 83 | # See the License for the specific language governing permissions and # limitations under the License. """PyTorch GPT-J model."""  import warnings |
| .venv/lib/python3.13/site-packages/transformers/models/gptj/__init__.py | ae014325cb3172ad72b65ec14d9b61afbb1299ac6a82049bbeb22c7b272613eb | 30 | 4 |  if TYPE_CHECKING:     from .configuration_gptj import *     from .modeling_flax_gptj import *     from .modeling_gptj import * |
| .venv/lib/python3.13/site-packages/transformers/models/gptj/modeling_tf_gptj.py | 4472c747ae494801fd202f91a776545592859097da84d259ce55705bef873311 | 1095 | 76 | # See the License for the specific language governing permissions and # limitations under the License. """TF 2.0 GPT-J model."""  from __future__ import annotations |
| .venv/lib/python3.13/site-packages/transformers/models/gptj/configuration_gptj.py | c09536a33d8b62e95ea29404cc0daca106ae1f069eec98a70b1262fe11b3d983 | 221 | 30 | # See the License for the specific language governing permissions and # limitations under the License. """GPT-J model configuration"""  from collections import OrderedDict |
| .venv/lib/python3.13/site-packages/transformers/models/gptj/modeling_flax_gptj.py | ce87789506448bf1fcb32e336ed99bd869f99848854a63d98d86df7e9ced5fff | 722 | 69 | from jax import lax  from ...modeling_flax_outputs import FlaxBaseModelOutput, FlaxCausalLMOutput from ...modeling_flax_utils import ACT2FN, FlaxPreTrainedModel, append_call_sample_docstring from ...u |
| .venv/lib/python3.13/site-packages/transformers/models/distilbert/configuration_distilbert.py | 876ac1287fdafda11d443a3ee4910701b57051fd7ee92cbac693518dd2ef8671 | 142 | 6 |             Vocabulary size of the DistilBERT model. Defines the number of different tokens that can be represented by             the `inputs_ids` passed when calling [`DistilBertModel`] or [`TFDisti |
| .venv/lib/python3.13/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py | b4e5fa5c6731257732de53eeac4debd294635f45384cc584c5bf8441b15ce1e0 | 1147 | 52 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     add_code_sample_docstrings, |
| .venv/lib/python3.13/site-packages/transformers/models/distilbert/modeling_distilbert.py | 6eccfb49b710e6752b836a6a602ef0db21ad9ba85ca319c6f83c3086986090eb | 1290 | 203 |   def create_sinusoidal_embeddings(n_pos: int, dim: int, out: torch.Tensor):     if is_deepspeed_zero3_enabled():         import deepspeed |
| .venv/lib/python3.13/site-packages/transformers/models/distilbert/modeling_flax_distilbert.py | 5348c7ee77a12f5bc4b7580f4c3c00f3cdabf1ead3e8e97f4273a182fee8c2ba | 907 | 24 |     - [Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)     - [Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#autom |
| .venv/lib/python3.13/site-packages/transformers/models/dac/configuration_dac.py | 1317f46e1ce6b04bf12f14894cea5d8cf2fa3dcdf4487296d4c676dda55db753 | 115 | 1 |             Number of discrete codes in each codebook.         codebook_dim (`int`, *optional*, defaults to 8):             Dimension of the codebook vectors. If not defined, uses `encoder_hidden_size |
| .venv/lib/python3.13/site-packages/transformers/models/dac/modeling_dac.py | c60ebd79370855ad168e9a0092360ef104ef7b06c9f82700e41024ccb8bce427 | 685 | 12 |   class DacVectorQuantize(nn.Module):     """     Implementation of VQ similar to Karpathy's repo (https://github.com/karpathy/deep-vector-quantization) |
| .venv/lib/python3.13/site-packages/transformers/models/encodec/modeling_encodec.py | 8660f29a91641d3809095940cde405cfe7bdd008127fc685f6003e39ebab5326 | 814 | 17 |     r"""     audio_codes (`torch.LongTensor`  of shape `(nb_frames, batch_size, nb_quantizers, frame_len)`, *optional*):         Discrete code embeddings computed using `model.encode`.     audio_value |
| .venv/lib/python3.13/site-packages/transformers/models/encodec/configuration_encodec.py | ca2d35ea799739d80cf4d812496256eab0c31e9cd320f249f201bd38764af37c | 200 | 1 |             Number of discret codes that make up VQVAE.         codebook_dim (`int`, *optional*):             Dimension of the codebook vectors. If not defined, uses `hidden_size`.         use_conv_sh |
| .venv/lib/python3.13/site-packages/transformers/models/glm4v_moe/configuration_glm4v_moe.py | 7d826e0989b1219d5569cc589c4d441ea2ad688218f5c112a0cd726200bacf26 | 386 | 21 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/glm4v_moe/modular_glm4v_moe.py | af515449365092e26df3486f4d63247982cf5d9247cf997aed6b6426655ebecd | 460 | 42 |     GLM-4.5V model according to the specified arguments, defining the model architecture. Instantiating a     configuration with the defaults will yield a similar configuration to that of     GLM-4.5V |
| .venv/lib/python3.13/site-packages/transformers/models/glm4v_moe/modeling_glm4v_moe.py | fb8261985d17e4529b0a32b0114806aaad4d4f0d193f5ff81f2c4fda9433a2e1 | 1769 | 137 |  def apply_multimodal_rotary_pos_emb(q, k, cos, sin, mrope_section, unsqueeze_dim=1):     """Applies Rotary Position Embedding with Multimodal Sections to the query and key tensors (https://qwenlm.git |
| .venv/lib/python3.13/site-packages/transformers/models/lightglue/modular_lightglue.py | 289190cecd0fc062e235b20b606f121bc96f92ff20d12c5224f5085201c86ce0 | 1075 | 10 |     ) -> Union[tuple[torch.Tensor], tuple[torch.Tensor, torch.Tensor]]:         projected_keypoints = self.projector(keypoints)         embeddings = projected_keypoints.repeat_interleave(2, dim=-1)    |
| .venv/lib/python3.13/site-packages/transformers/models/lightglue/modeling_lightglue.py | a080ad8331881aff878812e31b56ebe7e3bf76dadd203563648d71fa5d17ded9 | 917 | 14 |     ) -> Union[tuple[torch.Tensor], tuple[torch.Tensor, torch.Tensor]]:         projected_keypoints = self.projector(keypoints)         embeddings = projected_keypoints.repeat_interleave(2, dim=-1)    |
| .venv/lib/python3.13/site-packages/transformers/models/bridgetower/configuration_bridgetower.py | 12dad5b608e27a6be657e0a32679e5f7c05019ea46efb611614acad6532c3915 | 309 | 17 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/bridgetower/modeling_bridgetower.py | b66e679efe248cbda76dd1457653f9f234258f67c530c0dc2e868d29e62a6738 | 1876 | 143 |         Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).     text_embeds (`torch.FloatTensor)`, *optional*, returned when model is initialized with `w |
| .venv/lib/python3.13/site-packages/transformers/models/mt5/modeling_mt5.py | 7a34fd3be26ca34b4455e0b51c876cc4b5dfba75dbb8d1cdc8f214054c9642db | 2453 | 73 |     Args:         device_map (`dict[int, list]`, *optional*):             A dictionary that maps attention modules to devices. Note that the embedding module and LMHead are always             automati |
| .venv/lib/python3.13/site-packages/transformers/models/mt5/configuration_mt5.py | a174e6b55c57c798be4bbd1611c99a668fe42350942826b103b69ea2ce625fb9 | 183 | 3 |         use_cache=True,         tokenizer_class="T5Tokenizer",         tie_word_embeddings=False,         pad_token_id=0,         eos_token_id=1, |
| .venv/lib/python3.13/site-packages/transformers/models/deberta_v2/configuration_deberta_v2.py | f7a4ce3e96eb3525b67be32fb360f74be02e2b26fcaff90bb52b6fd13447feb6 | 200 | 10 |             are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddings, encoder, and pooler |
| .venv/lib/python3.13/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py | 98fa398f62e446e1f6303ff67fa7aceddac4f746a1a6013226896c3fa4e6cdd6 | 1379 | 140 |             self.max_relative_positions = getattr(config, "max_relative_positions", -1)             if self.max_relative_positions < 1:                 self.max_relative_positions = config.max_positio |
| .venv/lib/python3.13/site-packages/transformers/models/deberta_v2/modeling_tf_deberta_v2.py | dde24a0c6f064027035d228ef005a2901b0242e519cce382fad60ed63df268bd | 1880 | 118 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import add_code_sample_docstrings, add_start_docstrings, add_start_docstrings_to_m |
| .venv/lib/python3.13/site-packages/transformers/models/speecht5/feature_extraction_speecht5.py | 32a9e37cbd52ffe5429c984411681fbfd900629dbf9e53bd319f4eb6c112257d | 397 | 4 |             normed_input_values = []              for vector, length in zip(input_values, attention_mask.sum(-1)):                 normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:le |
| .venv/lib/python3.13/site-packages/transformers/models/speecht5/modeling_speecht5.py | 480a6606b130bbb0c1cb83ded15c5904d3fbcb2abfa736b7d1002a70a5432b7e | 3245 | 158 |     Seq2SeqSpectrogramOutput, ) from ...modeling_utils import EmbeddingAccessMixin, PreTrainedModel from ...utils import auto_docstring, logging from ...utils.deprecation import deprecate_kwarg |
| .venv/lib/python3.13/site-packages/transformers/models/speecht5/configuration_speecht5.py | aba4f05bf33ffeca5c803f4d38e6cd95c399b7cff1bcbe95e509b5c906754f52 | 423 | 37 |             The dropout probability for the text position encoding layers.         hidden_dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected la |
| .venv/lib/python3.13/site-packages/transformers/models/glm4_moe/modular_glm4_moe.py | f94122849b84ff0206f435fa457b860a8f0e6cb99b989986b44b0ad0cfc03ad2 | 331 | 24 | from ..deepseek_v3.modeling_deepseek_v3 import (     DeepseekV3DecoderLayer,     DeepseekV3ForCausalLM,     DeepseekV3MLP,     DeepseekV3Model, |
| .venv/lib/python3.13/site-packages/transformers/models/glm4_moe/modeling_glm4_moe.py | 6a89edd8180b7efef6b5df07ddc9d4a74d73a5c52eb445c7e86634fdca0eb42a | 617 | 27 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWith |
| .venv/lib/python3.13/site-packages/transformers/models/glm4_moe/configuration_glm4_moe.py | ba1354f75d286e28ad2f4fc80276cefd24f2eeeb88058feeba0b1c4f471a0091 | 243 | 18 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py | 8c8587466db875c4f0942731af20ad1248843411515c66bbfd94e42171d6c78c | 1620 | 119 | # Copyright 2024 The Qwen team, Alibaba Group and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in  |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_vl/configuration_qwen2_vl.py | 4baa8a6f2084d8240d733ba3ed733936eb686cb5897bb6cf94bbc5d7453f6322 | 326 | 20 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_vl/video_processing_qwen2_vl.py | 67181120f42dadb415f3ab5b2c50756703528f55e05ae753880cc5bd247ada34 | 335 | 4 | # Copyright 2025 The Qwen team, Alibaba Group and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in  |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_vl/processing_qwen2_vl.py | 6d17dd3726caaf29dafa6e4cf84452e32804152139a8cb4ce6e54a368669cfda | 256 | 5 | # Copyright 2024 The Qwen team, Alibaba Group and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in  |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_vl/image_processing_qwen2_vl_fast.py | a2caffa8b81f2a1af3c1f66a1c93c4b2fd7b323f2fa96e7a111e3fdcd4dbf0d0 | 316 | 5 | # Copyright 2025 The Qwen team, Alibaba Group and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in  |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_vl/image_processing_qwen2_vl.py | db944a4f65d66c6fe8c4defebc0cf689e2aad045dba9c5495a44fc62b1979c68 | 520 | 6 | # Copyright 2024 The Qwen team, Alibaba Group and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in  |
| .venv/lib/python3.13/site-packages/transformers/models/mm_grounding_dino/modular_mm_grounding_dino.py | 36377cb71f0c83a610c0e09735d349792403de386ae50b10b6cacc2dc3c2d872 | 435 | 28 | from ..grounding_dino.configuration_grounding_dino import GroundingDinoConfig from ..grounding_dino.modeling_grounding_dino import (     GroundingDinoContrastiveEmbedding,     GroundingDinoConvEncoder |
| .venv/lib/python3.13/site-packages/transformers/models/mm_grounding_dino/configuration_mm_grounding_dino.py | d6be997091cdc50748c462bf3d8b2f85f5d50264e13c856f2204842fdf53e0a1 | 304 | 17 |             Dimension of the layers.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.  |
| .venv/lib/python3.13/site-packages/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py | 40b4c388cae83cb379539b07031b6dff4ca983ef3b42dc62a008bc5731845392 | 2606 | 144 |   class MMGroundingDinoContrastiveEmbedding(nn.Module):     def __init__(self, config):         super().__init__() |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_sw3/tokenization_gpt_sw3.py | eb3e9877d78ba8580429bfd9e28c3c9053ae8595530f47a3adba1cf5a92d3487 | 302 | 11 | """The tokenizer used by the GPT-SW3 models."""  import os |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_sw3/__init__.py | fa0e96949e84861ac92820ac3dfefc720bc60fba16bdf796f460460695bac1c3 | 27 | 1 |  if TYPE_CHECKING:     from .tokenization_gpt_sw3 import * else:     import sys |
| .venv/lib/python3.13/site-packages/transformers/models/swiftformer/modeling_tf_swiftformer.py | 06d4ad672465a147285aede49bf4cb8a13f330f897039413f3c590b61b8c4bc4 | 867 | 18 |   class TFSwiftFormerPatchEmbeddingSequential(keras.layers.Layer):     """     The sequential component of the patch embedding layer. |
| .venv/lib/python3.13/site-packages/transformers/models/swiftformer/configuration_swiftformer.py | cdceae76e120771c1cfc0a4daec00316a192282d6a947fa471e1d2b945874022 | 149 | 1 |             Depth of each stage         embed_dims (`list[int]`, *optional*, defaults to `[48, 56, 112, 220]`):             The embedding dimension at each stage         mlp_ratio (`int`, *optional*,  |
| .venv/lib/python3.13/site-packages/transformers/models/swiftformer/modeling_swiftformer.py | d40c44553f3ea21d858740ae5807509bfa151028b5624b680f7dd777b7043664 | 545 | 10 |   class SwiftFormerPatchEmbedding(nn.Module):     """     Patch Embedding Layer constructed of two 2D convolutional layers. |
| .venv/lib/python3.13/site-packages/transformers/models/swinv2/configuration_swinv2.py | 9b6ca39e9ad95dcaad178765c36240bfc3168c1066ea4873b46cc2500a78ac7c | 160 | 9 |             The number of input channels.         embed_dim (`int`, *optional*, defaults to 96):             Dimensionality of patch embedding.         depths (`list(int)`, *optional*, defaults to `[2 |
| .venv/lib/python3.13/site-packages/transformers/models/swinv2/modeling_swinv2.py | 573b153459f0ba67b3f45c73161a700b5dd1e5ecc10dc96c449d7c7a23232bf2 | 1344 | 75 |   # drop_path, Swinv2PatchEmbeddings, Swinv2PatchMerging and Swinv2DropPath are from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/swin_transformer_v2.py.   |
| .venv/lib/python3.13/site-packages/transformers/models/regnet/modeling_regnet.py | 0cf36ac9116960e687ca438a0134e1452f75835d86f63c685bfc713b60b4d845 | 397 | 7 |   class RegNetEmbeddings(nn.Module):     """     RegNet Embeddings (stem) composed of a single aggressive convolution. |
| .venv/lib/python3.13/site-packages/transformers/models/regnet/configuration_regnet.py | 4e0620810898b2c1637178f32c87b964356b3313f8a909756699af6612e2d888 | 95 | 5 |         num_channels (`int`, *optional*, defaults to 3):             The number of input channels.         embedding_size (`int`, *optional*, defaults to 64):             Dimensionality (hidden size)  |
| .venv/lib/python3.13/site-packages/transformers/models/regnet/modeling_tf_regnet.py | 473cbedfa433aaed70469fea61901f123fb9b19c9c344816404db5d04046983f | 612 | 7 |   class TFRegNetEmbeddings(keras.layers.Layer):     """     RegNet Embeddings (stem) composed of a single aggressive convolution. |
| .venv/lib/python3.13/site-packages/transformers/models/regnet/modeling_flax_regnet.py | a2fe925f25ed9055f03520bdaae5ad7b5bcc97a01991e278f6196aa74975ef59 | 823 | 8 |     - [Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)     - [Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#autom |
| .venv/lib/python3.13/site-packages/transformers/models/pop2piano/modeling_pop2piano.py | 2ae3b43ec0e78f51691f11c2598ccc32b93ec51951487071ce31f03d8947cbac | 1331 | 50 |          if self.has_relative_attention_bias:             self.relative_attention_bias = nn.Embedding(self.relative_attention_num_buckets, self.n_heads)         self.pruned_heads = set()         self. |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_5_omni/configuration_qwen2_5_omni.py | 3d8ed4cfb8fa346bf88e8e8531d46442b09cd07f95c4d5eb984669c0468ffb15 | 1092 | 52 |             Dimensionality of the layers.         dropout (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in the embeddings, encoder, and poo |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py | 14bfa9067545859b384be236ea6f0655aef6f3926709b19b7099f379e6894583 | 4325 | 289 | from transformers.models.qwen2_audio.configuration_qwen2_audio import Qwen2AudioEncoderConfig from transformers.models.qwen2_audio.modeling_qwen2_audio import Qwen2AudioEncoderLayer from transformers. |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py | e945f5be233e595462d297548a88000e7912390f7b3b36c052e6a994cbd80889 | 4020 | 290 |             causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)             if attention_mask is not None:                 causal_mask = causal_mask.clone()  # copy to contiguous |
| .venv/lib/python3.13/site-packages/transformers/models/roberta_prelayernorm/modeling_tf_roberta_prelayernorm.py | 0afea3113685a159d80b8adb928e6593728bd7543b0ae58ca9a289942b9f36ab | 1808 | 66 |     TFBaseModelOutputWithPastAndCrossAttentions,     TFBaseModelOutputWithPoolingAndCrossAttentions,     TFCausalLMOutputWithCrossAttentions,     TFMaskedLMOutput,     TFMultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/roberta_prelayernorm/configuration_roberta_prelayernorm.py | 600c6a8c9993172b36f930b2a38f81f18d669be905d84c4eaa6c624b0e62e02e | 158 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/roberta_prelayernorm/modeling_roberta_prelayernorm.py | 2888cdce1006422dc7c45376e50fc13a30db596fdd9b6b7573435985df7f3712 | 1443 | 98 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/roberta_prelayernorm/modeling_flax_roberta_prelayernorm.py | 7d0cd65b6c7ee1f7c048fb39577b212b872dbddbe60652abaa605e3fa994b043 | 1528 | 58 |     FlaxBaseModelOutputWithPooling,     FlaxBaseModelOutputWithPoolingAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxMaskedLMOutput,     FlaxMultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/wav2vec2_bert/configuration_wav2vec2_bert.py | 5e9b1413e92f9388538b1acae6c6c2953f00e63e3a0375f0cc1730583b3913b8 | 314 | 52 |             `"relu"`, `"selu"`, `"swish"` and `"gelu_new"` are supported.         hidden_dropout (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected lay |
| .venv/lib/python3.13/site-packages/transformers/models/wav2vec2_bert/modular_wav2vec2_bert.py | 3f9693a23740516b06d1cf57a70c76fc0589fee34268cd7bf00755832025ddbb | 1071 | 78 | from ...modeling_outputs import (     BaseModelOutput,     CausalLMOutput,     SequenceClassifierOutput,     TokenClassifierOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/wav2vec2_bert/modeling_wav2vec2_bert.py | 12671e7e56f5e8e4243f38fda8e48b1eebc5bd8fe22b845c3ce1391d90c0934e | 1518 | 119 | from ...modeling_outputs import (     BaseModelOutput,     CausalLMOutput,     SequenceClassifierOutput,     TokenClassifierOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/levit/modeling_levit.py | 60b2b43407c685065f51628312eedd2c05f896edaa42fa3b6f8545cc414ebd43 | 678 | 44 |   class LevitConvEmbeddings(nn.Module):     """     LeViT Conv Embeddings with Batch Norm, used in the initial patch embedding layer. |
| .venv/lib/python3.13/site-packages/transformers/models/levit/configuration_levit.py | 50eb540dc64aea2e243ebb636200a85a966cc5fec0d414197998c26285e731e9 | 145 | 4 |             Number of channels in the input image.         kernel_size (`int`, *optional*, defaults to 3):             The kernel size for the initial convolution layers of patch embedding.         st |
| .venv/lib/python3.13/site-packages/transformers/models/patchtsmixer/modeling_patchtsmixer.py | 4dbe066567ca69713036dd7646be93359a789d0b015eafe5ce651f451e04c92f | 2121 | 15 |          Returns:             `torch.Tensor`: The embedding. `list`: List of all hidden states if `output_hidden_states` is set to             `True`.         """ |
| .venv/lib/python3.13/site-packages/transformers/models/patchtsmixer/configuration_patchtsmixer.py | 875c3e6110ff43d02041428146fcf18b6241116df935b0daa7cc6476e8be7375 | 236 | 1 |             Number of self-attention heads. Works only when `self_attn` is set to `True`.         use_positional_encoding (`bool`, *optional*, defaults to `False`):             Enable the use of posit |
| .venv/lib/python3.13/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py | 8a117d0e3aa1a0ea2379b0144e28f16d0b8b36cd2712a2418bdba6c91fa01e00 | 426 | 29 |         use_cache (`bool`, *optional*, defaults to `True`):             Whether or not the model should return the last key/values attentions (not used by all models).         max_position_embeddings  |
| .venv/lib/python3.13/site-packages/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py | 66e068b66c7d27845230c9a31aec31e9f6437d6291346887a520e2b170dfe861 | 4401 | 150 |     inputs_embeds (`torch.FloatTensor` of shape`(batch_size, sequence_length, hidden_size)`, *optional*):         Optionally, instead of passing `input_ids` you can choose to directly pass an embedded |
| .venv/lib/python3.13/site-packages/transformers/models/dinov2_with_registers/modular_dinov2_with_registers.py | a72bf17b4060b9b55651b45e8b6a7cd079afef11ed6a61be0d22b18593f999c7 | 437 | 51 |     Dinov2ForImageClassification,     Dinov2Model,     Dinov2PatchEmbeddings,     Dinov2PreTrainedModel, ) |
| .venv/lib/python3.13/site-packages/transformers/models/dinov2_with_registers/configuration_dinov2_with_registers.py | 26fda58704adde54af37c050ba1b0aeab996d482ad4aa9b8ba7e50b2f766e832 | 160 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/dinov2_with_registers/modeling_dinov2_with_registers.py | b31aad1f6223e37e423816ec7ddde0d757f21da7f78b82d82a5f8c8f9b9c3fe7 | 713 | 61 |   class Dinov2WithRegistersPatchEmbeddings(nn.Module):     """     This class turns `pixel_values` of shape `(batch_size, num_channels, height, width)` into the initial |
| .venv/lib/python3.13/site-packages/transformers/models/xlnet/modeling_xlnet.py | af3919455fc7487fa26372e09b099162446b8b3f2e3f698589df9ebac91818a1 | 2381 | 43 |         model = model.transformer      # Embeddings and output     tf_to_pt_map.update(         { |
| .venv/lib/python3.13/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py | 163906a339a1907eaa20f8503b5e550a40c93163958f6403eda091dcd6f5db04 | 1821 | 53 |     TFSequenceClassificationLoss,     TFSequenceSummary,     TFSharedEmbeddings,     TFTokenClassificationLoss,     get_initializer, |
| .venv/lib/python3.13/site-packages/transformers/models/xlnet/configuration_xlnet.py | 53f5a90a8a802eff3a71bbd35e04d59c9c0e7e5de7cdc19381925dffd48386f6 | 241 | 9 |             The epsilon used by the layer normalization layers.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embedd |
| .venv/lib/python3.13/site-packages/transformers/models/mpnet/configuration_mpnet.py | 0ec0a04d513a84319c695c5ddb2a843e3ecf87e24b1369cfcadd40265559931e | 117 | 5 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/mpnet/modeling_tf_mpnet.py | b488e046321e97aefaa2b4430182baa10d589cfb0f318eeb9420f470c05d73f6 | 1354 | 60 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     add_code_sample_docstrings, |
| .venv/lib/python3.13/site-packages/transformers/models/mpnet/modeling_mpnet.py | dd223b40b11102bb41a8dd2b45bb1331ab249ff1b29c8fbc57b0c64a7a1bf710 | 968 | 46 |             if module.bias is not None:                 module.bias.data.zero_()         elif isinstance(module, nn.Embedding):             module.weight.data.normal_(mean=0.0, std=self.config.initial |
| .venv/lib/python3.13/site-packages/transformers/models/ernie/configuration_ernie.py | ff5b21c918294d53104b6cfb9045bc145eeca65b950dcf9ace5746abc0a5af86 | 164 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/ernie/modeling_ernie.py | 459b68ab1700185416e88f4498400799e66107b7bb44e5fa0fb0badbc42f4c8c | 1690 | 131 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/falcon_h1/modular_falcon_h1.py | d8f5ed4187f444941f42f2355d05dab47b42032a22b824bd2871c490398abca7 | 1381 | 57 | # Copyright 2025 Technology Innovation Institute and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations  |
| .venv/lib/python3.13/site-packages/transformers/models/falcon_h1/configuration_falcon_h1.py | aa5f163d2fd32ad7f628fcf42a8fd6c49a5fecd567cae7e7f81fa3db491ec1f7 | 283 | 20 |             Vocabulary size of the FalconH1 model. Defines the number of different tokens that can be represented by the             `inputs_ids` passed when calling [`FalconH1Model`]         tie_word |
| .venv/lib/python3.13/site-packages/transformers/models/falcon_h1/modeling_falcon_h1.py | 108cbd818509c3dfd260b9cc518360b56c3b078984583b0482ab7dfa79d3ef70 | 1616 | 59 | # Copyright 2025 Technology Innovation Institute and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations  |
| .venv/lib/python3.13/site-packages/transformers/models/instructblip/modeling_instructblip.py | 9301747a8bf54f1a6b1dbd2e4cc4dc8eb464f47088b5e48864d4f839a2b81c78 | 1717 | 129 | from ...pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer from ...utils import ModelOutput, TransformersKwargs, auto_docstring, can_return_tuple, log |
| .venv/lib/python3.13/site-packages/transformers/models/instructblip/configuration_instructblip.py | fc46330481d7b8ce834e157911fa4956e825b0bece0aef9ac6f374bbf61f9363 | 340 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/bros/modeling_bros.py | 6b6f2e48543b7138948e3f81e1f4d6bc920d6b4226347c0c65232efbd293752a | 1138 | 76 |   class BrosPositionalEmbedding1D(nn.Module):     # Reference: https://github.com/kimiyoung/transformer-xl/blob/master/pytorch/mem_transformer.py#L15  |
| .venv/lib/python3.13/site-packages/transformers/models/bros/configuration_bros.py | f55826be4de167e55c72c386841f0e9543e3339a233ee7d22011dada86382392 | 139 | 5 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/detr/modeling_detr.py | 25486f6486e8e1e79acd57e76735c2aeaece6343782cff6f2780ec876ba60715 | 1694 | 78 | class DetrConvModel(nn.Module):     """     This module adds 2D position embeddings to all intermediate feature maps of the convolutional encoder.     """  |
| .venv/lib/python3.13/site-packages/transformers/models/detr/image_processing_detr.py | bc78df04fa676a064b0a383653268fc792e9b33cc8ff5c646a8baa0883b11a4b | 2050 | 4 |      # Keep track of instances of each class     stuff_memory_list: dict[str, int] = {}     for k in range(pred_labels.shape[0]):         pred_class = pred_labels[k].item() |
| .venv/lib/python3.13/site-packages/transformers/models/detr/configuration_detr.py | c12744fa9b3381e9692cf3014448668d793beedf2c3d8b619fd0a3e10a34d98f | 298 | 6 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/hgnet_v2/modular_hgnet_v2.py | ced27bb7fc6808f8280169e74cae136c7aa28c9d31a6f324f0d8ea38915607fc | 619 | 24 |         num_channels (`int`, *optional*, defaults to 3):             The number of input channels.         embedding_size (`int`, *optional*, defaults to 64):             Dimensionality (hidden size)  |
| .venv/lib/python3.13/site-packages/transformers/models/hgnet_v2/modeling_hgnet_v2.py | 6461500a5e8cae075a415469f9e00a702bb6f36b00630bfa3af456dcd6488776 | 496 | 19 |   class HGNetV2Embeddings(nn.Module):     def __init__(self, config: HGNetV2Config):         super().__init__() |
| .venv/lib/python3.13/site-packages/transformers/models/hgnet_v2/configuration_hgnet_v2.py | 1abf0de3c7d72e2bc5fe32a0a66eb6fb5993beaa394037f0fa1d0971e0976e36 | 153 | 5 |         num_channels (`int`, *optional*, defaults to 3):             The number of input channels.         embedding_size (`int`, *optional*, defaults to 64):             Dimensionality (hidden size)  |
| .venv/lib/python3.13/site-packages/transformers/models/florence2/processing_florence2.py | ded863b8eeb686e6cd1fc2911094dba8ea3cb0cd15e18dbaaf0889832a8d0f52 | 804 | 1 |             The tokenizer is a required input.         num_additional_image_tokens (`int`, *optional*, defaults to 0):             Number of additional tokens added to the image embeddings, such as CL |
| .venv/lib/python3.13/site-packages/transformers/models/florence2/configuration_florence2.py | 7a54841e33f0544dc670e502243564b4b10836dfe50f60482424809c5aa51615 | 216 | 13 |             The patch padding of the image.         patch_prenorm (`Tuple[bool]`, *optional*, defaults to `(False, True, True, True)`):             Whether to apply layer normalization before the patc |
| .venv/lib/python3.13/site-packages/transformers/models/florence2/modular_florence2.py | 53350fa8d9acccf8cd0c381cf8aae85c72411c1189be37bdc97dd74fca15d4be | 1808 | 41 |             The patch padding of the image.         patch_prenorm (`Tuple[bool]`, *optional*, defaults to `(False, True, True, True)`):             Whether to apply layer normalization before the patc |
| .venv/lib/python3.13/site-packages/transformers/models/florence2/modeling_florence2.py | 8074c40663ca61af22dfef36ec7ff7faa31d2f1e2848ed7695a3ad3b09b709a5 | 1029 | 37 |   class Florence2VisionLearnedAbsolutePositionEmbedding2D(nn.Module):     """     This module learns positional embeddings up to a fixed maximum size. |
| .venv/lib/python3.13/site-packages/transformers/models/sam2_video/configuration_sam2_video.py | b89a878d51783672f0a12dac3e46796c5b0604f90f15085095d43fb86c60a425 | 394 | 119 |         mask_input_channels (`int`, *optional*, defaults to 16):             The number of channels to be fed to the `MaskDecoder` module.         num_point_embeddings (`int`, *optional*, defaults to  |
| .venv/lib/python3.13/site-packages/transformers/models/sam2_video/modeling_sam2_video.py | b2d84581d4fbfa1f9c90afa15dd352839d4de2ce2b4db513f5fd89ecf336c24c | 2551 | 421 |         max_vision_features_cache_size: int = 1,     ):         # store as a list to avoid double memory allocation with torch.cat when adding new frames         self.processed_frames = list(video.to( |
| .venv/lib/python3.13/site-packages/transformers/models/sam2_video/modular_sam2_video.py | ce747d89777040bcb0a05e3d165f7e0933565c2883f1012ecfa833ab90166c99 | 2355 | 355 |     Sam2LayerNorm,     Sam2Model,     Sam2SinePositionEmbedding,     Sam2TwoWayAttentionBlock,     eager_attention_forward, |
| .venv/lib/python3.13/site-packages/transformers/models/mra/configuration_mra.py | a0d851cfa3ddbd42bfba0a220211c3b8d9068013720e0b804e041d29e4c90676 | 138 | 10 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/mra/modeling_mra.py | 3d44cd4d449c4527dbd5b70ccd3d202fdbfe84c340ec3244bc9356128503a6f2 | 1393 | 65 |   class MraEmbeddings(nn.Module):     """Construct the embeddings from word, position and token_type embeddings."""  |
| .venv/lib/python3.13/site-packages/transformers/models/internvl/modeling_internvl.py | b3247a0322733d87d4eb6118b72589c297d1c87f8aa8f85dcf21d40b68114d23 | 1007 | 62 |         """Initialize the weights"""         super()._init_weights(module)         if isinstance(module, InternVLVisionEmbeddings):             module.cls_token.data.zero_()             if module.mask |
| .venv/lib/python3.13/site-packages/transformers/models/internvl/modular_internvl.py | a0523ed59fcbd7bd91d50f8346cd90c120e1b38fd705194aa226cd4ec95434c0 | 699 | 52 | from ..llama.modeling_llama import LlamaRMSNorm from ..llava.modeling_llava import (     LlavaCausalLMOutputWithPast,     LlavaForConditionalGeneration,     LlavaModel, |
| .venv/lib/python3.13/site-packages/transformers/models/internvl/configuration_internvl.py | a473f001b0c1b3e6b6982a1a753180fbceb2f30f62a3ef6b9fe9a11523057b6d | 226 | 6 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/llava/modeling_llava.py | ad4ebd137f35c49bda0c59b2772cdd2848fecb3be6a22f2a1b6192613319e085 | 515 | 15 |     """ ) class LlavaCausalLMOutputWithPast(ModelOutput):     r"""     loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided): |
| .venv/lib/python3.13/site-packages/transformers/models/llava/processing_llava.py | 2b15b5d349a9cdf56157f6376ac4463e020cd0ef43904f23a01b04c0465b97fe | 213 | 1 |             Special token used to denote image location.         num_additional_image_tokens (`int`, *optional*, defaults to 0):             Number of additional tokens added to the image embeddings,  |
| .venv/lib/python3.13/site-packages/transformers/models/llava/configuration_llava.py | 3332935e3786325afe28d156ecbf13e218346f1fa867d621d9b855b6fdd052de | 138 | 1 |             vision features.         image_seq_length (`int`, *optional*, defaults to 576):             Sequence length of one image embedding.         multimodal_projector_bias (`bool`, *optional*, d |
| .venv/lib/python3.13/site-packages/transformers/models/perceiver/modeling_perceiver.py | 924dc8fd1edcb40dafb9a6a58ce0b133326b36624974f63f928f20bb6cefd941 | 3407 | 80 |   class PerceiverEmbeddings(nn.Module):     """Construct the latent embeddings."""  |
| .venv/lib/python3.13/site-packages/transformers/models/perceiver/configuration_perceiver.py | d21e4d082ea226203f70ebfd82f729c4d82215cd2bdb946fbfb3c81e1d63a7a4 | 246 | 5 |             The number of latents.         d_latents (`int`, *optional*, defaults to 1280):             Dimension of the latent embeddings.         d_model (`int`, *optional*, defaults to 768):        |
| .venv/lib/python3.13/site-packages/transformers/models/instructblipvideo/modular_instructblipvideo.py | 72dcb3323bfa4e438dd64bfd9ef9e29efb855c0d613796e9c5ac0c59f21b290c | 615 | 9 |         image_embeds = vision_outputs[0]          # step 2: forward the query tokens through the QFormer, using the image embeddings for cross-attention         image_attention_mask = torch.ones(image |
| .venv/lib/python3.13/site-packages/transformers/models/instructblipvideo/modeling_instructblipvideo.py | 212e7dcebc8affe36db3527697ee73b5e5ef5322a9c5bba05fd36e9832c10472 | 1749 | 128 | from ...pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer from ...utils import ModelOutput, TransformersKwargs, auto_docstring, can_return_tuple, log |
| .venv/lib/python3.13/site-packages/transformers/models/instructblipvideo/configuration_instructblipvideo.py | 45626ed1f384f9472f6512d82c2641d0c1e65ce511791bf762137d96c96243af | 346 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/gpt2/tokenization_gpt2.py | ddb2e0c5a6a9fba6297a1cd923e0d1e6cd0553c3ccd2b8898ec99a8aa287ff74 | 335 | 9 | # See the License for the specific language governing permissions and # limitations under the License. """Tokenization classes for OpenAI GPT."""  import json |
| .venv/lib/python3.13/site-packages/transformers/models/gpt2/modeling_gpt2.py | 8b48a8d3049ec598dc197965fe0fdcb2251fc14f6ae4cabe381c71191ec089cf | 1641 | 112 | # See the License for the specific language governing permissions and # limitations under the License. """PyTorch OpenAI GPT-2 model."""  import math |
| .venv/lib/python3.13/site-packages/transformers/models/gpt2/__init__.py | 3518bb698bb781ecc33ec8978a21ba7604a908c1d222f1690b7888d30f89300d | 33 | 7 |  if TYPE_CHECKING:     from .configuration_gpt2 import *     from .modeling_flax_gpt2 import *     from .modeling_gpt2 import * |
| .venv/lib/python3.13/site-packages/transformers/models/gpt2/tokenization_gpt2_tf.py | 31aed9e259170f2789793c39fb0c24270b6dbc87549c6a6dce69e19afcc25fb0 | 120 | 21 | from ...modeling_tf_utils import keras from ...utils.import_utils import is_keras_nlp_available, requires from .tokenization_gpt2 import GPT2Tokenizer   |
| .venv/lib/python3.13/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py | a4a2763d5692cd65122235d6a0ba74afc2e222ea6d864ffca1a4cd843f8f840c | 134 | 12 | # See the License for the specific language governing permissions and # limitations under the License. """Tokenization classes for OpenAI GPT."""  from typing import Optional |
| .venv/lib/python3.13/site-packages/transformers/models/gpt2/modeling_flax_gpt2.py | 201947955159c3e3bf040ae4e69a8c25693ec2c4d534b40b79fe8c18d0e50919 | 783 | 67 | from ...modeling_flax_outputs import (     FlaxBaseModelOutputWithPastAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions, ) from ...modeling_flax_utils import ACT2FN, FlaxPreTrainedModel, a |
| .venv/lib/python3.13/site-packages/transformers/models/gpt2/modeling_tf_gpt2.py | c563e98da1b22c339b1aae3edf3c2c6f9810569b97519d9ac93651238c0b0767 | 1239 | 88 | # See the License for the specific language governing permissions and # limitations under the License. """TF 2.0 OpenAI GPT-2 model."""  from __future__ import annotations |
| .venv/lib/python3.13/site-packages/transformers/models/gpt2/configuration_gpt2.py | a1676b0550e680fa90276a2bcf310b6ea91b13f86f2a4f4ea78a70b445cdde16 | 275 | 38 | # See the License for the specific language governing permissions and # limitations under the License. """OpenAI GPT-2 configuration"""  from collections import OrderedDict |
| .venv/lib/python3.13/site-packages/transformers/models/ibert/modeling_ibert.py | 67c6acfa7331fa26809df8329d9dc999d56cda41e8d3686a1e2d8e01ea2e229c | 1255 | 89 | from ...utils import auto_docstring, logging from .configuration_ibert import IBertConfig from .quant_modules import IntGELU, IntLayerNorm, IntSoftmax, QuantAct, QuantEmbedding, QuantLinear   |
| .venv/lib/python3.13/site-packages/transformers/models/ibert/quant_modules.py | 211ab824e7c39fc0410da9f6cc3cbc15aef46cc27c59ada0a2b34378d541eae7 | 821 | 11 |   class QuantEmbedding(nn.Module):     """     Quantized version of `torch.nn.Embedding`. Adds quantization-specific arguments on top of `torch.nn.Embedding`. |
| .venv/lib/python3.13/site-packages/transformers/models/ibert/configuration_ibert.py | 9cb460a4ecd7cfcacda6b9067e7cf92d5b8f2966d89d07e402e6c9a7db096321 | 143 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/glm/modular_glm.py | ace49706cc84099844370689f0cf5b07127534ad8bc2fecf399bbaed4bb7c604 | 116 | 9 | from ..llama.modeling_llama import (     LlamaAttention,     LlamaForCausalLM,     LlamaForSequenceClassification,     LlamaForTokenClassification, |
| .venv/lib/python3.13/site-packages/transformers/models/glm/configuration_glm.py | d22ee11a818facfdf4f163aa67665b182c36fb4e864620efc40bff9b615df858 | 153 | 10 |         attention_dropout (`float`, *optional*, defaults to 0.0):             The dropout ratio for the attention probabilities.         max_position_embeddings (`int`, *optional*, defaults to 131072) |
| .venv/lib/python3.13/site-packages/transformers/models/glm/modeling_glm.py | 3dc9a1163a2e46445cdc7e91309f7f7a19e378835d363e25f88c0e33dd5b23e2 | 513 | 27 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py | c1a59effb4c7eef7f4c11998a9e26669f2ef6c24a23b75f22ea3674619d7e038 | 1064 | 46 | from ...modeling_attn_mask_utils import AttentionMaskConverter from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, MoeCausalLMOutputWithP |
| .venv/lib/python3.13/site-packages/transformers/models/granitemoeshared/modular_granitemoeshared.py | 500430db1590f1abe0712e4be42f8097e960dfc58c545e324978bbcd669d94cb | 201 | 10 | from ..granitemoe.modeling_granitemoe import (     GraniteMoeDecoderLayer,     GraniteMoeForCausalLM,     GraniteMoeModel,     GraniteMoePreTrainedModel, |
| .venv/lib/python3.13/site-packages/transformers/models/granitemoeshared/configuration_granitemoeshared.py | 9586ebcdb6111f14795dff316ffec6565c3734091619a31efdc56af07ea3207f | 201 | 22 | # Copyright 2024 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/flaubert/modeling_tf_flaubert.py | cde656a67622e7a9cf280ae63f8ddfe934c33cec7139b8608ddd025c9e18dd0a | 1344 | 50 |     TFSequenceClassificationLoss,     TFSequenceSummary,     TFSharedEmbeddings,     TFTokenClassificationLoss,     get_initializer, |
| .venv/lib/python3.13/site-packages/transformers/models/flaubert/modeling_flaubert.py | a3dd600b7c265803381d77de02d53c070310ce5aa63aff8fa3f1d996314bdb33 | 1701 | 44 |   # Copied from transformers.models.xlm.modeling_xlm.create_sinusoidal_embeddings def create_sinusoidal_embeddings(n_pos, dim, out):     position_enc = np.array([[pos / np.power(10000, 2 * (j // 2) /  |
| .venv/lib/python3.13/site-packages/transformers/models/flaubert/configuration_flaubert.py | f76d0d4a6b40e08d4d6de4e4eb8d84f0ebca1160fd4e7c01820b5a206cb1ef45 | 236 | 19 |             Number of attention heads for each attention layer in the Transformer encoder.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully con |
| .venv/lib/python3.13/site-packages/transformers/models/vit_mae/configuration_vit_mae.py | de79d60c06e9e962df3872ceded68950d12e191964de801ad2a68b1042608c74 | 141 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/vit_mae/modeling_tf_vit_mae.py | 18a5e9caca8e7289fc296fb72914281bd9af2c16f96fc988936231e954326211 | 1375 | 70 |             Tensor containing the original index of the (shuffled) masked patches.         hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `c |
| .venv/lib/python3.13/site-packages/transformers/models/vit_mae/modeling_vit_mae.py | 4af6f866db1fcec00b562b4eab86eccb0b60b67fa083641bfa892f2e4efb5416 | 970 | 67 | def get_2d_sincos_pos_embed(embed_dim, grid_size, add_cls_token=False):     """     Create 2D sin/cos positional embeddings.      Args: |
| .venv/lib/python3.13/site-packages/transformers/models/roc_bert/modeling_roc_bert.py | 4f24d373ed449b2b92b6b3211b4599c075c9b7f55c99c29b82222b2c701e3c1f | 1934 | 157 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/roc_bert/configuration_roc_bert.py | df0dede375f4664ce219e7ed9a5160f32a335a3e7b3e7e64ca785bc5752434c9 | 164 | 12 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/prophetnet/configuration_prophetnet.py | 5cf701ee2b506c2a8ccce354777fb8020eb0b411c2e1fdfe8d66fa3944f2c684 | 181 | 5 |             The dropout ratio for the attention probabilities.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/prophetnet/modeling_prophetnet.py | 47741ac10a650b31560593dd0eefd679e9cbd1f3c3c5b3e085c6f495977ca0d1 | 2051 | 157 |         used (see `past_key_values` input) to speed up sequential decoding.     decoder_ngram_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed |
| .venv/lib/python3.13/site-packages/transformers/models/glm4v/processing_glm4v.py | 42a633cc08af93fde26e8b7d52f9d85d2152dd25ebf70c5cc2c8bacc289dacef | 295 | 2 |             - **pixel_values** -- Pixel values to be fed to a model. Returned when `images` is not `None`.             - **pixel_values_videos** -- Pixel values of videos to be fed to a model. Returne |
| .venv/lib/python3.13/site-packages/transformers/models/glm4v/image_processing_glm4v.py | 4a3062a3bc3fc79e916e2fc05267adae49c8e6fb86f890dff47d5038858b9e41 | 473 | 3 |             The temporal patch size of the vision encoder.         merge_size (`int`, *optional*, defaults to 2):             The merge size of the vision encoder to llm encoder.     """  |
| .venv/lib/python3.13/site-packages/transformers/models/glm4v/configuration_glm4v.py | cef75564c7b92629e8f63c1e94c23730dfaf5d62757d1587fcbcfb002404bffd | 354 | 19 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/glm4v/modular_glm4v.py | 1ac5b4c923ef380d104be909cbcd3bb359be49263c473e484f64bc59f3698031 | 1683 | 145 | from ..qwen2_5_vl.modeling_qwen2_5_vl import (     Qwen2_5_VisionPatchEmbed,     Qwen2_5_VisionRotaryEmbedding,     Qwen2_5_VLCausalLMOutputWithPast,     Qwen2_5_VLForConditionalGeneration, |
| .venv/lib/python3.13/site-packages/transformers/models/glm4v/image_processing_glm4v_fast.py | 31c92ef645419d17012e633b2731bb30f6f72f6436ff3419a76ce3022ea649b5 | 206 | 1 |         The temporal patch size of the vision encoder.     merge_size (`int`, *optional*, defaults to 2):         The merge size of the vision encoder to llm encoder.     """  |
| .venv/lib/python3.13/site-packages/transformers/models/glm4v/video_processing_glm4v.py | db508cfdd5588c11b1daa5082a747dbb74190486f1fa9af401ea013224c8f19a | 272 | 1 |             The temporal patch size of the vision encoder.         merge_size (`int`, *optional*, defaults to 2):             The merge size of the vision encoder to llm encoder.     """, ) |
| .venv/lib/python3.13/site-packages/transformers/models/glm4v/modeling_glm4v.py | d103b97e2283db9c9b6b43dd7ed4ce2ee46f5b96cc4a9aef3b6b9e6415cbae30 | 1653 | 140 |   class Glm4vVisionRotaryEmbedding(nn.Module):     inv_freq: torch.Tensor  # fix linting for `register_buffer`  |
| .venv/lib/python3.13/site-packages/transformers/models/falcon/modeling_falcon.py | 1497d99fbbb103d0fa31fa83a0d436bf7d1b51aaf9b19336d24b464c9fcbf766 | 1401 | 52 | from ...modeling_outputs import (     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     QuestionAnsweringModelOutput,     SequenceClassifierOutputWithPast, |
| .venv/lib/python3.13/site-packages/transformers/models/falcon/configuration_falcon.py | e6f875d0b0248a85facb7a8987ce2edd29579aede03c0ad734c7b56a933b7fd8 | 212 | 12 |         bias (`bool`, *optional*, defaults to `False`):             Whether to use bias on Linear layers.         max_position_embeddings (`int`, *optional*, defaults to 2048):             The maximum |
| .venv/lib/python3.13/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py | 8191a8a93f3fd621c28057a24b74224eea896c71546862596d0103a9f7eb1ef2 | 1557 | 64 |     BaseModelOutput,     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     Seq2SeqLMOutput,     Seq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py | e209fb260b8582f7dfdea13562ca60828f7df008b5c9cb3a0b02455c9bfdce89 | 1529 | 48 |     FlaxBaseModelOutput,     FlaxBaseModelOutputWithPastAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxSeq2SeqLMOutput,     FlaxSeq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/blenderbot_small/configuration_blenderbot_small.py | 9a893495a70b2e4482dcb950e82e94c430476510565b5a44506ca301b6a655ca | 392 | 15 | class BlenderbotSmallConfig(PretrainedConfig):     r"""     This is the configuration class to store the configuration of a [`BlenderbotSmallModel`]. It is used to instantiate     an BlenderbotSmall m |
| .venv/lib/python3.13/site-packages/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py | f7217e8775f7fd91fe602e11fd64e2e15b90455f2fba91f03fa01a36baecdc1e | 1528 | 57 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     add_code_sample_docstrings, |
| .venv/lib/python3.13/site-packages/transformers/models/phi4_multimodal/modeling_phi4_multimodal.py | 19bc09c3425909187735264f6e037596e575fb8faf3f04eaa0176bfe285d9c1e | 1897 | 75 |     BaseModelOutputWithPast,     BaseModelOutputWithPooling,     CausalLMOutputWithPast, ) from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update |
| .venv/lib/python3.13/site-packages/transformers/models/phi4_multimodal/processing_phi4_multimodal.py | 6fbb773e2ebe8684c6fbe4291df302b68219cf2618c2642dbccd446d4ae2888b | 174 | 7 | class Phi4MultimodalProcessor(ProcessorMixin):     r"""     Constructs a Phi4Multimodal processor which raps an image processor, a audio processor, and a GPT tokenizer into a single processor.      [` |
| .venv/lib/python3.13/site-packages/transformers/models/phi4_multimodal/configuration_phi4_multimodal.py | 4487586e7bdcb3ff1590570963de8cd3a3d4108d64b7bd16154fd80c4f3ef6f2 | 483 | 21 |             Dropout probability for mlp outputs.         embd_pdrop (`int`, *optional*, defaults to 0.0):             The dropout ratio for the embeddings.         attention_dropout (`float`, *optiona |
| .venv/lib/python3.13/site-packages/transformers/models/phi4_multimodal/modular_phi4_multimodal.py | 28780e327519a9b83517461288df9595171fa4a4b6e784c0cd535f7cbd26b12b | 1745 | 81 |     BaseModelOutputWithPast,     BaseModelOutputWithPooling,     CausalLMOutputWithPast, ) from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel |
| .venv/lib/python3.13/site-packages/transformers/models/megatron_bert/modeling_megatron_bert.py | c9ec844d15ccdebc29a237b8210f1e5d4e1ac2a64a104a48a0407d580741b936 | 1650 | 96 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/megatron_bert/configuration_megatron_bert.py | 67c03fea158fc81682ffae001c396fc4607ed3cbaaa460321e55f5dadcb5936b | 130 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py | 6a630e9d58b3b2dad90a475ab56179527dc1eb8147ee6437fdd779cd855421e7 | 936 | 57 | # See the License for the specific language governing permissions and # limitations under the License. """PyTorch GPTBigCode model."""  import math |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_bigcode/__init__.py | 29035becf3b9ede6693f7e39c126defc2de22fe37854fb1cc35198da6bfcd6e1 | 28 | 2 |  if TYPE_CHECKING:     from .configuration_gpt_bigcode import *     from .modeling_gpt_bigcode import * else: |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_bigcode/configuration_gpt_bigcode.py | e692f599ec82550657bdca3d5ac20536f0e111db690045604ce83ec60d9c5abc | 146 | 20 | # See the License for the specific language governing permissions and # limitations under the License. """GPTBigCode configuration"""  from ...configuration_utils import PretrainedConfig |
| .venv/lib/python3.13/site-packages/transformers/models/funnel/modeling_tf_funnel.py | 64c76ac0d3cadd6921ccef8701f683b5bb6872d4301038c6b1f887b09fc25d68 | 1884 | 56 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     ModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/funnel/configuration_funnel.py | 6f9de08b9096ecaa66cc5140336925395383c1bd49ab7d176f35f5ac836eef1f | 167 | 3 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the  |
| .venv/lib/python3.13/site-packages/transformers/models/funnel/modeling_funnel.py | 939ae430d98712427660e3766c30e66f96bd92b4bdcfe663c5947ed4e488b8ca | 1453 | 52 |         "beta": "bias",         "lookup_table": "weight",         "word_embedding": "word_embeddings",         "input": "embeddings",     } |
| .venv/lib/python3.13/site-packages/transformers/models/smollm3/modeling_smollm3.py | 06816c41869a75e66dc78468987c75f64349450c44c980b786a20b22041596ec | 528 | 77 | #                🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨 #           This file was automatically generated from src/transformers/models/smollm3/modular_smollm3.py. #               Do NOT edit |
| .venv/lib/python3.13/site-packages/transformers/models/smollm3/__init__.py | 0590363220e91a6bf6b30835c8ed78b64822fd2674c9583c9ddafe3c9c18f9f2 | 28 | 2 |  if TYPE_CHECKING:     from .configuration_smollm3 import *     from .modeling_smollm3 import * else: |
| .venv/lib/python3.13/site-packages/transformers/models/smollm3/configuration_smollm3.py | f963e22a0267c2987c7950006050fba861e58cb21e0f3ef0fe512f4e64c8fe5a | 248 | 32 | #                🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨 #           This file was automatically generated from src/transformers/models/smollm3/modular_smollm3.py. #               Do NOT edit |
| .venv/lib/python3.13/site-packages/transformers/models/smollm3/modular_smollm3.py | 448fb453801d095ed5fd5934dce1a140665971ba18d5882f8a8a183bf445bb59 | 362 | 51 |     LlamaAttention,     LlamaDecoderLayer,     LlamaForCausalLM,     LlamaForQuestionAnswering,     LlamaForSequenceClassification, |
| .venv/lib/python3.13/site-packages/transformers/models/phi/modeling_phi.py | 1909a7ce9dafe4d0735310f22afc18adac0ee0b4327f54053c2d51dbf0f2d9c5 | 523 | 28 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/phi/configuration_phi.py | c58936c6f6b62971b993f0e4f0d0f724e6c38dc7cfba495475290d213d03609f | 218 | 21 |             Dropout probability for mlp outputs.         embd_pdrop (`int`, *optional*, defaults to 0.0):             The dropout ratio for the embeddings.         attention_dropout (`float`, *optiona |
| .venv/lib/python3.13/site-packages/transformers/models/phi/modular_phi.py | 29dd938fe6e39def8f17a1418dcc48cc7fddd40b8cceb0df0280e1490ce3a43f | 302 | 17 | from ..llama.modeling_llama import (     LlamaAttention,     LlamaForCausalLM,     LlamaForSequenceClassification,     LlamaForTokenClassification, |
| .venv/lib/python3.13/site-packages/transformers/models/fsmt/configuration_fsmt.py | 4d635585044e100d563022fa8f71d7de7464ca156c0769f693035be90904e296 | 226 | 15 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/fsmt/modeling_fsmt.py | d697ca9c0970a9289097ec7fda478633b4499a446d278d362095427b9b9a7a7b | 1258 | 52 | #   to match fairseq outputs, you need to pass ``early_stopping=True`` to ``generate()``. # # SinusoidalPositionalEmbedding is slightly different from Bart's - generates # different embeddings. This i |
| .venv/lib/python3.13/site-packages/transformers/models/xmod/modeling_xmod.py | f59770feec23bc0a2dcbc971fa3a979c4a2b688a762dd704dac59858476bb749 | 1518 | 109 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/xmod/configuration_xmod.py | 5b96d02db4e1dc484c77e2efb1eca5dbcb9086455509d3d27617115c93bb85c8 | 186 | 12 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/sam2/configuration_sam2.py | 2b58a72a12d18123d1814c5def018da3b2ff5bcce9456d0f2ad130e6fdacb658 | 458 | 19 |         query_stride (`list[int]`, *optional*, defaults to `[2, 2]`):             The downsample stride between stages.         window_positional_embedding_background_size (`list[int]`, *optional*, de |
| .venv/lib/python3.13/site-packages/transformers/models/sam2/modeling_sam2.py | 217dd0cef184e829e660d33f34815766a02e6dae2eca5857b0500de9d22fafca | 1616 | 251 |         `(batch_size, hidden_size, height, width)`. Positional encodings corresponding to the `fpn_hidden_states`.     hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidd |
| .venv/lib/python3.13/site-packages/transformers/models/sam2/modular_sam2.py | 6d248d574e1cf3d5a4832015f83f17fb38f6eba85cf1830bb9121a9ccdd302a2 | 1472 | 189 | from ...utils.generic import TransformersKwargs, check_model_inputs from ..auto import AutoModel from ..maskformer.modeling_maskformer import MaskFormerSinePositionEmbedding from ..sam.image_processin |
| .venv/lib/python3.13/site-packages/transformers/models/sam2/image_processing_sam2_fast.py | aa60a5584266ef4bcd4eedaef6a3d9fa254efead0db6e3a2a201f0e7b3b7525d | 738 | 1 | def _compute_stability_score(masks: "torch.Tensor", mask_threshold: float, stability_score_offset: int):     # One mask is always contained inside the other.     # Save memory by preventing unnecessar |
| .venv/lib/python3.13/site-packages/transformers/models/vitpose_backbone/configuration_vitpose_backbone.py | 935ed2acd2bfd48edc138dc2dc2bb6654e55e559d6400ed1b263924b35c210c1 | 140 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probabilitiy for all fully connected layers i |
| .venv/lib/python3.13/site-packages/transformers/models/vitpose_backbone/modeling_vitpose_backbone.py | 21a7317a7d57e2e01df82f0463a82d3bca184e9b7177249ab2a25ffa4f07cc2e | 470 | 34 |  This code is the same as the original Vision Transformer (ViT) with 2 modifications: - use of padding=2 in the patch embedding layer - addition of a mixture-of-experts MLP layer """ |
| .venv/lib/python3.13/site-packages/transformers/models/persimmon/configuration_persimmon.py | e8a57eafe079b2a0bd77661bce29ddfd80f1aa73349484df6c7e733ea1a0e8ae | 177 | 19 |         hidden_act (`str` or `function`, *optional*, defaults to `"relu2"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`, |
| .venv/lib/python3.13/site-packages/transformers/models/persimmon/modeling_persimmon.py | 8e8943d83d025bebc18bfa893e05e615b6020b40632c0344ccf73954a797d900 | 774 | 50 | # Copyright 2023 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py | 998cc78671442735ef29884db72e4de59b92db02a5b9e8510fb3d1fa8714913e | 1999 | 51 |         encoder_hidden_states=None,         encoder_attention_mask=None,         position_embeddings: Optional[torch.Tensor] = None,         reference_points=None,         spatial_shapes=None, |
| .venv/lib/python3.13/site-packages/transformers/models/rt_detr_v2/configuration_rt_detr_v2.py | 22319083382058cbb8b86a0f127f031cc734d2518909d4dcbb67ef67a35a990b | 388 | 3 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         eval_size (`tuple[int, int]`, *optional*):             Height and width used to compute the effective height and width of the pos |
| .venv/lib/python3.13/site-packages/transformers/models/rt_detr_v2/modular_rt_detr_v2.py | a05101c461ec96da2544ff5f4852d16ffe23dbe376d9f5c06edc0f3fc48bf23c | 637 | 6 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         eval_size (`tuple[int, int]`, *optional*):             Height and width used to compute the effective height and width of the pos |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_neox_japanese/tokenization_gpt_neox_japanese.py | d24fcb7a7e3a24cf29e7472e6e406e92566d880c1c6494da48ecacd24f0de122 | 370 | 8 | # See the License for the specific language governing permissions and # limitations under the License. """Tokenization classes for GPTNeoXJapanese."""  import collections |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_neox_japanese/configuration_gpt_neox_japanese.py | 31a7b4e6ea02aaadeadb47be75ad42a02c427a047f360eaae51fb586b71a7152 | 168 | 32 | # See the License for the specific language governing permissions and # limitations under the License. """GPTNeoX Japanese model configuration"""  from ...configuration_utils import PretrainedConfig |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_neox_japanese/__init__.py | cf891b5266528c4f87b3d6daf2e97762771cf59272ede3ee7dbc304657ea5aac | 29 | 3 |  if TYPE_CHECKING:     from .configuration_gpt_neox_japanese import *     from .modeling_gpt_neox_japanese import *     from .tokenization_gpt_neox_japanese import * |
| .venv/lib/python3.13/site-packages/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py | 726906015683a69ae1e9178f11a146281902583730fbe8a3bdf2ced0aa5f3539 | 761 | 91 | # See the License for the specific language governing permissions and # limitations under the License. """PyTorch GPTNeoX model."""  import math |
| .venv/lib/python3.13/site-packages/transformers/models/layoutlm/modeling_tf_layoutlm.py | 9db9c568cc0717aa381f7eca8ee985b2cdcf9011b526f47d6ea49a09481e40ed | 1692 | 100 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import add_start_docstrings, add_start_docstrings_to_model_forward, logging, repla |
| .venv/lib/python3.13/site-packages/transformers/models/layoutlm/configuration_layoutlm.py | 757c7f535842afb3842a45f52a69ef5f6f3f6051bedd87e1ca8a21b48289bee0 | 214 | 24 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/layoutlm/modeling_layoutlm.py | 304ead73c3031f122480b38d816453398624a474e23db29e6bd06e65c25a42e3 | 1146 | 96 |   class LayoutLMEmbeddings(nn.Module):     """Construct the embeddings from word, position and token_type embeddings."""  |
| .venv/lib/python3.13/site-packages/transformers/models/owlv2/configuration_owlv2.py | d7c2abaf4468676e5e53478248f7a01d75ca02803ae33c3e6e49ec09e0643d3b | 284 | 4 |         num_attention_heads (`int`, *optional*, defaults to 8):             Number of attention heads for each attention layer in the Transformer encoder.         max_position_embeddings (`int`, *opti |
| .venv/lib/python3.13/site-packages/transformers/models/owlv2/modeling_owlv2.py | 38610a4c62da4e36b927be6da171ed15d46ce5f2d4ca55bdd5c8635cf5df0bc3 | 1718 | 90 |         similarity scores.     text_embeds (`torch.FloatTensor` of shape `(batch_size * num_max_text_queries, output_dim`):         The text embeddings obtained by applying the projection layer to the |
| .venv/lib/python3.13/site-packages/transformers/models/ernie4_5/configuration_ernie4_5.py | 4a0deaa984418c4ac7edd3dcc8f75f7b708a6276b14a98e8e5ddad23944056fb | 203 | 18 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/ernie4_5/modular_ernie4_5.py | 6a47b6b52f41718198417b4878bdaabc28c4b12a6a22dad63ad6b1253cbafed5 | 124 | 11 | from ..llama.modeling_llama import (     LlamaAttention,     LlamaForCausalLM,     LlamaMLP,     LlamaRotaryEmbedding, |
| .venv/lib/python3.13/site-packages/transformers/models/ernie4_5/modeling_ernie4_5.py | b7a169a5b3f53bb89c45fa0eb29b3f70d43728b76f1538a4beb2b9740beb198e | 472 | 22 | from ...masking_utils import create_causal_mask from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeli |
| .venv/lib/python3.13/site-packages/transformers/models/kyutai_speech_to_text/modular_kyutai_speech_to_text.py | 4c7b6c684f5a41dbcb061152c15ba6bc7313efd4c65f9dbecd3c86c5784eba3e | 514 | 5 | from ..auto import AutoModel from ..encodec.feature_extraction_encodec import EncodecFeatureExtractor from ..llama.modeling_llama import LlamaForCausalLM from ..mimi.modeling_mimi import MimiConv1dPad |
| .venv/lib/python3.13/site-packages/transformers/models/kyutai_speech_to_text/configuration_kyutai_speech_to_text.py | 79e054cc57d99c3961702ba14336857213454ff5aafb6fa60715cf27f95e9672 | 189 | 10 |             paper](https://huggingface.co/papers/2305.13245). If it is not specified, will default to             `num_attention_heads`.         max_position_embeddings (`int`, *optional*, defaults to |
| .venv/lib/python3.13/site-packages/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py | da6bb0886c6ee3aa8c110eb625c6c53c1c3dd0908e568b9dba0a1f25d47a8b93 | 1378 | 22 | from ...modeling_flash_attention_utils import flash_attn_supports_top_left_mask, is_flash_attn_available from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseM |
| .venv/lib/python3.13/site-packages/transformers/models/git/configuration_git.py | 48d708daa1df9c0bb00dc6167e23fc49bfd34173eda2c1e5c35bc363c6c4974e | 223 | 20 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/git/modeling_git.py | 8f72834509c8a1e7c80df2b087e4fed3451069ac226c96d054a255e75efd57de | 1465 | 162 |     BaseModelOutputWithPast,     BaseModelOutputWithPooling,     CausalLMOutputWithPast, ) from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel |
| .venv/lib/python3.13/site-packages/transformers/models/mistral/modeling_tf_mistral.py | fe7ee480411826468aec48690d9436bfc45d8c364b57b3838a485b8c69c943ee | 1017 | 31 | # Copyright 2024 Mistral AI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/mistral/modular_mistral.py | 1899025349efb1b291e40e5f3aa8e481eaf3fd3830c59ab7d6b54670505c11d5 | 200 | 9 |     LlamaAttention,     LlamaDecoderLayer,     LlamaForCausalLM,     LlamaForSequenceClassification,     LlamaForTokenClassification, |
| .venv/lib/python3.13/site-packages/transformers/models/mistral/modeling_flax_mistral.py | 255439f7477d9f184f6761619ac98e135df5e8c4ab28299aa680d1b7c1166582 | 745 | 41 |     FlaxBaseModelOutput,     FlaxBaseModelOutputWithPast,     FlaxCausalLMOutput,     FlaxCausalLMOutputWithCrossAttentions, ) |
| .venv/lib/python3.13/site-packages/transformers/models/mistral/configuration_mistral.py | 7b8db76cb42acca62b9c8afab645407dc30956a991796ce573f8d58f88c11f6a | 170 | 10 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/mistral/modeling_mistral.py | 3fbb6202376a1fdf57166d199dd4d43f81226b1e0634ec8b61dcb1ade7de153e | 481 | 26 |     GradientCheckpointingLayer, ) from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ...mo |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_moe/configuration_qwen2_moe.py | dc105fa73dcfbb70ee682b93b56685758fc92b942b2d55ab5be462f8acb6d392 | 245 | 18 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py | 6d3407e67d9427a0f742a9fb73cd3ca14890be278b86d33314fa3e573d7c19f4 | 1178 | 46 | # Copyright 2024 The Qwen team, Alibaba Group and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in  |
| .venv/lib/python3.13/site-packages/transformers/models/nemotron/configuration_nemotron.py | 40c1ff330e3c6600afa2f7c4dccb5433a5bfdf80d551beee9e9af6ec96954c88 | 157 | 11 |         hidden_act (`str` or `function`, *optional*, defaults to `"relu2"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`, |
| .venv/lib/python3.13/site-packages/transformers/models/nemotron/modeling_nemotron.py | a59a1f1f342c7bbf1723b97b5b9a038693a55e212ad853634189483c5cdf8760 | 964 | 53 | from ...modeling_outputs import (     BaseModelOutputWithPast,     CausalLMOutputWithPast, ) from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update |
| .venv/lib/python3.13/site-packages/transformers/models/fnet/configuration_fnet.py | a19546b3374462c13e9c99e94a5994debe2d10d09fc079cd29a2f8366ac3ecde | 120 | 5 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/fnet/modeling_fnet.py | 0c3f6776251619bafb8a48dc91f6e5646726278c5f46ab62c5bef406af0c80bf | 1095 | 59 |   class FNetEmbeddings(nn.Module):     """Construct the embeddings from word, position and token_type embeddings."""  |
| .venv/lib/python3.13/site-packages/transformers/models/bitnet/configuration_bitnet.py | 1f984ded073f4d605c32bdf1985d38a11ae0dfa81dfc822cfd7fb050c4ece3b9 | 148 | 10 |         hidden_act (`str` or `function`, *optional*, defaults to `"relu2"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`, |
| .venv/lib/python3.13/site-packages/transformers/models/bitnet/modeling_bitnet.py | 4c62f93cc86f1e9d5d8beba343ea4d9a47916218217d7b8c8f1c0bd62df4f95e | 489 | 24 | from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWith |
| .venv/lib/python3.13/site-packages/transformers/models/bitnet/modular_bitnet.py | e559dc1d3750d6f68b0ba2b112350f4f4abd79985ce48168988cf331a17480b8 | 156 | 10 | from ...cache_utils import Cache from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_outputs import CausalLMOutputWithPast from ...modeling_utils import ALL_ATTENTION_F |
| .venv/lib/python3.13/site-packages/transformers/models/canine/configuration_canine.py | f1196dfb2fa5918e09c338b801aecd5cde1326d0e843295ba2050e8edfeaf480 | 142 | 8 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/canine/modeling_canine.py | a8d18f1d7a4a301c5af4874fe552e6ecada398521692fb174be8b75f942c7cac | 1551 | 84 |         if name[0] == "bert":             name[0] = "encoder"         # remove "embeddings" middle name of HashBucketCodepointEmbedders         elif name[1] == "embeddings":             name.remove(na |
| .venv/lib/python3.13/site-packages/transformers/models/openai/modeling_tf_openai.py | 9995abeaa73c7c25d347acba1972dcfc4fc58079f9f8207a77330e8465db7d53 | 937 | 88 | # See the License for the specific language governing permissions and # limitations under the License. """TF 2.0 OpenAI GPT model."""  from __future__ import annotations |
| .venv/lib/python3.13/site-packages/transformers/models/openai/tokenization_openai.py | 321c52e86fa140b1cb7666ab1b138f069bcc11b34b1ee15165e84e8f383ea3dd | 397 | 5 | # See the License for the specific language governing permissions and # limitations under the License. """Tokenization classes for OpenAI GPT."""  import json |
| .venv/lib/python3.13/site-packages/transformers/models/openai/tokenization_openai_fast.py | a816a555c45baaaf406409f3905bd84dba24a78794f81be03b7408598a2a9dda | 67 | 6 | # See the License for the specific language governing permissions and # limitations under the License. """Fast Tokenization classes for OpenAI GPT."""  from typing import Optional |
| .venv/lib/python3.13/site-packages/transformers/models/openai/configuration_openai.py | 11115f72bb1a184b86fbc5a7b810df6321d1eee7398a112bf497c8b41306666d | 157 | 40 | # See the License for the specific language governing permissions and # limitations under the License. """OpenAI GPT configuration"""  from ...configuration_utils import PretrainedConfig |
| .venv/lib/python3.13/site-packages/transformers/models/openai/modeling_openai.py | cff0c49b84ef2f2e65eccde839c730e76e18f127368ef3e463dc147c5181b299 | 847 | 70 | # See the License for the specific language governing permissions and # limitations under the License. """PyTorch OpenAI GPT model."""  import json |
| .venv/lib/python3.13/site-packages/transformers/models/dinov2/modeling_dinov2.py | 81116a0fddfd3d96f9d175cc56a22ded11382eb21bc78748e79b29d34660f862 | 686 | 54 |   class Dinov2Embeddings(nn.Module):     """     Construct the CLS token, mask token, position and patch embeddings. |
| .venv/lib/python3.13/site-packages/transformers/models/dinov2/configuration_dinov2.py | d36d05e792619389f06e9cf17c3c738bbecfa1efb93a9b8667e7fe9b11036058 | 180 | 2 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/dinov2/modeling_flax_dinov2.py | 75f99e533dca43d77b7a85f45f442a24f28b1d9bfb73c18ead3d9517dfe0ef39 | 802 | 35 |     - [Just-In-Time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit)     - [Automatic Differentiation](https://jax.readthedocs.io/en/latest/jax.html#autom |
| .venv/lib/python3.13/site-packages/transformers/models/lilt/configuration_lilt.py | acf03b3fd7fd0767f6f7f43be03c7ddfe597ca12b5253e56ebb3e84ab0cea107 | 132 | 18 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/lilt/modeling_lilt.py | 2d73672a041d6ec80cdd7007e8a5efd7bcb9d36e0dc8a5bdd43d77b4ceac83b6 | 1094 | 131 |   class LiltTextEmbeddings(nn.Module):     def __init__(self, config):         super().__init__() |
| .venv/lib/python3.13/site-packages/transformers/models/llama/tokenization_llama.py | 2903ad0bd2739babecf6e813fbe4b21e36ff5cb394159e0cc13359b94ea0526f | 416 | 3 | # Copyright 2022 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/llama/configuration_llama.py | 9becb04559331628af1b4b72f44d68a07265bd0c95e383d11d4c5da5ed3a408e | 226 | 23 | # Copyright 2022 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/llama/modeling_flax_llama.py | dff3d2997fce3ebec436751271f032b9ea43c1e8cdfb6a85463e6f9b2f32f8a3 | 748 | 39 | # Copyright 2023 Meta AI, EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this libr |
| .venv/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py | 31bf660a663259134324bc65da4e155951dc89c5ca46471d2325a9938e859e26 | 506 | 29 | # Copyright 2022 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/whisper/tokenization_whisper_fast.py | 43a1dd2ce1547a347e684209668d12902908402b452fb7924b2bd210959b689d | 640 | 6 |         self.predict_timestamps = predict_timestamps      # Copied from transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast._batch_encode_plus     def _batch_encode_plus(self, *args, **k |
| .venv/lib/python3.13/site-packages/transformers/models/whisper/modeling_whisper.py | 747674848b803958cbe1fff84013a28f5331cab7d4380d9c53976fd19f475fe3 | 1643 | 52 |     BaseModelOutput,     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     Seq2SeqLMOutput,     Seq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/whisper/modeling_tf_whisper.py | 0244c39cce582ddda1377ca352707d20b43920e5b8e030a90af5e74d1bd3e362 | 1755 | 48 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import add_start_docstrings, add_start_docstrings_to_model_forward, logging, repla |
| .venv/lib/python3.13/site-packages/transformers/models/whisper/tokenization_whisper.py | 2711c2eabc8a77c92338b5ce22329fdfb8dd11fe3c63531c76b59c9a8b512c77 | 1421 | 24 |   # Copied from transformers.models.gpt2.tokenization_gpt2.bytes_to_unicode def bytes_to_unicode():     """ |
| .venv/lib/python3.13/site-packages/transformers/models/whisper/configuration_whisper.py | 09981c8176c37524b1bc0c2f274066b15ba124b14e5607862a72a7f37cb3f7bf | 349 | 18 |             Dimensionality of the layers.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddings, encoder, and poo |
| .venv/lib/python3.13/site-packages/transformers/models/whisper/generation_whisper.py | 8c0583e4e4a31be660f472a563b6708ab457c770b1d7ec1dc6575d252c23e0b5 | 2097 | 2 |         >>> transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)         >>> transcription[0]         " Folks, if you watch the show, you know, I spent a lot of time right o |
| .venv/lib/python3.13/site-packages/transformers/models/whisper/feature_extraction_whisper.py | e37bf304b0c28d4f1ad3637cfa6b8b4d8d95e017bb4390f46d23f491d537df88 | 344 | 5 |             normed_input_values = []              for vector, length in zip(input_values, attention_mask.sum(-1)):                 normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:le |
| .venv/lib/python3.13/site-packages/transformers/models/whisper/modeling_flax_whisper.py | 49db7ecf96505ef0fa239d35aec09d3c7997e54b95b73d675829a9b7cb9be586 | 1708 | 28 |     FlaxBaseModelOutput,     FlaxBaseModelOutputWithPastAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxSeq2SeqLMOutput,     FlaxSeq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/llava_onevision/configuration_llava_onevision.py | 786782f630533477a8b98ac9f0a3ff2146152d26e33bcc928f4a0536f1882450 | 195 | 5 |             A list of possible resolutions to use for processing high resolution images. Each item in the list should be a tuple or list             of the form `(height, width)`.         tie_word_emb |
| .venv/lib/python3.13/site-packages/transformers/models/llava_onevision/modular_llava_onevision.py | c66b22ff42dddcd5ede3e0098b68fd3bf54cbf001cc3e9f50d5a29cb040c79df | 761 | 9 | from transformers.models.llava_next.image_processing_llava_next_fast import LlavaNextImageProcessorFast from transformers.models.llava_next_video.modeling_llava_next_video import (     LlavaNextVideoC |
| .venv/lib/python3.13/site-packages/transformers/models/llava_onevision/image_processing_llava_onevision.py | 56b599eaf8f117eb7a6908d304a49951cca23987b7b99a78da962f5725e737a2 | 787 | 3 |                 The padding mode to use. Can be one of:                     - `"constant"`: pads with a constant value.                     - `"reflect"`: pads with the reflection of the vector mirror |
| .venv/lib/python3.13/site-packages/transformers/models/llava_onevision/modeling_llava_onevision.py | 73e305e6beeb9faa825994fbd6cefe90ae1573c4479c9ae81660cf218b9dd4e4 | 971 | 19 |     """ ) class LlavaOnevisionCausalLMOutputWithPast(ModelOutput):     r"""     loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided): |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py | fa03161ca6dc013e6b20b626355ca997d92458488a39560a458eb0696ea9a144 | 898 | 38 | from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel from ...utils import auto_docstring, logging from ..auto import AutoModel, AutoModelForCausalLM from .configuration_qwen2_audio i |
| .venv/lib/python3.13/site-packages/transformers/models/qwen2_audio/configuration_qwen2_audio.py | 537eec03b3bc1af6eb9453b05e0052beabb6f0acf6b8a24e46a8ed86a1fc5271 | 204 | 7 |             Dimensionality of the layers.         dropout (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in the embeddings, encoder, and poo |
| .venv/lib/python3.13/site-packages/transformers/models/rembert/modeling_rembert.py | cf00ef0b6834055970ef84204b5670de6b7aa16eae590ecf6144447ba5aa6802 | 1362 | 74 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/rembert/configuration_rembert.py | c12055e952c4bdc28cbcfd8f670e8a81aa9e958cf221684afcd64357c9335fff | 163 | 16 |         num_attention_heads (`int`, *optional*, defaults to 18):             Number of attention heads for each attention layer in the Transformer encoder.         input_embedding_size (`int`, *option |
| .venv/lib/python3.13/site-packages/transformers/models/rembert/modeling_tf_rembert.py | 0a1c9155b4e5746ad3b966b2c8d2e39bdd664b894e2b6e50e1202e353179173a | 1721 | 84 |     TFBaseModelOutputWithPastAndCrossAttentions,     TFBaseModelOutputWithPoolingAndCrossAttentions,     TFCausalLMOutputWithCrossAttentions,     TFMaskedLMOutput,     TFMultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/qwen3_moe/modeling_qwen3_moe.py | d5a21d065ff83094d617606ce0db5bb43bd4641f7c1334d0cb1f532f7a0afb7e | 713 | 28 |     GradientCheckpointingLayer, ) from ...modeling_outputs import MoeCausalLMOutputWithPast, MoeModelOutputWithPast from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update from ... |
| .venv/lib/python3.13/site-packages/transformers/models/qwen3_moe/modular_qwen3_moe.py | 9a244a24ee5dbf59580552464c27e41f0d0ee4582626f9658e548fd35dcccce4 | 297 | 12 | from ...cache_utils import Cache from ...modeling_flash_attention_utils import FlashAttentionKwargs from ...modeling_outputs import MoeCausalLMOutputWithPast, MoeModelOutputWithPast from ...processing |
| .venv/lib/python3.13/site-packages/transformers/models/qwen3_moe/configuration_qwen3_moe.py | 0d0cc24a2c28d527cfac452bff0255d7837ca8cee254022e8460c8b7b0593c7c | 241 | 18 |         hidden_act (`str` or `function`, *optional*, defaults to `"silu"`):             The non-linear activation function (function or string) in the decoder.         max_position_embeddings (`int`,  |
| .venv/lib/python3.13/site-packages/transformers/models/seggpt/image_processing_seggpt.py | f506bff89b00b81768dc973fd19fe35ca1549fc18e2bdbf5d68b2c50b0019d24 | 616 | 7 | # See the License for the specific language governing permissions and # limitations under the License. """Image processor class for SegGPT."""  from typing import Optional, Union |
| .venv/lib/python3.13/site-packages/transformers/models/seggpt/__init__.py | 47357c0ca097d653961aa5efd81944d51ed3e10b8471d600572fdcb1c70bbc4c | 29 | 3 |  if TYPE_CHECKING:     from .configuration_seggpt import *     from .image_processing_seggpt import *     from .modeling_seggpt import * |
| .venv/lib/python3.13/site-packages/transformers/models/seggpt/configuration_seggpt.py | 55e1e8a1c6e5b7e108445f853bc264ad51947013ca6d73d60093255d1965cf8e | 144 | 25 | # See the License for the specific language governing permissions and # limitations under the License. """SegGpt model configuration"""  from ...configuration_utils import PretrainedConfig |
| .venv/lib/python3.13/site-packages/transformers/models/seggpt/modeling_seggpt.py | ff5f39d63d879b36992793f903e3b71c2e2f6e922ca7a6913b5ffec263a50138 | 981 | 184 | # See the License for the specific language governing permissions and # limitations under the License. """PyTorch SegGpt model."""  import collections.abc |
| .venv/lib/python3.13/site-packages/transformers/models/swin2sr/configuration_swin2sr.py | e99455232a3acf5a10bcf9b5dd0be4ad670aa5fd6a8cc7f442ac2674731dbeda | 155 | 9 |             The number of output channels. If not set, it will be set to `num_channels`.         embed_dim (`int`, *optional*, defaults to 180):             Dimensionality of patch embedding.          |
| .venv/lib/python3.13/site-packages/transformers/models/swin2sr/modeling_swin2sr.py | 0bc0b3c1a5c5858708c7fa6c4ba4c4e187b7419c009e110997c66d35c14a0fdd | 1106 | 51 |   class Swin2SREmbeddings(nn.Module):     """     Construct the patch and optional position embeddings. |
| .venv/lib/python3.13/site-packages/transformers/models/mbart/configuration_mbart.py | 6963568e99878ef4551fa870e8971c02c5db6a6783dbe7d7071baf77bc53991f | 392 | 10 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/mbart/modeling_flax_mbart.py | cca2f28b606e8483520d853e59f172e3c2d2cf3f6124106847711999e0411512 | 1781 | 46 |     FlaxBaseModelOutput,     FlaxBaseModelOutputWithPastAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions,     FlaxSeq2SeqLMOutput,     FlaxSeq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/mbart/modeling_mbart.py | d02f832423fd7ef33546276af3fb023aebd8ddafee5f693b7a726cf97125966c | 1911 | 75 |     BaseModelOutput,     BaseModelOutputWithPastAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     Seq2SeqLMOutput,     Seq2SeqModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/mbart/modeling_tf_mbart.py | 53f2c1ff3ecd369e404a841fd0775f10f74fa4bfca99e10ff8027c0bad125479 | 1573 | 56 |     unpack_inputs, ) from ...tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax from ...utils import (     add_code_sample_docstrings, |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/__init__.py | ba90607cc552cc5331359612778017346bddd089301d9fb281f75fdf8b2b69fa | 50 | 1 |     from .efficientformer import *     from .ernie_m import *     from .gptsan_japanese import *     from .graphormer import *     from .jukebox import * |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/graphormer/collating_graphormer.py | 0c50e3af4b3b07f846e09ddfa123900e8cb998532caec2b53024eafc7c1703e2 | 136 | 2 |         edge_attr = np.asarray(item["edge_attr"], dtype=np.int64)     else:         edge_attr = np.ones((len(item["edge_index"][0]), 1), dtype=np.int64)  # same embedding for all      if keep_features |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/graphormer/configuration_graphormer.py | be0e8eff063e5e7fda4d54e0e574d8a8d444a330289922c21d5a3f7621fd3dab | 221 | 18 |             Maximum number of nodes which can be parsed for the input graphs.         share_input_output_embed (`bool`, *optional*, defaults to `False`):             Shares the embedding layer between |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/graphormer/modeling_graphormer.py | 41b40d9a22b379da482daad7868162651f4c700dbd409d70fde2760d568c7694 | 913 | 68 |     Remarks:         - Module weights must have the right sizes wrt the block size         - Only Linear, Embedding and Conv2d modules are supported for the moment         - For more detail on how to  |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/trajectory_transformer/modeling_trajectory_transformer.py | 83920968be50675643cdadc60e30f9329a915742764ca82cfbe3cb30e01baa02 | 603 | 28 |         pointer = model         for m_name in name:             if re.fullmatch(r"[A-Za-z]+_\d+", m_name):                 scope_names = re.split(r"_(\d+)", m_name)             else: |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/trajectory_transformer/configuration_trajectory_transformer.py | 1049124d7fecc3679898da98bad8f569cc6366794cfa3165744b6ac9c3b0264a | 156 | 7 |             Number of attention heads for each attention layer in the Transformer encoder.         n_embd (`int`, *optional*, defaults to 128):             Dimensionality of the embeddings and hidden  |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py | 783f115b1b8d87e39583705643c2094c83ff19330c082114abf48af01424ba20 | 2306 | 168 | XLM_PROPHETNET_START_DOCSTRING = r"""     This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the     library implements for all its model (such as |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py | e66d39deef58f4d11b982509961a6b186742f19ad7cbd564645dd41a0ddfb26a | 323 | 1 |             self.fairseq_tokens_to_ids[tok] = 5 + i          # The first "real" token "," has position 15 in the embedding vocab and position 3 in the spm vocab         self.fairseq_offset = 12        |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/xlm_prophetnet/configuration_xlm_prophetnet.py | 7853288931f9a8528be91d1a2e157dfaea94bc1da8555720ac089aeb0b8b9c06 | 182 | 5 |             The dropout ratio for the attention probabilities.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/qdqbert/configuration_qdqbert.py | 1c2bd2a39369a2ca405158a726ef0d106b43a3839ad8a1d05feff591390503a8 | 124 | 5 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/qdqbert/modeling_qdqbert.py | 0f1743d9eefb1f28c78eb8731dfa5d4cddd7fcac377f1ae735608c02b3629507 | 1737 | 88 |     BaseModelOutputWithPastAndCrossAttentions,     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/nat/configuration_nat.py | ed96577ec7b1d017d34391cc748362b766800b58ffea67b7d1cb57e080ccdf9a | 149 | 3 |             The number of input channels.         embed_dim (`int`, *optional*, defaults to 64):             Dimensionality of patch embedding.         depths (`list[int]`, *optional*, defaults to `[3 |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/nat/modeling_nat.py | ca4788227361b472792588addb68f9b24e4d0f67db43070735cbcc2d21923c30 | 954 | 45 |             Sequence of hidden-states at the output of the last layer of the model.         hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed o |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/open_llama/configuration_open_llama.py | 230a71b316bce6352e92b55cb559e1cf5cceb300d1f3cf5961c5db5baf9bc6e0 | 170 | 24 | # Copyright 2023 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/open_llama/modeling_open_llama.py | d6cadb076d3b8a970f045b770dfbc57f8229d2bf76268dbbced47bc2abf5f035 | 941 | 57 | # Copyright 2023 EleutherAI and the HuggingFace Inc. team. All rights reserved. # # This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX # and OPT implementations in this library. It h |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py | c814ef4c0174a8196a3d4e54e2643d27bdf7c33cd899f89b3204e5827c9ad54f | 1304 | 96 |      if hasattr(model, "transformer"):         # We are loading in a TransfoXLLMHeadModel => we will load also the Adaptive Softmax         tf_to_pt_map.update(             { |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py | 8f8ca857d61143ac6ba165755d74c8607e3a10429780503dff1f182081aeefa4 | 1129 | 44 |   class TFPositionalEmbedding(keras.layers.Layer):     def __init__(self, demb, **kwargs):         super().__init__(**kwargs) |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/transfo_xl/configuration_transfo_xl.py | e6552c354ceb9b0df05b0ff7e6ce134205d085fec2f90a2f14390bb3b47be08a | 190 | 6 |             Dimensionality of the model's hidden states.         d_embed (`int`, *optional*, defaults to 1024):             Dimensionality of the embeddings         n_head (`int`, *optional*, defaults |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py | 3dc50407613f664ac20e2c96871b556870b7a1ae831c40507e36bbd9567ae5b0 | 826 | 2 |     def move_added_token(self, token: str, target_idx: int):         """         Moves an added token to a specific position in the vocab. This method should be used when resizing an embedding         |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/ernie_m/modeling_ernie_m.py | 1a5254c2c019c286a0372c81f67191bb2ca381da8f9c5b81441db964eaa30c3e | 1062 | 63 |   # Adapted from paddlenlp.transformers.ernie_m.modeling.ErnieEmbeddings class ErnieMEmbeddings(nn.Module):     """Construct the embeddings from word and position embeddings.""" |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/ernie_m/tokenization_ernie_m.py | b1edde604cc5adf6b567f5e795af65edce16b1705e17881e3d7561d237fcd4ae | 410 | 1 |     """      # Ernie-M model doesn't have token_type embedding.     model_input_names: list[str] = ["input_ids"]  |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/ernie_m/configuration_ernie_m.py | 8cf9925a6a37f28bc88b2af321c1ef9e3f8275b9f3aa4a2009370290f3ec7f4a | 113 | 7 |     Args:         vocab_size (`int`, *optional*, defaults to 250002):             Vocabulary size of `inputs_ids` in [`ErnieMModel`]. Also is the vocab size of token embedding matrix.             Defi |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/van/modeling_van.py | 0303b8fb89c2d1692d9d71880a83b91dbb80284557eab30250743205e44ed307 | 542 | 3 |     ):         super().__init__()         self.embeddings = VanOverlappingPatchEmbedder(in_channels, hidden_size, patch_size, stride)         self.layers = nn.Sequential(             *[ |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/van/configuration_van.py | 7d37da0a1987bb0daaa22fe6671210c541fb26855105d900dfc47fa8f6eb7371 | 111 | 2 |             The number of input channels.         patch_sizes (`list[int]`, *optional*, defaults to `[7, 3, 3, 3]`):             Patch size to use in each stage's embedding layer.         strides (`li |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/tvlt/configuration_tvlt.py | 3da2573edb42c38b7cdf63eaa35a55d0c0586bd7fea039637e67364813055c22 | 188 | 1 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/tvlt/image_processing_tvlt.py | cf07c3ea9abfae900a97436cfd72259ac35754cadf3d9f0a3f3cb86bf3cc1d3e | 439 | 2 |             `size` in the `preprocess` method.         patch_size (`list[int]` *optional*, defaults to [16,16]):             The patch size of image patch embedding.         num_frames (`int` *optiona |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/tvlt/modeling_tvlt.py | 958a3fe1580ba0ab487069b01f943984c83eb72034bca3abad95a86030614ca7 | 1276 | 71 |             Tensor containing the ids permutation of audio masking.         hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.o |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/tvlt/feature_extraction_tvlt.py | 0e7981f11225a1a4df99f6082932fef61306b95b56320c1acc8262871fba7717 | 234 | 1 |             Number of audio channels.         patch_size (`list[int]` *optional*, defaults to `[16, 16]`):             The patch size of audio patch embedding.         feature_size (`int`, *optional*, |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/mctct/feature_extraction_mctct.py | 9fa24e87b329e88a9f1934d92a9349c7d103c9ab72a313f90cc161bc49288cef | 292 | 1 |     def _extract_mfsc_features(self, one_waveform: np.array) -> np.ndarray:         """         Extracts MFSC Features for one waveform vector (unbatched). Adapted from Flashlight's C++ MFSC code.     |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/mctct/configuration_mctct.py | b1ee674e4741b225894fd78621bb008eee28955fdff8675d503b5b6b71d44849 | 185 | 5 |         attention_head_dim (`int`, *optional*, defaults to 384):             Dimensions of each attention head for each attention layer in the Transformer encoder.         max_position_embeddings (`in |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/mctct/modeling_mctct.py | e5b91e9eba861041ea8a9d575744842dbb2bf86775f74eeabcd242a0bc6adbdc | 780 | 43 | from ....modeling_attn_mask_utils import _prepare_4d_attention_mask from ....modeling_layers import GradientCheckpointingLayer from ....modeling_outputs import BaseModelOutput, CausalLMOutput from ... |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/nezha/configuration_nezha.py | 819bdbdcd5626e22e632b4eb8f394a7028660444fa74e8720100a31450f2a746 | 106 | 5 |             The non-linear activation function (function or string) in the encoder and pooler.         hidden_dropout_prob (`float`, optional, defaults to 0.1):             The dropout probability for |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/nezha/modeling_nezha.py | c2f2290c0b1f0447763949821c70b9f6bbe89844b97cec8c6ac489d39a32b27e | 1690 | 56 |         pointer = model         for m_name in name:             if re.fullmatch(r"[A-Za-z]+_\d+", m_name):                 scope_names = re.split(r"_(\d+)", m_name)             else: |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/mmbt/configuration_mmbt.py | 50d92c56c4a63fa7bfe76be57f9a5af444e0890c3a336a4cda8715c6ae767d66 | 46 | 1 |             Size of final Linear layer for classification.         modal_hidden_size (`int`, *optional*, defaults to 2048):             Embedding dimension of the non-text modality encoder.     """  |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/mmbt/modeling_mmbt.py | c6297bb96e50d5f1e8fb4ca8e1e0b42ba7a037eb0ed0b6aca81c5edb0a7d9d31 | 411 | 72 |   class ModalEmbeddings(nn.Module):     """Generic Modal Embeddings which takes in an encoder, and a transformer embedding."""  |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/mega/configuration_mega.py | 9d6764fb33efa5223b52651e5e70a503093e8445c23397f9bede31c49c8013f1 | 244 | 7 |             The dropout probability for EMA self-attention         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/mega/modeling_mega.py | 8adf8f79c183c8302e398e11bc6cab276dd4ea82948bc353bd6f9ed667321e10 | 2277 | 68 | from ....modeling_outputs import (     BaseModelOutputWithPoolingAndCrossAttentions,     CausalLMOutputWithCrossAttentions,     MaskedLMOutput,     MultipleChoiceModelOutput, |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/jukebox/configuration_jukebox.py | 7adafec8ca75b7ce7513aa265d5f59ad976bb902fb3640359627c1bbd87a7fa0 | 614 | 9 |             Number of layers of the transformer architecture.         emb_dropout (`int`, *optional*, defaults to 0):             Embedding dropout used in the lyric decoder.         encoder_config (` |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/jukebox/modeling_jukebox.py | 4ec29d08288eae96eea04736703655e75f09c8e815ee6928154a1b8dc16bd150 | 2671 | 36 |      def dequantise(self, music_tokens):         dequantised_states = F.embedding(music_tokens, self.codebook)         return dequantised_states  |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/tapex/tokenization_tapex.py | 9ab464c203ca1f2554a4e298488d76c7dfcf82bdd8caff2e59c78f171296b88f | 1471 | 1 |     the tokenizer for instance to prepare them for the model.      Tokenization itself is based on the BPE algorithm. It is identical to the one used by BART, RoBERTa and GPT-2.      This tokenizer in |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/vit_hybrid/configuration_vit_hybrid.py | 1287fa07ffeabaefb6036483c3b7ab843ea0a2095b755b20077c2a246129f561 | 181 | 3 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.0):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/vit_hybrid/modeling_vit_hybrid.py | 24271b12b455d5f34bf843677f4bc66fce5cca39eee123a5fc78c6fbbc136908 | 764 | 51 |   class ViTHybridEmbeddings(nn.Module):     """     Construct the CLS token, position and patch embeddings. Optionally, also the mask token. |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/deta/modeling_deta.py | bed56c92460e51301d8a039b16955ab3aa6593d7646b6c53a2670577be12c855 | 2817 | 115 |             Stacked intermediate reference points (reference points of each layer of the decoder).         hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=Tr |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/deta/configuration_deta.py | 1efaf8419008aee430facec2d896ab1b0033ad7cea83c154e340a8ea0ec78657 | 279 | 9 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         dropout (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in the embeddi |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/retribert/configuration_retribert.py | 9c0aac2822f8e8dd9e27095cc9f0ecda28ea096a3b483b0e227ab8aceb03021b | 109 | 5 |             `"relu"`, `"silu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/retribert/modeling_retribert.py | 3f33ff8f83d345bd302e962f4b703a0fd0a3445353fa073df4c668b352f0051f | 218 | 8 |             if module.bias is not None:                 module.bias.data.zero_()         elif isinstance(module, nn.Embedding):             module.weight.data.normal_(mean=0.0, std=self.config.initial |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/speech_to_text_2/configuration_speech_to_text_2.py | d277fc56b85eb9cff77e96617377cd15f774e5f5cb7cabc27ba9fd07984070d0 | 135 | 7 | class Speech2Text2Config(PretrainedConfig):     r"""     This is the configuration class to store the configuration of a [`Speech2Text2ForCausalLM`]. It is used to     instantiate an Speech2Text2 mode |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/speech_to_text_2/modeling_speech_to_text_2.py | df269c64074f28f86fbd2eb4412a3677c2e53c3e25f54a059a0488931c9b4733 | 905 | 42 | from ....modeling_attn_mask_utils import _prepare_4d_attention_mask, _prepare_4d_causal_attention_mask from ....modeling_layers import GradientCheckpointingLayer from ....modeling_outputs import BaseM |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/efficientformer/configuration_efficientformer.py | 96247d08e64cd5636dd42a7b2ed6348419b81d0c5c15c4d230be52a24abc2707 | 171 | 1 |             Ratio of size of the hidden dimensionality of an MLP to the dimensionality of its input.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probabi |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/efficientformer/modeling_efficientformer.py | 2fbd19fe00768609b17e39187b394a45b41b3999ca768a940a15c091cd76c250 | 808 | 10 |   class EfficientFormerPatchEmbeddings(nn.Module):     """     This class performs downsampling between two stages. For the input tensor with the shape [batch_size, num_channels, |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/efficientformer/modeling_tf_efficientformer.py | e6f1da6e5ff7e829a1aaf597a0fd8bc5b9e8f62d0c5ec284ad0b58e37f9b7fe5 | 1199 | 10 |   class TFEfficientFormerPatchEmbeddings(keras.layers.Layer):     """     This class performs downsampling between two stages. For the input tensor with the shape [batch_size, num_channels, |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/realm/configuration_realm.py | d429a710a089c9852679d3f9a5772f2f0ad3d9384d0f76077ae1df684a24cf73 | 170 | 5 |             `"relu"`, `"selu"` and `"gelu_new"` are supported.         hidden_dropout_prob (`float`, *optional*, defaults to 0.1):             The dropout probability for all fully connected layers in |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/realm/modeling_realm.py | 60fca30b1b54beb2b5d895e0eb27f0714b43fd58e2fc7210fcb31df1fcec0245 | 1855 | 103 |         pointer = model         for m_name in name:             if re.fullmatch(r"[A-Za-z]+_\d+", m_name):                 scope_names = re.split(r"_(\d+)", m_name)             else: |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/gptsan_japanese/modeling_gptsan_japanese.py | ec57fa10d50d68df86de22dea0a29ada2d662aee0ba8850d58b8853183e783f4 | 1331 | 133 | # See the License for the specific language governing permissions and # limitations under the License. """PyTorch GPTSANJapanese model."""  from typing import Optional, Union |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/gptsan_japanese/__init__.py | 434288fccb8c45b40d281cd8384b0380d64b92d1948d3516966fb5f9399d01e1 | 29 | 3 |  if TYPE_CHECKING:     from .configuration_gptsan_japanese import *     from .modeling_gptsan_japanese import *     from .tokenization_gptsan_japanese import * |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/gptsan_japanese/tokenization_gptsan_japanese.py | e5280596bb53f2a09751acbaa5a2a21085bc87a6e1f4d37daeae4127e89270c2 | 519 | 20 | # See the License for the specific language governing permissions and # limitations under the License. """Tokenization classes for GPTSANJapanese."""  import collections |
| .venv/lib/python3.13/site-packages/transformers/models/deprecated/gptsan_japanese/configuration_gptsan_japanese.py | 5106f3af662be04923660504d218fc1d8b9e9500d9662d1bee7c3fbf0b4ebef9 | 158 | 16 | # See the License for the specific language governing permissions and # limitations under the License. """GPTSAN-japanese model configuration"""  from ....configuration_utils import PretrainedConfig |
| .venv/lib/python3.13/site-packages/transformers/models/xglm/modeling_flax_xglm.py | 04b5bdeb98a4d2244347d7c66dbc3cd92cae0f136cffff6a29d43164b3eaed72 | 804 | 30 | from ...modeling_flax_outputs import (     FlaxBaseModelOutputWithPastAndCrossAttentions,     FlaxCausalLMOutputWithCrossAttentions, ) from ...modeling_flax_utils import ACT2FN, FlaxPreTrainedModel, a |
| .venv/lib/python3.13/site-packages/transformers/models/xglm/modeling_tf_xglm.py | 08731df769d8f94b0703e94f0ca38a76b3d71ca5055a1dffec20c41af9b3cb71 | 1003 | 34 |     replace_return_docstrings, ) from ...modeling_tf_outputs import TFBaseModelOutputWithPastAndCrossAttentions, TFCausalLMOutputWithCrossAttentions from ...modeling_tf_utils import (     TFCausalLang |
| .venv/lib/python3.13/site-packages/transformers/models/xglm/configuration_xglm.py | 9b4b1f3d87f4a8a974a53f6c39ddecb2842fd77cade485919d49f5d5a1836b54 | 140 | 10 |             Vocabulary size of the XGLM model. Defines the number of different tokens that can be represented by the             `inputs_ids` passed when calling [`XGLMModel`] or [`FlaxXGLMModel`].    |
| .venv/lib/python3.13/site-packages/transformers/models/xglm/modeling_xglm.py | 5180bb14e5344ab6bca7f9d19c44ef1c3106c294df01eae2fad4b9e629bf0f0b | 712 | 46 | from ...modeling_attn_mask_utils import _prepare_4d_attention_mask, _prepare_4d_causal_attention_mask from ...modeling_layers import GradientCheckpointingLayer from ...modeling_outputs import BaseMode |
| .venv/lib/python3.13/site-packages/transformers/integrations/bitnet.py | f8043b2426bb70e72eab8b46ade560c8c13f93b8b70f9055513f4e60cfad83ec | 429 | 1 |     The function will be run recursively and replace all `torch.nn.Linear` modules except for the `lm_head` that should     be kept as a `torch.nn.Linear` module. The replacement is done under `init_e |
| .venv/lib/python3.13/site-packages/transformers/integrations/finegrained_fp8.py | 025851c6387b6e39fed03c289cdad68625ed05088296bac5de11c97f776560bc | 427 | 1 |     stride_Bs_k,     stride_Bs_n,     # Meta-parameters     BLOCK_SIZE_M: tl.constexpr,     BLOCK_SIZE_N: tl.constexpr, |
| .venv/lib/python3.13/site-packages/transformers/integrations/deepspeed.py | 8a808305b15d77347f4dc76d688ff1e2bec3670fab39c4927f1f79aa2d7194c4 | 504 | 1 |      A `weakref` of this object is stored in the module's globals to be able to access the config from areas where     things like the Trainer object is not available (e.g. `from_pretrained` and `_get |
| .venv/lib/python3.13/site-packages/transformers/integrations/higgs.py | 1c72edcddda4c0cd8255217ae32c401b413cb077f9603dbaead08066261ce5f6 | 658 | 2 | # See the License for the specific language governing permissions and # limitations under the License. "HIGGS through FLUTE (Flexible Lookup Table Engine for LUT-quantized LLMs) integration file"  fro |
| .venv/lib/python3.13/site-packages/transformers/integrations/peft.py | a0b086edbbd7b4497b908c0e23c0c1cb7be5427dd98016b6412a68cdd6389241 | 625 | 19 | if is_accelerate_available():     from accelerate import dispatch_model     from accelerate.utils import get_balanced_memory, infer_auto_device_map  # Minimum PEFT version supported for the integratio |
| .venv/lib/python3.13/site-packages/transformers/integrations/__init__.py | c19c06c5aa86b894379d73f03ae746bcacb46712294342231888f3f3a25e33ae | 311 | 2 |     ],     "mxfp4": [         "Mxfp4GptOssExperts",         "convert_moe_packed_tensors",         "dequantize", |
| .venv/lib/python3.13/site-packages/transformers/integrations/vptq.py | 85ee985f69e11eed2407303df85e9053e5848c4322d01eeffffcc42539fae97f | 102 | 3 | # See the License for the specific language governing permissions and # limitations under the License. "VPTQ (Vector Post-Training Quantization) integration file"  import torch.nn as nn |
| .venv/lib/python3.13/site-packages/transformers/integrations/tensor_parallel.py | 8c5c21c030a2b7e8ff21a42d1f478369d499fdcc1c3bf5f44983442582e65de9 | 1107 | 6 | class RowwiseParallel(TensorParallelLayer):     """     Partition a compatible nn.Module in a row-wise fashion. Currently supports nn.Linear and nn.Embedding.     Users can compose it with ColwisePara |
| .venv/lib/python3.13/site-packages/transformers/integrations/fbgemm_fp8.py | 8f04e2f210bf635d9848a92d5ea524b420ad97fa8ef8d731deebc8c857278b5a | 285 | 2 |         output_shape = (*x.shape[:-1], -1)         # x_quantized and x_scale are not necessarily on the same device as x, this is an issue.         # https://github.com/pytorch/FBGEMM/blob/e08af8539c3 |
| .venv/lib/python3.13/site-packages/transformers/integrations/eetq.py | c29a1f772e791dcbda4da397acefd531b986d517e5cbe90dd497f33b1c395f45 | 122 | 2 |     A helper function to replace all `torch.nn.Linear` modules by `eetq.EetqLinear` modules from the `eetq`     library. This will enable running your models using high performance int8 weight-only ge |
| .venv/lib/python3.13/site-packages/transformers/integrations/awq.py | 8080043a3dd37a977f79069d05b3e478ca519477378ade2d0c5cd07fc5ce285e | 499 | 5 |     "falcon": {"act": "act", "layer_before_act": "dense_h_to_4h"},     "mpt": {"act": "act", "layer_before_act": "up_proj"},     "gptj": {"act": "act", "layer_before_act": "fc_in"},     "gpt_neox": {" |
| .venv/lib/python3.13/site-packages/transformers/integrations/ggml.py | a3acd38c840f4a8250530ba4c51a4c98c620d755367a4a22bf2d99a3935108e3 | 754 | 45 |  from .. import AddedToken from ..convert_slow_tokenizer import GemmaConverter, GPT2Converter, LlamaConverter, Qwen2Converter, T5Converter from ..utils import logging from ..utils.logging import tqdm |
| .venv/lib/python3.13/site-packages/transformers/integrations/bitsandbytes.py | 511ec139809c9d80e08b2ae6cd7ccb4391087532bc1f1b4d943b5930da9e547a | 543 | 17 |                 new_value = torch.tensor(value, device="cpu")              # Support models using `Conv1D` in place of `nn.Linear` (e.g. openai-community/gpt2) by transposing the weight matrix prior t |
| .venv/lib/python3.13/site-packages/transformers/integrations/executorch.py | 7cc311f22e4c2259ca7f659d574779d52c301941448bcd062797622c0a3e59cf | 1202 | 11 |     This class handles the export of three main components:         1. Vision encoder (processes images to visual features)         2. Connector/projector (maps visual features to text embedding space |
| .venv/lib/python3.13/site-packages/transformers/integrations/mxfp4.py | cac7e6ce1ae495f04b4c05c0443e88e1c9796dc1b29eec853c7449d30edc8b31 | 476 | 11 |   # Copied from GPT_OSS repo and vllm def quantize_to_mxfp4(w, triton_kernels_hub):     downcast_to_mxfp_torch = triton_kernels_hub.numerics_details.mxfp.downcast_to_mxfp_torch |
| .venv/lib/python3.13/site-packages/transformers/integrations/integration_utils.py | dc5b8d1707da0f8456a873f485456304effbaccc3f0bfecfb43be7cf12c381a9 | 2514 | 30 | def run_hp_search_optuna(trainer, n_trials: int, direction: str, **kwargs) -> BestRun:     import optuna     from accelerate.utils.memory import release_memory      if trainer.args.process_index == 0: |
| .venv/lib/python3.13/site-packages/transformers/commands/serving.py | 06fc0d0b4493f8bb682a04279fb449f9b86bbb801111f41f65f0980aa015ff66 | 1628 | 24 |  class Modality(enum.Enum):     LLM = "LLM"     VLM = "VLM"     STT = "STT" |
| .venv/lib/python3.13/site-packages/transformers/commands/convert.py | 221caa2aa3b7dda9c9888c2778e042a20c5110991f1fba883ffdc0b76c67a151 | 166 | 8 |              convert_tf_checkpoint_to_pytorch(self._tf_checkpoint, self._config, self._pytorch_dump_output)         elif self._model_type == "gpt":             from ..models.openai.convert_openai_orig |
| .venv/lib/python3.13/site-packages/transformers/commands/chat.py | edecc3c61eee6550518a5fe28ad68d1e48a57d761fe026dae66e32ea1a3de926 | 754 | 6 |      from transformers import (         AutoModelForCausalLM,         AutoTokenizer,         BitsAndBytesConfig, |
| .venv/lib/python3.13/site-packages/transformers/generation/configuration_utils.py | 69cb5c4b5ae2bf46e9a634efbb674a8c7f334472a0ced36bbfa81d003b606afb | 1548 | 15 |         bad_words_ids (`list[list[int]]`, *optional*):             List of list of token ids that are not allowed to be generated. Check             [`~generation.NoBadWordsLogitsProcessor`] for furth |
| .venv/lib/python3.13/site-packages/transformers/generation/flax_utils.py | 334e02866e92d0488682df5748113bd2248bf186071a1bb841e02c157d5d0422 | 1033 | 4 |             if generation_config.max_length == GenerationConfig().max_length:                 generation_config.max_length = generation_config.max_length + input_ids_seq_length                 max_pos |
| .venv/lib/python3.13/site-packages/transformers/generation/logits_process.py | 90e5f20ab9354798e14cb78af2bb0e70c94f32b4c515e02789040d22e0c723ce | 3242 | 95 |     r"""     [`LogitsProcessor`] enforcing a min-length by setting EOS probability to 0. Note that, for decoder-only models     like most LLMs, the length includes the prompt.      Args: |
| .venv/lib/python3.13/site-packages/transformers/generation/tf_logits_process.py | abd298e85c7aa5f435e7fecb9bfa000f8fc4cabdc0a4ce299a18de35c35e1783 | 601 | 1 |   class TFNoBadWordsLogitsProcessor(TFLogitsProcessor):     """     [`TFLogitsProcessor`] that enforces that specified sequences will never be sampled. |
| .venv/lib/python3.13/site-packages/transformers/generation/stopping_criteria.py | 16a37bccfe2a94fb7d19246d89b0621daa5c8dccb7035419208551024e973164 | 521 | 42 |  logger = logging.get_logger(__name__) # We maintain a module-level cache of the embedding vectors for the stop string criterion # because they are slow to compute STOP_STRING_EMBEDDING_CACHE = Ordere |
| .venv/lib/python3.13/site-packages/transformers/generation/candidate_generator.py | 688b6f5a12c0dd2e0713b9aba3ec12b2782c64171033dacc382c802ce91024e0 | 1219 | 26 |   class _MapInputEmbedding(nn.Module):     def __init__(self, original_embedding: nn.Embedding, assistant_overlap_token_ids):         """ |
| .venv/lib/python3.13/site-packages/transformers/generation/watermarking.py | 21b4ff68d6a6f324c5099974a17a722c38b88a5667c88ab248728eaba3f2fbe1 | 550 | 6 |      ```python     >>> from transformers import AutoTokenizer, AutoModelForCausalLM, WatermarkDetector, WatermarkingConfig      >>> model_id = "openai-community/gpt2" |
| .venv/lib/python3.13/site-packages/transformers/generation/__init__.py | 0d7df361c35e2958d68f379ac7dd8be9edf133cccd402f9686a66b492d49a39b | 353 | 4 |         "MinNewTokensLengthLogitsProcessor",         "MinPLogitsWarper",         "NoBadWordsLogitsProcessor",         "NoRepeatNGramLogitsProcessor",         "PrefixConstrainedLogitsProcessor", |
| .venv/lib/python3.13/site-packages/transformers/generation/beam_search.py | 69244f1f0d55a7ca22091ff81d270c31cebaa1fb72f1a7550268fcd3fd4e6c00 | 1014 | 1 |      Adapted in part from [Facebook's XLM beam search     code](https://github.com/facebookresearch/XLM/blob/9e6f6814d17be4fe5b15f2e6c43eb2b2d76daeb4/src/model/transformer.py#L529).      Reference for |
| .venv/lib/python3.13/site-packages/transformers/generation/streamers.py | 323fdb3c53c2878db6e59fe814b739c0b7a024f094cc5f37a69a230dd875f660 | 319 | 18 |          ```python         >>> from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer          >>> tok = AutoTokenizer.from_pretrained("openai-community/gpt2") |
| .venv/lib/python3.13/site-packages/transformers/generation/utils.py | df1d630d771f802e7f0f9dbc8ded9bbfb5197714a5faa8ee307079457bd6860e | 4505 | 43 |     MinNewTokensLengthLogitsProcessor,     MinPLogitsWarper,     NoBadWordsLogitsProcessor,     NoRepeatNGramLogitsProcessor,     PrefixConstrainedLogitsProcessor, |
| .venv/lib/python3.13/site-packages/transformers/generation/tf_utils.py | e81e3cbb70a908eec012d49d852c4e8cd55fa83a73708210a8d47d3664d409ba | 3133 | 43 | from tensorflow.compiler.tf2xla.python.xla import dynamic_update_slice  from ..modeling_tf_outputs import TFCausalLMOutputWithPast, TFSeq2SeqLMOutput from ..models.auto import (     TF_MODEL_FOR_CAUSA |
| .venv/lib/python3.13/site-packages/transformers/generation/beam_constraints.py | 72da73e8f601167c895974bbb6064f1be7d14f33247f6a8ea0acc6c162b62704 | 525 | 1 |     def reset(self):         """         Resets the state of this constraint to its initialization. We would call this in cases where the fulfillment of         a constraint is abrupted by an unwanted |
| .venv/lib/python3.13/site-packages/transformers/generation/continuous_batching/cache.py | e72d437cb3f68ba950876860e9ee07ec0629bfe094616a4d17617407f35a62ce | 397 | 68 | from ...generation.configuration_utils import GenerationConfig from ...utils.metrics import attach_tracer, traced from .classes import RequestState, get_device_and_memory_breakdown, logger   |
| .venv/lib/python3.13/site-packages/transformers/generation/continuous_batching/scheduler.py | 67c1eedb0b55665298e1c662738a51fe87b3da915551964739530446678ac7f7 | 315 | 17 |      @abstractmethod     def schedule_batch(self, token_budget: int) -> list[RequestState]:         pass  |
| .venv/lib/python3.13/site-packages/transformers/generation/continuous_batching/classes.py | 17fccd97e89e5ad03ef8fd3f597e0397b251e2524c68a880155e5b79866e8a19 | 211 | 20 |  @staticmethod def get_device_and_memory_breakdown() -> tuple[torch.device, int, int, int]:     if torch.cuda.is_available():         device = torch.device("cuda") |
| .venv/lib/python3.13/site-packages/transformers/generation/continuous_batching/continuous_api.py | b06f4c897612c6b4285acbb800e1a1a9da3a6bafb6107828720c7a7794839d89 | 843 | 8 | from ...utils.metrics import ContinuousBatchProcessorMetrics, attach_tracer, traced from .cache import PagedAttentionCache from .classes import GenerationOutput, RequestState, RequestStatus, get_devic |
| .venv/lib/python3.13/site-packages/jsonschema/validators.py | 008d1b42b189a6f107d5148edf29f059c36f7e4a8de9624f832cb454ded69521 | 1411 | 6 | def _warn_for_remote_retrieve(uri: str):     from urllib.request import Request, urlopen     headers = {"User-Agent": "python-jsonschema (deprecated $ref resolution)"}     request = Request(uri, heade |
| .venv/lib/python3.13/site-packages/jsonschema/_format.py | 8a9d4dd7a08104e6fff2c33f89e8f25b4539258f645e8cf73bf0058f5487165f | 547 | 1 |     if not isinstance(instance, str):         return True     return bool(_RE_DATE.fullmatch(instance) and date.fromisoformat(instance))   |
| .venv/lib/python3.13/site-packages/jsonschema/tests/test_deprecations.py | c86ea6911247a531db5a8c692c2e72e47edf93c7ab18eb3c7fff55e2d081121f | 433 | 1 |             # Request.get_header does not also normalize them...             (header, value), = request.header_items()             self.assertEqual(header.lower(), "user-agent")             self.asser |
| .venv/lib/python3.13/site-packages/jsonschema/benchmarks/nested_schemas.py | 9a8d3b771f82220992388eb608db38839c6ed45cc79252c1a644280f159870ab | 57 | 1 |         "https://json-schema.org/draft/2020-12/vocab/unevaluated": True,         "https://json-schema.org/draft/2020-12/vocab/validation": True,         "https://json-schema.org/draft/2020-12/vocab/me |
| .venv/lib/python3.13/site-packages/cyclonedx/schema/_res/bom-1.4.SNAPSHOT.schema.json | 8f780198a5cf710fca83d00c12f740e644c5bd04cb7240be26b0c36c75ff08dc | 1694 | 2 |           "$ref": "#/definitions/scoreMethod"         },         "vector": {           "type": "string",           "title": "Vector", |
| .venv/lib/python3.13/site-packages/cyclonedx/schema/_res/bom-1.5.SNAPSHOT.schema.json | 3ef35aa21345e71d20e934c47d8af0b9f43194171a3d6f8e0e34133bf2f1590e | 3797 | 7 |           ],           "title": "URL",           "description": "The URI (URL or URN) to the external reference. External references are URIs and therefore can accept any URL scheme including https ([ |
| .venv/lib/python3.13/site-packages/cyclonedx/schema/_res/bom-1.6.SNAPSHOT.schema.json | cb88c8121ae6be6ec0d2f01909b4458e12852f260b372f18d20e3dc2ef90ea15 | 5700 | 14 |       "type": "string",       "title": "BOM Serial Number",       "description": "Every BOM generated SHOULD have a unique serial number, even if the contents of the BOM have not changed over time. If |
| .venv/lib/python3.13/site-packages/cyclonedx/schema/_res/spdx.SNAPSHOT.schema.json | c41917196639055e9f9670811bac23ef777732144f3ff5a2f39686f61580dbe6 | 738 | 1 |     "Adobe-Glyph",     "Adobe-Utopia",     "ADSL",     "AFL-1.1",     "AFL-1.2", |
| .venv/lib/python3.13/site-packages/cyclonedx/model/crypto.py | 81ed05e6ce25752dba13d536298d0b9294dbd357434e9bc61b08f714bdde8844 | 1599 | 3 |     CREDENTIAL = 'credential'     DIGEST = 'digest'     INITIALIZATION_VECTOR = 'initialization-vector'     KEY = 'key'     NONCE = 'nonce' |
| .venv/lib/python3.13/site-packages/cyclonedx/model/vulnerability.py | db18febcb9d0f3b4be8b484178273056473d70cfdb98d181a4feffac289103d1 | 1368 | 44 |         History:         * In v1.4 JSON scheme, both properties were mandatory           https://github.com/CycloneDX/specification/blob/d570ffb8956d796585b9574e57598c42ee9de770/schema/bom-1.4.schema. |
| .venv/lib/python3.13/site-packages/pybase64/_fallback.py | 2fe8b92a746d2d4d8f7c16ca20bda13621e636b5acd4b796621df1183f26ae23 | 168 | 3 |         return s     try:         mv = memoryview(s)         if not mv.c_contiguous:             msg = f"{s.__class__.__name__!r:s}: underlying buffer is not C-contiguous" |
| .venv/lib/python3.13/site-packages/tqdm/std.py | b568f3ebe4026bdd9aa988f3ecf21d90b50201f8b2fa525985e06d672208c8ed | 1525 | 1 |     COLOUR_RGB = '\x1b[38;2;%d;%d;%dm'     COLOURS = {'BLACK': '\x1b[30m', 'RED': '\x1b[31m', 'GREEN': '\x1b[32m',                'YELLOW': '\x1b[33m', 'BLUE': '\x1b[34m', 'MAGENTA': '\x1b[35m',       |
| .venv/lib/python3.13/site-packages/tqdm/contrib/discord.py | 32d5482f5b3f7711f6d46e2c2fc141810e167a2db7868f449394fe0289a6bcd7 | 157 | 5 |  from requests import Session from requests.utils import default_user_agent  from ..auto import tqdm as tqdm_auto |
| .venv/lib/python3.13/site-packages/mypy/build.py | e1ad8bef735c2d430e80da5763dd9170c2879832a2c93bed43fa43f39b4921d3 | 3559 | 2 |         # processed. We store this in BuildManager so that we can compute         # dependencies as we go, which allows us to free ASTs and type information,         # saving a ton of memory on net.   |
| .venv/lib/python3.13/site-packages/mypy/options.py | e153b24310e4784e2f5dd98ea07dd0f6cc81b99f2c43fce6f44f29339951d2d5 | 626 | 8 |         "plugins",         "disable_bytearray_promotion",         "disable_memoryview_promotion",         "strict_bytes",     } |
| .venv/lib/python3.13/site-packages/mypy/checkstrformat.py | 94f962ec4dc38d5ee95e497540593f19cb6a07883fee647e8a377d5981a41dce | 1100 | 2 |     result: list[ConversionSpecifier] = []     for target, start_pos in top_targets:         match = FORMAT_RE_NEW.fullmatch(target)         if match:             conv_spec = ConversionSpecifier(match |
| .venv/lib/python3.13/site-packages/mypy/inspections.py | a460b5e7f160a880b3b627ee9f9bcfc1bf0578fb204f5558e0278589fed78bf4 | 627 | 1 |         if reload_needed:             # TODO: line/column are not stored in cache for vast majority of symbol nodes.             # Adding them will make thing faster, but will have visible memory impa |
| .venv/lib/python3.13/site-packages/mypy/memprofile.py | 02be05c1a54138de36893d8e1c7a23ebf1b954bd583673c0654fdca789a0965f | 123 | 5 | """Utility for dumping memory usage stats.  This is tailored to mypy and knows (a little) about which list objects are |
| .venv/lib/python3.13/site-packages/mypy/partially_defined.py | 332f1638a28dc71068feb8872cb9e9a32a75ccfa2cbeddcf6a9e628287ae6081 | 682 | 1 |             # after finally, we need to process try/except with branch skipping enabled.             # Therefore, we need to process try/finally twice.             # Because processing is not idempote |
| .venv/lib/python3.13/site-packages/mypy/semanal_classprop.py | f350a5475280dbb4c3108974e2f3777292cf4d5304269845886a789fcee44636 | 189 | 3 |     "builtins.float": "complex",     "builtins.bytearray": "bytes",     "builtins.memoryview": "bytes", }  |
| .venv/lib/python3.13/site-packages/mypy/semanal_main.py | 4763561610e7ce4d2f5c4be19b3927181a75c5f165619447432bf3339bce58a1 | 562 | 2 |     analyzer.incomplete_namespaces.discard(module)     # After semantic analysis is done, discard local namespaces     # to avoid memory hoarding.     analyzer.saved_locals.clear()  |
| .venv/lib/python3.13/site-packages/mypy/typeops.py | 14151d6ecfa8cfd96f385bf6912c2228951e4a6fdee0c33b6918a6ad655863c8 | 1282 | 2 |         return UninhabitedType(line=t.line, column=t.column)     elif not t.can_be_false:         # All values of t are already True-ish, so true_only is idempotent in this case         return t     e |
| .venv/lib/python3.13/site-packages/mypy/dmypy_server.py | d0825f4fe3f46ff2733b6dd1658df0fcd6e2f8f6950e5c94e6971c4cb94cdffe | 1127 | 11 | """Server for mypy daemon mode.  This implements a daemon process which keeps useful state in memory to enable fine-grained incremental reprocessing of changes. """ |
| .venv/lib/python3.13/site-packages/mypy/plugin.py | b3d3b976e9ccb8a1227efd893aec17075ae0cf059ea5e38ba485f28e28d42052 | 903 | 3 |    references are not ready yet, for example. This means that semantic analyzer    related plugin hooks can be called multiple times for the same full name.    These plugin methods must thus be idempo |
| .venv/lib/python3.13/site-packages/mypy/defaults.py | 0b85958865fb3cbe5a9ed9f6adf1a6558c8cdb21fb4b61e489215021ba22c304 | 45 | 1 |     "any-exprs",     "linecoverage",     "memory-xml",     "cobertura-xml",     "xml", |
| .venv/lib/python3.13/site-packages/mypy/main.py | 8af477386723cefea7e3dc559a87ea3ca607ad283a52bde60d43d567fb4e10c5 | 1683 | 8 |  orig_stat: Final = os.stat MEM_PROFILE: Final = False  # If True, dump memory profile RECURSION_LIMIT: Final = 2**14  |
| .venv/lib/python3.13/site-packages/mypy/checkexpr.py | 9f08c82bfa6059c09399e15ac2116b4ff0989f8598d2c19aace977d28d09be7a | 6668 | 1 |     "builtins.bytes",     "builtins.bytearray",     "builtins.memoryview", }  |
| .venv/lib/python3.13/site-packages/mypy/report.py | 0c38cb4364a091dbfa48482440e74a2ec15047cc5ea25c95c946dc5a26ec7db7 | 928 | 22 |     def __init__(self, reports: Reports, output_dir: str) -> None:         self.output_dir = output_dir         if output_dir != "<memory>":             os.makedirs(output_dir, exist_ok=True)  |
| .venv/lib/python3.13/site-packages/mypy/fscache.py | 5ba0b03e85d6b6ba24cfc2a4b6812503006fdc06dacdc0847f8788ba5fb87986 | 303 | 1 |             results = os.listdir(path)         except OSError as err:             # Like above, take a copy to reduce memory use.             self.listdir_error_cache[path] = copy_os_error(err)        |
| .venv/lib/python3.13/site-packages/mypy/semanal.py | 0f8807b21351e7db3477e4add9ba6ec65b9b8a26cbe1d3820bbb686e4e889b6f | 7816 | 2 | * Changes performed by the analysis need to be reversible, since mypy   daemon strips and reuses existing ASTs (to improve performance and/or   reduce memory use). """  |
| .venv/lib/python3.13/site-packages/mypy/checkpattern.py | 5557117cf12cebfaa9711739682809d9e10f951ce0747e456ebc222a95df4d07 | 818 | 1 |             return any(self.can_match_sequence(get_proper_type(item)) for item in typ.items)         for other in self.non_sequence_match_types:             # We have to ignore promotions, as memoryvi |
| .venv/lib/python3.13/site-packages/mypy/stubtest.py | 5d0ab00297216588605186e8da6f63084da82a214c845b50c18d5e035b159a4e | 2180 | 5 |                     runtime_module = "typing"                 runtime_fullname = f"{runtime_module}.{runtime_name}"                 if re.fullmatch(rf"_?{re.escape(stub_origin.fullname)}", runtime_ful |
| .venv/lib/python3.13/site-packages/mypy/dmypy/client.py | 5e4f8e4a7cd2b784d8d811ac474e3370dac584756176951a111ffe14e63e4ec8 | 763 | 1 | """Client for mypy daemon mode.  This manages a daemon process which keeps useful state in memory rather than having to read it back from disk on each run. """ |
| .venv/lib/python3.13/site-packages/mypy/test/testtypes.py | 62fb06bdac0ace48ff03116fb65d8175d5da0426c167f6470af45d1019f5142e | 1595 | 2 |         assert_type(UninhabitedType, to)      def test_true_only_of_true_type_is_idempotent(self) -> None:         always_true = self.tuple(AnyType(TypeOfAny.special_form))         to = true_only(alwa |
| .venv/lib/python3.13/site-packages/mypy/test/helpers.py | 4ca50c666cce086189712040d109f3bfb97342e8e6893dc0515ff63321e887f9 | 473 | 1 |          if isinstance(expected_content, Pattern):             if expected_content.fullmatch(actual_output_content) is not None:                 continue             raise AssertionError( |
| .venv/lib/python3.13/site-packages/mypy/test/data.py | 87da0e6f222ab9c19f854c0990130fc728bc7c409a2d76a89108bb83837cf657 | 831 | 1 |         data = next(cases_iter)          m = _case_name_pattern.fullmatch(case_id)         if not m:             raise RuntimeError(f"Invalid testcase id {case_id!r}") |
| .venv/lib/python3.13/site-packages/mypy/test/meta/_pytest.py | 0471a85ee493d4dd88a950655ac24f02f052c5cd2a56900b0e3c8b59556fc4f0 | 73 | 1 |     p_test_data = Path(test_data_prefix)     p_root = p_test_data.parent.parent     p = p_test_data / f"{data_file_prefix}-meta-{uuid.uuid4()}.test"     assert not p.exists()     data_suite = dedent_d |
| .venv/lib/python3.13/site-packages/mypy/test/meta/test_update_data.py | cb0a2245846be1dca2f20931c39fae6910027a2e8d411e9fecd54bd72e940b6c | 136 | 1 | A "meta test" which tests the `--update-data` feature for updating .test files. Updating the expected output, especially when it's in the form of inline (comment) assertions, can be brittle, which is  |
| .venv/lib/python3.13/site-packages/mypy/plugins/dataclasses.py | e16805f560990440fe3e184c206e3a1a601ae2fedd3d573c20e0d7a7ee53f061 | 1135 | 1 |      Note that this may be executed multiple times on the same class, so     everything here must be idempotent.      This runs after the main semantic analysis pass, so you can assume that |
| .venv/lib/python3.13/site-packages/mypy/server/update.py | 9188614882ce38352031ccb1a13a4928ce58db97e6ed1428a455fd48b7cbd5df | 1342 | 6 | Here is some motivation for this mode:  * By keeping program state in memory between incremental runs, we   only have to process changed modules, not their dependencies. The   classic incremental mode |
| .venv/lib/python3.13/site-packages/mypy/server/aststrip.py | 82f1f1b6e371f007866ccb583f46d484f6a20f83b31be305d43c0fcb1e215271 | 282 | 2 | sometimes changed during semantic analysis main pass, and running semantic analysis again on those nodes would produce incorrect results, since this pass isn't idempotent. This pass resets AST nodes t |
| .venv/lib/python3.13/site-packages/sphinx/config.py | ed169afc6545e92d2e6560db60be95906f4df0e94a1ccee0e6ce423e0c8736d5 | 906 | 1 |         'tls_verify': _Opt(True, 'env', frozenset((bool,))),         'tls_cacerts': _Opt(None, 'env', frozenset((str, dict, types.NoneType))),         'user_agent': _Opt(None, 'env', frozenset((str,)) |
| .venv/lib/python3.13/site-packages/sphinx/addnodes.py | 405beb0a0f5b1a01ffcec18555e53319672fa88417b42f9bee35d461910946c9 | 625 | 1 |   # meta-information nodes   |
| .venv/lib/python3.13/site-packages/sphinx/domains/cpp/_ids.py | 8cf24788325f38b8c4e146caf90fc718027807077317d365e9bb412a856cb734 | 606 | 1 |     'std::istream': 'is',     'std::iostream': 'ios',     'std::vector': 'v',     'std::map': 'm', } |
| .venv/lib/python3.13/site-packages/sphinx/util/logging.py | bf9bdcaea219de3122bffd53adcaefef45e702c48800d251122200317df2a7eb | 643 | 6 |   class MemoryHandler(logging.handlers.BufferingHandler):     """Handler buffering all logs."""  |
| .venv/lib/python3.13/site-packages/sphinx/util/inspect.py | f443b11c786fc7877da07517b764def967fb495489260c4c2daf4d4b1ee74935 | 1061 | 3 | logger = logging.getLogger(__name__)  memory_address_re = re.compile(r' at 0x[0-9a-f]{8,16}(?=>)', re.IGNORECASE)  # re-export as is |
| .venv/lib/python3.13/site-packages/sphinx/util/images.py | 59b24564b34e81e2700eb0c2a0e36e6ce5fb3c1ef00df346b1dc7bca81959b9b | 152 | 1 |         return 'png'      # Scalable Vector Graphics     # https://svgwg.org/svg2-draft/struct.html     if b'<svg' in header.lower(): |
| .venv/lib/python3.13/site-packages/sphinx/util/requests.py | 159a7a8ab475df793c7d770ae2af93beec336bd0ac567bddc3ebd9baf2abc24d | 112 | 8 |   _USER_AGENT = (     f'Mozilla/5.0 (X11; Linux x86_64; rv:100.0) Gecko/20100101 Firefox/100.0 '     f'Sphinx/{sphinx.__version__}' |
| .venv/lib/python3.13/site-packages/sphinx/util/typing.py | 3318726be6f030d7cee304b6c004b5a58481fe7451d7477f900e2476e3c077a4 | 633 | 1 | TitleGetter: TypeAlias = Callable[[nodes.Node], str]  # inventory data on memory Inventory: TypeAlias = dict[str, dict[str, '_InventoryItem']]  |
| .venv/lib/python3.13/site-packages/sphinx/util/parallel.py | 923e6fca5740f1c3d3acef23125dda5c21eca13fb8798803c47f658d30450608 | 170 | 1 |         except Exception:             # shutdown other child processes on failure             # (e.g. OSError: Failed to allocate memory)             self.terminate()  |
| .venv/lib/python3.13/site-packages/sphinx/util/inventory.py | 675e84ac015f6b6966ba82077f6a8ab1b47742b1389b3b3d1c286d47154fc32e | 329 | 1 |  class _Inventory:     """Inventory data in memory."""      __slots__ = ('data',) |
| .venv/lib/python3.13/site-packages/sphinx/builders/linkcheck.py | 4c217aa45eb9bd5943188e7a67492fcf81f54fcefe51c965b9bd3b64c3bd48de | 813 | 4 |             self._timeout_status = _Status.TIMEOUT          self.user_agent = config.user_agent         self.tls_verify = config.tls_verify         self.tls_cacerts = config.tls_cacerts |
| .venv/lib/python3.13/site-packages/sphinx/builders/_epub_base.py | f003236a250c716982f85cdb5763c7bae371761dc5eab2a84fb28e8fbc4afd8f | 802 | 12 | }  VECTOR_GRAPHICS_EXTENSIONS = ('.svg',)  # Regular expression to match colons only in local fragment identifiers. |
| .venv/lib/python3.13/site-packages/sphinx/builders/epub3.py | 2b111d6d22172c06ac5f47251cc18825020367b724ac765fd91d873ed4d5a36a | 361 | 1 |      It creates the metainfo files content.opf, nav.xhtml, toc.ncx, mimetype,     and META-INF/container.xml. Afterwards, all necessary files are zipped to     an epub file.     """ |
| .venv/lib/python3.13/site-packages/sphinx/ext/intersphinx/_load.py | c32149beed03c78a6f5de125cf923cdbe7dba5ab02195f397ac31bf3ec5c0b68 | 433 | 5 |     tls_verify: bool     tls_cacerts: str \| dict[str, str] \| None     user_agent: str      @classmethod |
| .venv/lib/python3.13/site-packages/sphinx/ext/intersphinx/_cli.py | 0de84e437645c72030f0449f2796a458d814ae248d90be8b2da9c10a5814443f | 52 | 1 |         tls_verify=False,         tls_cacerts=None,         user_agent='',     )  |
| .venv/lib/python3.13/site-packages/sphinx/search/ja.py | 6646b94f7a31e5639516848730be8fb1e63ec31e425b3f424e97c7d557a113c0 | 548 | 16 |              'KOK': -1009, 'MHH': -2694, 'MHM': -457, 'MHO': 123, 'MMH': -471,              'NNH': -1689, 'NNO': 662, 'OHO': -3393}     TC4__ = {'HHH': -203, 'HHI': 1344, 'HHK': 365, 'HHM': -122, 'HHN |
| .venv/lib/python3.13/site-packages/sphinx/testing/util.py | ea06366a6d7755c53605d5e6031fe370cb95939d51c5ae3db5885bcfdaa421b7 | 292 | 2 |     @property     def status(self) -> StringIO:         """The in-memory text I/O for the application status messages."""         # sphinx.application.Sphinx uses StringIO for a quiet stream         a |
| .venv/lib/python3.13/site-packages/sphinx/transforms/post_transforms/__init__.py | c79e4fcf702f39accff278f1850c60ac9de672205dd6a60220c0e9d995970a23 | 400 | 2 |                     return any(                         (                             re.fullmatch(ignore_type, entry_type)                             and re.fullmatch(ignore_target, entry_target)    |
| .venv/lib/python3.13/site-packages/sphinx/transforms/post_transforms/images.py | 823882605763db9491bdbde6251ef387a0c04195ca8292a29edcfb2967fb3047 | 303 | 2 |             node['uri'],             headers=headers,             _user_agent=config.user_agent,             _tls_info=(config.tls_verify, config.tls_cacerts),         ) |
| .venv/lib/python3.13/site-packages/sphinx/environment/__init__.py | b85f836f0c3e90ada4a20dfb520d51b89535a7bf94e45c99298c2cad0113ec5a | 1125 | 4 |          self._pickled_doctree_cache: dict[str, bytes] = {}         """In-memory cache for reading pickled doctrees from disk.         docname -> pickled doctree  |
| .venv/lib/python3.13/site-packages/sphinx/themes/classic/theme.toml | fcb7dc316ebaca6ba46376970f5237e6dea9c6d4501e6f512a7f17661a2d8f28 | 35 | 1 | footerbgcolor    = "#11303d" footertextcolor  = "#ffffff" sidebarbgcolor   = "#1c4e63" sidebarbtncolor  = "#3c6e83" sidebartextcolor = "#ffffff" |
| .venv/lib/python3.13/site-packages/radon/cli/colors.py | 67f18ff53d86272c8e2580c1f73983f2884c2a4d6acae45f0789ab2d578b0029 | 50 | 4 |         colorama.Fore.RED,     )     MAGENTA, CYAN, WHITE = (         colorama.Fore.MAGENTA,         colorama.Fore.CYAN, |
| .venv/lib/python3.13/site-packages/python_multipart/multipart.py | a64de8dde0772976cdc73381c5b12309dcfed444846483175487e5d7682b1bea | 1874 | 22 |         UPLOAD_KEEP_EXTENSIONS: bool         UPLOAD_ERROR_ON_BAD_CTE: bool         MAX_MEMORY_FILE_SIZE: int         MAX_BODY_SIZE: float  |
| .venv/lib/python3.13/site-packages/snowballstemmer/arabic_stemmer.py | 4fd3c12d3ccbce37e45a101f187bf13961b9c09090e58e16b6f7b0a8856af86b | 1201 | 1 |         Among(u"\uFEC2", -1, 34),         Among(u"\uFEC3", -1, 34),         Among(u"\uFEC4", -1, 34),         Among(u"\uFEC5", -1, 35),         Among(u"\uFEC6", -1, 35), |
| .venv/lib/python3.13/site-packages/aioredis/client.py | 74d39472adef80eeae9f6f4e0ce09fccd43aa3013702d086740def14c81a8a81 | 4805 | 21 | ZScoreBoundT = Union[float, str]  # str allows for the [ or ( prefix BitfieldOffsetT = Union[int, str]  # str allows for #x syntax _StringLikeT = Union[bytes, str, memoryview] KeyT = _StringLikeT  # M |
| .venv/lib/python3.13/site-packages/aioredis/connection.py | 80d3b91a77a61e0a2bd665566467ded6ec46999c0e5f6e5a4d4ebb065f4988f8 | 1669 | 8 | )  EncodedT = Union[bytes, memoryview] DecodedT = Union[str, int, float] EncodableT = Union[EncodedT, DecodedT] |
| .venv/lib/python3.13/site-packages/aioredis/lock.py | 0a707d2e9bf290011711d432044720514ee21f1c0d177c6e1b35fb518b946e24 | 307 | 1 |         self,         redis: "Redis",         name: Union[str, bytes, memoryview],         timeout: Optional[float] = None,         sleep: float = 0.1, |
| .venv/lib/python3.13/site-packages/fastapi/_compat.py | 3f019365de9dfaeda8e9817d33ca506a1b81b43ff7ab72a98fbbd4e7e9e00a17 | 665 | 1 |         if "$ref" not in json_schema:             # TODO remove when deprecating Pydantic v1             # Ref: https://github.com/pydantic/pydantic/blob/d61792cc42c80b13b23e3ffa74bc37ec7c77f7d1/pydan |
| .venv/lib/python3.13/site-packages/fastapi/openapi/models.py | 3ea931422a9c1208caba17d42163d93d07324dcb9bb54081def70e6cbb01ed51 | 446 | 1 |     contentSchema: Optional["SchemaOrBool"] = None     # Ref: JSON Schema Validation 2020-12: https://json-schema.org/draft/2020-12/json-schema-validation.html#name-a-vocabulary-for-basic-meta     # A |
| .venv/lib/python3.13/site-packages/boolean/test_boolean.py | 1570818011cab58eeb24e7bc059fa8d4e4b9c608fbb5029101958bb56644af47 | 1353 | 2 |         _0 = algebra1.FALSE         _1 = algebra1.TRUE         # Idempotence         assert (a & a).simplify() == a         # Idempotence + Associativity |
| .venv/lib/python3.13/site-packages/boolean/boolean.py | e9697b2d3f59722f35793890614b5f4b118089f510b728e74d2efa6afd96865c | 1663 | 3 |          - commutative: order does not matter and different orders are equal.         - idempotent: so args can appear more often in one term than in the other.         """         if self is other: |
| .venv/lib/python3.13/site-packages/safetensors/paddle.py | d0866a422fd518a139571d7bf5a04e7de0f4501b0419cae774f5afa96492106e | 145 | 2 |     import paddle      tensors = {"embedding": paddle.zeros((512, 1024)), "attention": paddle.zeros((256, 256))}     byte_data = save(tensors)     ``` |
| .venv/lib/python3.13/site-packages/safetensors/numpy.py | a485539c6c406144b392d92beb1a29f01d492b6b77cc11f6f56b3ea03ce8da10 | 187 | 2 |     import numpy as np      tensors = {"embedding": np.zeros((512, 1024)), "attention": np.zeros((256, 256))}     byte_data = save(tensors)     ``` |
| .venv/lib/python3.13/site-packages/safetensors/tensorflow.py | 019f8eefe80cf89a937e37336720940079b712bf864909d059a17263b9802107 | 140 | 2 |     import tensorflow as tf      tensors = {"embedding": tf.zeros((512, 1024)), "attention": tf.zeros((256, 256))}     byte_data = save(tensors)     ``` |
| .venv/lib/python3.13/site-packages/safetensors/torch.py | 2b6d7a7ba0d010bee02c9904778452fa5463a0ae837d2f005ec8a2bbf98eefcb | 593 | 5 |                 "Error while trying to find names to remove to save state dict, but found no suitable name to keep"                 f" for saving amongst: {shared}. None is covering the entire storage |
| .venv/lib/python3.13/site-packages/safetensors/flax.py | 4f9f5e954ab3543c86606751efc433344bb0c8073c2ab10ed04b8b05228e9d4b | 139 | 2 |     from jax import numpy as jnp      tensors = {"embedding": jnp.zeros((512, 1024)), "attention": jnp.zeros((256, 256))}     byte_data = save(tensors)     ``` |
| .venv/lib/python3.13/site-packages/safetensors/mlx.py | 211e758d1a5c26ae9ea5bd00823f15b3123dc6a052e8d8de0099ebf8dcb48c95 | 141 | 2 |     import mlx.core as mx      tensors = {"embedding": mx.zeros((512, 1024)), "attention": mx.zeros((256, 256))}     byte_data = save(tensors)     ``` |
| .venv/lib/python3.13/site-packages/rich/logging.py | 50be9364d95aa6d60a1cd850e392d1132fb6f4f97eb50b0187bab71d29d62000 | 298 | 1 |     divide()     sleep(1)     log.critical("Out of memory!")     log.info("Server exited with code=-1")     log.info("[bold]EXITING...[/bold]", extra=dict(markup=True)) |
| .venv/lib/python3.13/site-packages/rich/tree.py | 4283b0838db816477019f47c2b4b59e90eeab7358d0143ff9b8b05698b86ea7c | 258 | 4 |      table.add_column("Released", style="cyan", no_wrap=True)     table.add_column("Title", style="magenta")     table.add_column("Box Office", justify="right", style="green")  |
| .venv/lib/python3.13/site-packages/rich/console.py | ae0c9f29f9929c91e21b1567bfec321862073e824581b3a88983dec895d47255 | 2681 | 1 |             >>> console = Console()             >>> with console.capture() as capture:             ...     console.print("[bold magenta]Hello World[/]")             >>> print(capture.get())  |
| .venv/lib/python3.13/site-packages/rich/box.py | 492a2583cfe9cc7cd8f50bc9428faaa74b5b3ec9e3f0eff65b88668b597e668d | 475 | 1 |         table.add_row("Cell", "Cell")         table.box = getattr(box, box_name)         table.title = Text(f"box.{box_name}", style="magenta")         columns.add_renderable(table)     console.print( |
| .venv/lib/python3.13/site-packages/rich/color.py | dc74942d50e3eea4245d47455afefc24e8926737f2e72d6791c6219dadbde95d | 622 | 7 |     "yellow": 3,     "blue": 4,     "magenta": 5,     "cyan": 6,     "white": 7, |
| .venv/lib/python3.13/site-packages/rich/default_styles.py | 8fd7998129fb6ea9f29b1633629f21fb43864d1cb664e8fe3df63db68aa9d11c | 194 | 14 |     "green": Style(color="green"),     "yellow": Style(color="yellow"),     "magenta": Style(color="magenta"),     "cyan": Style(color="cyan"),     "white": Style(color="white"), |
| .venv/lib/python3.13/site-packages/rich/markup.py | 6eda6bdbbd412e18824758cd825467bf606923355c35e7d8c1231e5bdb5e0db7 | 252 | 2 |     MARKUP = [         "[red]Hello World[/red]",         "[magenta]Hello [b]World[/b]",         "[bold]Bold[italic] bold and italic [/bold]italic[/italic]",         "Click [link=https://www.willmcguga |
| .venv/lib/python3.13/site-packages/rich/_inspect.py | 44e4f43cb0b618c5a26a559992a2488e662aec83518a34109284a89164da0222 | 269 | 1 |             yield Text.from_markup(                 f"[b cyan]{not_shown_count}[/][i] attribute(s) not shown.[/i] "                 f"Run [b][magenta]inspect[/]([not b]inspect[/])[/b] for options."    |
| .venv/lib/python3.13/site-packages/rich/text.py | bfebc2386f204bf0f940384e854d7de3bf3ec842460172958bc89808293b3bf3 | 1362 | 1 |      console.rule("justify='full'")     console.print(text, style="magenta", justify="full")     console.print() |
| .venv/lib/python3.13/site-packages/rich/live.py | b45dee90000967f37665b19c96a67e8b02e822867c7f41c7533efd8c0c89aa3f | 401 | 1 |         "Text may be printed while the progress bars are rendering.",         Panel("In fact, [i]any[/i] renderable will work"),         "Such as [magenta]tables[/]...",         table,         "Pretty |
| .venv/lib/python3.13/site-packages/rich/syntax.py | e5904dc63223dc2d450bddaf2f005537e0b960074a8cf1df1fa4aa0b315a3981 | 986 | 6 |     Keyword: Style(color="blue"),     Keyword.Type: Style(color="cyan"),     Operator.Word: Style(color="magenta"),     Name.Builtin: Style(color="cyan"),     Name.Function: Style(color="green"), |
| .venv/lib/python3.13/site-packages/rich/table.py | e76866a0ba07a5e244a26ce75af5bc09eda6d70eb61ee40348699a1ba7d8caa2 | 1007 | 1 |             "Released", header_style="bright_cyan", style="cyan", no_wrap=True         )         table.add_column("Title", style="magenta")         table.add_column("Box Office", justify="right", styl |
| .venv/lib/python3.13/site-packages/rich/segment.py | ee039dc123ebceed1ada0466c410edbb7bb64bc886e6cf65ef0941e7c74a332d | 753 | 2 |     code = """from rich.console import Console console = Console() text = Text.from_markup("Hello, [bold magenta]World[/]!") console.print(text)"""  |
| .venv/lib/python3.13/site-packages/rich/progress.py | 09473696453e5f9f6655d19f8cc0819197a218f2f7bb174e36384d245d93ef06 | 1716 | 2 |         return block      def readinto(self, b: Union[bytearray, memoryview, mmap]):  # type: ignore[no-untyped-def, override]         n = self.handle.readinto(b)  # type: ignore[attr-defined]         |
| .venv/lib/python3.13/site-packages/rich/cells.py | 2ab4248f9f8b821082a492d23502320198e775ce1b9c4a8e1268b962e67d5026 | 175 | 1 |     """Get the number of cells required to display text.      This method always caches, which may use up a lot of memory. It is recommended to use     `cell_len` over this method.  |
| .venv/lib/python3.13/site-packages/rich/_win32_console.py | a3640dfc8471d746e218fdc0a759de6aa5fc1411a550a4a658ce8ac3839283e5 | 662 | 2 |         6,  # yellow                      define FOREGROUND_RED             0x0004 -- 0000 0100         1,  # blue                        define FOREGROUND_INTENSITY       0x0008 -- 0000 1000          |
| .venv/lib/python3.13/site-packages/rich/__main__.py | 6285da3c171bf8b7903038fd8e165e8c2498d032b880fe7bb8e96781b3f17f89 | 246 | 6 |             "✓ [bold green]4-bit color[/]\n"             "✓ [bold blue]8-bit color[/]\n"             "✓ [bold magenta]Truecolor (16.7 million)[/]\n"             "✓ [bold yellow]Dumb terminals[/]\n"    |
| .venv/lib/python3.13/site-packages/rich/status.py | 9243e987761e019068f97fb8c0fa7c813a99c94e3ae8d2f06410383d94d37b0a | 132 | 1 |      console = Console()     with console.status("[magenta]Covid detector booting up") as status:         sleep(3)         console.log("Importing advanced AI") |
| .venv/lib/python3.13/site-packages/blib2to3/pgen2/tokenize.py | 75ce9fa2edbcf3699d04b1e6e8893eaac4e4ceec7b4fe89001fb4f66cd15fb64 | 1115 | 1 |                     yield tok                 elif initial == "\\":  # continued stmt                     # This yield is new; needed for better idempotency:                     if stashed:            |
| .venv/lib/python3.13/site-packages/pluggy/_hooks.py | 13a7f79d8708e9d6c4b8ed069b2eb5a3380653fe7dfdeebd902d3c6b4e8406ea | 715 | 1 |     # `subset_hook_caller` used to be implemented by creating a full-fledged     # HookCaller, copying all hookimpls from the original. This had problems     # with memory leaks (#346) and historic ca |
| .venv/lib/python3.13/site-packages/prometheus_client/metrics.py | 29a0e9b3c2aee8799d5c0ad265ba9c21e5bd6080344bc48c7f4003afe11665c0 | 754 | 2 |         - Inprogress requests         - Number of items in a queue         - Free memory         - Total memory         - Temperature |
| .venv/lib/python3.13/site-packages/prometheus_client/exposition.py | e217cf066eb37ddd1b012f2115d084c5250d3cde69c650225b5eaf17a5011cb7 | 680 | 2 |     generically guarantee no violations of HTTP RFC 2616 requirements for     the user to explicitly confirm redirects that could have unexpected     side effects (such as rendering a PUT request non- |
| .venv/lib/python3.13/site-packages/prometheus_client/process_collector.py | 07ccb7e8bd62ab473728596f74d8f517924440b4de735d7a87acb79bd26193dd | 102 | 5 |  class ProcessCollector(Collector):     """Collector for Standard Exports such as cpu and memory."""      def __init__(self, |
| .venv/lib/python3.13/site-packages/anthropic/_types.py | 3f0033c164caa7d6f4f054e59615a340f5fffbc08b5d687a53ef5ab695181f18 | 256 | 1 |     params: Query     extra_json: AnyMapping     idempotency_key: str     follow_redirects: bool  |
| .venv/lib/python3.13/site-packages/anthropic/_base_client.py | ef4cb4f422657f1c49fdcc5d5a58757c4409763e41a6d4cbef5f9761e629d351 | 2132 | 26 |     timeout: Union[float, Timeout, None]     _strict_response_validation: bool     _idempotency_header: str \| None     _default_stream_cls: type[_DefaultStreamT] \| None = None  |
| .venv/lib/python3.13/site-packages/anthropic/_models.py | 81acc6c66ca9853ec21d2ddb15585d9214b4aecc768b25557295e43784d7b477 | 861 | 2 |     timeout: float \| Timeout \| None     files: HttpxRequestFiles \| None     idempotency_key: str     json_data: Body     extra_json: AnyMapping |
| .venv/lib/python3.13/site-packages/anthropic/types/message_create_params.py | e5f6771998e16fecaf3a50d9495716897b679bbef1d32a7f8a533b208040010f | 316 | 3 |       { "role": "user", "content": "Hello there." },       { "role": "assistant", "content": "Hi, I'm Claude. How can I help you?" },       { "role": "user", "content": "Can you explain LLMs in plain  |
| .venv/lib/python3.13/site-packages/anthropic/types/message_count_tokens_params.py | f2842553b6137e6d7399ce89c1bfc57c698f17e0e005dc797505074dbf3ef9a7 | 198 | 3 |       { "role": "user", "content": "Hello there." },       { "role": "assistant", "content": "Hi, I'm Claude. How can I help you?" },       { "role": "user", "content": "Can you explain LLMs in plain  |
| .venv/lib/python3.13/site-packages/anthropic/types/beta/message_create_params.py | 689cbac1be6a0988487e0160f4d4111100f183c730a0e5b92806a6e959dac2ba | 300 | 3 |       { "role": "user", "content": "Hello there." },       { "role": "assistant", "content": "Hi, I'm Claude. How can I help you?" },       { "role": "user", "content": "Can you explain LLMs in plain  |
| .venv/lib/python3.13/site-packages/anthropic/types/beta/message_count_tokens_params.py | 6063a6ccd2513cb2358e229188c2d28d3595a10cac0f5c6533ed6a98a87b77f3 | 234 | 3 |       { "role": "user", "content": "Hello there." },       { "role": "assistant", "content": "Hi, I'm Claude. How can I help you?" },       { "role": "user", "content": "Can you explain LLMs in plain  |
| .venv/lib/python3.13/site-packages/anthropic/resources/beta/messages/messages.py | 3a54552a8b18729156fb39abad97300d1a4a348e741ae07da676a1104071fd85 | 2595 | 24 |                 { "role": "user", "content": "Hello there." },                 { "role": "assistant", "content": "Hi, I'm Claude. How can I help you?" },                 { "role": "user", "content": " |
| .venv/lib/python3.13/site-packages/anthropic/resources/beta/messages/batches.py | eac6c5a45082442faa377efee67ee53b707319728655a5e13eff72ec36a3d3ed | 885 | 2 |         timeout: float \| httpx.Timeout \| None \| NotGiven = NOT_GIVEN,     ) -> BetaMessageBatch:         """This endpoint is idempotent and can be used to poll for Message Batch         completion.  |
| .venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py | 3c18592f78ae1be0345a135c6b0477a51b602fc7d1f2a4a6018b31e3c324b22f | 2492 | 24 |                 { "role": "user", "content": "Hello there." },                 { "role": "assistant", "content": "Hi, I'm Claude. How can I help you?" },                 { "role": "user", "content": " |
| .venv/lib/python3.13/site-packages/anthropic/resources/messages/batches.py | c3f6cd820fcd578ac54240de8b126d46892298f213dce5698a6afc0fcffbbf96 | 715 | 2 |         timeout: float \| httpx.Timeout \| None \| NotGiven = NOT_GIVEN,     ) -> MessageBatch:         """This endpoint is idempotent and can be used to poll for Message Batch         completion.  |
| .venv/lib/python3.13/site-packages/tiktoken_ext/openai_public.py | 954392738e60d0fb6dca1dad80872efc47c8e2733babecbbf0a23970ed66c2cb | 163 | 8 | ENDOFPROMPT = "<\|endofprompt\|>"  # The pattern in the original GPT-2 release is: # r"""'s\|'t\|'re\|'ve\|'m\|'ll\|'d\| ?[\p{L}]+\| ?[\p{N}]+\| ?[^\s\p{L}\p{N}]+\|\s+(?!\S)\|\s+""" # This is equivalent, but execu |
| .venv/lib/python3.13/site-packages/torchgen/native_function_generation.py | 662031da893ac0c9d4634f0b8a3c0732212c8fe424d769e2f36e31fadb78239b | 652 | 6 |     "sym_constrain_range",  # no return     "sym_constrain_range_for_size",  # no return     "_nested_tensor_storage_offsets",  # returns a vector of ints     "_chunk_grad_outputs_efficient_attention" |
| .venv/lib/python3.13/site-packages/torchgen/gen_vmap_plumbing.py | 603218989f6817269b320b1fbb893a943b4a7f712951d34b2bb0e4c3cb72c678 | 276 | 3 |         elif is_tensor_list(ret.type):             wrapped_returns.append(                 f"makeBatchedVector(std::get<{idx}>({results_var}), std::get<{idx + 1}>({results_var}), {cur_level_var})"     |
| .venv/lib/python3.13/site-packages/torchgen/gen.py | 7afcf0f4b9d344bbc57ff6ad079db56da4a8c3bfde4dd55816f7c70493cfc357 | 3004 | 11 |  # Translates arguments of `sig` to CppSignature bindings. # Note that we have a special case for `memory_format` argument and this case is not covered by # tools.codegen.api.translate() yet as its ap |
| .venv/lib/python3.13/site-packages/torchgen/gen_functionalization_type.py | 8fb0f02bc3b53b1487218a1df50b3bb7fc234a9641fefa2fcc078da0a4b0b1ae | 883 | 11 |     tensorListT,     tensorT,     VectorCType,     ViewInverseSignature, ) |
| .venv/lib/python3.13/site-packages/torchgen/gen_aoti_c_shim.py | b3e2815bb3c468513a9776867c04d38f96baf69ecfe739070398b54fa06b23e1 | 716 | 7 |     BaseTy.DeviceIndex: "int32_t",     BaseTy.Layout: "int32_t",  # Represent enum as int     BaseTy.MemoryFormat: "int32_t",  # Represent enum as int     BaseTy.ScalarType: "int32_t",  # Represent en |
| .venv/lib/python3.13/site-packages/torchgen/model.py | 19554a7f4a40769541b404f7fb1e9cb36b7fbe127cc153a608ac7f3afdb1fcfb | 2886 | 11 |      CPUScalar = auto()     CPUVector = auto()      # These are the ones users will usually specify, and |
| .venv/lib/python3.13/site-packages/torchgen/gen_lazy_tensor.py | 87a3db5091f0b0bc89af96a647bfac9d86fea888e0439181bdc8f3cfe4d131ad | 586 | 4 |   auto out = at::native::empty_strided_meta_symint(tensor.sym_sizes(), tensor.sym_strides(), \ /*dtype=*/tensor.scalar_type(), /*layout=*/tensor.layout(), \ /*device=*/c10::Device(c10::kMeta), /*pin_m |
| .venv/lib/python3.13/site-packages/torchgen/packaged/autograd/load_derivatives.py | a9a929c722c3ff23302e5d1fe572f44be8e968f895dcd7a778f5278a74c78a6a | 1020 | 7 |     tensorOptionsT,     typeAndSizeT,     VectorCType, ) from torchgen.context import with_native_function |
| .venv/lib/python3.13/site-packages/torchgen/packaged/autograd/gen_autograd_functions.py | 617dc1a3ace8616f8510630d96a15c8ff73fc45c280c33ed46d74c6231dba7d0 | 1075 | 16 |     tensorListT,     tensorT,     VectorCType, ) from torchgen.code_template import CodeTemplate |
| .venv/lib/python3.13/site-packages/torchgen/packaged/autograd/gen_variable_type.py | ee91f455e53f332f955cb6f9964af5b189352f2c0b53520da3cd7745cdd2a019 | 2187 | 30 |     tensorT,     TupleCType,     VectorCType, ) from torchgen.code_template import CodeTemplate |
| .venv/lib/python3.13/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py | dd10560ce4e1cb1d770f0b7a48a95c31a83633eb82a88e0bae984e5b208088eb | 674 | 1 |         ):             # It's not safe to close over IntArrayRef by value, since this is a             # reference type, so materialize a vector to close over by value             arg_vec = arg + "_ve |
| .venv/lib/python3.13/site-packages/torchgen/packaged/autograd/gen_trace_type.py | d420e66818731c59a13dd918299f2e4a1a753d63c44d597c58e4ef8bd093791d | 540 | 14 |                 ADD_TRACE_INPUT.substitute(name=name, input="options.layout()"),                 ADD_TRACE_INPUT.substitute(name=name, input="options.device()"),                 ADD_TRACE_INPUT.substi |
| .venv/lib/python3.13/site-packages/torchgen/packaged/autograd/derivatives.yaml | c6b7690f5b7a5b876db958d40d5927831957dd2b6d4b830ead56508977b9a98f | 3236 | 57 | # Note about possibly confusing nomenclature: An 'output gradient' is the # gradient of an output of a forward function. Output gradients are used as # the inputs to backward functions. `grads` is a v |
| .venv/lib/python3.13/site-packages/torchgen/packaged/autograd/gen_view_funcs.py | bd27674c6185711a9cdf3d6ca67493f70b05ca58a169e4c5cbb8e3b50a23ec77 | 340 | 17 |     SymIntT,     tensorT,     VectorCType, ) from torchgen.code_template import CodeTemplate |
| .venv/lib/python3.13/site-packages/torchgen/packaged/ATen/native/native_functions.yaml | ba3e58d5f640cb3463d07e4324b3940659334fd0e71a1e92a181daf5a3aaf09f | 15856 | 229 |     CompositeExplicitAutograd: _functional_sym_constrain_range_for_size  - func: _make_dep_token(*, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryForma |
| .venv/lib/python3.13/site-packages/torchgen/static_runtime/generator.py | 4820335188c60099471630c3ba8e6391bcb28e11bc2ad755b0b7d6ebd5824fcb | 815 | 9 |         "cudnn_grid_sampler",         "diag_embed",         "embedding",         "embedding_dense_backward",         "_embedding_bag_dense_backward", |
| .venv/lib/python3.13/site-packages/torchgen/static_runtime/gen_static_runtime_ops.py | 4e9b52e64e28d2c398c82ad81f578f3220dfab258915b595402e78ccd9079940 | 232 | 3 | #include <ATen/cpu/vec/functional.h> #include <ATen/cpu/vec/vec.h> #include <ATen/native/EmbeddingBag.h> #include <ATen/native/Fill.h> #include <ATen/native/IndexingUtils.h> |
| .venv/lib/python3.13/site-packages/torchgen/operator_versions/gen_mobile_upgraders.py | f67666b59aac28da904a9009feb433078f6fc0d5c01cf2e8a35fc7f8586c1edb | 387 | 13 |  INSTRUCTION_LIST = CodeTemplate(     """std::vector<Instruction>({         ${instruction_list}     }), // instructions list""" |
| .venv/lib/python3.13/site-packages/torchgen/dest/lazy_ts_lowering.py | f5052f2ff67e986a917e1b4afd7d914841e51a614ea83aff27c71826b00b506e | 49 | 3 |     )     return f"""\     std::vector<torch::jit::NamedValue> arguments;     std::vector<torch::jit::NamedValue> kwarguments;     arguments.reserve({len(emplace_arguments)}); |
| .venv/lib/python3.13/site-packages/torchgen/dest/ufunc.py | 5a9689479125b58773db58a141856a7d8abd5050f627eb3da791e814a0334afc | 554 | 11 |     scalar_t,     StructuredImplSignature,     VectorizedCType, ) from torchgen.context import with_native_function |
| .venv/lib/python3.13/site-packages/torchgen/dest/lazy_ir.py | d481c51175a0b33408c925ac73ffdfff3b3756c557997f7a45f9d2dd5ba29463 | 708 | 14 |     NativeSignature,     OptionalCType,     VectorCType, ) from torchgen.context import method_with_native_function |
| .venv/lib/python3.13/site-packages/torchgen/dest/register_dispatch_key.py | fabbc0e980a8440a6b957a3e2fd6716582e434293f9263bbd3d1252f4080c211 | 1017 | 3 |   if (resized) {     if (!strides.empty()) {       TORCH_INTERNAL_ASSERT(!options.memory_format_opt().has_value());       // TODO: avoid the redispatch here       out.as_strided_(sizes, strides); |
| .venv/lib/python3.13/site-packages/torchgen/api/dispatcher.py | 80fae0f6d274a1bd44ad75a81972431994e0d0c6c30a2bd300b284ee48c84d4e | 126 | 2 | # Prominent characteristics of the dispatcher API: # #   - dtype, layout, device and pin_memory are represented as separate #     arguments. # |
| .venv/lib/python3.13/site-packages/torchgen/api/translate.py | 281a03f0aebfd5ee08d5fb557f684302862b8b8cc82f1aecfb7673893a98376b | 438 | 34 |     ListCType,     longT,     memoryFormatT,     MutRefCType,     NamedCType, |
| .venv/lib/python3.13/site-packages/torchgen/api/ufunc.py | 06e9080cac094ca64ca1ab1fbf328b4e23fe906388a1cee9b4088bb6b3377a09 | 210 | 1 |  # Stubs are the DispatchStub trampolines that CPU kernels use to get to their # vectorized versions.  E.g., # # using structured_binary_fn_alpha = void(*)(TensorIteratorBase&, const Scalar& alpha); |
| .venv/lib/python3.13/site-packages/torchgen/api/native.py | c69c9ee5255ea4d31a1d2205cc87dcac6fba0640f1081ddf3dd4143dc8a57f9c | 160 | 2 |             ),             Binding(                 nctype=NamedCType("pin_memory", OptionalCType(BaseCType(boolT))),                 name="pin_memory",                 default=default, |
| .venv/lib/python3.13/site-packages/torchgen/api/cpp.py | 6671fcfdc51bd71928fab7d7d94e35da8ddaf4b16d814343af32f0eabf7c2015 | 470 | 11 |     tensorT,     TupleCType,     VectorCType,     voidT, ) |
| .venv/lib/python3.13/site-packages/torchgen/api/unboxing.py | fc922f3f3645f8ba110e47a7b24cf1e09553aa2022b79f934d793417ea4e8da5 | 242 | 8 | #      aten::empty.names(int[] size, *, Dimname[]? names, #                        ScalarType? dtype=None, Layout? layout=None, #                        Device? device=None, bool? pin_memory=None, #   |
| .venv/lib/python3.13/site-packages/torchgen/api/functionalization.py | 1d983546097a627db6a19fb8fb28766d6c9edd1cb4c69f8b6c9e85993f625b02 | 200 | 1 |     # capture arguments include all arguments except `self`.     # Importantly, they don't include any C++ reference types (or else we'll get a dangling reference in the capture),     # So any referen |
| .venv/lib/python3.13/site-packages/torchgen/api/autograd.py | 9e116b0f6db36edd54742cae11e8c5d2d4ca554f3d6d25e59ec6103b2998c9d6 | 875 | 2 |      # All named gradients that are available for use, in the same     # order as in the grads vector.     available_named_gradients: Sequence[str]  |
| .venv/lib/python3.13/site-packages/torchgen/api/python.py | 1f66cc9f6514c7f8ac946ab67ef74503f89efb3c6e22b1b347968d1c9ca2dfc7 | 1549 | 30 | #      aten::empty.names(int[] size, *, Dimname[]? names, #                        ScalarType? dtype=None, Layout? layout=None, #                        Device? device=None, bool? pin_memory=None, #   |
| .venv/lib/python3.13/site-packages/torchgen/api/lazy.py | d0a9a6d42e0cf5ae2eadf10c3e47b5a14238d48ff2a219d708c45e9bdce66a47 | 469 | 12 |     ListCType,     longT,     memoryFormatT,     NamedCType,     OptionalCType, |
| .venv/lib/python3.13/site-packages/torchgen/api/types/types.py | 8ff73bc07761575c7479340d166871d6ad77b3373a040d5ba1c4e08ccd2d4c9e | 182 | 10 | dimnameT = BaseCppType("at", "Dimname") dimnameListT = BaseCppType("at", "DimnameList") dimVectorT = BaseCppType("at", "DimVector") layoutT = BaseCppType("at", "Layout") deviceT = BaseCppType("at", "D |
| .venv/lib/python3.13/site-packages/torchgen/api/types/signatures.py | ca8980d56672141fd629a3bd4fef2b592a60bd6caf92925a509b3069b75d5be7 | 429 | 1 |         )         # allow_expensive_conversions is set because we want to convert         # some reference types (IntArrayRef) to value types (vector<int64_t>).         capture_exprs = translate.trans |
| .venv/lib/python3.13/site-packages/torchgen/api/types/types_base.py | e4accc459ee276d5bc552ef152b047db815e369190e01cb0ed4028e6c8d4287d | 239 | 7 |  class SpecialArgName(Enum):     possibly_redundant_memory_format = auto()   |
| .venv/lib/python3.13/site-packages/torchgen/aoti/fallback_ops.py | 3ecad04ff4c725050ce2805cbe4dbe3fa2022716897694afd0b5dba32ee178ae | 176 | 4 |     "aten._efficient_attention_forward.default": {},     "aten._efficientzerotensor.default": {},     "aten._embedding_bag_dense_backward.default": {},     "aten._embedding_bag_forward_only.default":  |
| .venv/lib/python3.13/site-packages/urllib3/__init__.py | 24ca35b60d67215d40789daf10d0bf4f17e5d1ee61e86ce5f43195935ad645ba | 212 | 2 |      :param headers:         Dictionary of custom headers to send, such as User-Agent,         If-None-Match, etc.  |
| .venv/lib/python3.13/site-packages/urllib3/response.py | 4d54d2bba43553453b8681d8308471c6e878ceba1e328f1be442380ce035dc4a | 1308 | 5 |  class BytesQueueBuffer:     """Memory-efficient bytes buffer      To return decoded data in read() and still follow the BufferedIOBase API, we need a |
| .venv/lib/python3.13/site-packages/urllib3/connection.py | 88fe2981226da6eb17c9895e8f3367fa08a1ff0582c4c53eab2e8e53591a6a97 | 1094 | 5 |         if sys.version_info < (3, 11, 9):             # `_tunnel` copied from 3.11.13 backporting             # https://github.com/python/cpython/commit/0d4026432591d43185568dd31cef6a034c4b9261        |
| .venv/lib/python3.13/site-packages/urllib3/_collections.py | b4cedce89d622ad599615fd01986fcfabecdaf5e76e037a19ec6b451f87afe65 | 480 | 1 |     # Backwards compatibility for httplib     getheaders = getlist     getallmatchingheaders = getlist     iget = getlist  |
| .venv/lib/python3.13/site-packages/urllib3/_request_methods.py | 802785f3948efd45385a83f0607228cffb70f9e33f1153a42c5a7c385b02ec30 | 279 | 3 |          :param headers:             Dictionary of custom headers to send, such as User-Agent,             If-None-Match, etc. If None, pool headers are used. If provided,             these headers co |
| .venv/lib/python3.13/site-packages/urllib3/connectionpool.py | 64486e76c6bc048b9b0f63345e8c4106c8f16ec5f0320512707ee843d8be8f56 | 1179 | 3 |          :param headers:             Dictionary of custom headers to send, such as User-Agent,             If-None-Match, etc. If None, pool headers are used. If provided,             these headers co |
| .venv/lib/python3.13/site-packages/urllib3/util/ssltransport.py | 133e0ef2947fbd3f1d6a7fc5bea0584ba7600df05710c7d57ebcdc754a167e2e | 272 | 4 |   _WriteBuffer = typing.Union[bytearray, memoryview] _ReturnValue = typing.TypeVar("_ReturnValue")  |
| .venv/lib/python3.13/site-packages/urllib3/util/request.py | 5ee02c1014f9f030196144f0a4c1f91ebdc0d4e3e830dbcd21822e9db22a6dcf | 267 | 11 | # emitting some HTTP headers that are added automatically. # The only headers that are supported are ``Accept-Encoding``, # ``Host``, and ``User-Agent``. SKIP_HEADER = "@@@SKIP_HEADER@@@" SKIPPABLE_HE |
| .venv/lib/python3.13/site-packages/urllib3/util/retry.py | 6e3fb6614a9b9712e5bfc4c78397f1c30f83339e1709b8e0657210ef55e2a026 | 534 | 1 |          By default, we only retry on methods which are considered to be         idempotent (multiple requests with the same parameters end with the         same state). See :attr:`Retry.DEFAULT_ALLOW |
| .venv/lib/python3.13/site-packages/urllib3/contrib/emscripten/fetch.py | 91ca34ea55a843e7dd15f379d7e9f3793cb03d50441e0f3d588b2ddf71f7c5c8 | 729 | 3 | See also https://github.com/koenvo/pyodide-http/issues/22 """ HEADERS_TO_IGNORE = ("user-agent",)  SUCCESS_HEADER = -1 |
| .venv/lib/python3.13/site-packages/urllib3/http2/connection.py | e030740e46440b7c889211a3503207075ef0ad808b68bd008396c35b6fe618f2 | 357 | 4 | from .._base_connection import _TYPE_BODY from .._collections import HTTPHeaderDict from ..connection import HTTPSConnection, _get_default_user_agent from ..exceptions import ConnectionError from ..re |
| .venv/lib/python3.13/site-packages/flatbuffers/encode.py | 48cac66f5cbcfc471c326e6f314d4f8e00216fdfcd1d3885923f3790d23b7678 | 43 | 3 | from . import number_types as N from . import packer from .compat import memoryview_type from .compat import import_numpy, NumpyRequiredForThisFeature  |
| .venv/lib/python3.13/site-packages/flatbuffers/compat.py | db13fdc75a2f5fe21d3de6b21c8c2bfdd26942f270ba044f375c0ae6f8fb5ee5 | 87 | 5 |     binary_types = (bytes,bytearray)     range_func = range     memoryview_type = memoryview     struct_bool_decl = "?" else: |
| .venv/lib/python3.13/site-packages/flatbuffers/builder.py | 93abde4a4a2c2af461815270bdaed5a4e8912b94ad100c70b44523955e7fbbd3 | 825 | 51 | from . import compat from .compat import range_func from .compat import memoryview_type from .compat import import_numpy, NumpyRequiredForThisFeature  |
| .venv/lib/python3.13/site-packages/flatbuffers/flexbuffers.py | 1665c42ed4ef59d7f08a0b3a218886a7d5f26be40389463851ce20e23bf402e6 | 1537 | 171 |    These are used in the lower 2 bits of a type field to determine the size of   the elements (and or size field) of the item pointed to (e.g. vector).   """   W8 = 0  # 2^0 = 1 byte |
| .venv/lib/python3.13/site-packages/flatbuffers/table.py | f0e99e922a84cb043fa4ca93ed0e144c9c8c094f1e5610012a996b29208d4219 | 139 | 16 |         return bytes(self.Bytes[start:start+length])      def VectorLen(self, off):         """VectorLen retrieves the length of the vector whose offset is stored            at "off" in this object."" |
| .venv/lib/python3.13/site-packages/posthog/client.py | 151be6a3c9532c4858f1728ddad88bff66cc6cb0ec3a06e369835130c08aa992 | 1482 | 1 |     """     Returns standardized OS name and version information.     Similar to how user agent parsing works in JS.     """     os_name = "" |
| .venv/lib/python3.13/site-packages/posthog/request.py | 66ca9accefffc4fa7617acd3d456afc2a0873f40f28bf2e5c1f4121e4a279a18 | 192 | 6 |  # Retry on both connect and read errors # by default read errors will only retry idempotent HTTP methods (so not POST) adapter = requests.adapters.HTTPAdapter(     max_retries=Retry( |
| .venv/lib/python3.13/site-packages/posthog/exception_utils.py | 4fbbe1f3c5563b5816112e55904f2e47bcca39ecfa2810be9110e748f40a0340 | 970 | 1 |         return pre_context, context_line, post_context     except IndexError:         # the file may have changed since it was loaded into memory         return [], None, []  |
| .venv/lib/python3.13/site-packages/posthog/test/test_feature_flags.py | 09b987ef0802b2697596837c6f5a87c4c0c35356ec86d449a53588898bfba81e | 5312 | 1 |     @mock.patch.object(Client, "capture")     @mock.patch("posthog.client.flags")     def test_capture_multiple_users_doesnt_out_of_memory(         self, patch_flags, patch_capture     ): |
| .venv/lib/python3.13/site-packages/posthog/test/test_client.py | a49fc824b77d75273bdcc63f45883b228a82a2e82081ab430afd2e4eacfdd169 | 1722 | 4 |                     "$current_url": "https://example.com/page",                     "$process_person_profile": False,                     "$raw_user_agent": "Mozilla/5.0 Test Agent",                   |
| .venv/lib/python3.13/site-packages/posthog/ai/utils.py | 47a80ce9c10eb4496aa9d8b66a7c126a8cf80f2593e780c1955d036a9c3d1ae6 | 545 | 4 |         "n",         "stop",         "stream",  # OpenAI-specific field         "streaming",  # Anthropic-specific field     ]: |
| .venv/lib/python3.13/site-packages/posthog/ai/gemini/__init__.py | 6cc3419c9e8d3bf3c2402c26c4a222c3869d16e110d3a84514100bb7e6835bed | 12 | 1 |   # Create a genai-like module for perfect drop-in replacement class _GenAI:     Client = Client |
| .venv/lib/python3.13/site-packages/posthog/ai/gemini/gemini.py | 289f6b83999f4c3460be61b0d9b3689a94f08cb6463cbfe2f0e685361355ee83 | 367 | 3 |  from posthog.ai.utils import (     call_llm_and_track_usage,     get_model_params,     with_privacy_mode, |
| .venv/lib/python3.13/site-packages/posthog/ai/langchain/callbacks.py | 26f4e318a5e49b8b2e46f6074c5d68ab8d88eb710f13939682e19f82b80264c3 | 842 | 43 |  from langchain.callbacks.base import BaseCallbackHandler from langchain.schema.agent import AgentAction, AgentFinish from langchain_core.documents import Document from langchain_core.messages import  |
| .venv/lib/python3.13/site-packages/posthog/ai/anthropic/anthropic_async.py | 899d784cc05e7000f892ec0803d1d21f0f5bcf9b92b4abd902d7057b2527077b | 218 | 3 |  from posthog.ai.utils import (     call_llm_and_track_usage_async,     get_model_params,     merge_system_prompt, |
| .venv/lib/python3.13/site-packages/posthog/ai/anthropic/anthropic.py | 2a40cd2b5a9f4651a976d29ebb0da3e950daf37b8c4fc410bda4c7e08b48b427 | 218 | 3 |  from posthog.ai.utils import (     call_llm_and_track_usage,     get_model_params,     merge_system_prompt, |
| .venv/lib/python3.13/site-packages/posthog/ai/anthropic/anthropic_providers.py | b38bfb9d239c195d18297fd693babad36990ae3d6cefa807d5456ad567095b9e | 63 | 4 | class AnthropicBedrock(anthropic.AnthropicBedrock):     """     A wrapper around the Anthropic Bedrock SDK that automatically sends LLM usage events to PostHog.     """  |
| .venv/lib/python3.13/site-packages/posthog/ai/openai/openai.py | 5a51a1e31d2ca667fe719f3547eea5c480966eafae956f3a21e795114d6adbd9 | 637 | 23 |  from posthog.ai.utils import (     call_llm_and_track_usage,     get_model_params,     with_privacy_mode, |
| .venv/lib/python3.13/site-packages/posthog/ai/openai/openai_providers.py | fbd1dcbbbf6c2e6f426c0fdfa6645d0f7041d1c14c72da39333b874afb7aaa04 | 96 | 17 |     WrappedBeta,     WrappedChat,     WrappedEmbeddings,     WrappedResponses, ) |
| .venv/lib/python3.13/site-packages/posthog/ai/openai/openai_async.py | 21f589ae2f759e30fadd6876e831300de1bce03f46263f237a449691c93aea51 | 640 | 23 |  from posthog.ai.utils import (     call_llm_and_track_usage_async,     get_model_params,     with_privacy_mode, |
| .venv/lib/python3.13/site-packages/posthog/exception_integrations/django.py | c72d664eef132ba97296d7a9f8785b876dd84460706753aa1255dccb2be798c6 | 118 | 2 |             "distinct_id": distinct_id,             "ip": headers.get("X-Forwarded-For"),             "user_agent": headers.get("User-Agent"),             "traceparent": traceparent,             "$req |
| .venv/lib/python3.13/site-packages/coloredlogs/__init__.py | 1716a2235a50d09cd161bc762b97ff02bf566b599e64b8395ca1961ca80f04da | 1525 | 2 | DEFAULT_FIELD_STYLES = dict(     asctime=dict(color='green'),     hostname=dict(color='magenta'),     levelname=dict(color='black', bold=True),     name=dict(color='blue'), |
| .venv/lib/python3.13/site-packages/coloredlogs/converter/__init__.py | b74f1ef55f3e11df72f5e35262fdf1d431f485781a5c7266416a79e23fdada79 | 404 | 1 |     # 2. If every single space is replaced by a non-breaking space,     #    web browsers perform awkwardly unintuitive word wrapping.     # 3. The HTML output would be bloated for no good reason.     |
| .venv/lib/python3.13/site-packages/coloredlogs/converter/colors.py | d4dd8fa426be11830c5b20ba0f0ed21b6597d600baec5f45e4eb5e7855b9d923 | 311 | 3 |     '#FFC706',  # yellow     '#006FB8',  # blue     '#762671',  # magenta     '#2CB5E9',  # cyan     '#CCC',     # white |
| .venv/lib/python3.13/site-packages/jsonschema_specifications/__init__.py | aa84c1d83298eeabcdac684c3c7ea0b6600944b8a599543e7c56704faaf2ab0d | 13 | 2 | """ The JSON Schema meta-schemas and vocabularies, exposed as a Registry. """  |
| .venv/lib/python3.13/site-packages/jsonschema_specifications/tests/test_jsonschema_specifications.py | 5a46d8456e80e85a19d2b8af4a17ea54b482b00887276c7c4f1a840894d73d36 | 42 | 1 |     assert isinstance(schema, Mapping)     assert schema["$id"] == "http://json-schema.org/draft-07/schema#"     assert schema["title"] == "Core schema meta-schema"   |
| .venv/lib/python3.13/site-packages/jsonschema_specifications/schemas/draft6/metaschema.json | c29dfce9f54835c3a06c03b3c5d5ec0eda77706568f9c4df7cfbc7566a51006d | 154 | 1 |     "$schema": "http://json-schema.org/draft-06/schema#",     "$id": "http://json-schema.org/draft-06/schema#",     "title": "Core schema meta-schema",     "definitions": {         "schemaArray": { |
| .venv/lib/python3.13/site-packages/jsonschema_specifications/schemas/draft7/metaschema.json | 3d5392088261606c559b603f385329c9f1ab45b5d667eb990687453b055d405e | 167 | 1 |     "$schema": "http://json-schema.org/draft-07/schema#",     "$id": "http://json-schema.org/draft-07/schema#",     "title": "Core schema meta-schema",     "definitions": {         "schemaArray": { |
| .venv/lib/python3.13/site-packages/jsonschema_specifications/schemas/draft201909/metaschema.json | 7b761b3e121f0a0ca1ea2a0b8e2cc856bcf801604b8268d71bacaa202bc0c13b | 43 | 4 |         "https://json-schema.org/draft/2019-09/vocab/applicator": true,         "https://json-schema.org/draft/2019-09/vocab/validation": true,         "https://json-schema.org/draft/2019-09/vocab/met |
| .venv/lib/python3.13/site-packages/jsonschema_specifications/schemas/draft202012/metaschema.json | 41da76f5afb7ce062d248f762463a92f7ca47e4e0f905b224ba6afeef91ded0f | 59 | 4 |         "https://json-schema.org/draft/2020-12/vocab/unevaluated": true,         "https://json-schema.org/draft/2020-12/vocab/validation": true,         "https://json-schema.org/draft/2020-12/vocab/me |
| .venv/lib/python3.13/site-packages/jsonschema_specifications/schemas/draft4/metaschema.json | e1489d0b4755f02793302591d3fcb8f07b6893a82a94f24895f8e4edf11b82e2 | 150 | 1 |     "id": "http://json-schema.org/draft-04/schema#",     "$schema": "http://json-schema.org/draft-04/schema#",     "description": "Core schema meta-schema",     "definitions": {         "schemaArray": |
| .venv/lib/python3.13/site-packages/setuptools/_vendor/typing_extensions.py | 8307a4a721bd0d51b797158a5f89e2f2eee793759ee6c946f7c980f45dc3250c | 3642 | 2 |          The buffer protocol allows Python objects to expose a low-level         memory buffer interface. Before Python 3.12, it is not possible         to implement the buffer protocol in pure Python |
| .venv/lib/python3.13/site-packages/setuptools/_vendor/packaging/version.py | a257f2ba4fc33db7e5364278c0159eb57435edcef8c770c1e74d5d7a052fec36 | 583 | 1 | A string containing the regular expression used to match a valid version.  The pattern is not anchored at either end, and is intended for embedding in larger expressions (for example, matching a versi |
| .venv/lib/python3.13/site-packages/setuptools/_vendor/packaging/licenses/_spdx.py | a009b5ced3c5c25b2608a7bb94002cbff38839f4b57160eef5b34191ebbeda7b | 760 | 2 |     'adobe-glyph': {'id': 'Adobe-Glyph', 'deprecated': False},     'adobe-utopia': {'id': 'Adobe-Utopia', 'deprecated': False},     'adsl': {'id': 'ADSL', 'deprecated': False},     'afl-1.1': {'id': ' |
| .venv/lib/python3.13/site-packages/setuptools/_vendor/jaraco/functools/__init__.py | 844009692dae49946e17f258e02c421c8621efd669c5a3e9f4e887cabf44275c | 634 | 2 |     Decorate func so it's only ever called the first time.      This decorator can ensure that an expensive or non-idempotent function     will not be expensive on subsequent calls and is idempotent.  |
| .venv/lib/python3.13/site-packages/setuptools/_vendor/jaraco/collections/__init__.py | 3dcd7e4aa8d69bcd5a7753f4f86b6da64c0efcb5a59da63a814abc81c2a1dafd | 1092 | 1 |     # (https://peps.python.org/pep-0443/#abstract-base-classes).     if isinstance(obj, re.Pattern):         return obj.fullmatch     # mypy issue: https://github.com/python/mypy/issues/11071     if n |
| .venv/lib/python3.13/site-packages/setuptools/_vendor/wheel/macosx_libfile.py | 935c7b084dcb3ed3951aa8fa3574359d319854f69e46b855cd41bf28fab7cc3b | 483 | 4 |     uint32_t	cmdsize;	/* includes sizeof section structs */     char		segname[16];	/* segment name */     uint32_t	vmaddr;		/* memory address of this segment */     uint32_t	vmsize;		/* memory size of |
| .venv/lib/python3.13/site-packages/setuptools/_vendor/wheel/vendored/packaging/version.py | 3c525a6190f1060cb191f6211f7490c38a9f13d202096ad39a2b6fab5e32ddbb | 562 | 1 | A string containing the regular expression used to match a valid version.  The pattern is not anchored at either end, and is intended for embedding in larger expressions (for example, matching a versi |
| .venv/lib/python3.13/site-packages/setuptools/_vendor/zipp/__init__.py | 42e235834d06e1f440706b7e1ea6d5d285889264a079d086198b071d8ccd6bc0 | 502 | 1 |         prefix = re.escape(self.at)         tr = Translator(seps='/')         matches = re.compile(prefix + tr.translate(pattern)).fullmatch         names = (data.filename for data in self.root.fileli |
| .venv/lib/python3.13/site-packages/setuptools/_vendor/zipp/glob.py | 7ad5a99df1284727d4beb52c8bab13886984aef3f07ba1f363aa53f2383f9542 | 107 | 1 |         matches newlines (valid on Unix).          Append '\Z' to imply fullmatch even when match is used.         """         return rf'(?s:{pattern})\Z' |
| .venv/lib/python3.13/site-packages/setuptools/_vendor/more_itertools/more.py | d44e64cc59dc44a4c3c34718bf5c915cc80376e9ecb4b41dd504ad7272fa53dd | 4807 | 6 |      This is similar to using ``zip(*iterable)``, but it avoids reading     *iterable* into memory. Note, however, that this function uses     :func:`itertools.tee` and thus may require significant st |
| .venv/lib/python3.13/site-packages/setuptools/_vendor/typeguard/_checkers.py | 251ae02a271d3847c8068344b5e81808422586969df9ad6ed449bb1828f45822 | 994 | 1 |     memo: TypeCheckMemo, ) -> None:     if not isinstance(value, (bytearray, bytes, memoryview)):         raise TypeCheckError("is not bytes-like")  |
| .venv/lib/python3.13/site-packages/setuptools/_vendor/platformdirs/windows.py | 205a62a21501c313ed0b39722b036dc725b8264f2169ae96f28e7d99fac35d5a | 273 | 1 |         "CSIDL_LOCAL_APPDATA": "Local AppData",         "CSIDL_PERSONAL": "Personal",         "CSIDL_DOWNLOADS": "{374DE290-123F-4565-9164-39C4925E467B}",         "CSIDL_MYPICTURES": "My Pictures",    |
| .venv/lib/python3.13/site-packages/setuptools/tests/test_build_meta.py | 92f8b4067e29f4305599edf3c9642c9f742007da0f76af12d796a08f59baf4bd | 960 | 1 |                 self._kill(pid)                 pytest.xfail(f"Backend did not respond before timeout ({TIMEOUT} s)")             except (futures.process.BrokenProcessPool, MemoryError, OSError):      |
| .venv/lib/python3.13/site-packages/setuptools/tests/test_virtualenv.py | 83e9e30bff494c0b35615c7fd5d189fd0e919489cee2a295bbdf9702035be936 | 114 | 1 |         venv.run(["python", "-m", "pip", "install", "-U", pip_version, "--retries=1"])     with pytest.raises(subprocess.CalledProcessError):         # Meta-test to make sure setuptools is not install |
| .venv/lib/python3.13/site-packages/setuptools/tests/config/test_pyprojecttoml.py | d0b79f4a58d4840e8caad279015ccb8689aa65c62214a76eff57240de313d4b6 | 397 | 1 |     }      assert pkg_root  # Meta-test: cannot be empty string.      if pkg_root == ".": |
| .venv/lib/python3.13/site-packages/setuptools/_distutils/version.py | bc8993e7e1025e4436d6828bd17605893a8ae8dc8cd3d729cc136803fdf80905 | 349 | 1 |         1.3.a4         1.3pl1         1.3c4      The rationale for this version numbering system will be explained |
| .venv/lib/python3.13/site-packages/setuptools/_distutils/core.py | 1841ca6850b8f13de8fbf4a61f8f3ae06bcacb1d4881b542e884883d5971edae | 290 | 1 |     """Run a setup script in a somewhat controlled environment, and     return the Distribution instance that drives things.  This is useful     if you need to find out the distribution meta-data (pas |
| .venv/lib/python3.13/site-packages/setuptools/_distutils/dist.py | 816e7df1413458c9335d0437d4dafef0becc3f0d2820ecf9392491cd8665c2b3 | 1387 | 2 |             setattr(self, attr, False)          # Store the distribution meta-data (name, version, author, and so         # forth) in a separate object -- we're getting to have enough         # inform |
| .venv/lib/python3.13/site-packages/setuptools/_distutils/command/check.py | ca835ed8c3d8e0971333baf0a0841d7d9ef9ab9462d39f08d9ca22f86abd0a33 | 153 | 5 |  class check(Command):     """This command checks the meta-data of the package."""      description = "perform some checks on the package" |
| .venv/lib/python3.13/site-packages/setuptools/_distutils/command/sdist.py | 711205e87b75849e9ac8e38557270c14150dc63a3de1efeb1583f1e078bc0217 | 522 | 2 |             'metadata-check',             None,             "Ensure that all required elements of meta-data "             "are supplied. Warn if any missing. [default]",         ), |
| .venv/lib/python3.13/site-packages/setuptools/_distutils/command/bdist_rpm.py | 9f17175efe5aec1fb59ed5aee036c6982b444b810120dac968141c44d0180892 | 599 | 2 |         ('binary-only', None, "only generate binary RPM"),         ('use-bzip2', None, "use bzip2 instead of gzip to create source distribution"),         # More meta-data: too RPM-specific to put in  |
| .venv/lib/python3.13/site-packages/authlib/consts.py | 6206a529dc9da0584f83bf7c5de01c6dde7a09119675bddf32c0d553d69ca588 | 12 | 1 | author = "Hsiaoming Yang <me@lepture.com>" homepage = "https://authlib.org" default_user_agent = f"{name}/{version} (+{homepage})"  default_json_headers = [ |
| .venv/lib/python3.13/site-packages/authlib/oauth2/rfc6749/parameters.py | 0d69b6313de683571f3e32f70c657e570113e5253dd4a31df6dae89c3de9acf6 | 210 | 2 |     :param state: An opaque value used by the client to maintain                   state between the request and callback.  The authorization                   server includes this value when redirect |
| .venv/lib/python3.13/site-packages/authlib/oauth2/rfc6749/grants/implicit.py | b42c109ccf934f10f1633b1bc77b1bdc191052939bc28038663843f179e4b681 | 226 | 7 |      Since this is a redirection-based flow, the client must be capable of     interacting with the resource owner's user-agent (typically a web     browser) and capable of receiving incoming requests |
| .venv/lib/python3.13/site-packages/authlib/oauth2/rfc6749/grants/authorization_code.py | 097a754537b34c0608db2c4c52dc96db61deb996f843f1355ff73a49129cdda8 | 391 | 6 |     tokens and refresh tokens and is optimized for confidential clients.     Since this is a redirection-based flow, the client must be capable of     interacting with the resource owner's user-agent  |
| .venv/lib/python3.13/site-packages/authlib/oauth2/rfc6749/grants/base.py | e7d62004812f603a1451b1a493403b9602d77919ea0a2af58a6bd457f619a967 | 159 | 1 |     # application/json should always in UTF-8.     # The example on RFC is incorrect.     # https://tools.ietf.org/html/rfc4627     TOKEN_RESPONSE_HEADER = default_json_headers  |
| .venv/lib/python3.13/site-packages/authlib/jose/rfc7516/models.py | 69e389b405b42fa098c0ad22c20307c124229397ee561a9a55ca1eee7ec8b573 | 158 | 2 |         :param msg: text to be encrypt in bytes         :param aad: additional authenticated data in bytes         :param iv: initialization vector in bytes         :param key: encrypted key in bytes  |
| .venv/lib/python3.13/site-packages/authlib/jose/rfc7516/jwe.py | 3133adcb0306e898b6f8f334a5a5b88f1e2be6ad73542d0634bde966f7861eee | 760 | 7 |             BASE64URL(UTF8(JWE Protected Header)) \|\| '.' \|\|             BASE64URL(JWE Encrypted Key) \|\| '.' \|\|             BASE64URL(JWE Initialization Vector) \|\| '.' \|\|             BASE64URL(JWE Ciph |
| .venv/lib/python3.13/site-packages/authlib/jose/rfc7518/jwe_encs.py | 034c0a863f6ef6117f079d54ee71f16454394ec9117c9e54b9b7b50e5bc1f00c | 148 | 4 |         :param msg: text to be encrypt in bytes         :param aad: additional authenticated data in bytes         :param iv: initialization vector in bytes         :param key: encrypted key in bytes  |
| .venv/lib/python3.13/site-packages/authlib/jose/rfc7518/jwe_algs.py | b41c3f95452bb3d442623c958b838ebb5fc5821d7942da7e878a878c201cd1ef | 351 | 1 |          #: https://tools.ietf.org/html/rfc7518#section-4.7.1.1         #: The "iv" (initialization vector) Header Parameter value is the         #: base64url-encoded representation of the 96-bit IV v |
| .venv/lib/python3.13/site-packages/authlib/jose/drafts/_jwe_enc_cryptography.py | c9deb7a0db9b97ebd2302f07fe0f3114608c6b70141213b3ad7427192d930525 | 52 | 2 |         :param msg: text to be encrypt in bytes         :param aad: additional authenticated data in bytes         :param iv: initialization vector in bytes         :param key: encrypted key in bytes  |
| .venv/lib/python3.13/site-packages/authlib/jose/drafts/_jwe_enc_cryptodome.py | f90abe256b01aee8b9f94256d50a8396db090b282f58089c4a46d0a9c1f48dda | 54 | 2 |         :param msg: text to be encrypt in bytes         :param aad: additional authenticated data in bytes         :param iv: initialization vector in bytes         :param key: encrypted key in bytes  |
| .venv/lib/python3.13/site-packages/authlib/integrations/base_client/sync_app.py | ddd58050779f0f5fb7aa869652bf70fab3b056c9c9da307c1a228b3286130e9e | 378 | 13 | from authlib.common.security import generate_token from authlib.common.urls import urlparse from authlib.consts import default_user_agent  from .errors import MismatchingStateError |
| .venv/lib/python3.13/site-packages/authlib/oauth1/rfc5849/authorization_server.py | cbebc343bf7e0858c2974e55f6462a4c3845742182319f7063d4baea63239817 | 351 | 2 |         Assume the endpoint for authorization request is         ``https://photos.example.net/authorize``, the client redirects Jane's         user-agent to the server's Resource Owner Authorization e |
| .venv/lib/python3.13/site-packages/kubernetes/dynamic/test_discovery.py | 1ac402dc9452b19aed655ef33b6fae67ff47c91df83e7e250ed11395e29c7e79 | 62 | 1 |         # do Discoverer.__init__         client = DynamicClient(api_client.ApiClient(configuration=self.config))         # the resources of client will use _cache['resources'] in memory         deploy |
| .venv/lib/python3.13/site-packages/kubernetes/config/kube_config.py | ed76cf8a0e42caa84601850bb305ca9fecb46dcf45b54c8a53fa589ec9e62d60 | 902 | 1 |         atexit.register(_cleanup_temp_files)     # Because we may change context several times, try to remember files we     # created and reuse them at a small memory cost.     content_key = str(cont |
| .venv/lib/python3.13/site-packages/kubernetes/utils/quantity.py | 3c568e71032e144568280cb21af64d78dc23c526f7a4e05d2e3f53cdd0315a5d | 143 | 8 |     like "200Mi".Users can specify an additional decimal number to quantize the output.      Example -  Relatively increase pod memory limits:      # retrieve my_pod |
| .venv/lib/python3.13/site-packages/kubernetes/client/api_client.py | 078e31ae99fd93d4553c3ae8373dd30973208100e1fc6bf3917bd5c204f6a36f | 648 | 8 |             self.default_headers[header_name] = header_value         self.cookie = cookie         # Set default User-Agent.         self.user_agent = 'OpenAPI-Generator/33.1.0/python'         self.cli |
| .venv/lib/python3.13/site-packages/kubernetes/client/models/v1_node_swap_status.py | ce39fefde27091ee216b049d7eeb08afa52676de593f959d3fae8c4f07fa0dcc | 123 | 2 |         """Gets the capacity of this V1NodeSwapStatus.  # noqa: E501          Total amount of swap memory in bytes.  # noqa: E501          :return: The capacity of this V1NodeSwapStatus.  # noqa: E501 |
| .venv/lib/python3.13/site-packages/kubernetes/client/models/v1_secret.py | eab069ad4f05a28cd5fa723f1881b44dd18be1971021c352d288b0db4c7da459 | 289 | 2 |         """Gets the data of this V1Secret.  # noqa: E501          Data contains the secret data. Each key must consist of alphanumeric characters, '-', '_' or '.'. The serialized form of the secret da |
| .venv/lib/python3.13/site-packages/kubernetes/client/models/v1_object_meta.py | 264702231cc891b25b34bfea9b05533de799be41dd5313439c13a26e0625a85b | 515 | 4 |         """Gets the generate_name of this V1ObjectMeta.  # noqa: E501          GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been pro |
| .venv/lib/python3.13/site-packages/kubernetes/client/models/v1_service_spec.py | ae782bcf14a52fc93bd6f5ae2bdd56ceadfc1ca23957801dcb0939f36bec5cc7 | 653 | 4 |         """Gets the publish_not_ready_addresses of this V1ServiceSpec.  # noqa: E501          publishNotReadyAddresses indicates that any agent which deals with endpoints for this Service should disre |
| .venv/lib/python3.13/site-packages/kubernetes/client/models/v2_hpa_scaling_rules.py | a5cd07bbfb598325c71355098ab5b5f87a3aa8a9da752690895942068958340c | 207 | 2 |         """Gets the tolerance of this V2HPAScalingRules.  # noqa: E501          tolerance is the tolerance on the ratio between the current and desired metric value under which no updates are made to  |
| .venv/lib/python3.13/site-packages/kubernetes/client/models/v1_container_resize_policy.py | 3d8595b030451f2092c9cd002256c5babf40946e17d6ab0a54a013a2f49a7bdf | 153 | 2 |         """Gets the resource_name of this V1ContainerResizePolicy.  # noqa: E501          Name of the resource to which this resource resize policy applies. Supported values: cpu, memory.  # noqa: E50 |
| .venv/lib/python3.13/site-packages/kubernetes/client/models/v1_empty_dir_volume_source.py | 4ae50633b184268efd79cb11c5e68acfcffe6f0203e11222873fbaa6abec0cdc | 151 | 8 |         """Gets the medium of this V1EmptyDirVolumeSource.  # noqa: E501          medium represents what type of storage medium should back this directory. The default is \"\" which means to use the n |
| .venv/lib/python3.13/site-packages/kubernetes/client/models/v1_mutating_webhook.py | 14aa745bd43cd2ed1f81473f270f1c5bf0d4892cf55bb20a541d63b1cafe7a9f | 429 | 2 |         """Gets the reinvocation_policy of this V1MutatingWebhook.  # noqa: E501          reinvocationPolicy indicates whether this webhook should be called multiple times as part of a single admissio |
| .venv/lib/python3.13/site-packages/kubernetes/client/models/v1_stateful_set_ordinals.py | 366f32fb9e58bcef1171e03923dcafbe2f3a28e8f0ee3d36c55d92b045b17ab3 | 123 | 2 |         """Gets the start of this V1StatefulSetOrdinals.  # noqa: E501          start is the number representing the first replica's index. It may be used to number replicas from an alternate index (e |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/admissionregistration_v1beta1_api.py | 739b01f6c2f6597e30b89fb1881359f4bdb21001874afa5dbfb34f8920d18a81 | 2631 | 34 |         :param async_req bool: execute request asynchronously         :param V1beta1ValidatingAdmissionPolicy body: (required)         :param str pretty: If 'true', then the output is pretty printed.  |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/node_v1_api.py | 99d2d1eed121867a1c8279bb8809ffafe64963c9612bdcb96c7db60e2c794074 | 1180 | 14 |         :param async_req bool: execute request asynchronously         :param V1RuntimeClass body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaults to 'false |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/flowcontrol_apiserver_v1_api.py | 1019599bec649ef19741132dd90be909dad3f838e2c01203d670d9b692ad0da8 | 3045 | 40 |         :param async_req bool: execute request asynchronously         :param V1FlowSchema body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaults to 'false'  |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/autoscaling_v1_api.py | a181b18279892ca2e0b36494058e586822a1172be9c3048704d1f31631371104 | 1844 | 22 |         :param str namespace: object name and auth scope, such as for teams and projects (required)         :param V1HorizontalPodAutoscaler body: (required)         :param str pretty: If 'true', then |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/storagemigration_v1alpha1_api.py | b323fd11364e2b23774c8ac37be256c5a91d59f19a7cc4817c2d30f85313ccb5 | 1594 | 20 |         :param async_req bool: execute request asynchronously         :param V1alpha1StorageVersionMigration body: (required)         :param str pretty: If 'true', then the output is pretty printed. D |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/networking_v1beta1_api.py | 1dd7b0da473633e79e00b3170abbbdf614c57068c80fa43ae4e95fa2755036aa | 2631 | 34 |         :param async_req bool: execute request asynchronously         :param V1beta1IPAddress body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaults to 'fal |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/apps_v1_api.py | d1c65dca4b945f941f7a31e2700d0e73292b08cfdb1169ff3e65839146efe65f | 9530 | 122 |         :param str namespace: object name and auth scope, such as for teams and projects (required)         :param V1ControllerRevision body: (required)         :param str pretty: If 'true', then the  |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/certificates_v1_api.py | aed9bd44c96ebf58ad11d2107aad37fe0b06a29a0d1fedba210a37cf5a9afce2 | 2008 | 26 |         :param async_req bool: execute request asynchronously         :param V1CertificateSigningRequest body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defau |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/storage_v1beta1_api.py | bbd7140702ecae8e8ba8950a38e2cc2d8b3258296cef93a0455742771d56203d | 1180 | 14 |         :param async_req bool: execute request asynchronously         :param V1beta1VolumeAttributesClass body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defa |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/batch_v1_api.py | 816ec17cd4bea62eb9ab32791f62341b1a364de4a155ab1ac7d2633789253a45 | 3545 | 44 |         :param str namespace: object name and auth scope, such as for teams and projects (required)         :param V1CronJob body: (required)         :param str pretty: If 'true', then the output is p |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/storage_v1_api.py | 9ee913241e0124b0fb08be48c9406e6db126e4b51f6f8034e63cfd217a317853 | 5965 | 78 |         :param async_req bool: execute request asynchronously         :param V1CSIDriver body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaults to 'false' u |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/authentication_v1_api.py | 84a40b37a4fbf5e02eb8378f00a7b0af8e695f213eecfa0a38ec334267b5a013 | 411 | 4 |         :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printabl |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/resource_v1beta1_api.py | e379b428954ac3bbbe745cb917f91cb9fa376eabc33b356b9952aaa8ec213eae | 5178 | 66 |         :param async_req bool: execute request asynchronously         :param V1beta1DeviceClass body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaults to 'f |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/coordination_v1beta1_api.py | 434030974a5e35f39aee95197cf8365c5c788bf2d803adce37497ab91546b0c9 | 1403 | 16 |         :param str namespace: object name and auth scope, such as for teams and projects (required)         :param V1beta1LeaseCandidate body: (required)         :param str pretty: If 'true', then the |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/apiregistration_v1_api.py | 5efdbd7dc8238a9a4ede489975da812d3f82c013d51b311e3557fd1f9c42da27 | 1594 | 20 |         :param async_req bool: execute request asynchronously         :param V1APIService body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaults to 'false'  |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/core_v1_api.py | 93863aa01bdca0c1bf8814773ad67df0d7ac464d431462f888a072543be73d22 | 30455 | 314 |         :param async_req bool: execute request asynchronously         :param V1Namespace body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaults to 'false' u |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/authorization_v1_api.py | 83cca84101302c0344b5d7ba87de89269b47edd9c39daf4dc4590943de2e3010 | 688 | 8 |         :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printabl |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/certificates_v1alpha1_api.py | a1787a18ebab62eecc7b5647a4e2671e3518ebed70c1bb9a646e194c7c51c5f0 | 1180 | 14 |         :param async_req bool: execute request asynchronously         :param V1alpha1ClusterTrustBundle body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaul |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/discovery_v1_api.py | 7186ff68a8e0124d1a1bdd7b7d0a0686ca920acbe9a98e0a2d15891fc8728d55 | 1403 | 16 |         :param str namespace: object name and auth scope, such as for teams and projects (required)         :param V1EndpointSlice body: (required)         :param str pretty: If 'true', then the outpu |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/events_v1_api.py | 470456179d119e2a3696eb7540cafccee5ab0e1b381f7ae23c85993a890dd52b | 1403 | 16 |         :param str namespace: object name and auth scope, such as for teams and projects (required)         :param EventsV1Event body: (required)         :param str pretty: If 'true', then the output  |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/admissionregistration_v1alpha1_api.py | 7b1a9a394ce362376a3c8ee2f190cef62c87a1b48a532e3b938b755a7c631ef6 | 2217 | 28 |         :param async_req bool: execute request asynchronously         :param V1alpha1MutatingAdmissionPolicy body: (required)         :param str pretty: If 'true', then the output is pretty printed. D |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/storage_v1alpha1_api.py | 015ef5a885d9b89d169f8cc3b6653ec8071298f6d538c88648059ae8789ea195 | 1180 | 14 |         :param async_req bool: execute request asynchronously         :param V1alpha1VolumeAttributesClass body: (required)         :param str pretty: If 'true', then the output is pretty printed. Def |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/autoscaling_v2_api.py | 1820d6a821f00cb109b751687d3c821886f8d8f447bfa93633bcfb6cbe3896c5 | 1844 | 22 |         :param str namespace: object name and auth scope, such as for teams and projects (required)         :param V2HorizontalPodAutoscaler body: (required)         :param str pretty: If 'true', then |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/internal_apiserver_v1alpha1_api.py | fc9861678016eb12338618bb4ac02c587990b0285d312bde685942dc1d4fd519 | 1594 | 20 |         :param async_req bool: execute request asynchronously         :param V1alpha1StorageVersion body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaults t |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/networking_v1_api.py | 901c16949b3f5f95e7abe493772a677620c9beb6136d9ec8022e2a646338b83e | 6629 | 86 |         :param async_req bool: execute request asynchronously         :param V1IngressClass body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaults to 'false |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/policy_v1_api.py | b4e061cfe960610ea39723aecb0e781adb4643c7339bfccc5a4513c3f63a446b | 1844 | 22 |         :param str namespace: object name and auth scope, such as for teams and projects (required)         :param V1PodDisruptionBudget body: (required)         :param str pretty: If 'true', then the |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/coordination_v1alpha2_api.py | 48df400eee652ae46288715c3e8c868ea11418e6c1cc773742c709450be93439 | 1403 | 16 |         :param str namespace: object name and auth scope, such as for teams and projects (required)         :param V1alpha2LeaseCandidate body: (required)         :param str pretty: If 'true', then th |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/rbac_authorization_v1_api.py | 6bb8071647e10b0acf4864ccb0e697647b04e4d8fe02df57d3c90af902185d66 | 4737 | 60 |         :param async_req bool: execute request asynchronously         :param V1ClusterRole body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaults to 'false' |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/certificates_v1beta1_api.py | 199a68f0bc132df4bd3d9c19c5fd7ad21b0d6a2c8c7d3c45c2fe8f600aecb5c3 | 1180 | 14 |         :param async_req bool: execute request asynchronously         :param V1beta1ClusterTrustBundle body: (required)         :param str pretty: If 'true', then the output is pretty printed. Default |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/coordination_v1_api.py | 3d4fa0e9a281dfc99841ff68609dcab697021a76dd104c1e63c0c031c2402573 | 1403 | 16 |         :param str namespace: object name and auth scope, such as for teams and projects (required)         :param V1Lease body: (required)         :param str pretty: If 'true', then the output is pre |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/admissionregistration_v1_api.py | 2ea099a0096c5e222ecd16866c50b8418fda37bbb9a933a19c8c8e3309584cfb | 4705 | 62 |         :param async_req bool: execute request asynchronously         :param V1MutatingWebhookConfiguration body: (required)         :param str pretty: If 'true', then the output is pretty printed. De |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/resource_v1alpha3_api.py | 2bfc27cab67862a7ee029493821f88f20037547b53f56dbb97fdb38dda23bc71 | 6215 | 80 |         :param async_req bool: execute request asynchronously         :param V1alpha3DeviceClass body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaults to ' |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/resource_v1beta2_api.py | d3222d899a433bb07beff3b3c8690c91db64536e3170c701cfb0ceb63fc5a45f | 5178 | 66 |         :param async_req bool: execute request asynchronously         :param V1beta2DeviceClass body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaults to 'f |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/scheduling_v1_api.py | 3a12ad27e59398fc1211a92e5f3aabf48191bed337f7dac34b8fbd73922474c9 | 1180 | 14 |         :param async_req bool: execute request asynchronously         :param V1PriorityClass body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaults to 'fals |
| .venv/lib/python3.13/site-packages/kubernetes/client/api/apiextensions_v1_api.py | 541ddf8af1881f0a10dacb9a4c9c7dab134e03b284aed285b9275e795ed533e2 | 1594 | 20 |         :param async_req bool: execute request asynchronously         :param V1CustomResourceDefinition body: (required)         :param str pretty: If 'true', then the output is pretty printed. Defaul |
| .venv/lib/python3.13/site-packages/virtualenv/discovery/cached_py_info.py | 2d67ec43549e7ce2245b5b939f4ee0ca5ebdbb64f0c79d3f2673ca93571d8916 | 216 | 2 |     # pyenv.cfg somewhere alongside on python3.5+     exe_path = Path(exe)     if not ignore_cache and exe_path in _CACHE:  # check in the in-memory cache         result = _CACHE[exe_path]     else:   |
| .venv/lib/python3.13/site-packages/virtualenv/discovery/builtin.py | 5f47e506683525201142d1e0f91ab9cbd2b7b6ee64f4116ea08ca957bf96a6d3 | 265 | 1 |         # 5. or from the spec we can deduce if a name on path matches         for exe in path.iterdir():             match = pat.fullmatch(exe.name)             if match:                 # the impleme |
| .venv/lib/python3.13/site-packages/virtualenv/create/via_global_ref/builtin/cpython/common.py | 14a58fa74500abb9455ffbdc0422406504baab337aba8ef7774493f0323e1243 | 74 | 1 |  def is_macos_brew(interpreter):     return interpreter.platform == "darwin" and _BREW.fullmatch(interpreter.system_prefix) is not None   |
| .venv/lib/python3.13/site-packages/pip_api/_vendor/pyparsing.py | d020ebeed3c64fceb2f771326f0e5e0fe170f8a9d87cf6af2cc463c54cb5efb1 | 7108 | 18 |         return self      def setResultsName(self, name, listAllMatches=False):         """         Define name for referencing matching tokens as a nested attribute |
| .venv/lib/python3.13/site-packages/pip_api/_vendor/packaging/_manylinux.py | 23f348d461deead94af26236635de8fe3644ffd157510d497b02f1997067ce5b | 302 | 1 |         """      ELF_MAGIC_NUMBER = 0x7F454C46     ELFCLASS32 = 1     ELFCLASS64 = 2 |
| .venv/lib/python3.13/site-packages/pydantic/color.py | e06aed3ef14204a74cfb53692d514e0bb2a42de8f265dd418842df08abd3db2c | 605 | 8 |         return ints_to_rgba(r, g, b, None)      m = re.fullmatch(r_hex_short, value_lower)     if m:         *rgb, a = m.groups() |
| .venv/lib/python3.13/site-packages/pydantic/config.py | a6349978ffc9015bc6c2ca13798b513ccdc4e7beaab99137b7b8b2f0cfd9e8f3 | 1063 | 2 |     Whether to cache strings to avoid constructing new Python objects. Defaults to True.      Enabling this setting should significantly improve validation performance while increasing memory usage sl |
| .venv/lib/python3.13/site-packages/pydantic/version.py | 698e84955974b1bb773ef87bce36ff4fa7bd53d3adc05df151a04ec59101b2c7 | 79 | 2 |      It parses normal version like `0.930` and extra info followed by a `+` sign     like `0.940+dev.04cac4b5d911c4f9529e6ce86a27b44f28846f5d.dirty`.      Args: |
| .venv/lib/python3.13/site-packages/pydantic/networks.py | a5090ebf9586ea59f0f2e02326b8413acc9fc4799a6278e1b8f6c105d26adec6 | 779 | 1 |         )      m = pretty_email_regex.fullmatch(value)     name: str \| None = None     if m: |
| .venv/lib/python3.13/site-packages/pydantic/main.py | a150eb94fa79e9c39a9b8e24d482a49e54d4e9b771386080bdb16da756577a0b | 1611 | 2 |             exclude_defaults: Whether to exclude fields that are set to their default value.             exclude_none: Whether to exclude fields that have a value of `None`.             round_trip: If |
| .venv/lib/python3.13/site-packages/pydantic/v1/_hypothesis_plugin.py | e444b9c56bb0d45400b3298b7b3cbc4209d5cf466955f5378e4993ef81f6ed54 | 392 | 4 |         st.builds(             '{} <{}>'.format,  # type: ignore[arg-type]             st.from_regex('[A-Za-z0-9_]+( [A-Za-z0-9_]+){0,5}', fullmatch=True),             st.emails().filter(is_valid_emai |
| .venv/lib/python3.13/site-packages/pydantic/v1/color.py | 8990012d8a7a395a28d801643fd229ae2ff049cebe2a496ef18ba149aaed7798 | 495 | 8 |         return ints_to_rgba(r, g, b, None)      m = re.fullmatch(r_hex_short, value_lower)     if m:         *rgb, a = m.groups() |
| .venv/lib/python3.13/site-packages/pydantic/v1/fields.py | 56a5890ab894362132a6d5eba03549e74d49a550347a7d9500d724b2a5cbd9bf | 1254 | 3 |         Prepare the field but inspecting self.default, self.type_ etc.          Note: this method is **not** idempotent (because _type_analysis is not idempotent),         e.g. calling it it multiple  |
| .venv/lib/python3.13/site-packages/pydantic/v1/types.py | 165b71e46a0ffea69498092d946cfb9c57896b5df2372dc5635f9170ccc456df | 1206 | 1 |     # it monkeypatches this function.     # If Hypothesis is never used, the total effect is to keep a weak reference     # which has minimal memory usage and doesn't even affect garbage collection.   |
| .venv/lib/python3.13/site-packages/pydantic/v1/networks.py | 1d836d2807ce98e9ca269b0383583a488923f563e153ffa2f25e5ed89281a46e | 748 | 4 |         elif host_type == 'domain':             is_international = False             d = ascii_domain_regex().fullmatch(host)             if d is None:                 d = int_domain_regex().fullmatch |
| .venv/lib/python3.13/site-packages/pydantic/_internal/_typing_extra.py | b7f4cd4221f67e4c2d479464bd9d62500d05928a7505660e03fc1cd962f894a4 | 582 | 1 |         https://github.com/pydantic/pydantic/issues/6912          Implemented as EAFP with memory.         """         return typing.ForwardRef(arg, is_argument) |
| .venv/lib/python3.13/site-packages/pydantic/_internal/_generics.py | 280e9a3732f01e523af5de59b905bcdbf714691ac07fa8b84aed3e3e81ae7569 | 519 | 1 |      class LimitedDict(dict):         """Limit the size/length of a dict used for caching to avoid unlimited increase in memory usage.          Since the dict is ordered, and we always remove elements |
| .venv/lib/python3.13/site-packages/license_expression/data/scancode-licensedb-index.json | d7594273825a68b2d5676d76d336c560210072f07a77edb193ad608694067596 | 31418 | 114 |   },   {     "license_key": "3dslicer-1.0",     "category": "Permissive",     "spdx_license_key": "3D-Slicer-1.0", |
| .venv/lib/python3.13/site-packages/black/handle_ipynb_magics.py | d6cf510f9f653a04bbd5f3a013c6c45c988f794744a2e5183d3bbaff0bf97fa7 | 509 | 5 |     tree = ast.parse(src)      cell_magic_finder = CellMagicFinder()     cell_magic_finder.visit(tree)     if cell_magic_finder.cell_magic is None: |
| .venv/lib/python3.13/site-packages/black/__init__.py | 338f86433b0ef7f39d856d04a1f42b916de7e59d71510fff92a8d47e200ed796 | 1597 | 1 |     if sys.version_info[:3] == (3, 12, 5):         out(             "Python 3.12.5 has a memory safety issue that can cause Black's "             "AST safety checks to fail. "             "Please upgr |
| .venv/lib/python3.13/site-packages/psutil/_pswindows.py | d767d4c4eed7c701ced3e2150ac59f95cd825db5e0f0dcdfbe01e9b604ebe272 | 1104 | 25 | scputimes = namedtuple('scputimes',                        ['user', 'system', 'idle', 'interrupt', 'dpc']) # psutil.virtual_memory() svmem = namedtuple('svmem', ['total', 'available', 'percent', 'used |
| .venv/lib/python3.13/site-packages/psutil/_common.py | d15ea993fe9daa4688301d9f6dd971111595d2322df26d722f130f0aab15cc0a | 951 | 1 |  # fmt: off # psutil.swap_memory() sswap = namedtuple('sswap', ['total', 'used', 'free', 'percent', 'sin',                              'sout']) |
| .venv/lib/python3.13/site-packages/psutil/__init__.py | b4f4a4154a17f441adbca883cd17123188546c79487456c2c39edae32b0dccb1 | 2408 | 55 |  """psutil is a cross-platform library for retrieving information on running processes and system utilization (CPU, memory, disks, network, sensors) in Python. Supported platforms:  |
| .venv/lib/python3.13/site-packages/psutil/_psosx.py | 3b41c0e7c58c40c7ccc3a4ab8f20a7d90de83771a94330bae812bdf36eb0d37f | 545 | 16 | # psutil.cpu_times() scputimes = namedtuple('scputimes', ['user', 'nice', 'system', 'idle']) # psutil.virtual_memory() svmem = namedtuple(     'svmem', ['total', 'available', 'percent', 'used', 'free' |
| .venv/lib/python3.13/site-packages/psutil/_psbsd.py | de97636b3f5054f8f639e0914125d75c67fcf62b3d1628eddf6f1d3488bc2678 | 972 | 20 |  # fmt: off # psutil.virtual_memory() svmem = namedtuple(     'svmem', ['total', 'available', 'percent', 'used', 'free', |
| .venv/lib/python3.13/site-packages/psutil/_psaix.py | e6168ae48b2aa201fbc2cfae8a46e1ecb272c2ab104cbe22855f8a4f7089f9ff | 566 | 11 |   # psutil.Process.memory_info() pmem = namedtuple('pmem', ['rss', 'vms']) # psutil.Process.memory_full_info() |
| .venv/lib/python3.13/site-packages/psutil/_pslinux.py | dbdb17ee0c3ab4b5f0a7c7922d9fcd715a9ae368259199461a89dc9165a54eb7 | 2296 | 29 |  # fmt: off # psutil.virtual_memory() svmem = namedtuple(     'svmem', ['total', 'available', 'percent', 'used', 'free', |
| .venv/lib/python3.13/site-packages/psutil/_pssunos.py | fcdd2dd2f28fbf8865fab6d59113a27805a058ffe93d406c34edbd99eef181ce | 735 | 15 |     'pcputimes', ['user', 'system', 'children_user', 'children_system'] ) # psutil.virtual_memory() svmem = namedtuple('svmem', ['total', 'available', 'percent', 'used', 'free']) # psutil.Process.memo |
| .venv/lib/python3.13/site-packages/psutil/tests/test_contracts.py | 7df3cd399d672b8c55ee0298c49b359ce8ce46433458bf8f492c4f42fabca672 | 326 | 2 |         )      def test_memory_maps(self):         hasit = hasattr(psutil.Process, "memory_maps")         assert hasit == (not (OPENBSD or NETBSD or AIX or MACOS)) |
| .venv/lib/python3.13/site-packages/psutil/tests/test_unicode.py | 0afda9a7da92e62409f1130f291a30f7ef90a07b0fd50f6783a68abdb267496b | 314 | 5 | * Process.environ() * Process.exe() * Process.memory_maps() * Process.name() * Process.net_connections('unix') |
| .venv/lib/python3.13/site-packages/psutil/tests/test_posix.py | 6cd4057c8ae02d83521716dea7d42ca9e8f8e841bbcb31faf7fb656e9cf7a1d6 | 489 | 4 |     @skip_on_access_denied()     @retry_on_failure()     def test_rss_memory(self):         # give python interpreter some time to properly initialize         # so that the results are the same |
| .venv/lib/python3.13/site-packages/psutil/tests/test_linux.py | 570d61c329f69865d0d4361292c056cdf0410329da8b25a15ca44c585ffedd28 | 2293 | 60 |  def free_swap():     """Parse 'free' cmd and return swap memory's s total, used and free     values.     """ |
| .venv/lib/python3.13/site-packages/psutil/tests/test_sunos.py | efc9d4abfe08d802e27562e238646380fef29058869bc78657724d022228395b | 40 | 2 | @pytest.mark.skipif(not SUNOS, reason="SUNOS only") class SunOSSpecificTestCase(PsutilTestCase):     def test_swap_memory(self):         out = sh(f"env PATH=/usr/sbin:/sbin:{os.environ['PATH']} swap - |
| .venv/lib/python3.13/site-packages/psutil/tests/__init__.py | 9da537838938c55081a9765e97d9c724432826440a96dc5b2b27e30c4fba1f03 | 2026 | 37 |     'CI_TESTING', 'VALID_PROC_STATUSES', 'TOLERANCE_DISK_USAGE', 'IS_64BIT',     "HAS_CPU_AFFINITY", "HAS_CPU_FREQ", "HAS_ENVIRON", "HAS_PROC_IO_COUNTERS",     "HAS_IONICE", "HAS_MEMORY_MAPS", "HAS_PR |
| .venv/lib/python3.13/site-packages/psutil/tests/test_aix.py | 3b922a300537ab0d4d5ef23e9e135bf6fd4b6cd1dbd6ade21517b93a4aa0a682 | 143 | 5 | @pytest.mark.skipif(not AIX, reason="AIX only") class AIXSpecificTestCase(PsutilTestCase):     def test_virtual_memory(self):         out = sh('/usr/bin/svmon -O unit=KB')         re_pattern = r"memor |
| .venv/lib/python3.13/site-packages/psutil/tests/test_process_all.py | 91b7ba1ead14346b870b1d13f632e893c3be13b443422e512c1672094ff07b94 | 536 | 5 |         assert ret in list(range(psutil.cpu_count()))      def memory_info(self, ret, info):         assert is_namedtuple(ret)         for value in ret: |
| .venv/lib/python3.13/site-packages/psutil/tests/test_process.py | ee0d2f2ebe597488ffb04cd691d488a5d0654657314c623652d5036ba2ae7d41 | 1668 | 24 | from psutil.tests import HAS_ENVIRON from psutil.tests import HAS_IONICE from psutil.tests import HAS_MEMORY_MAPS from psutil.tests import HAS_PROC_CPU_NUM from psutil.tests import HAS_PROC_IO_COUNTER |
| .venv/lib/python3.13/site-packages/psutil/tests/test_bsd.py | c002edd8a06cbfc2e6b926c00c69d7c7787700bedd4e178298f041f7f8b0137f | 594 | 31 |         NETBSD, reason="skipped on NETBSD"  # we check /proc/meminfo     )     def test_virtual_memory_total(self):         num = sysctl('hw.physmem')         assert num == psutil.virtual_memory().tot |
| .venv/lib/python3.13/site-packages/psutil/tests/test_system.py | 521983c34a6c4dd98081f366952d7be87bfb84ec1497b175e3cbdceea1f5f461 | 980 | 6 |   class TestMemoryAPIs(PsutilTestCase):     def test_virtual_memory(self):         mem = psutil.virtual_memory() |
| .venv/lib/python3.13/site-packages/psutil/tests/test_osx.py | cac6f7752c097f3a34ec49671494e1a092a6c2abaa42852c68a78bd6ccfccdff | 198 | 7 |     def test_vmem_total(self):         sysctl_hwphymem = sysctl('sysctl hw.memsize')         assert sysctl_hwphymem == psutil.virtual_memory().total      @pytest.mark.skipif( |
| .venv/lib/python3.13/site-packages/psutil/tests/test_memleaks.py | 842d116babf767084c98bb89a024de2d4089ba1e706b4111f14bc7552553b22a | 488 | 19 | # found in the LICENSE file.  """Tests for detecting function memory leaks (typically the ones implemented in C). It does so by calling a function many times and checking whether process memory usage  |
| .venv/lib/python3.13/site-packages/psutil/tests/test_windows.py | 3844a61c136c602c1fa5ca9e96816692f45f03325ffa757be5ad1bd33b4f51c1 | 915 | 28 |     """Currently not used, but available just in case. Usage:      >>> wmic("Win32_OperatingSystem", "FreePhysicalMemory")     2134124534     """ |
| .venv/lib/python3.13/site-packages/psutil/tests/test_scripts.py | 2befb1419adc36fe0006d6b1efa003054fc38d62b5edc71e4cf83e8c5a06a5b2 | 241 | 3 | from psutil.tests import CI_TESTING from psutil.tests import HAS_BATTERY from psutil.tests import HAS_MEMORY_MAPS from psutil.tests import HAS_SENSORS_BATTERY from psutil.tests import HAS_SENSORS_FANS |
| .venv/lib/python3.13/site-packages/psutil/tests/test_testutils.py | d9e9c7895f2631aa70acbc1a7488f4e15dd9e0cd4eb321f8f47860e5b7f75715 | 578 | 2 | from psutil.tests import PYTHON_EXE_ENV from psutil.tests import PsutilTestCase from psutil.tests import TestMemoryLeak from psutil.tests import bind_socket from psutil.tests import bind_unix_socket |
| .venv/lib/python3.13/site-packages/lxml/html/_difflib.py | 1a01ff8d5ad9402f2d23c595fe515942c5c527798e4c03eea75ce304936f90fa | 2107 | 2 |         assert alo < ahi and blo < bhi         # dump the shorter block first -- reduces the burden on short-term         # memory if the blocks are of very different sizes         if bhi - blo < ahi  |
| .venv/lib/python3.13/site-packages/scipy/conftest.py | 2ab57622b49a5c891a1d034aa260f44eec89d92e452f296f3b1692e91ce4102c | 684 | 2 |             'scipy.sparse.csgraph.floyd_warshall',             'scipy.sparse.csgraph.dijkstra',             'scipy.sparse.csgraph.bellman_ford',             'scipy.sparse.csgraph.johnson',             |
| .venv/lib/python3.13/site-packages/scipy/__init__.py | a72412a5c62442876e073a01da1910c84b7214d1382380b71a873b470420dd68 | 139 | 1 | ::   cluster                      --- Vector Quantization / Kmeans  constants                    --- Physical and mathematical constants and units  datasets                     --- Dataset methods |
| .venv/lib/python3.13/site-packages/scipy/odr/_odrpack.py | 9f7d03571efc3a1d330c8b6329da83689a625d2c953ea1d81a4eb76b5fb93598 | 1155 | 3 | =====  * Array formats -- FORTRAN stores its arrays in memory column first, i.e., an   array element A(i, j, k) will be next to A(i+1, j, k). In C and, consequently,   NumPy, arrays are stored row fir |
| .venv/lib/python3.13/site-packages/scipy/odr/__init__.py | 084af1309d3205fbbf72f0a828932ef568ea51aa212c8aaa7f6dbc1a6f575892 | 132 | 1 |        def f(B, x):            '''Linear function y = m*x + b'''            # B is a vector of the parameters.            # x is an array of the current x values.            # x is in the same format  |
| .venv/lib/python3.13/site-packages/scipy/cluster/vq.py | 1ca1590c16b3ab7e563a3f3fd4e7e0f3be5d1b69878a8083990001f36b11e866 | 833 | 16 | """ K-means clustering and vector quantization (:mod:`scipy.cluster.vq`) ====================================================================  |
| .venv/lib/python3.13/site-packages/scipy/cluster/__init__.py | a60cd6896479b26437af0b9dd9d8672e7e9da640f9963bbf9a8125429ff38681 | 32 | 1 | Clustering algorithms are useful in information theory, target detection, communications, compression, and other areas. The `vq` module only supports vector quantization and the k-means algorithms.  T |
| .venv/lib/python3.13/site-packages/scipy/cluster/hierarchy.py | 8fd2ca95416a9f536ff2b0314596196dff735b8d983c0f31b44be88ea9ab2abe | 4349 | 22 |         triangular of the distance matrix. This is the form that         ``pdist`` returns. Alternatively, a collection of         m observation vectors in n dimensions may be passed as         an m b |
| .venv/lib/python3.13/site-packages/scipy/cluster/tests/test_disjoint_set.py | 12e1c6044dd95443275856c29fcb6323effa096acd5dfa67bf96d405af6a8562 | 203 | 1 |         assert len(dis2) == i + 1          # test idempotency by adding element again         dis2.add(x)         assert len(dis2) == i + 1 |
| .venv/lib/python3.13/site-packages/scipy/cluster/tests/test_vq.py | 24c6afaf63655a3cfe114a6eb3d0760178523450279759a1aea1eb90c501aabd | 435 | 1 |     @xfail_xp_backends('dask.array', reason="Wrong answer")     @pytest.mark.skipif(sys.platform == 'win32',                         reason='Fails with MemoryError in Wine.')     def test_krandinit(se |
| .venv/lib/python3.13/site-packages/scipy/cluster/tests/test_hierarchy.py | 8f907757aefed16b3853933d32e1aa31b04aec865773596e6e7b4c5659be6130 | 1239 | 2 |     def test_gh_22183(self, xp):         # check for lack of segfault         # (out of bounds memory access)         # and correct interception of         # invalid linkage matrix |
| .venv/lib/python3.13/site-packages/scipy/ndimage/_delegators.py | 108d97b26c3a1832fc3272de41867ab8af5d56432fd3558e7757d94cb4bf06b5 | 304 | 1 |   def vectorized_filter_signature(     input, function, size=None, footprint=None, output=None, *args, **kwds ): |
| .venv/lib/python3.13/site-packages/scipy/ndimage/_measurements.py | 30275bc8a9482e07e69ded2a1453801422affa85aaaa71266fcde21bc4e5c2e9 | 1690 | 2 |     .. [1] James R. Weaver, "Centrosymmetric (cross-symmetric)        matrices, their basic properties, eigenvalues, and        eigenvectors." The American Mathematical Monthly 92.10        (1985): 71 |
| .venv/lib/python3.13/site-packages/scipy/ndimage/_ni_docstrings.py | 121ad6f90fd1d9f3bda435d885cf31292d506399d717142d11777668b586e463 | 215 | 1 | _nan_doc = ( """The behavior of this function with NaN elements is undefined. To control behavior in the presence of NaNs, consider using `vectorized_filter`.""") _size_foot_doc = ( """size : scalar o |
| .venv/lib/python3.13/site-packages/scipy/ndimage/__init__.py | 2946c37e72cf37b07e53ae74361f9755fedf4346d6f2f9040cfb2c1bca19b22e | 175 | 1 |    uniform_filter - Multidimensional uniform filter    uniform_filter1d - 1-D uniform filter along the given axis    vectorized_filter  Fourier filters |
| .venv/lib/python3.13/site-packages/scipy/ndimage/_support_alternative_backends.py | 72fe10fd11f9c90677ed07ad0f78a0dcf5b9bb32e2ce298b82adbcec5757fd3c | 85 | 1 | # Some cupyx.scipy.ndimage functions don't exist or are incompatible with # their SciPy counterparts CUPY_BLOCKLIST = ['vectorized_filter']   |
| .venv/lib/python3.13/site-packages/scipy/ndimage/_filters.py | 3ae56ebdfc58ee26cb1b3477aa211c13b57fe92ab3ebd004dda9b138f131bb8b | 2423 | 52 |            'maximum_filter1d', 'minimum_filter', 'maximum_filter',            'rank_filter', 'median_filter', 'percentile_filter',            'generic_filter1d', 'generic_filter', 'vectorized_filter'] |
| .venv/lib/python3.13/site-packages/scipy/ndimage/_morphology.py | 1e5811e97f1e758b233923720af9a0d51a9385525e2a1b71baa5002d20945425 | 2635 | 6 |         output = bool     output = _ni_support._get_output(output, input)     temp_needed = np.may_share_memory(input, output)     if temp_needed:         # input and output arrays cannot share memory |
| .venv/lib/python3.13/site-packages/scipy/ndimage/_interpolation.py | 28a40c8b15385607c4a6b2cd3d478b58dbf37c1049fe786bf5b9c9613de8ecd7 | 1034 | 1 |     Apply an affine transformation.      Given an output image pixel index vector ``o``, the pixel value     is determined from the input image at position     ``np.dot(matrix, o) + offset``. |
| .venv/lib/python3.13/site-packages/scipy/ndimage/tests/test_interpolation.py | 984ab9df8ad8ce855d7d9e1f6e212b0d35a4cdcfe7b500e4ed0569ed2fc3b343 | 1492 | 3 |     @pytest.mark.skipif('win32' in sys.platform or np.intp(0).itemsize < 8,                         reason='do not run on 32 bit or windows '                                '(no sparse memory)')     d |
| .venv/lib/python3.13/site-packages/scipy/ndimage/tests/test_morphology.py | c33644e00cea7c64f263e8132cb4a0a9a70c45119840386818c462b296e2098d | 2951 | 1 |         assert_array_almost_equal(out, expected)          # test with output memory overlap         ndimage.binary_erosion(data, struct, border_value=1,                                iterations=3, ou |
| .venv/lib/python3.13/site-packages/scipy/ndimage/tests/test_filters.py | 3d2d8ce8d0abb41daed609e00cf839790cdeeee760b18e01b2c0e20ae50633f1 | 3084 | 57 |      @uses_output_array     def test_gauss_memory_overlap(self, xp):         input = xp.arange(100 * 100, dtype=xp.float32)         input = xp.reshape(input, (100, 100)) |
| .venv/lib/python3.13/site-packages/scipy/linalg/_matfuncs_inv_ssq.py | f1d2fbc43e8353c0f88766321dc623461650befd6948e13332e2a518feb3a27c | 887 | 6 |     t : int, optional         A positive parameter controlling the tradeoff between         accuracy versus time and memory usage.         Larger values take longer and use more memory         but giv |
| .venv/lib/python3.13/site-packages/scipy/linalg/_sketches.py | 49e597d76b16b70f8489fafd436a61cabb1957373fb2779f6ed4e3fc80908229 | 190 | 1 |     .. math:: k \geq \frac{2}{\epsilon^2\delta}      Then for any fixed vector ``x``,      .. math:: \\|Ax\\| = (1\pm\epsilon)\\|A'x\\| |
| .venv/lib/python3.13/site-packages/scipy/linalg/_procrustes.py | 382ff2c09fcf6f01251ac5fff3a8dda98cf0f91c86ad4a77641e708543a11ad7 | 114 | 1 |     if A.shape != B.shape:         raise ValueError(f'the shapes of A and B differ ({A.shape} vs {B.shape})')     # Be clever with transposes, with the intention to save memory.     # The conjugate ha |
| .venv/lib/python3.13/site-packages/scipy/linalg/_decomp_qr.py | c43ec9dd4ab03776bd83217d97f65af6dd04acfff5926100f201624caf0ca1f9 | 495 | 1 |      Calculate the decomposition ``A = Q R`` where Q is unitary/orthogonal     and R upper triangular. Multiply Q with a vector or a matrix c.      Parameters |
| .venv/lib/python3.13/site-packages/scipy/linalg/_decomp_svd.py | 81de8e5f72a565f5ee3143b1b4450c8e920a38e07201d39710fd09a7c387028f | 546 | 9 |     -------     U : ndarray         Unitary matrix having left singular vectors as columns.         Of shape ``(M, M)`` or ``(M, K)``, depending on `full_matrices`.     s : ndarray |
| .venv/lib/python3.13/site-packages/scipy/linalg/_decomp.py | ccddacc5f267dd34daf58e6941ae053d1b0bdacd0216eb49ec8b82cb48aecf8c | 1646 | 61 | def _make_complex_eigvecs(w, vin, dtype):     """     Produce complex-valued eigenvectors from LAPACK DGGEV real-valued output     """     # - see LAPACK man page DGGEV at ALPHAI |
| .venv/lib/python3.13/site-packages/scipy/linalg/__init__.py | 50e1595f8182bacad08dc68f07a34d35eae1b150deef4ec1be57c4ed707c2b35 | 237 | 5 |    matmul_toeplitz - Multiply a Toeplitz matrix with an array.    det - Find the determinant of a square matrix    norm - Matrix and vector norm    lstsq - Solve a linear least-squares problem    pinv |
| .venv/lib/python3.13/site-packages/scipy/linalg/_matfuncs.py | 9188c381bc9f79fa9ea29fc2d7c702d81f6439b6cb3a9bf9d7f6e99dd009a862 | 1051 | 8 |     data.      For input with size ``n``, the memory usage is in the worst case in the     order of ``8*(n**2)``. If the input data is not of single and double     precision of real and complex dtypes |
| .venv/lib/python3.13/site-packages/scipy/linalg/_decomp_lu.py | d67a85d9fc3512b7ffd389daac66b3729b6663fe7c944dfc28edabf7d97eb1b6 | 402 | 1 |      p : (..., M, M) ndarray         Permutation arrays or vectors depending on `p_indices`     l : (..., M, K) ndarray         Lower triangular or trapezoidal array with unit diagonal. |
| .venv/lib/python3.13/site-packages/scipy/linalg/_solvers.py | 827f9fa0ab763f0ab05ee7fa2f7e62da8e770e425a35dea7cff509a8cf262735 | 863 | 2 |     of the product :math:`U_2 U_1^{-1}` and condition number of     :math:`U_1`. Here, :math:`U` is the 2m-by-m matrix that holds the     eigenvectors spanning the stable subspace with 2-m rows and pa |
| .venv/lib/python3.13/site-packages/scipy/linalg/interpolative.py | f24099bf5cf752dcc1b8fbe89a90145231d3a0bb5ae1f7ef3a35552d26912de4 | 990 | 9 |  This automatically sets up methods describing the action of the matrix and its adjoint on a vector.  Computing an ID |
| .venv/lib/python3.13/site-packages/scipy/linalg/blas.py | 86717c9ced34b7d3ab3ff00fe10cdf00e5cef4aa23b437a6abd06bd6009bc3cd | 496 | 3 |     The common ``overwrite_<>`` option in many routines, allows the    input arrays to be overwritten to avoid extra memory allocation.    However this requires the array to satisfy two conditions     |
| .venv/lib/python3.13/site-packages/scipy/linalg/_decomp_ldl.py | 779c3a000c83c31370bd5f0464eb35e3864651d17c208efb369840fdfda4f0d7 | 357 | 2 |     --------     Given an upper triangular array ``a`` that represents the full symmetric     array with its entries, obtain ``l``, 'd' and the permutation vector `perm`:      >>> import numpy as np |
| .venv/lib/python3.13/site-packages/scipy/linalg/_decomp_qz.py | 6a30b281be52e242ec35bb5c29c283201123f143ebf8b3d6e5612dd66740dc90 | 453 | 4 |         Generalized Schur form of B.     Q : (N, N) ndarray         The left Schur vectors.     Z : (N, N) ndarray         The right Schur vectors. |
| .venv/lib/python3.13/site-packages/scipy/linalg/_expm_frechet.py | fd1bd7ea6d67b5484b95b79352b6efbf8f1af34516e2408ce2014105e771c79f | 418 | 3 |   # The b vectors and U and V are copypasted # from scipy.sparse.linalg.matfuncs.py. # M, Lu, Lv follow (6.11), (6.12), (6.13), (3.3) |
| .venv/lib/python3.13/site-packages/scipy/linalg/_basic.py | cf11de4a1d7f9371c6c9097c6db5b5438cc0820fd03e5b027336055f148466d6 | 2147 | 25 |     -----     If the input b matrix is a 1-D array with N elements, when supplied     together with an NxN input a, it is assumed as a valid column vector     despite the apparent size mismatch. This  |
| .venv/lib/python3.13/site-packages/scipy/linalg/_misc.py | b9d86fc467c41f1852dde71006ec10eb95bd7b355021a541c3c24e99fa87fe81 | 192 | 6 | def norm(a, ord=None, axis=None, keepdims=False, check_finite=True):     """     Matrix or vector norm.      This function is able to return one of eight different matrix norms, |
| .venv/lib/python3.13/site-packages/scipy/linalg/lapack.py | c595b94c229c81565c71415ce6f5c48adf0f8ab32504c1541e6fcc81c4197697 | 1082 | 3 |      The common ``overwrite_<>`` option in many routines, allows the     input arrays to be overwritten to avoid extra memory allocation.     However this requires the array to satisfy two conditions  |
| .venv/lib/python3.13/site-packages/scipy/linalg/_special_matrices.py | d1c9c29c10f8a8ff29f51c7974d3d41a845095faeaa4b4f4e7af8b59ea79e94a | 1323 | 1 |     Notes     -----     When `scale` is None, multiplying a vector by the matrix returned by     `dft` is mathematically equivalent to (but much less efficient than)     the calculation performed by ` |
| .venv/lib/python3.13/site-packages/scipy/linalg/tests/test_basic.py | 1ac8a5891f1b779e6b0d55739cdeade1412a0ed2779ac3b89c148fac0a663eab | 2075 | 4 |  from scipy.linalg._testutils import assert_no_overwrite from scipy._lib._testutils import check_free_memory, IS_MUSL from scipy.linalg.blas import HAS_ILP64  |
| .venv/lib/python3.13/site-packages/scipy/linalg/tests/test_decomp.py | 1ce06677bf27b6cff501065cef04b20222bef67f6c57fa331cd10fbe0a278791 | 3190 | 26 | from scipy.sparse._sputils import matrix  from scipy._lib._testutils import check_free_memory from scipy.linalg.blas import HAS_ILP64 try: |
| .venv/lib/python3.13/site-packages/scipy/linalg/tests/test_fblas.py | 6246fb2ca8dbc4f5c07490fe2245cc02c6d4997300924bb61500abfa39434d41 | 608 | 5 | def matrixmultiply(a, b):     if len(b.shape) == 1:         b_is_vector = True         b = b[:, newaxis]     else: |
| .venv/lib/python3.13/site-packages/scipy/linalg/tests/test_sketches.py | 14ba9cf309fd7ac53c2db4ac592eff382d2c67e05c18f44ea8fbab04cf016577 | 119 | 2 |     ]      # Test vector with norm ~1     x = rng.random((n_rows, 1)) / np.sqrt(n_rows)  |
| .venv/lib/python3.13/site-packages/scipy/linalg/tests/test_lapack.py | 6c79dd55285153c6419fecf1d105ce335cde0b638c8a947e04d7661402cfaae3 | 3617 | 5 |         expected[1] = alpha          # assemble householder vector         v = np.zeros_like(a[1:, 0])         v[0] = 1.0 |
| .venv/lib/python3.13/site-packages/scipy/linalg/tests/test_special_matrices.py | e4a9104aedda1669c86b79b77aea4da76f9ff8bfca4588160c5312a03e5f04ce | 637 | 4 |     """      def create_vector(self, n, cpx):         """Make a complex or real test vector of length n."""         x = np.linspace(-2.5, 2.2, n) |
| .venv/lib/python3.13/site-packages/scipy/linalg/tests/test_decomp_update.py | 3024b38540fe6dc0acd4b979a4726a09d453804a6298282567795bf1bcf066ab | 1702 | 1 |      # all full qr, row deletes and single column deletes should be able to     # handle any non negative strides. (only row and column vector     # operations are used.) p column delete require fortr |
| .venv/lib/python3.13/site-packages/scipy/linalg/tests/test_blas.py | f30ffaaf8081ae27fd307ebdbf5e488a5e6b11cc910e552181b6d99c2f3f05c9 | 1128 | 7 |             assert_allclose(f(1.0, x, lower=True), resx.T, rtol=rtol)             assert_allclose(f(1.0, y, incx=2, offx=2, n=4), resx, rtol=rtol)             # negative increments imply reversed vect |
| .venv/lib/python3.13/site-packages/scipy/linalg/tests/test_batch.py | 56e4fa61452e7c7b232ce7121cb68ba7538d406db46a708b194069d5d17b1a9e | 589 | 1 |                    broadcast=True, check_kwargs=True):         # Check that all outputs of batched call `fun(A, **kwargs)` are the same         # as if we loop over the separate vectors/matrices in `A |
| .venv/lib/python3.13/site-packages/scipy/optimize/_linprog_ip.py | 4019548f0ea3977984667a2e131b6e69cd9d9489fd1ad922e72255ce449f7d25 | 1142 | 3 |              x : 1-D array                 Current solution vector             fun : float                 Current value of the objective function |
| .venv/lib/python3.13/site-packages/scipy/optimize/_linprog_rs.py | c11546671092a68e2db70e023e9997a334af33d5915c3d7bf5f1a21a1f20390e | 573 | 3 |     Conceptually, this is done by stacking an identity matrix on the right of     the original constraint matrix, adding artificial variables to correspond     with each of these new columns, and gene |
| .venv/lib/python3.13/site-packages/scipy/optimize/_root.py | 661f96b6daec965a029420e0ed52a1ad56d19031c14644b8fa28c9908fbfb708 | 733 | 12 | Functions --------- - root : find a root of a vector function. """ __all__ = ['root'] |
| .venv/lib/python3.13/site-packages/scipy/optimize/_cobyla_py.py | b3390b727501b348c8a22c3da8e2c04cde335afd221e77e31abf2e6bd5454c7a | 298 | 3 |     callback : callable, optional         Called after each iteration, as ``callback(x)``, where ``x`` is the         current parameter vector.      Returns |
| .venv/lib/python3.13/site-packages/scipy/optimize/_shgo.py | e387c2ed1ee4498c8454e6f9d2bf5cef9af474054b3c4d7e15e92e226efd1894 | 1607 | 8 |     callback : callable, optional         Called after each iteration, as ``callback(xk)``, where ``xk`` is the         current parameter vector.     minimizer_kwargs : dict, optional         Extra ke |
| .venv/lib/python3.13/site-packages/scipy/optimize/_optimize.py | 249d8c04cd780f14bc60150c363a8affb976fa3d425b2a8b87c6e63925c42b70 | 4170 | 28 |         where 'n' is the number of independent variables.     jac : {callable,  '2-point', '3-point', 'cs', None}, optional         Method for computing the gradient vector. If it is a callable, it    |
| .venv/lib/python3.13/site-packages/scipy/optimize/_linprog_simplex.py | f7f9f171597ea1f1cdf69fdd0f20b50ba8c794fb6d49f3bd929f16175493e093 | 664 | 3 |              x : 1-D array                 Current solution vector             fun : float                 Current value of the objective function |
| .venv/lib/python3.13/site-packages/scipy/optimize/_milp.py | f8ae2ea0cfe2f698fd19fcd5bd2e70e17fc4a1acc3117054f52cab584e7b0683 | 395 | 2 |         & x_i \in \mathbb{Z}, i \in X_i      where :math:`x` is a vector of decision variables;     :math:`c`, :math:`b_l`, :math:`b_u`, :math:`l`, and :math:`u` are vectors;     :math:`A` is a matrix |
| .venv/lib/python3.13/site-packages/scipy/optimize/_linprog_doc.py | 02a46080912a9dcaed8415b48821b6ce183edcab38f9947f077c1341239fb251 | 1435 | 24 |         & l \leq x \leq u ,      where :math:`x` is a vector of decision variables; :math:`c`,     :math:`b_{ub}`, :math:`b_{eq}`, :math:`l`, and :math:`u` are vectors; and     :math:`A_{ub}` and :mat |
| .venv/lib/python3.13/site-packages/scipy/optimize/_trustregion_ncg.py | cbb6fb4231417e7075c03b5bc27bca0fd0d8a73ef2ecda95ac9f5184d3dc8a9c | 127 | 2 |                          'minimization')     if hess is None and hessp is None:         raise ValueError('Either the Hessian or the Hessian-vector product '                          'is required for N |
| .venv/lib/python3.13/site-packages/scipy/optimize/_minimize.py | d477b6272da62e76ce0be3c58376e41dc502d1b3533dc85f1c931d0b13ad0f1b | 1200 | 15 |         depending on whether or not the problem has constraints or bounds.     jac : {callable,  '2-point', '3-point', 'cs', bool}, optional         Method for computing the gradient vector. Only for  |
| .venv/lib/python3.13/site-packages/scipy/optimize/_lbfgsb_py.py | dbe7b28094c1c5a591c6e3fe7fd07bca8b0792cd3f3b96a5ffac10cbc8d7d7e3 | 635 | 12 |     m : int, optional         The maximum number of variable metric corrections         used to define the limited memory matrix. (The limited memory BFGS         method does not store the full hessia |
| .venv/lib/python3.13/site-packages/scipy/optimize/_zeros_py.py | e8d37fbc90fe42770c8219ef0c8a61a3d4717f64084d0b94d841888bff3b27dc | 1476 | 6 |     If `x0` is a sequence with more than one item, `newton` returns an array:     the roots of the function from each (scalar) starting point in `x0`.     In this case, `func` must be vectorized to re |
| .venv/lib/python3.13/site-packages/scipy/optimize/elementwise.py | f1e1105bf3de364af8f5805344eaf9c560cb81e25deebc6d750937b55b841024 | 39 | 1 | counterparts in the base :mod:`scipy.optimize` namespace, these functions work elementwise, enabling the solution of many related problems in an efficient, vectorized call. Furthermore, when environme |
| .venv/lib/python3.13/site-packages/scipy/optimize/_linprog.py | 4c697d93d22887e8601d882d9dd37904d714e2fa9fa599bcc2144ad9fe1e8504 | 734 | 9 |          x : 1-D array             The independent variable vector which optimizes the linear             programming problem.         fun : float |
| .venv/lib/python3.13/site-packages/scipy/optimize/_slsqp_py.py | 50c50f614e79ceb290e01657970ef8a6e693c397a0a87b43eff4478e187f1fe0 | 604 | 3 |     ----------     x : array_like         The state vector at which to compute the Jacobian matrix.     func : callable f(x,*args)         The vector-valued function. |
| .venv/lib/python3.13/site-packages/scipy/optimize/_hessian_update_strategy.py | c66b5110a1a52e056f941ca78dbe5e0a73dbb07fb16cf729ad2f99a33886f343 | 480 | 10 |     Some of these  approximations, however, do not actually need to store     the entire matrix or can compute the internal matrix product with a     given vector in a very efficiently manner. This cl |
| .venv/lib/python3.13/site-packages/scipy/optimize/__init__.py | ed9cde3ea145d57d77efb7ffb3776955d7a0e7523763031a9ee87c3e5e0cd661 | 461 | 1 |    rosen_der - The derivative of the Rosenbrock function.    rosen_hess - The Hessian matrix of the Rosenbrock function.    rosen_hess_prod - Product of the Rosenbrock Hessian with a vector.  Legacy f |
| .venv/lib/python3.13/site-packages/scipy/optimize/_elementwise.py | 7a3c9dc1cd89523a640a46c7b3487a05620240f3c34fc889777946758f582724 | 799 | 1 |     points ``xl < xm < xr`` such that ``f(xl) >= f(xm)`` and ``f(xr) >= f(xm)``,     where at least one of the inequalities is strict. Unlike `scipy.optimize.bracket`,     this function can operate in |
| .venv/lib/python3.13/site-packages/scipy/optimize/_nnls.py | 1a172c4aa4a128e3714f13f8dc8e6e9f0bf2f04e6c683376b8c467e838e22a7a | 97 | 2 |         Coefficient array     b : (m,) ndarray, float         Right-hand side vector.     maxiter: int, optional         Maximum number of iterations, optional. Default value is ``3 * n``. |
| .venv/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py | af0d1861a7e33fec35913392eb7008eb09f9466257ab1f0019a1b40008787811 | 836 | 17 |         function.     grad : {callable, '2-point', '3-point', 'cs'}         Method for computing the gradient vector.         If it is a callable, it should be a function that returns the gradient     |
| .venv/lib/python3.13/site-packages/scipy/optimize/_trustregion_krylov.py | 28676e749b285d744e5c073cd9a67c002a230f7ae29afcb1e4f622b5ba385334 | 66 | 3 |     Minimization of a scalar function of one or more variables using     a nearly exact trust-region algorithm that only requires matrix     vector products with the hessian matrix.      .. versionadd |
| .venv/lib/python3.13/site-packages/scipy/optimize/_trustregion.py | 31ca7dea0becaed06a5d1263bb62877c24fec46c5a35afbcf1eac5bb615da37d | 319 | 3 |         inexact : bool             Accuracy to solve subproblems. If True requires less nonlinear             iterations, but more vector products. Only effective for method             trust-krylov.  |
| .venv/lib/python3.13/site-packages/scipy/optimize/_minpack_py.py | cc3cb698d859c5f71276bbedf2a3c49a488d26ecf1d3bbe2db7812c9374bdc46 | 1179 | 8 |     ----------     func : callable ``f(x, *args)``         A function that takes at least one (possibly vector) argument,         and returns a value of the same length.     x0 : ndarray |
| .venv/lib/python3.13/site-packages/scipy/optimize/_linprog_util.py | b6bcba8fdd5f062771de94cfdeb8ae78e3105aa5e36bd48ef344aa408818852d | 1522 | 27 |         coefficients of a linear inequality constraint on ``x``.     b_ub : 1D array, optional         The inequality constraint vector. Each element represents an         upper bound on the correspon |
| .venv/lib/python3.13/site-packages/scipy/optimize/_direct_py.py | fad131e75ffd8e0eb7ce60dc4a69aa78cb539715e9722f1f4a1f5347f7450f83 | 281 | 1 |     "Forced stop",     "Invalid arguments",     "Out of memory", )  |
| .venv/lib/python3.13/site-packages/scipy/optimize/_dual_annealing.py | 614efd68446842e55958439f0f2cdd9a3ecef15f2d83754c2d7df8d700723422 | 733 | 13 |         # Wrapper to the local minimizer         self.minimizer_wrapper = minimizer_wrapper         self.not_improved_idx = 0         self.not_improved_max_idx = 1000         self._rand_gen = rand_gen |
| .venv/lib/python3.13/site-packages/scipy/optimize/_root_scalar.py | 5d2c232805d565126b1b049cee1229413b9c0f026ff3871666971894b0cb1775 | 539 | 2 |     --------     show_options : Additional options accepted by the solvers     root : Find a root of a vector function.      Notes |
| .venv/lib/python3.13/site-packages/scipy/optimize/_tnc.py | 86d421b29817a3e3f48eded39b29e600fceaabca9968ce3256623c3b57089865 | 439 | 3 |         Integer interface to messages. 0 = no message, 5 = all messages     maxCGit : int, optional         Maximum number of hessian*vector evaluations per main         iteration. If maxCGit == 0, th |
| .venv/lib/python3.13/site-packages/scipy/optimize/_trustregion_exact.py | 4e750099dca691f8c2bf3c9b3a7f910ad18ea07a523ba320d6b7debb9d7a146c | 438 | 8 | def estimate_smallest_singular_value(U):     """Given upper triangular matrix ``U`` estimate the smallest singular     value and the correspondent right singular vector in O(n**2) operations.      Par |
| .venv/lib/python3.13/site-packages/scipy/optimize/_constraints.py | c2291ed1177633a9e6d55fa12b7fecb76de55e6543dce39882df7c5ca658c688 | 599 | 18 |  from ._differentiable_functions import (     VectorFunction, LinearVectorFunction, IdentityVectorFunction ) from ._hessian_update_strategy import BFGS |
| .venv/lib/python3.13/site-packages/scipy/optimize/_differentialevolution.py | 8323aeecc635700cab93e4ae4519b695f808c9c88072bb523dbffa4780301f0a | 1971 | 76 |                            init='latinhypercube', atol=0, updating='immediate',                            workers=1, constraints=(), x0=None, *,                            integrality=None, vectorize |
| .venv/lib/python3.13/site-packages/scipy/optimize/_nonlin.py | 4b04d67339ebbe57e627eef88bbf710bf8b1ae7b83246234a6c96f7d3043ac8e | 1635 | 13 |     x_rtol : float, optional         Relative minimum step size. If omitted, not used.     tol_norm : function(vector) -> scalar, optional         Norm to use in convergence check. Default is the maxi |
| .venv/lib/python3.13/site-packages/scipy/optimize/_bracket.py | 45664d614dedf2ab0d5615b84dc3fb7ad1d3ca8a1c6623c60b1cc2d6e2a43db0 | 707 | 1 |     points ``xl < xm < xr`` such that ``f(xl) >= f(xm)`` and ``f(xr) >= f(xm)``,     where at least one of the inequalities is strict. Unlike `scipy.optimize.bracket`,     this function can operate in |
| .venv/lib/python3.13/site-packages/scipy/optimize/_remove_redundancy.py | d34fd973cff9b98eaada906bf20bb6fc0624ee45fd6018c5f0ba9ac60a932946 | 523 | 4 |          # Due to overhead, it tends to be faster (for problems tested) to         # compute the full matrix-vector product rather than individual         # vector-vector products (with the chance of  |
| .venv/lib/python3.13/site-packages/scipy/optimize/_numdiff.py | ab92e82d0f93f2c7a35eba0a2800b70cf8015d97ccf094abf556206211beb00b | 964 | 6 |      x0_dtype: np.dtype         dtype of parameter vector      method: {'2-point', '3-point', 'cs'} |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_chandrupatla.py | 053fd3ab053c6a4641c0fa872a5eb3e9d0f154ca0a99d1d5afaf8a7a11e97f34 | 983 | 6 |   def _vectorize(xp):     # xp-compatible version of np.vectorize     # assumes arguments are all arrays of the same shape |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_constraint_conversion.py | eee45978ec550fa2856f2562ea1f8f4adb3707104f1621593d573386255de5be | 287 | 1 |   class TestNewToOldSLSQP:     method = 'slsqp'     elec = Elec(n_electrons=2) |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_tnc.py | 6a14b0bbc175b5470f574f65d4cb1b69c5175e2d5abd01f340d9e26216517f8b | 346 | 4 |         assert_allclose(self.f3(x), self.f3(xopt), atol=1e-8)      def test_minimize_tnc4(self):         x0,bnds = [1.125, 0.125], [(1, None), (0, None)]         xopt = [1, 0] |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_optimize.py | e51a123a77e7f28f4fac05df2ac30a337625ed332b0af2f285e4c2d9d68994ec | 3336 | 8 |                   direction='random_projection', rng=1234)      # checking can be done for derivatives of vector valued functions     r = optimize.check_grad(himmelblau_grad, himmelblau_hess, himmelbl |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_linprog.py | 5563a41fdbdf797141480cc361a68643ed0132963ac75e6e1dbf8173e4a8d144 | 2578 | 1 |         res = linprog(c, A_ub, b_ub, A_eq, b_eq, bounds,                       method=self.method, options=self.options)         # solution vector x is not unique         _assert_success(res, desired_ |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_nnls.py | 89be6b7cc68594322adbc22bf07e5925fbd8b957796733e3ad7b6a289ec1b4cd | 470 | 1 |      def test_2D_not_singleton_RHS_input_2(self):         # Test that a 2D but not a column vector RHS input is rejected         A = np.array([[1.0, 0.5, -1.],                       [1.0, 0.5, 0.0], |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_trustregion_exact.py | a4f63f191659d1dc17a946e839b6ad60ca51bb0552c1149c09fbaee1692e49bc | 352 | 4 |     A = np.dot(Qaux, Q.T)      # Generate gradient vector accordingly     # to the case is being tested.     if case == 'hard': |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test__differential_evolution.py | b113639553f024533bbe6891617e68617c1081e73bb66b47b5cf5391cb8c4d13 | 1704 | 26 |             assert_allclose(cv, np.atleast_2d(v))          # vectorized calculation of a series of solutions         assert_allclose(             solver._constraint_violation_fn(np.array(xs)), np.arra |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_least_squares.py | e0ebee171993a056ce436bd61158bbb9a08dea2ebf2edf5ee31cee5e5e2298a5 | 987 | 2 | from scipy.optimize import least_squares, Bounds from scipy.optimize._lsq.least_squares import IMPLEMENTED_LOSSES from scipy.optimize._lsq.common import EPS, make_strictly_feasible, CL_scaling_vector  |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_minpack.py | 1fbdcd345f378190415f5f08c3ab847afd860a75c535a7d209fc0ba198566a68 | 1195 | 1 |          with assert_raises(TypeError,                            match='Improper input: func input vector length N='):             optimize.leastsq(func, x0=[0, 1])  |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_constraints.py | 5f7637d67687c97060c88d37528c0738f63fab1851acbd88f5f26d0af676906a | 256 | 4 |         assert_array_equal(strict_ub, [4, 4, 4])      def test_vectorvalue_unique_enforce_feasibility(self):         m = 3         lb = [1, 2, 3] |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_milp.py | 57829e5bd67709f0af0a4fcd4fcf32aafc3d13fb76afe688abec891705486966 | 460 | 2 |     variable_bounds = Bounds(variable_lb, variable_ub)     integrality = np.ones(100)     c_vector = -np.ones(100)     res = milp(         c_vector, |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_nonlin.py | 71b49d58057f9388a66af8430da6bdbbb100bc1abc51cef3578d396c39e2ee9b | 573 | 1 |                 'linearmixing': nonlin.linearmixing,                 'diagbroyden': nonlin.diagbroyden} # In the extreme case, the Jacobian inversion yielded zero vector for nonlinear # problem solved |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_lsq_common.py | 6a508b3cf401e26af12c8028feb9fb7a0f71ac2107ec37ab341a334a298e4110 | 298 | 3 | from scipy.optimize._lsq.common import (     step_size_to_bound, find_active_constraints, make_strictly_feasible,     CL_scaling_vector, intersect_trust_region, build_quadratic_1d,     minimize_quadra |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_trustregion_krylov.py | a2d14ca0761c259ccf772bfb50a3a07ab7a11895e9381f1858fd3e9581d88549 | 171 | 2 |          # `H` is chosen such that `g` is not orthogonal to the         # eigenvector associated with the smallest eigenvalue.         H = np.array([[1.0, 0.0, 4.0],                       [0.0, 2.0, 0 |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test__numdiff.py | 7c5ff4dd4a8343b6fcb8229302187043b8f269c6f1f1f4c0d827bd82278dc049 | 886 | 113 |         return np.cosh(x)      def fun_scalar_vector(self, x):         return np.array([x[0]**2, np.tan(x[0]), np.exp(x[0])])  |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test__shgo.py | 6549e97635f3485974c2f22cad6403673cf53443cc6a07d7fda4d5a93ffff316 | 1165 | 4 |     """      # amended to test vectorisation of constraints     def f(self, x):         return 0.01 * (x[0]) ** 2 + (x[1]) ** 2 |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_bracket.py | 859328e9de46f92252af8e4e6811b21ede947df2de509b75e71f47c5a658f114 | 897 | 4 |      @pytest.mark.parametrize('shape', [tuple(), (12,), (3, 4), (3, 2, 2)])     def test_vectorization(self, shape, xp):         # Test for correct functionality, output shapes, and dtypes for various |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_slsqp.py | c22f7483a6f9b3c5b116cc196ec4c00a56b1a92353fba2b5d95f28aa5ff5956b | 646 | 4 |      def f_ieqcon2(self, x):         """ Vector inequality constraint """         return np.asarray(x)  |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_differentiable_functions.py | e4d80d530722a0845b3efa4b43fb5f7136e73ab821757e7a949c08f3d7cdf14e | 1026 | 59 | from scipy.sparse.linalg import LinearOperator from scipy.optimize._differentiable_functions import (ScalarFunction,                                                       VectorFunction,               |
| .venv/lib/python3.13/site-packages/scipy/optimize/tests/test_cobyla.py | 80b0958fcc66992a08c79a2290132bf4f5698321aca32006e4975c3406499a65 | 196 | 2 |             callback.last_x,             decimal=5,             err_msg="Last design vector sent to the callback is not equal to"                  " returned value.",         ) |
| .venv/lib/python3.13/site-packages/scipy/optimize/_shgo_lib/_vertex.py | 2364c0a8411d4caeba2a6e94224ac39b6fad2a978952e157ec301f4e4dd7bd48 | 461 | 4 |         Parameters         ----------         x : tuple or vector             The geometric location (domain).         nn : list, optional |
| .venv/lib/python3.13/site-packages/scipy/optimize/_shgo_lib/_complex.py | 9b2db2c82acf2a92db9b3d289c0f98fb12d3c36d0abb012229b3ab43e7e97ba1 | 1226 | 67 | """Base classes for low memory simplicial complex structures.""" import copy import logging |
| .venv/lib/python3.13/site-packages/scipy/optimize/_lsq/least_squares.py | edb25eca998c20b9cc10b3b22faf9b0861f9be5251209481b739f56d857b1b7c | 1045 | 21 | from scipy.sparse.linalg import LinearOperator from scipy.optimize import _minpack, OptimizeResult from scipy.optimize._differentiable_functions import VectorFunction from scipy.optimize._numdiff impo |
| .venv/lib/python3.13/site-packages/scipy/optimize/_lsq/dogbox.py | 03e43aff55d5dd36cdef05064bcbd3d8915e65f4b3f86b92f21f4728a44950c5 | 346 | 1 |      `active_set` mask is used to excluded active variables from computations     of matrix-vector products.     """     m, n = Jop.shape |
| .venv/lib/python3.13/site-packages/scipy/optimize/_lsq/trf_linear.py | 8c8b3b5af88ebbff0aa5beec4e59fc5bb60b82472776fd1e1883f5e60fe60b88 | 250 | 2 |     EPS, step_size_to_bound, find_active_constraints, in_bounds,     make_strictly_feasible, build_quadratic_1d, evaluate_quadratic,     minimize_quadratic_1d, CL_scaling_vector, reflective_transforma |
| .venv/lib/python3.13/site-packages/scipy/optimize/_lsq/common.py | 87f56c7cf40cddfcbe316618d966cf0ef7f366cb013ac665df199a116c5fb0c7 | 732 | 6 |         Gradient, defines the linear term.     s : ndarray, shape (n,)         Direction vector of a line.     diag : None or ndarray with shape (n,), optional         Addition diagonal part, affects  |
| .venv/lib/python3.13/site-packages/scipy/optimize/_lsq/lsq_linear.py | aec4c38ad2c22b8ef9833a7b5f4bd0d3b2a31e767cf7d295d76902de444da0c2 | 362 | 4 |     r"""Solve a linear least-squares problem with bounds on the variables.      Given a m-by-n design matrix A and a target vector b with m elements,     `lsq_linear` solves the following optimization |
| .venv/lib/python3.13/site-packages/scipy/optimize/_lsq/trf.py | 0c7c29d5d3fd6915720e9547f051d47e14ca5a821e7872686aa8cf1d1c4e4893 | 588 | 5 | The algorithm is based on ideas from paper [STIR]_. The main idea is to account for the presence of the bounds by appropriate scaling of the variables (or, equivalently, changing a trust-region shape) |
| .venv/lib/python3.13/site-packages/scipy/optimize/_trustregion_constr/tr_interior_point.py | 2adde3121eed3e8f5ca773da41debbe687e0ec9564fbce2c6336994bb500e94a | 362 | 1 |      def scaling(self, z):         """Returns scaling vector.         Given by:             scaling = [ones(n_vars), s] |
| .venv/lib/python3.13/site-packages/scipy/optimize/_trustregion_constr/qp_subproblem.py | 0282f03080d43113a578c18095d5c7de022da32cc9eaa453a4d843ae28f2bcd0 | 638 | 10 |     # Optimization" p.452 in Eq. (16.4).     kkt_matrix = block_array([[H, A.T], [A, None]], format="csc")     # Vector of coefficients.     kkt_vec = np.hstack([-c, -b])  |
| .venv/lib/python3.13/site-packages/scipy/optimize/_trustregion_constr/minimize_trustregion_constr.py | aa10347e69a4c9acf58af949754f212a16d08fa95d5f80a8a63b4992d3838281 | 585 | 5 | import numpy as np from scipy.sparse.linalg import LinearOperator from .._differentiable_functions import VectorFunction from .._constraints import (     NonlinearConstraint, LinearConstraint, Prepare |
| .venv/lib/python3.13/site-packages/scipy/optimize/_trustregion_constr/projections.py | 43bcc1b9c01de388718ff2b0bac69c0009c0b8b49abebdd3dea2d49386f037f9 | 412 | 11 |  def orthogonality(A, g):     """Measure orthogonality between a vector and the null space of a matrix.      Compute a measure of orthogonality between the null space |
| .venv/lib/python3.13/site-packages/scipy/optimize/_trustregion_constr/canonical_constraint.py | 81ce4ab9c1f0142cfffb0d8861677f0b55f51344c5cbfb1ecbeff428163f7631 | 391 | 1 |         ``dot(f_eq, v_eq) + dot(f_ineq, v_ineq)``. The signature is         ``hess(x, v_eq, v_ineq) -> H``, where ``H`` has an implied         shape (n, n) and provide a matrix-vector product operatio |
| .venv/lib/python3.13/site-packages/scipy/optimize/_trustregion_constr/tests/test_projections.py | 2d7b21304b76fe5d720a48531d40f1a0ed753fda93d7f816bf92a579201303f0 | 215 | 6 |                       [0, 8, 7, 0, 1, 5, 9, 0],                       [1, 0, 0, 0, 0, 1, 2, 3]])         test_vectors = ([-1.98931144, -1.56363389,                          -0.84115584, 2.2864762,     |
| .venv/lib/python3.13/site-packages/scipy/optimize/_trustregion_constr/tests/test_qp_subproblem.py | e6735a00e4cfe0fa31e9922a43d6fd8293811c02da3d8de6e084befbb3d7e1ad | 646 | 2 |      def test_2d_box_constraints(self):         # Box constraint in the direction of vector d         ta, tb, intersect = box_intersections([2, 0], [0, 2],                                              |
| .venv/lib/python3.13/site-packages/scipy/integrate/_quadpack_py.py | 1f87edad92aa58bbc7e12b7e1587f9e83fdfbc2731976be41a99012bd0d0c438 | 1284 | 1 |             "Bad integrand behavior occurs within one or more of the cycles.\n  "             "Location and type of the difficulty involved can be determined from \n  "             "the vector info['i |
| .venv/lib/python3.13/site-packages/scipy/integrate/_ode.py | ff896eb1e256bf4d598ff02f764eb1b4da6b67f1e8c979b53cf3621ac426ab87 | 1396 | 2 | #         # n - the size of the problem (number of equations) #         # has_jac - whether user has supplied its own routine for Jacobian #         <allocate memory,initialize further> # #     def ru |
| .venv/lib/python3.13/site-packages/scipy/integrate/_quadrature.py | 9af70005ed11ed37df7b53488035c9b054b473186bd9c6b6a0c632bfd878d1aa | 1337 | 5 |     ----------     func : callable         A Python function or method to integrate (must accept vector inputs).         If integrating a vector-valued function, the returned array must have         s |
| .venv/lib/python3.13/site-packages/scipy/integrate/_odepack_py.py | 0e11cb07baf1d29e93ad0433410970cea71bf2832e1510eb6b49c816bc9bd0cf | 274 | 14 |         dy/dt = func(y, t, ...)  [or func(t, y, ...)]      where y can be a vector.      .. note:: By default, the required order of the first two arguments of |
| .venv/lib/python3.13/site-packages/scipy/integrate/__init__.py | 0a63cb7e417aea35e11ec2b240f3acbc511cf67c6271163097a58301aedc7c99 | 123 | 1 |     quad          -- General purpose integration    quad_vec      -- General purpose integration of vector-valued functions    cubature      -- General purpose multi-dimensional integration of array-v |
| .venv/lib/python3.13/site-packages/scipy/integrate/_quad_vec.py | 4a4f873463d64dfc3c7c02f197bbcb6834b110e59ea9be8b94924e20b9411ec7 | 675 | 5 |              limit=10000, workers=1, points=None, quadrature=None, full_output=False,              *, args=()):     r"""Adaptive integration of a vector-valued function.      Parameters |
| .venv/lib/python3.13/site-packages/scipy/integrate/_bvp.py | 3addaaeb9ed45156986251477bc6d6151fe6ad182489e9c91ba60edc4076fffa | 1161 | 7 |     containing n components, followed by n + k boundary condition residuals.      There are n * m + k variables: m vectors of y, each containing n     components, followed by k values of vector p.  |
| .venv/lib/python3.13/site-packages/scipy/integrate/_cubature.py | 01a1aaa57c37229a864f2c4d207d77203d3ff40fe8a9dbd5501abb7ca491d5e5 | 730 | 2 |     Examples     --------     **1D integral with vector output**:      .. math:: |
| .venv/lib/python3.13/site-packages/scipy/integrate/_tanhsinh.py | 79ce41c2d76cc1644b0eb5fafff84d7cbdcec14067d832a3f6d6cffec032b802 | 1386 | 4 |     it requires the function to accept arguments of any shape.      "Vector-valued" integrands, such as those written for use with     `scipy.integrate.quad_vec`, are unlikely to satisfy this requirem |
| .venv/lib/python3.13/site-packages/scipy/integrate/tests/test_tanhsinh.py | 9069ed5cb177c0b7c131803f3d4b60733129299c2a43978958cecc4e8b9cce6b | 1172 | 7 |   def _vectorize(xp):     # xp-compatible version of np.vectorize     # assumes arguments are all arrays of the same shape |
| .venv/lib/python3.13/site-packages/scipy/integrate/tests/test_quadrature.py | 1468d63910ef0f03c968dd00268b29a0e0101c817f9bae988aab3d2f240542c2 | 731 | 2 |         assert_allclose(got, expected, rtol=1e-12)      def test_vector(self):         n = 4         p = np.arange(1, 2*n) |
| .venv/lib/python3.13/site-packages/scipy/integrate/tests/test_integrate.py | 2a2c97789ed38505292fcfd740a7ce4d9f22fcb055c200bbca4cc5e98839ef82 | 841 | 1 |         self._check_solver(solver)      def test_vector_param(self):         solver = self._get_solver(fv, jacv)         omega = [1.0, 1.0] |
| .venv/lib/python3.13/site-packages/scipy/integrate/_ivp/bdf.py | b533763a21518c69484fe3e4ac22e2fa605f52670067c344a6b1528f047f2b95 | 479 | 9 |         at time ``t``. The calling signature is ``fun(t, y)``, where ``t`` is a         scalar and ``y`` is an ndarray with ``len(y) = len(y0)``. ``fun`` must         return an array of the same shape |
| .venv/lib/python3.13/site-packages/scipy/integrate/_ivp/ivp.py | 0c698b1a4e136e1906841889be76de352719ccb7679beea72685adf3786bcfeb | 756 | 12 |  def solve_ivp(fun, t_span, y0, method='RK45', t_eval=None, dense_output=False,               events=None, vectorized=False, args=None, **options):     """Solve an initial value problem for a system o |
| .venv/lib/python3.13/site-packages/scipy/integrate/_ivp/common.py | 195293731f903bb58faf67a33408bde1a11d32fd37cc554eaf6e10d70dab6762 | 452 | 1 |     ----------     fun : callable         Right-hand side of the system implemented in a vectorized fashion.     t : float         Current time. |
| .venv/lib/python3.13/site-packages/scipy/integrate/_ivp/radau.py | d0aa4593431ef39ee07825db6ef0324e4a9bacef0e23fda42d377318ba6a6256 | 573 | 9 |         at time ``t``. The calling signature is ``fun(t, y)``, where ``t`` is a         scalar and ``y`` is an ndarray with ``len(y) = len(y0)``. ``fun`` must         return an array of the same shape |
| .venv/lib/python3.13/site-packages/scipy/integrate/_ivp/lsoda.py | b79b768d906004fb741b6d13388e12557b861406580217c39496617c2cde783a | 225 | 8 |         at time ``t``. The calling signature is ``fun(t, y)``, where ``t`` is a         scalar and ``y`` is an ndarray with ``len(y) = len(y0)``. ``fun`` must         return an array of the same shape |
| .venv/lib/python3.13/site-packages/scipy/integrate/_ivp/rk.py | fa5d6300917f4f949e699b116f59ae147159d5c6147d55d940dc9d3303891056 | 602 | 16 |      def __init__(self, fun, t0, y0, t_bound, max_step=np.inf,                  rtol=1e-3, atol=1e-6, vectorized=False,                  first_step=None, **extraneous):         warn_extraneous(extrane |
| .venv/lib/python3.13/site-packages/scipy/integrate/_ivp/base.py | 32579ffdd8269f4c338c5c59037a016ed1eb420adf759c3ff24d662d83593f80 | 291 | 18 |            automatically.         7. For convenience, a base class provides `fun_single(self, t, y)` and            `fun_vectorized(self, t, y)` for evaluating the rhs in            non-vectorized and |
| .venv/lib/python3.13/site-packages/scipy/integrate/_ivp/tests/test_ivp.py | 034870dc0a84357793169d5171bff86b212c2d82ee315173f6ced4ae095ab4b4 | 1288 | 7 |   def fun_rational_vectorized(t, y):     return np.vstack((y[1] / t,                       y[1] * (y[0] + 2 * y[1] - 1) / (t * (y[0] - 1)))) |
| .venv/lib/python3.13/site-packages/scipy/datasets/_fetchers.py | c652d2c4886dcaca1b3dede46052fbd7bb77d6a46ca53c28a9edf5886b5ebef0 | 226 | 1 |     # https://github.com/scipy/scipy/issues/21879     downloader = pooch.HTTPDownloader(         headers={"User-Agent": f"SciPy {sys.modules['scipy'].__version__}"}     )     # The "fetch" method retu |
| .venv/lib/python3.13/site-packages/scipy/datasets/_registry.py | 6ebd0a7f26a511b879cab40bce743f42f06d98de2b32c9b45313a39ec269e0e4 | 27 | 1 | registry = {     "ascent.dat": "03ce124c1afc880f87b55f6b061110e2e1e939679184f5614e38dacc6c1957e2",     "ecg.dat": "f20ad3365fb9b7f845d0e5c48b6fe67081377ee466c3a220b7f69f35c8958baf",     "face.dat": "9 |
| .venv/lib/python3.13/site-packages/scipy/datasets/_download_all.py | d3cf85d80f48682cc0607cb9cb3b221e410affdcc30382120e6832d8e6a765b6 | 72 | 1 |         path = pooch.os_cache('scipy-data')     # https://github.com/scipy/scipy/issues/21879     downloader = pooch.HTTPDownloader(headers={"User-Agent": "SciPy"})     for dataset_name, dataset_hash  |
| .venv/lib/python3.13/site-packages/scipy/io/wavfile.py | 2e9da962db6958f847bcee3599147e914143e0d467f095cdfe8046ebb5875761 | 939 | 4 |     LUCENT_SX5363S = 0x1C0C     CUSEEME = 0x1F03     NTCSOFT_ALF2CM_ACM = 0x1FC4     DVM = 0x2000     DTS2 = 0x2001 |
| .venv/lib/python3.13/site-packages/scipy/io/_netcdf.py | 073eb2c0d81a5f5858583a5adad0a302abca8b5ee4d03a4d7dce150ae72122a0 | 1105 | 6 |            NC_DOUBLE: ('d', 8)}  FILLMAP = {NC_BYTE: FILL_BYTE,            NC_CHAR: FILL_CHAR,            NC_SHORT: FILL_SHORT, |
| .venv/lib/python3.13/site-packages/scipy/io/tests/test_idl.py | d90a591815a8482c07e6372173dc2fa2dd8bd37a74aaa7aace3aaec7928ff9b3 | 484 | 2 |   # Define vectorized ID function for pointer arrays vect_id = np.vectorize(id)  |
| .venv/lib/python3.13/site-packages/scipy/io/_harwell_boeing/hb.py | a8e649c53f9b865a428c00f2bf7186bbbac12281ecdb0df2e4bebe38e1eae90c | 572 | 3 |  # XXX: reading is reasonably efficient (>= 85 % is in numpy.fromstring), but # takes a lot of memory. Being faster would require compiled code. # write is not efficient. Although not a terribly excit |
| .venv/lib/python3.13/site-packages/scipy/io/matlab/_mio5.py | 841bd5727014657da12d9cd00df4a79544155ad4250f9deeafcc3b564a53f50b | 902 | 1 |  The ``__function_workspace__`` matrix appears to be of double class (``mxCLASS_DOUBLE``), but stored as uint8, the memory for which is in the format of a mini .mat file, without the first 124 bytes o |
| .venv/lib/python3.13/site-packages/scipy/io/matlab/_mio4.py | 5bd15a17baf285b4f5d131201dcba8bd9926ef0db3214ded0ed9dbe602256254 | 633 | 4 |         '''         if hdr.is_complex:             # avoid array copy to save memory             res = self.read_sub_array(hdr, copy=False)             res_j = self.read_sub_array(hdr, copy=False) |
| .venv/lib/python3.13/site-packages/scipy/io/matlab/_miobase.py | 0263310f9a6e22ac5862ff0c092745db0503ab03934a8ca8f48ea1879d66c9a4 | 436 | 9 |      'oned_as':          '''oned_as : {'row', 'column'}, optional    If 'column', write 1-D NumPy arrays as column vectors.    If 'row', write 1D NumPy arrays as row vectors.''',      'unicode_strings |
| .venv/lib/python3.13/site-packages/scipy/io/matlab/_mio.py | 1ce3750b2b23955666b3b93298040efa6e6afb7e0127db48db6e5c94a92065b3 | 376 | 2 |         Whether or not to compress matrices on write. Default is False.     oned_as : {'row', 'column'}, optional         If 'column', write 1-D NumPy arrays as column vectors.         If 'row', write |
| .venv/lib/python3.13/site-packages/scipy/io/matlab/tests/test_miobase.py | 08679fad4ea6fc6a4ec1a2abfd0f77679ccaa799eebfbf75923c5c34d3fc8a21 | 33 | 3 |     assert_equal(matdims(np.array([1])), (1, 1))  # 1-D array, 1 element     assert_equal(matdims(np.array([1,2])), (2, 1))  # 1-D array, 2 elements     assert_equal(matdims(np.array([[2],[3]])), (2,  |
| .venv/lib/python3.13/site-packages/scipy/io/matlab/tests/test_mio.py | 777f4bd6b7bf48b1972e83756aba92f131e36665948d9356522f9fb74530bd05 | 1400 | 1 |  def test_1d_shape():     # New 5 behavior is 1D -> row vector     arr = np.arange(5)     for format in ('4', '5'): |
| .venv/lib/python3.13/site-packages/scipy/_lib/_testutils.py | a88cf5b189c60907c80ee9841c3603a1074c4c75e5638d3e0ea55f23d860eea9 | 374 | 9 |   __all__ = ['PytestTester', 'check_free_memory', '_TestPythranFunc', 'IS_MUSL']   |
| .venv/lib/python3.13/site-packages/scipy/_lib/_array_api.py | a06d4ee91ff70e8152680d997af506a1268db435c930b5628e267e2999f62c74 | 932 | 5 |     'xp_assert_close', 'xp_assert_equal', 'xp_assert_less',     'xp_copy', 'xp_device', 'xp_ravel', 'xp_size',     'xp_unsupported_param_msg', 'xp_vector_norm', 'xp_capabilities',     'xp_result_type' |
| .venv/lib/python3.13/site-packages/scipy/_lib/_elementwise_iterative_method.py | 7c2d68bbcbba5c70a93274d12acab0c8fe7fcd6d200eed13cc6ab0fa7a961005 | 347 | 3 | # `_elementwise_iterative_method.py` includes tools for writing functions that # - are vectorized to work elementwise on arrays, # - implement non-trivial, iterative algorithms with a callback interfa |
| .venv/lib/python3.13/site-packages/scipy/_lib/_util.py | 4aea2cf5efbc26ca75cb89d2256b035f7b66c2591908c9509b36d7e98c416063 | 1284 | 2 |  def _aligned_zeros(shape, dtype=float, order="C", align=None):     """Allocate a new ndarray with aligned memory.      Primary use case for this currently is working around a f2py issue |
| .venv/lib/python3.13/site-packages/scipy/_lib/_uarray/__init__.py | 470c3bc0b03b147e98a2783ba0c825fec1cfa63711b2545a4e387ad56ff1560e | 117 | 1 | signature ``(dispatchables, coerce)``. When ``coerce`` is ``False``, conversion between the formats should ideally be an ``O(1)`` operation, but it means that no memory copying should be involved, onl |
| .venv/lib/python3.13/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py | 666a005466ec8f4e2071f13b47457a37fec05c266b8584855d77f325f2793b86 | 377 | 2 |     --------     This function temporarily rechunks the array along `axis` to a single chunk.     This can be extremely inefficient and can lead to out-of-memory errors.      See the corresponding doc |
| .venv/lib/python3.13/site-packages/scipy/_lib/array_api_compat/dask/array/linalg.py | 02d9077ed27786e7eeb92959851c51d111fd22eade11eb77f3bae99f5877f175 | 73 | 3 |     return s  vector_norm = get_xp(da)(_linalg.vector_norm) diagonal = get_xp(da)(_linalg.diagonal)  |
| .venv/lib/python3.13/site-packages/scipy/_lib/array_api_compat/cupy/linalg.py | 9ca38cfbfc1c387cc7844795f4a07370c54d96f8892b89cfd6714152dbe78d33 | 50 | 5 | # These functions are completely new here. If the library already has them # (i.e., numpy 2.0), use the library version instead of our wrapper. if hasattr(cp.linalg, 'vector_norm'):     vector_norm =  |
| .venv/lib/python3.13/site-packages/scipy/_lib/array_api_compat/torch/linalg.py | 69c6dc83cd028da98c434243024ad62fb164c845b931f98657342cad14f4d233 | 122 | 5 |     # 2. x1.shape[:-1] == x2.shape     #     # See linalg_solve_is_vector_rhs in     # aten/src/ATen/native/LinearAlgebraUtils.h and     # TORCH_META_FUNC(_linalg_solve_ex) in |
| .venv/lib/python3.13/site-packages/scipy/_lib/array_api_compat/numpy/_aliases.py | 48a6827f3736798d5e02edd8ce6dc956e477b94a8becfa177fa1b26325e9730e | 191 | 1 | def _supports_buffer_protocol(obj: object) -> TypeIs[Buffer]:  # pyright: ignore[reportUnusedFunction]     try:         memoryview(obj)  # pyright: ignore[reportArgumentType]     except TypeError:     |
| .venv/lib/python3.13/site-packages/scipy/_lib/array_api_compat/numpy/linalg.py | 391bb8321b8de85e445cecbe9581f17cc1e4469551c765440b6f6b47007c070b | 144 | 8 |  # Note: unlike np.linalg.solve, the array API solve() only accepts x2 as a # vector when it is exactly 1-dimensional. All other cases treat x2 as a stack # of matrices. The np.linalg.solve behavior o |
| .venv/lib/python3.13/site-packages/scipy/_lib/array_api_compat/common/_linalg.py | 59d7f4173cf124d1221a138eb102a0f0f9ccbac3377d578de4203844122d17f6 | 233 | 5 | class EighResult(NamedTuple):     eigenvalues: Array     eigenvectors: Array  class QRResult(NamedTuple): |
| .venv/lib/python3.13/site-packages/scipy/_lib/tests/test__pep440.py | bbd84fa2894ae00a08212f91abbe03bb9489bb9a20d91c4cc20680bc6816bd1a | 68 | 1 |         assert Version('1.8.0rc1') < Version(ver)      for ver in ['1.8.0a2', '1.8.0b3', '1.7.2rc4']:         assert Version('1.8.0rc1') > Version(ver)  |
| .venv/lib/python3.13/site-packages/scipy/_lib/tests/test_array_api.py | 6b7df31e0874dc5f3252a6c8bb1236cdcb7da69168de63fe074a01623b560ccc | 323 | 1 |             x = xp.asarray([1, 2, 3])             y = xp_copy(x, xp=_xp)             # with numpy we'd want to use np.shared_memory, but that's not specified             # in the array-api             |
| .venv/lib/python3.13/site-packages/scipy/_lib/array_api_extra/testing.py | 3d0567b82dd6b84558af2354f02b067e92d6e150483c9561d27ba2c75a52afea | 360 | 1 |     try:         func._lazy_xp_function = tags  # type: ignore[attr-defined]  # pylint: disable=protected-access  # pyright: ignore[reportFunctionMemberAccess]     except AttributeError:  # @cython.ve |
| .venv/lib/python3.13/site-packages/scipy/_lib/array_api_extra/_lib/_at.py | 020996bc7ce11a7098d3d0464c8303063e8f88dd0915677197cf4ba66fa5782d | 464 | 1 |         # namespace that Dask is wrapping.         # Note that da.minimum _incidentally_ works on NumPy, CuPy, and sparse         # thanks to all these meta-namespaces implementing the __array_ufunc__ |
| .venv/lib/python3.13/site-packages/scipy/_lib/array_api_extra/_lib/_lazy.py | 52bb529daae25e824efbd11f85c8bc82ba6ac39950f70c83e6e43d53a5796535 | 358 | 1 |         .. warning::             The whole operation needs to fit in memory all at once on a single worker.          The outputs will also be returned as a single chunk and you should consider |
| .venv/lib/python3.13/site-packages/scipy/_lib/pyprima/cobyla/update.py | 3f00d128c63f54084129548e90c50239232119ece97e269f21a9ec5b5bea2382 | 290 | 1 |         # np.sum command. The differences were small, on the order of 1e-16, i.e. epsilon.         # According to numpy documentation, np.sum sometimes uses partial pairwise summation,         # depen |
| .venv/lib/python3.13/site-packages/scipy/_lib/pyprima/cobyla/cobyla.py | 622b8086d679bb5dee0dc88beec734ab1555a47e6de48289d91d17eea4c5330a | 560 | 17 | making them preferable for applications with expensive function evaluations. However, if function evaluations are not the dominant cost in your application, the Fortran 77 solvers are likely to be fas |
| .venv/lib/python3.13/site-packages/scipy/_lib/pyprima/cobyla/trustregion.py | e943624f2b5f132c56d7ea87a6a046cdc7a0472ae7c7403cd97c0b4b96fd37f5 | 493 | 9 | def trstlp(A, b, delta, g):     '''     This function calculated an n-component vector d by the following two stages. In the first     stage, d is set to the shortest vector that minimizes the greates |
| .venv/lib/python3.13/site-packages/scipy/_lib/pyprima/cobyla/geometry.py | f38ceb4af28d0abf969d7a85ae79dbfa7135d7254023f08c13bf6785573866f3 | 227 | 2 |     #====================#      # SIMI[JDROP, :] is a vector perpendicular to the face of the simplex to the opposite of vertex     # JDROP. Set D to the vector in this direction and with length DELBA |
| .venv/lib/python3.13/site-packages/scipy/_lib/pyprima/common/infos.py | 7dc224eb315642bb5486dbce1d87185336420e6804018dfd7e346c86339bf4ce | 31 | 1 | ASSERTION_FAILS = 101 VALIDATION_FAILS = 102 MEMORY_ALLOCATION_FAILS = 103 |
| .venv/lib/python3.13/site-packages/scipy/_lib/pyprima/common/consts.py | 830f8929c90b8411cf5d92cba75a8cad5b2a34ff4f27e91c82d06f7c26a393e8 | 48 | 2 | PRIMA_MAX_HIST_MEM_MB = 300  # 1MB > 10^5*REAL64. 100 can be too small.  # Maximal amount of memory (Byte) allowed for XHIST, FHIST, CONHIST, CHIST, and the filters. MHM = PRIMA_MAX_HIST_MEM_MB * 10** |
| .venv/lib/python3.13/site-packages/scipy/_lib/pyprima/common/linalg.py | 4306d7aae5296a8df8ab016842b789ee873169c0ace693bfee9f469fd4db07bf | 436 | 1 |     # Preconditions     if DEBUGGING:         assert len(x) == 2, "x must be a 2-vector"      # ================== |
| .venv/lib/python3.13/site-packages/scipy/_lib/pyprima/common/preproc.py | 19ed12c91c72ddfe3bb9fd5a9d7f169858df90e770f3673390c802f05943889b | 278 | 1 |                 warn(f'{solver}: MAXFILT is too small; it is set to {maxfilt}')             elif maxfilt < min(maxfilt_in, maxfun):                 warn(f'{solver}: MAXFILT is set to {maxfilt} due to  |
| .venv/lib/python3.13/site-packages/scipy/_lib/pyprima/common/_nonlinear_constraints.py | d0e199c05a5af09aad4e6e2b64a6f62cbf28c71d5295de003707c7fb4d10cb80 | 55 | 1 |         values = np.atleast_1d(np.array(nlc.fun(x), dtype=np.float64))                  # Upgrade the lower/upper bounds to vectors if necessary         lb = nlc.lb         try: |
| .venv/lib/python3.13/site-packages/scipy/_lib/pyprima/common/_project.py | a17d65fef1b0628775927434f2dfe3d8c675841393feccd3eb6d465df93aee71 | 174 | 4 |         x0_c = x0     else:         raise ValueError('{}: UNEXPECTED ERROR: x0 should be a vector.'.format(invoker))     try:         x0_c = np.asarray(x0_c, dtype=np.float64) |
| .venv/lib/python3.13/site-packages/scipy/_lib/pyprima/common/selectx.py | f0861fe8107e3a738e9eec67f3ff58b2b96568b14bb4829063936a4c745ceb54 | 297 | 4 |     '''     This subroutine saves X, F, and CSTRV in XFILT, FFILT, and CFILT (and CONSTR in CONFILT     if they are present), unless a vector in XFILT[:, :NFILT] is better than X.     If X is better t |
| .venv/lib/python3.13/site-packages/scipy/_lib/pyprima/common/history.py | 73abd67bb5c9e49333466ed3cda3df62198795a646a140d9cc4bcb75f64d6c00 | 39 | 1 |      However just like the Fortran version we should be concerned about both performance     and memory constraints. It will probably be better to initialize an array of NaN for     each of the histor |
| .venv/lib/python3.13/site-packages/scipy/_lib/cobyqa/models.py | 70033cfe7a7fc45491c0ab2368c459bbd0dcf7140e40f019556c6cbd1ffbaa31 | 1530 | 17 |     right_scaling[npt + 1:] = scale      eig_values, eig_vectors = eigh(a, check_finite=False)      _cache["xpt"] = np.copy(interpolation.xpt) |
| .venv/lib/python3.13/site-packages/scipy/_lib/cobyqa/framework.py | 94878a0a40cbc476cc9924e231cc9ab2f55eefb8d5be1fd84ce617d079cae109 | 1241 | 4 |         """         Evaluate the right product of the Hessian matrix of the Lagrangian         model with a given vector.          Parameters |
| .venv/lib/python3.13/site-packages/scipy/_lib/cobyqa/problem.py | 4a23e09a2153c625b9c89fc555fdfb67d1901a8e86c7f7c9dd15ccce1b2b9f8d | 1297 | 9 |     def b_ub(self):         """         Right-hand side vector of the linear inequality constraints.          Returns |
| .venv/lib/python3.13/site-packages/scipy/_lib/cobyqa/main.py | c33d0cda2a857f379369952afe3d53905ffd57f489d6def703ed1f747d1e4ace | 1507 | 4 |             lb = exact_1d_array(                 constraint.lb,                 "The lower bound of the linear constraints must be a vector.",             )             ub = exact_1d_array( |
| .venv/lib/python3.13/site-packages/scipy/_lib/cobyqa/subsolvers/geometry.py | 7604be0b44015219333e11d42c52116e76c5388101d34e46c8f604fa2f9cb856 | 388 | 2 |         Gradient :math:`g` as shown above.     curv : callable         Curvature of :math:`H` along any vector.              ``curv(s) -> float`` |
| .venv/lib/python3.13/site-packages/scipy/_lib/cobyqa/subsolvers/optim.py | 848b1e56aacfc88ddecc8086357902b4a969aaf00ed96e9941ed27eecc5f92cb | 1204 | 4 |         Gradient :math:`g` as shown above.     hess_prod : callable         Product of the Hessian matrix :math:`H` with any vector.              ``hess_prod(s) -> `numpy.ndarray`, shape (n,)`` |
| .venv/lib/python3.13/site-packages/scipy/special/_testutils.py | 72f96b8af320cb5f2826a40acc47b701d65b9b89d14c00a40bd92a83bc3082ac | 322 | 9 | def assert_func_equal(func, results, points, rtol=None, atol=None,                       param_filter=None, knownfailure=None,                       vectorized=True, dtype=None, nan_ok=False,          |
| .venv/lib/python3.13/site-packages/scipy/special/_mptestutils.py | a1ccbfc015ea1c6220df5d637e3013100f0edbd202978a8f9ef4e0b264e6e6a8 | 454 | 32 |         # 10 the other half in a logspace.         if n % 2 == 0:             nlogpts = n//2             nlinpts = nlogpts         else: |
| .venv/lib/python3.13/site-packages/scipy/special/__init__.py | 3c3e84d00010b6bf83a52d59fa0d9e6aa35f93b6194fc28a3f23bf2d93d17ba4 | 842 | 1 | Some of the special function routines can emit warnings or raise exceptions when an error occurs. By default this is disabled, except for memory allocation errors, which result in an exception being r |
| .venv/lib/python3.13/site-packages/scipy/special/_ellip_harm.py | 6071c565732dcdd271ca36572accb7a1c22c57e7a0ea77b7529efd06e165f4ff | 215 | 2 |   _ellip_harm_2_vec = np.vectorize(_ellipsoid, otypes='d')   |
| .venv/lib/python3.13/site-packages/scipy/special/_logsumexp.py | ce7fbc35d4d679b8a3b33f0d557a13a072acd779e51b793817a1db89143d4a89 | 427 | 1 |     Notes     -----     The formula for the softmax function :math:`\sigma(x)` for a vector     :math:`x = \{x_0, x_1, ..., x_{n-1}\}` is  |
| .venv/lib/python3.13/site-packages/scipy/special/_precompute/struve_convergence.py | cfb474439fd87be12a2c8f60fb2011765fe3e45a28a1f5cc4573cb56b2052504 | 132 | 1 |         def sh(v, z):             return float(mpmath.struvel(mpmath.mpf(v), mpmath.mpf(z)))     ex = np.vectorize(sh, otypes='d')(vs[:,None], zs[None,:])      err_a = err_metric(ra[0], ex) + 1e-300 |
| .venv/lib/python3.13/site-packages/scipy/special/tests/test_basic.py | caf3a32269f95a03d8280472410a0f2ffb8d5fae64efc2bcd67827b088fe28b6 | 4816 | 13 |      def test_binom_exact(self):         @np.vectorize         def binom_int(n, k):             n = int(n) |
| .venv/lib/python3.13/site-packages/scipy/special/tests/test_orthogonal.py | 30f1a6a22396596707f9ab80a3645037e329568b859af65c6a86736d389b0da7 | 822 | 2 |             C2 = orth.chebyc(2)             C3 = orth.chebyc(3)             C4 = orth.chebyc(4)             C5 = orth.chebyc(5)  |
| .venv/lib/python3.13/site-packages/scipy/special/tests/test_mpmath.py | 8f1c6a35587385cd2bb913520044ba8c4071f92dffa51c08fa76fb008b46acb0 | 2294 | 4 |          assert_func_equal(sc.erf, lambda x: complex(mpmath.erf(x)), points,                           vectorized=False, rtol=1e-13)         assert_func_equal(sc.erfc, lambda x: complex(mpmath.erfc(x) |
| .venv/lib/python3.13/site-packages/scipy/special/tests/test_sf_error.py | dfe02400386955f79aca448e45fc3b340e80b3641d04d3edadec7e2212bc4038 | 147 | 1 |     'arg': 8,     'other': 9,     'memory': 10, }  |
| .venv/lib/python3.13/site-packages/scipy/special/tests/test_data.py | 9faa7830545711e8d809efdbd10ec27c8bb73979e0e239f59c79cc3d3f6008e0 | 720 | 8 |              (0,1), 2, rtol=9.6e-14),         data(legendre_p_via_lpmn, 'legendre_p_ipp-legendre_p',              (0,1), 2, rtol=5e-14, vectorized=False),         data(legendre_p_via_lpmn, 'legendre_p |
| .venv/lib/python3.13/site-packages/scipy/special/tests/test_cdflib.py | 616e2ae25e7a8bdc1b721c4c4bac32b51425c05b78b154d120b1f00e35a2e896 | 713 | 1 |         FuncData(self.idmap, args,                  param_columns=param_columns, result_columns=result_columns,                  rtol=self.rtol, atol=self.atol, vectorized=False,                  para |
| .venv/lib/python3.13/site-packages/scipy/special/tests/test_ellip_harm.py | d0aa28cb7a531705aa9834f7dec8f1419d52f2a8cd7be32a3b880986070faeb2 | 279 | 1 |         func = known_funcs[n, p]         return func(h2, k2)     _ellip_norm = np.vectorize(_ellip_norm)      def ellip_normal_known(h2, k2, n, p): |
| .venv/lib/python3.13/site-packages/scipy/differentiate/_differentiate.py | bc1d0900982fe3ce89a49028a9439237bb0e79b002f30e6613e991cba73804a2 | 1130 | 20 |     (0.06215223140159822, 0.0625)      The implementation is vectorized over `x`, `step_direction`, and `args`.     The function is evaluated once before the first iteration to perform input     valid |
| .venv/lib/python3.13/site-packages/scipy/differentiate/tests/test_differentiate.py | 5427d9abe4b2026e4b3fd088d5ca65450469b51802396a68614d948db84b535a | 695 | 6 |     @pytest.mark.parametrize('order', [1, 6])     @pytest.mark.parametrize('shape', [tuple(), (12,), (3, 4), (3, 2, 2)])     def test_vectorization(self, order, shape, xp):         # Test for correct  |
| .venv/lib/python3.13/site-packages/scipy/fftpack/tests/test_import.py | 773c97407b6c756d962f9aee569ffe32ca9241dfe7fadbb2ab6da892bcd7946c | 34 | 1 |             # default encoding is defined (e.g., LANG='C')             with tokenize.open(str(path)) as file:                 assert_(all(not re.fullmatch(regexp, line)                             for |
| .venv/lib/python3.13/site-packages/scipy/interpolate/_rgi.py | 602f16398f937a74795bd04d9f56a6df6092f4355e3b7f8e03070a139365bb29 | 765 | 2 |         k = self._SPLINE_DEGREE_MAP[method]          # Non-stationary procedure: difficult to vectorize this part entirely         # into numpy-level operations. Unfortunately this requires explicit   |
| .venv/lib/python3.13/site-packages/scipy/interpolate/_rbfinterp.py | 39e9025ce94f008e13bd249b0077093e22630080a9e1b6505732450b44e3e5ca | 551 | 19 |     is the center of the RBF.      An RBF interpolant for the vector of data values :math:`d`, which are from     locations :math:`y`, is a linear combination of RBFs centered at :math:`y`     plus a  |
| .venv/lib/python3.13/site-packages/scipy/interpolate/_polyint.py | 2b4a3c15c45e1de662da82144e781864356e81f9be89559367973e15dbf3b83c | 1026 | 4 |     >>> KroghInterpolator(xi_k, yi_k)      To produce a vector-valued polynomial, supply a higher-dimensional     array for `yi`:  |
| .venv/lib/python3.13/site-packages/scipy/interpolate/_cubic.py | 118bb4dc5fa5e2889ed2c8226c4362f8a85826fd1c96bec42dc9de0cb26d7379 | 974 | 1 |     r"""Akima "visually pleasing" interpolator (C1 smooth).      Fit piecewise cubic polynomials, given vectors x and y. The interpolation     method by Akima uses a continuously differentiable sub-sp |
| .venv/lib/python3.13/site-packages/scipy/interpolate/_ndbspline.py | 1e24f7b4ba37ce81dd9d630ddf785bf8d015d2631877aa6bcad0bd4f3d449ca6 | 416 | 6 |       Here ``B(x; i, t)`` is the ``i``-th b-spline defined by the knot vector     ``t`` evaluated at ``x``.  |
| .venv/lib/python3.13/site-packages/scipy/interpolate/_bsplines.py | 11fd10d81a85724f3852274b50d2610983c2108def5dad4b9fdaf35008139754 | 2470 | 33 |     ----------     t : ndarray         knot vector     c : ndarray         spline coefficients |
| .venv/lib/python3.13/site-packages/scipy/interpolate/_bary_rational.py | 5fbaad29bf2fc497d71d0d105e7bb026f58a720a6963df1c1a2c01e55ac70f02 | 716 | 3 |         with np.errstate(invalid="ignore", divide="ignore"):             CC = 1 / np.subtract.outer(zv, self._support_points)             # Vector of values             r = CC @ (weights * support_val |
| .venv/lib/python3.13/site-packages/scipy/interpolate/_fitpack2.py | d9afaa814bd5b22c4ff31d13f1a046643d1e1050b3342b20c546aef7664ecb5e | 2398 | 3 |         """ Return positions of interior knots of the spline.          Internally, the knot vector contains ``2*k`` additional boundary knots.         """         data = self._data |
| .venv/lib/python3.13/site-packages/scipy/interpolate/_fitpack_impl.py | 88a3dc31316667078ec0c5b341d946f3756fd648403af113cdade53b7cf68c2f | 812 | 2 |     msg = "Too many data points to interpolate."      _int_overflow(x.size * y.size, MemoryError, msg=msg)      if dx != 0 or dy != 0: |
| .venv/lib/python3.13/site-packages/scipy/interpolate/_fitpack_repro.py | 441eff23beb5f7b2025c68ecf2f2a61a3f84ce8b51adc7cd3ed3614cefe68e1c | 997 | 11 |  def generate_knots(x, y, *, w=None, xb=None, xe=None, k=3, s=0, nest=None):     """Generate knot vectors until the Least SQuares (LSQ) criterion is satified.      Parameters |
| .venv/lib/python3.13/site-packages/scipy/interpolate/_fitpack_py.py | b02cd603e5fcba56f46e7f9871a06af59a357e91c3d270282a651120c6ea19e9 | 899 | 10 |     ----------     x : array_like         A list of sample vector arrays representing the curve.     w : array_like, optional         Strictly positive rank-1 array of weights the same length as `x[0] |
| .venv/lib/python3.13/site-packages/scipy/interpolate/tests/test_bsplines.py | ada3ded938d08a1f4e051bbf8673eba450ae8f0bc77d4fb648c72b8474cbae22 | 3755 | 14 |      def test_bernstein(self):         # a special knot vector: Bernstein polynomials         k = 3         t = np.asarray([0]*(k+1) + [1]*(k+1)) |
| .venv/lib/python3.13/site-packages/scipy/interpolate/tests/test_fitpack.py | 705266c2c5a1772b0ef81129679a4c1e8eac5d218ed536165a0ff5da899cbef9 | 520 | 6 | from pytest import raises as assert_raises import pytest from scipy._lib._testutils import check_free_memory  from scipy.interpolate import RectBivariateSpline |
| .venv/lib/python3.13/site-packages/scipy/interpolate/tests/test_interpnd.py | b4b5a85c0a47416f34d097d193e867e4ac87d5588ebee657b531abb53bed28b4 | 453 | 2 | from scipy._lib._array_api import xp_assert_close, assert_almost_equal  from scipy._lib._testutils import check_free_memory import scipy.interpolate._interpnd as interpnd import scipy.spatial._qhull a |
| .venv/lib/python3.13/site-packages/scipy/interpolate/tests/test_polyint.py | c1466a55da1245b5e6fe7eeb7dc2d0dc2fdd18290fc441be31da639813d1eef4 | 973 | 9 |         assert_almost_equal(self.true_poly(self.test_xs),P(self.test_xs))      def test_vector(self):         xs = [0, 1, 2]         ys = np.array([[0,1],[1,0],[2,1]]) |
| .venv/lib/python3.13/site-packages/scipy/interpolate/tests/test_rgi.py | f926dd32e14c6206eaa1103a89026ba84ab9f96053c6026907c1103b1e3a350b | 1152 | 1 |      def test_non_scalar_values_splinef2d(self):         # Vector-valued splines supported with fitpack         points, values = self._sample_4d_data()  |
| .venv/lib/python3.13/site-packages/scipy/interpolate/tests/test_rbfinterp.py | 4a4fdef87d7ccbdedd6757600a3331afd6f2c0052c78b05ba2eecfc25590d7a9 | 535 | 3 |          def _chunk_evaluator(*args, **kwargs):             kwargs.update(memory_budget=100)             return ce_real(*args, **kwargs)  |
| .venv/lib/python3.13/site-packages/scipy/interpolate/tests/test_interpolate.py | 62b059b54ec5ad09e39290ec6b30dd89ebae8a338d206bc308642da5f30b4fbd | 2631 | 1 |         x = np.linspace(0, 1)         y = np.linspace(0, 1)         # Confirm interp can be released from memory after use         with assert_deallocated(interp1d, x, y) as interp:             interp |
| .venv/lib/python3.13/site-packages/scipy/fft/_basic.py | 5b95afe3f25024db0288a44a65c7cbb5dc4a0ef14e776ed296cfa133559cfdaa | 1651 | 2 |     half of the spectrum from half of the signal.      When ``overwrite_x=True`` is specified, the memory referenced by ``x`` may     be used by the implementation in any way. This may include reusing |
| .venv/lib/python3.13/site-packages/scipy/fft/tests/test_basic.py | d2fed739bba40e2e3e2d0971ae11bbf3871b147b7d2bfe9922317210cc049924 | 505 | 3 |         x = xp.asarray(random(30), dtype=xp.float64)          x_norm = xp.linalg.vector_norm(x)         n = xp_size(x) * 2         func_pairs = [(fft.rfft, fft.irfft), |
| .venv/lib/python3.13/site-packages/scipy/sparse/_base.py | 375e86fe40746e739da98ee85dbaff4bbfa04750048465eb7f8ebf2997a065dc | 1614 | 26 |             'unsafe' means any data conversions may be done.         copy : bool, optional             If `copy` is `False`, the result might share some memory with this             array/matrix. If ` |
| .venv/lib/python3.13/site-packages/scipy/sparse/_compressed.py | 2499f6044fe58b57647a8e4fb4e47b19177973a256700c39526c4df6694080ae | 1329 | 10 |      def _multiply_2d_with_broadcasting(self, other):         """Element-wise multiplication by array/matrix, vector, or scalar."""         # Called after checking that other is not scalarlike and sel |
| .venv/lib/python3.13/site-packages/scipy/sparse/_bsr.py | d0eaee2fd7af3fe8fd5bf7ca22444cdf371cdfdd1cf7c89a50e23f98db10ccdf | 881 | 5 |         return self.tocoo(copy=False)._add_dense(other)      def _matmul_vector(self, other):         M,N = self.shape         R,C = self.blocksize |
| .venv/lib/python3.13/site-packages/scipy/sparse/_index.py | fad705ac593f6002776068d5ec30ea8d99bf067b61c7e99c6ebfb5cad50cb519 | 445 | 5 |             if isinstance(idx, slice):                 # check for simple case of slice that gives 1 item                 # Note: Python `range` does not use lots of memory                 idx_range = |
| .venv/lib/python3.13/site-packages/scipy/sparse/_sputils.py | b1cdc32d7e49fab5add7ec14f0858321275186e083362e6cc2628f6fef5a641f | 633 | 1 |      This is similar to the NumPy ``broadcast_shapes`` function but     does not check memory consequences of the resulting dense matrix.      Parameters |
| .venv/lib/python3.13/site-packages/scipy/sparse/__init__.py | eec62a0f12dc12c5bb970dc7d7dc0e1a7ea6d4a032b0a43c827fa5f683f22fb3 | 351 | 4 | conversion to CSC is less so.  Matrix vector product ---------------------  |
| .venv/lib/python3.13/site-packages/scipy/sparse/_csr.py | 5501ba4e13bea06f580149191f275ee6bd9f833c9e8bc3bc21ec2804148b96aa | 559 | 4 |     def _getrow(self, i):         """Returns a copy of row i of the matrix, as a (1 x n)         CSR matrix (row vector).         """         if self.ndim == 1: |
| .venv/lib/python3.13/site-packages/scipy/sparse/_coo.py | c34acdf2bde4dfcdbc54b122f1e269b3a94c0ee94f0385160b683dfe1d0e3559 | 1582 | 13 |         return A      def _matmul_vector(self, other):         if self.ndim > 2:             result = np.zeros(math.prod(self.shape[:-1]), |
| .venv/lib/python3.13/site-packages/scipy/sparse/_dia.py | f6c19e4619d5512b8eda2d403375c287ffabee74b2966929c920e9f1dee5c4b5 | 678 | 2 |         return self._dia_container((data, offsets), shape=self.shape)      def _matmul_vector(self, other):         x = other  |
| .venv/lib/python3.13/site-packages/scipy/sparse/_lil.py | b92de2e4cff284b8d30e4f71c921bfe0238680903641cc08a4aa61bb085c095e | 633 | 9 |         try:             x = np.asarray(idx)         except (ValueError, TypeError, MemoryError) as e:             raise IndexError('invalid index') from e         if x.ndim not in (1, 2): |
| .venv/lib/python3.13/site-packages/scipy/sparse/_csc.py | 03edaeaf5e5ab7924b20b6bdf96d366e898188db9a539b7aea9548e54b6e9b8f | 368 | 4 |     def _getrow(self, i):         """Returns a copy of row i of the matrix, as a (1 x n)         CSR matrix (row vector).         """         M, N = self.shape |
| .venv/lib/python3.13/site-packages/scipy/sparse/_matrix.py | 7b9ed3c4bfb8fd9342596c16e067706266367e995040242a8690617899fe5d19 | 170 | 5 |     def getcol(self, j):         """Returns a copy of column j of the matrix, as an (m x 1) sparse         matrix (column vector).         """         return self._getcol(j) |
| .venv/lib/python3.13/site-packages/scipy/sparse/_dok.py | 8c25f05bcc4f5f0f495328f7e8872df120821386e97f29af1421116ff2d94957 | 670 | 8 |         return new      def _matmul_vector(self, other):         res_dtype = upcast(self.dtype, other.dtype)  |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_interface.py | 2ff30baae88dc12217a82b4a72b9b1b557459fa17a1fb99989f2a3240c148256 | 921 | 18 | matrix representation, called the ``LinearOperator``. It can be used to do linear algebra with extremely large sparse or structured matrices, without representing those explicitly in memory. Such matr |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_expm_multiply.py | 28e4ae576a85e0e48aacb192c140054f589b9efe1b854f49045264bf2f405576 | 817 | 14 |  def traceest(A, m3, seed=None):     """Estimate `np.trace(A)` using `3*m3` matrix-vector products.      The result is not deterministic. |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/__init__.py | 28be78938783c047fb9876cbdb5b997bced2dab9d23c815c108fa94f75292c8c | 149 | 3 |    :toctree: generated/     eigs -- Find k eigenvalues and eigenvectors of the square matrix A    eigsh -- Find k eigenvalues and eigenvectors of a symmetric matrix    lobpcg -- Solve symmetric partia |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_matfuncs.py | 3b92390264825683f376104c3739a3c687823a63bc74de7bcd37c96db579196a | 941 | 13 |         raise ValueError('expected A to be like a square matrix')      # Explicitly make a column vector so that this works when A is a     # numpy matrix (in addition to ndarray and sparse arrays).   |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_svdp.py | 754af9bf9ddc4794b8d2bef5402015cb4a9474a3313af89a5804f4a6dadc8d34 | 310 | 16 |         object, it must define both ``matvec`` and ``rmatvec`` methods.     k : int         Number of singular values/vectors to compute     which : {"LM", "SM"}         Which singular triplets to com |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_norm.py | 7ebe008104e0d5ce67481e6c14a4a62fcfa840abadf7a0122511a359eebcbf95 | 196 | 3 |     axis : {int, 2-tuple of ints, None}, optional         If `axis` is an integer, it specifies the axis of `x` along which to         compute the vector norms.  If `axis` is a 2-tuple, it specifies t |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_special_sparse_arrays.py | d52ab0bb3d6aa317a100dbcd8d6dac49f7e65a32cbc59ee2994e24680bb57f09 | 950 | 32 | class LaplacianNd(LinearOperator):     """     The grid Laplacian in ``N`` dimensions and its eigenvalues/eigenvectors.      Construct Laplacian on a uniform rectangular grid in `N` dimensions |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_onenormest.py | 0645aef3d7df9a27e405d2c7fbe210ec3896d21bc3915122b9d531e0745599c2 | 468 | 30 |     t : int, optional         A positive parameter controlling the tradeoff between         accuracy versus time and memory usage.         Larger values take longer and use more memory         but giv |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_eigen/_svds.py | 9e257c3d1d00a27c3ce6b6e248fa4bf91b30027f5396da54c1c9e2dd0bbf925f | 541 | 49 |     maxiter = int(maxiter) if maxiter is not None else maxiter      # input validation/standardization for `return_singular_vectors`     # not going to be flexible with this; too complicated for littl |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_eigen/_svds_doc.py | d3fb02f2429bbb76f9058a46975eac3cbad9bba983c621618fcc646c6db0e7e5 | 383 | 74 | def _svds_arpack_doc(A, k=6, ncv=None, tol=0, which='LM', v0=None,                      maxiter=None, return_singular_vectors=True,                      solver='arpack', rng=None):     """ |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_eigen/arpack/__init__.py | cc3c5ff4ba24c8f8ad9f7ff477e3d45e804287ab562b47944afb008fa9e45c8d | 21 | 1 | Eigenvalue solver using iterative methods.  Find k eigenvectors and eigenvalues of a matrix A using the Arnoldi/Lanczos iterative methods from ARPACK [1]_,[2]_.  |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py | 13540b489c6a27c13b871d19ce242f63efff8231db27df5c0849768c18632441 | 1707 | 85 | """ Find a few eigenvectors and eigenvalues of a matrix.   |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_eigen/arpack/tests/test_arpack.py | ca22f6ce907bb62d2bc043f90d85d1643fbb244de6e967abd3b309e0eeb97b9b | 718 | 8 |     kwargs['tol'], rtol, atol = _get_test_tolerance(typ, mattype, d, which)     # on rare occasions, ARPACK routines return results that are proper     # eigenvalues and -vectors, but not necessarily  |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_eigen/tests/test_svds.py | deb433fea45b904a6ef6d14d2bdf0c7d10d830356fe59c8f6802d3cd68415b9e | 887 | 22 |  def sorted_svd(m, k, which='LM'):     # Compute svd of a dense matrix m, and return singular vectors/values     # sorted.     if issparse(m): |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_eigen/lobpcg/lobpcg.py | 09d3378487b4466ee97dd5c0225b7e75d0268498d32c91b1e054f69a0253b88b | 1111 | 330 |     """     If the input array is 2D return it, if it is 1D, append a dimension,     making it a column vector.     """     if ar.ndim == 2: |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_eigen/lobpcg/tests/test_lobpcg.py | d79b9799cc62d01c0f62db83e646a875db0b13df9b37b42f1c98a6a851a6b4e1 | 726 | 13 |     """Test B-orthonormalization by Cholesky with callable 'B'.     The function '_b_orthonormalize' is key in LOBPCG but may     lead to numerical instabilities. The input vectors are often     badly |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/tests/test_matfuncs.py | 4ea0e72451e229d8b05cfd066fac9a5cd01e891795e937417b8c0c4179974c8e | 593 | 4 |     def test_burkardt_6(self):         # This example is due to Moler and Van Loan.         # This matrix does not have a complete set of eigenvectors.         # That means the eigenvector approach wi |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/tests/test_onenormest.py | 4f39f415c55c2a66e3628b1e5249318eae2608e846d9c3df0f2a3d7d009854f2 | 253 | 3 |         assert_(0.9 < proportion_exact < 0.95)          # check the average number of matrix*vector multiplications         assert_(3.5 < np.mean(nmult_list) < 4.5)  |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/tests/test_norm.py | 749a7854d1a99cbe71113eb4f9bd5ea49a88059e20fb30c02d9592e5683ad1c4 | 155 | 2 |             assert_allclose(spnorm(m, -1, axis=axis), 6)      def test_vector_norm(self):         v = [4.5825756949558398, 4.2426406871192848, 4.5825756949558398]         for m, a in (self.b, 0), (sel |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/tests/test_expm_multiply.py | 2bbb52c32487174b0cc6ad3adfdd5f8730709fe791b24c159fbe10bacb2a7ab1 | 368 | 2 |      @pytest.mark.thread_unsafe     def test_matrix_vector_multiply(self):         np.random.seed(1234)         n = 40 |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/tests/test_special_sparse_arrays.py | d99eebd4b3f1ed04de92e5cd4cb72ca4639d27dae24708a8188a71cc86b42a1e | 338 | 8 |     @pytest.mark.parametrize('grid_shape', [(6, ), (2, 3), (2, 3, 4)])     @pytest.mark.parametrize('bc', ['neumann', 'dirichlet', 'periodic'])     def test_eigenvectors(self, grid_shape, bc):         |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/tests/test_propack.py | fbe4881525c31b3c81393746c0e860ad885291b572d518b22ff0edfd8a27a7fe | 166 | 3 |     assert_allclose(sigma1[:k], sigma2, rtol=tol, atol=tol)      # check that singular vectors are orthogonal     assert_orthogonal(u1, u2, rtol=tol, atol=tol)     assert_orthogonal(vt1.T, vt2.T, rtol |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_isolve/lsqr.py | 09ad928f23703055d27245135bf2ea60590573909639a675ca2601d2d2b6b81f | 590 | 5 |         ``scipy.sparse.linalg.LinearOperator``.     b : array_like, shape (m,)         Right-hand side vector ``b``.     damp : float         Damping coefficient. Default is 0. |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_isolve/tfqmr.py | 73ccd684b1a5c6b6367d485945e053ab3f819b6ef876cf7b9c44b5f6cca5917b | 180 | 2 |     callback : function, optional         User-supplied function to call after each iteration.  It is called         as ``callback(xk)``, where ``xk`` is the current solution vector.     show : bool,  |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_isolve/iterative.py | f9d7ace03295000d7b1a76dd12229208908a59140b741669e961b69733110e8f | 1052 | 6 |     callback : function         User-supplied function to call after each iteration.  It is called         as ``callback(xk)``, where ``xk`` is the current solution vector.      Returns |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_isolve/_gcrotmk.py | 0ba0883b7a978260a877f02657712b7480ebca6602c79fed6ea85bd19c1d0daf | 504 | 20 |         Operation A*x     v0 : ndarray         Initial vector, normalized to nrm2(v0) == 1     m : int         Number of GMRES rounds |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_isolve/minres.py | 6a44a825814f1399e8dd73d9ae4229758f031152ca75ff170a698dffacdc7821 | 373 | 4 |     callback : function         User-supplied function to call after each iteration.  It is called         as callback(xk), where xk is the current solution vector.     show : bool         If ``True`` |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_isolve/lsmr.py | f0c46dbfe1496bb9ce1e527b319e13b108960246709ed0f4af9e52390b91aaf2 | 487 | 4 |     is inconsistent, it solves the least-squares problem ``min \|\|b - Ax\|\|_2``.     ``A`` is a rectangular matrix of dimension m-by-n, where all cases are     allowed: m = n, m > n, or m < n. ``b`` is  |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_isolve/lgmres.py | e28fc130fae1ca35c71fa1c0061914f23a448d50d03da03374badd0056594f1c | 231 | 16 |     callback : function, optional         User-supplied function to call after each iteration.  It is called         as callback(xk), where xk is the current solution vector.     inner_m : int, option |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_isolve/tests/test_lsqr.py | b582ad953b97318607bdfa66ae1742aa5ce4d01232a219766fee1bd1203a9c18 | 121 | 1 |     assert norm(A.dot(x) - b) == pytest.approx(0)      # Test b being a column vector.     A = np.eye(10)     b = np.ones((10, 1)) |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_isolve/tests/test_minres.py | 77facb92a74e6c10c3e050694ce620cf0cac4ea06d623815e6fd480cb872afef | 98 | 3 |     matrix = rng.rand(10, 10)     matrix = matrix + matrix.T     # A random vector of length 10     vector = rng.rand(10)     return matrix, vector |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_isolve/tests/test_lgmres.py | f49d28ab828483852420ec0f427a7bcfb53d6c9329095f4db251c20c034271c2 | 226 | 2 |      def test_outer_v(self):         # Check that the augmentation vectors behave as expected          outer_v = [] |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_dsolve/_add_newdocs.py | e0d9ba44029094a238950b78cf6d2fd03ea6d1593c7aaa74988cc493981fced0 | 148 | 1 |     -------     x : ndarray, shape ``rhs.shape``         Solution vector(s)     """))  |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py | 340f184d52f929caf08d122da62951d5cc904c889da6e5382e12c4f1ff0265ee | 883 | 11 |  def spsolve(A, b, permc_spec=None, use_umfpack=True):     """Solve the sparse linear system Ax=b, where b may be a vector or a matrix.      Parameters |
| .venv/lib/python3.13/site-packages/scipy/sparse/linalg/_dsolve/tests/test_linsolve.py | c16fb3bfd2f93ef3c725af78b91ea766a3aa612f93d9c8fc1e8569c4334fc3c3 | 929 | 9 | import scipy.sparse  from scipy._lib._testutils import check_free_memory   |
| .venv/lib/python3.13/site-packages/scipy/sparse/tests/test_construct.py | 957d18a35ece911d80c0062f949bdb8e91c73877573652ce09a3cf26cfc47291 | 873 | 2 | import pytest from pytest import raises as assert_raises from scipy._lib._testutils import check_free_memory  from scipy.sparse import (csr_matrix, coo_matrix, |
| .venv/lib/python3.13/site-packages/scipy/sparse/tests/test_coo.py | bfa99d97b3424fe84e9bfa2e21b59c85dcf5dd5e6cb0fe342ee1c24958070b3c | 1120 | 4 |   def test_1d_matmul_vector():     den_a = np.array([0, -2, -3, 0])     den_b = np.array([0, 1, 2, 3]) |
| .venv/lib/python3.13/site-packages/scipy/sparse/tests/test_sparsetools.py | 9abc91248f8beec0bf79446a4ac624e284000beca0c300776000406d9b10c64e | 345 | 10 |                           bsr_matrix, dia_matrix) from scipy.sparse._sputils import supported_dtypes from scipy._lib._testutils import check_free_memory  import pytest |
| .venv/lib/python3.13/site-packages/scipy/sparse/tests/test_base.py | cc56ff1ac5ebe9d4b0394f743eb48fc6d74f1cd5877260fd313b928ef9c42065 | 5871 | 16 | NON_ARRAY_BACKED_FORMATS = frozenset(['dok'])  def sparse_may_share_memory(A, B):     # Checks if A and B have any numpy array sharing memory.  |
| .venv/lib/python3.13/site-packages/scipy/sparse/csgraph/_laplacian.py | 6e909db915a3221703a5c96f3db7edc7be0f1314e25b43f7104ebf66d8a8a756 | 564 | 14 |     copy: bool, optional         If False, then change `csgraph` in place if possible,         avoiding doubling the memory use.         Default: True, for backward compatibility.     form: 'array', o |
| .venv/lib/python3.13/site-packages/scipy/sparse/csgraph/__init__.py | ce7ac4778f0914b76571ebe5f0814348cd74e1897562f5c2d0efdff0e516013b | 211 | 4 |    dijkstra -- use Dijkstra's algorithm for shortest path    floyd_warshall -- use the Floyd-Warshall algorithm for shortest path    bellman_ford -- use the Bellman-Ford algorithm for shortest path    |
| .venv/lib/python3.13/site-packages/scipy/sparse/csgraph/tests/test_shortest_path.py | 0cda47a7afba7a45f1fbf3b8c57861dcf17edf91e3596db46e9dbf677ce9606c | 541 | 2 | from pytest import raises as assert_raises from scipy.sparse.csgraph import (shortest_path, dijkstra, johnson,                                   bellman_ford, construct_dist_matrix, yen,               |
| .venv/lib/python3.13/site-packages/scipy/sparse/csgraph/tests/test_pydata_sparse.py | 192bfd7ded213d1394f32ca701fda6e963bd242db2c98d5a2d25f177bfde891f | 198 | 2 |         spgraph.dijkstra,         spgraph.floyd_warshall,         spgraph.bellman_ford,         spgraph.johnson,         spgraph.reverse_cuthill_mckee, |
| .venv/lib/python3.13/site-packages/scipy/spatial/_spherical_voronoi.py | bf55e46d623bca85d0e84266247b35f39be5d2a1d5f327d1ae6ddcfe0046cb38 | 342 | 1 |         nbrs1 = np.array([r for region in self.regions for r in region])          # The calculation of nbrs2 is a vectorized version of:         # np.array([r for region in self.regions for r in np.ro |
| .venv/lib/python3.13/site-packages/scipy/spatial/_procrustes.py | aaf8473c7b7f3882a8fa07bf935f52e155aa6cfe9980c5cb56735ecb42714dbf | 133 | 1 |     r"""Procrustes analysis, a similarity test for two data sets.      Each input matrix is a set of points or vectors (the rows of the matrix).     The dimension of the space is the number of columns |
| .venv/lib/python3.13/site-packages/scipy/spatial/_kdtree.py | 2260e2475e033808702befb1f5584c8c0947fee86e9ac2ae3229f5369eb73bb4 | 921 | 6 |     ----------     x : (M, K) array_like         Matrix of M vectors in K dimensions.     y : (N, K) array_like         Matrix of N vectors in K dimensions. |
| .venv/lib/python3.13/site-packages/scipy/spatial/distance.py | 411c916bd38bb83d7a7aea8d15205c5278443cc1841341f7f3b1e0e622a9aca5 | 3148 | 168 | ------------------  Distance matrix computation from a collection of raw observation vectors stored in a rectangular array.  |
| .venv/lib/python3.13/site-packages/scipy/spatial/tests/test_kdtree.py | 76549a5cc0085c54bbdd230cd9597d50f11ef15b5bcb28b3ebdce675bf1d7580 | 1537 | 17 |   class Test_vectorization_KDTree:     def setup_method(self):         self.data = np.array([[0, 0, 0], |
| .venv/lib/python3.13/site-packages/scipy/spatial/tests/test_distance.py | 25c1db73c49b3b500cea3ae2ca3f5b921420aadf35ffa301ca852c694ae32030 | 2389 | 18 | from scipy.spatial.distance import (     squareform, pdist, cdist, num_obs_y, num_obs_dm, is_valid_dm, is_valid_y,     _validate_vector, _METRICS_NAMES)  # these were missing: chebyshev cityblock |
| .venv/lib/python3.13/site-packages/scipy/spatial/tests/test_spherical_voronoi.py | 602552a4eefe46b98a6808afc2b2e1e6b649e824d334ab8827d8b2857b22d7bf | 359 | 1 |          # Test a non-sequence/-ndarray based array-like         s5 = SphericalVoronoi(memoryview(self.points))  # type: ignore[arg-type]         assert_array_equal(s5.center, np.array([0, 0, 0]))     |
| .venv/lib/python3.13/site-packages/scipy/spatial/tests/test_hausdorff.py | 5dc0c4cf016e391f4168b7a0223f833e9e46ac08bf46cbdc5bca06a897f4c648 | 200 | 3 |         import psutil     except ModuleNotFoundError:         pytest.skip("psutil required to check available memory")     if psutil.virtual_memory().available < 80*2**30:         # Don't run the test |
| .venv/lib/python3.13/site-packages/scipy/spatial/transform/_rotation_spline.py | 075c26153a91df85be08c02080d16f16067056b80fdafda21552338e70319c0f | 461 | 25 |  def _create_skew_matrix(x):     """Create skew-symmetric matrices corresponding to vectors.      Parameters |
| .venv/lib/python3.13/site-packages/scipy/spatial/transform/tests/test_rotation_spline.py | 43d7e834ed185a8184ce3cb7868bbc06032be475e1a854e9fabb6aff71793fcd | 184 | 6 |     _angular_rate_to_rotvec_dot_matrix,     _rotvec_dot_to_angular_rate_matrix,     _matrix_vector_product_of_stacks,     _angular_acceleration_nonlinear_term,     _create_block_3_diagonal_matrix) |
| .venv/lib/python3.13/site-packages/scipy/spatial/transform/tests/test_rotation.py | 31f83962c53b2369405186c3a7c1eee1b51be662aede637fcbb02c61a99f2224 | 2570 | 96 |     is_numpy,     is_lazy_array,     xp_vector_norm,     xp_assert_close,     eager_warns, |
| .venv/lib/python3.13/site-packages/scipy/spatial/transform/tests/test_rigid_transform.py | 1330a1f0157a6ade2147efb1fe6876534b9537bde894e412e3ce4f35c8d3bea6 | 1222 | 25 | from scipy._lib._array_api import (     is_lazy_array,     xp_vector_norm,     is_numpy,     xp_assert_close, |
| .venv/lib/python3.13/site-packages/scipy/signal/_ltisys.py | 6bf7018bbd6f5f3af23d0be49e59076f4ea38b0a7ade64864561a61e67579283 | 3547 | 22 |         output is desired.  Must be nonnegative, increasing, and equally spaced.     X0 : array_like, optional         The initial conditions on the state vector (zero by default).     interp : bool,  |
| .venv/lib/python3.13/site-packages/scipy/signal/_delegators.py | 1d701be46856fb278d77c052a312ed93a88c8d09dd04937381a0a3716f56b15d | 569 | 3 |  def find_peaks_cwt_signature(     vector, widths, wavelet=None, max_distances=None, *args, **kwds ):     return array_namespace(vector, widths, max_distances) |
| .venv/lib/python3.13/site-packages/scipy/signal/_spectral_py.py | 5b49f6753f7dc13739d1fc318533026b65cbe6d8185f10aa9cfbfbdf850f8f8e | 2472 | 7 |         )      # weight vector must sum to 1     weights *= 1.0 / weights.sum()  |
| .venv/lib/python3.13/site-packages/scipy/signal/signaltools.py | 23b53f84cb8c7f4db3a5d362d0b70fa20b9c4c37f49d45544a4319d5e028ab71 | 28 | 1 |     'residuez', 'resample', 'resample_poly', 'detrend',     'lfilter_zi', 'sosfilt_zi', 'sosfiltfilt', 'choose_conv_method',     'filtfilt', 'decimate', 'vectorstrength',     'dlti', 'upfirdn', 'get_w |
| .venv/lib/python3.13/site-packages/scipy/signal/_waveforms.py | d067a66e8e87b18fbe99927cdad142130e516337e1c5e0d8fa01473877495c19 | 688 | 1 | def unit_impulse(shape, idx=None, dtype=float):     r"""     Unit impulse signal (discrete delta function) or unit basis vector.      Parameters |
| .venv/lib/python3.13/site-packages/scipy/signal/_signaltools.py | 4d65f6b4876612c61d5c4e68505cac33ada350acb6d2e34565abd6b1d78212ec | 5310 | 46 |            'residuez', 'resample', 'resample_poly', 'detrend',            'lfilter_zi', 'sosfilt_zi', 'sosfiltfilt', 'choose_conv_method',            'filtfilt', 'decimate', 'vectorstrength']   |
| .venv/lib/python3.13/site-packages/scipy/signal/__init__.py | 3560d7b614002e6b8789c2c584f5a7014140acec88c15df39c56162263a8bbd4 | 317 | 2 |    spectrogram    -- Compute the spectrogram (legacy).    lombscargle    -- Computes the Lomb-Scargle periodogram.    vectorstrength -- Computes the vector strength.    ShortTimeFFT   -- Interface for |
| .venv/lib/python3.13/site-packages/scipy/signal/_filter_design.py | 2b77e8db0d28d681aa60c39371afe051d578fdab8cb101ba1b074010d4587639 | 5894 | 3 |     Split into complex and real parts, combining conjugate pairs.      The 1-D input vector `z` is split up into its complex (`zc`) and real (`zr`)     elements. Every complex element must be part of  |
| .venv/lib/python3.13/site-packages/scipy/signal/_czt.py | b793f591108cde2c3778268bf614e072d31f40a7b392a9e36e084b8c291f7d01 | 576 | 1 |     For transforms that do lie on the unit circle, accuracy is better when     using `ZoomFFT`, since any numerical error in `w` is     accumulated for long data lengths, drifting away from the unit c |
| .venv/lib/python3.13/site-packages/scipy/signal/_short_time_fft.py | 378874ef3e74c4eeae1bcce6edfc5da69640064bdc3aeaa5ab39bf06917308f0 | 2188 | 1 |         poorer time-frequency resolution of the STFT.         Hence, the choice of the `hop` interval will be a compromise between         a time-frequency resolution and memory requirements demanded  |
| .venv/lib/python3.13/site-packages/scipy/signal/_peak_finding.py | 7bdbe958bf7c390f489357fb8302e5e1de5f793022c8bc0f9bfc9aac9ab74fff | 1311 | 12 |         to consider ``comparator(n,n+x)`` to be True.     mode : str, optional         How the edges of the vector are treated. 'wrap' (wrap around) or         'clip' (treat overflow as the same as th |
| .venv/lib/python3.13/site-packages/scipy/signal/_spline_filters.py | 99e4d249ed292119eeb44b9f2efc493563e9c5b2c41612e7bfc71e9c02e99672 | 849 | 1 |     ----------     x : array_like         a knot vector     n : int         The order of the spline. Must be non-negative, i.e., n >= 0 |
| .venv/lib/python3.13/site-packages/scipy/signal/_lti_conversion.py | 7985b4cb150557fa6728964c3a604823a92326023942fa9c40675b10515e59d8 | 535 | 2 |      >>> A = [[-2, -1], [1, 0]]     >>> B = [[1], [0]]  # 2-D column vector     >>> C = [[1, 2]]    # 2-D row vector     >>> D = 1 |
| .venv/lib/python3.13/site-packages/scipy/signal/tests/test_signaltools.py | 55de2ac784a388973daeba311794895005ff7b98e59fd20d20fa54fb76779b87 | 4730 | 20 |     fftconvolve, oaconvolve, choose_conv_method, envelope,     hilbert, hilbert2, lfilter, lfilter_zi, filtfilt, butter, zpk2tf, zpk2sos,     invres, invresz, vectorstrength, lfiltic, tf2sos, sosfilt, |
| .venv/lib/python3.13/site-packages/scipy/signal/tests/test_ltisys.py | c14d990bb13e94a0d0db7ff552f6de9b73c0fe835ac91bf3c9c708694a896e77 | 1226 | 1 |          # Try to reach the specific case in _YT_complex where the rank two         # update yields two null vectors. This test was found via Monte Carlo.          A = np.array( |
| .venv/lib/python3.13/site-packages/scipy/signal/tests/test_dltisys.py | 584b390ec0d22900e6e07edd798afa94252f9bc4e488577d4b8489225b9159f8 | 600 | 4 |          # Create an input matrix with inputs down the columns (3 cols) and its         # respective time input vector         u = np.hstack((np.linspace(0, 4.0, num=5)[:, np.newaxis],                 |
| .venv/lib/python3.13/site-packages/scipy/signal/windows/_windows.py | d93c398305c7e70a7a4528fc6c16df2c9737ce5e8f04f4d66600afd0ec6ee3c4 | 2514 | 3 |     Notes     -----     This computation uses the tridiagonal eigenvector formulation given     in [2]_.  |
| .venv/lib/python3.13/site-packages/scipy/stats/_multivariate.py | 1bce4d73d672c438e245ed9131b9a9b763aff52bf67bd4560075600c595440d8 | 7282 | 78 |     ----------     v : iterable of numbers         This may be thought of as a vector of eigenvalues or singular values.     eps : float         Values with magnitude no greater than eps are considere |
| .venv/lib/python3.13/site-packages/scipy/stats/_covariance.py | 48b145ac2972e543eed1dfa79f63ff53e8dd23bd6a6b7c3a00654c9c3b31be2d | 637 | 18 |         -----         Let the diagonal elements of a diagonal covariance matrix :math:`D` be         stored in the vector :math:`d`.          When all elements of :math:`d` are strictly positive, whit |
| .venv/lib/python3.13/site-packages/scipy/stats/_wilcoxon.py | d418a2a39a91bfd861c44f5c0baff696e07009c68c4b7d6d3797c98003adc50f | 266 | 2 |      def _cdf(self, k, n):         return np.vectorize(self._cdf1, otypes=[float])(k, n)      def _sf1(self, k, n): |
| .venv/lib/python3.13/site-packages/scipy/stats/_stats_py.py | c1f98867bce4a0bdb336b6c33bd930bcf50f8b9aae6a654e1f9a6d2064bda3b4 | 11090 | 13 |     is_cupy,     xp_size,     xp_vector_norm,     xp_promote,     xp_capabilities, |
| .venv/lib/python3.13/site-packages/scipy/stats/_qmvnt.py | 20f86f42445234f8ec16d795fb6ce551276dbef3860d2ea190f9649e506f76ee | 455 | 1 |     -------     q : float array : shape=(n_dim,)         The lattice generator vector. All values are in the open interval         ``(0, 1)``.     actual_n_qmc_samples : int |
| .venv/lib/python3.13/site-packages/scipy/stats/_stats_mstats_common.py | 7fd07f5e6b8dd8e4d97a2d82a56427aef1cefeb71d7dd057b2f420072212638a | 323 | 10 |         warnings.warn(msg, RuntimeWarning, stacklevel=2)     slopes.sort()     medslope = np.median(slopes)     if method == 'joint':         medinter = np.median(y - medslope * x) |
| .venv/lib/python3.13/site-packages/scipy/stats/_continued_fraction.py | d96c8bb905acc7d6881e462f4c4e3f5657a901f48a1b8a2d8aefd8e7061bcca0 | 388 | 1 |     An expression that converges more rapidly is expressed as the difference     between two continued fractions. We will compute both of them in one     vectorized call to `_continued_fraction`.      |
| .venv/lib/python3.13/site-packages/scipy/stats/_ksstats.py | f0ea3fd010006670e42e0724932480146c54a39d64b270c00f39017b845d9265 | 601 | 1 |     # Generate initial matrix H of size m*m where m=(2k-1)     # Compute k-th row of (n!/n^n) * H^n, scaling intermediate results.     # Requires memory O(m^2) and computation O(m^2 log(n)).     # Mos |
| .venv/lib/python3.13/site-packages/scipy/stats/_resampling.py | ad8335279281c69d4a3bbf4449100e3ac5e1f5bc7af360963133973ed2a64d7e | 2353 | 110 |   def _vectorize_statistic(statistic):     """Vectorize an n-sample statistic"""     # This is a little cleaner than np.nditer at the expense of some data |
| .venv/lib/python3.13/site-packages/scipy/stats/_page_trend_test.py | ef03a1d8c15abc1426d9b2649fe9b232a1bd02358f2032dc1ac5c9fc9f435650 | 487 | 2 |      # Calculate the L statistic     L = _l_vectorized(ranks, predicted_ranks)      # Calculate the p-value |
| .venv/lib/python3.13/site-packages/scipy/stats/_mstats_basic.py | 4e18752246545f71f022e9b052f3784922c8b041984e4bf7856cac2ee7e8104e | 3659 | 9 |     compr = np.asarray(ma.compressed(arr), dtype=np.float64)     try:         need_copy = np.may_share_memory(compr, arr)     except AttributeError:         # numpy < 1.8.2 bug: np.may_share_memory([] |
| .venv/lib/python3.13/site-packages/scipy/stats/__init__.py | 994ac49d6f5f889e267a6770d631ff812b9aaf7f5736ae08ced79c385eb86ba8 | 671 | 1 |    BootstrapMethod  Multiple Hypothesis Testing and Meta-Analysis --------------------------------------------- These functions are for assessing the results of individual tests as a whole. |
| .venv/lib/python3.13/site-packages/scipy/stats/_finite_differences.py | 41a039a77e93d280ede1efe830e137406053f200760b7137ce26525a490117d8 | 146 | 1 |     Assumes equally-spaced function points.      If weights are in the vector w, then     derivative is w[0] * f(x-ho*dx) + ... + w[-1] * f(x+h0*dx)  |
| .venv/lib/python3.13/site-packages/scipy/stats/_qmc.py | cf0211a7987245acac5a0d72d9fe46f8b607582228004a8c09ae1eb22f216d43 | 2957 | 5 |     def _scramble(self) -> None:         """Scramble the sequence using LMS+shift."""         # Generate shift vector         self._shift = np.dot(             rng_integers(self.rng, 2, size=(self.d,  |
| .venv/lib/python3.13/site-packages/scipy/stats/_discrete_distns.py | 2d9fcc6a40db9b5e3282edb897e06a593f64e35952a6d56ef4e56af756d0d8ad | 2099 | 10 |  from ._distn_infrastructure import (rv_discrete, get_distribution_names,                                     _vectorize_rvs_over_shapes,                                     _ShapeInfo, _isintegral,   |
| .venv/lib/python3.13/site-packages/scipy/stats/_kde.py | 78b8794cff140c9c8aa90971dfeab6ed4c8bbd289b8a60e8a1934fa5c28b8432 | 733 | 4 |         ----------         points : (# of dimensions, # of points)-array             Alternatively, a (# of dimensions,) vector can be passed in and             treated as a single point.  |
| .venv/lib/python3.13/site-packages/scipy/stats/_hypotests.py | f301049c2acd22cf4cae87dfd1c09d6e0cda51ab78fa470fc4e006a8b276acdd | 2061 | 4 |     .. [1] NIST/SEMATECH e-Handbook of Statistical Methods, "7.4.7.1. Tukey's            Method."            https://www.itl.nist.gov/div898/handbook/prc/section4/prc471.htm,            28 November 20 |
| .venv/lib/python3.13/site-packages/scipy/stats/_sampling.py | 8d5746b6c1f2208d463d3c0714a6dafda51000450862768f2b3ff7bf4c8a19f2 | 1315 | 2 | # The keys of the latter dictionary are: # - pdf: the pdf of the distribution (callable). The signature of the pdf #   is float -> float (i.e., the function does not have to be vectorized). #   If pos |
| .venv/lib/python3.13/site-packages/scipy/stats/_distn_infrastructure.py | 0235213a0aa6fbf47fde5780b2aa30a3f86cd0666fbc68348da2dcecb6c8082e | 4202 | 29 |  from numpy import (arange, putmask, ones, shape, ndarray, zeros, floor,                    logical_and, log, sqrt, place, argmax, vectorize, asarray,                    nan, inf, isinf, empty)  |
| .venv/lib/python3.13/site-packages/scipy/stats/_mstats_extras.py | d0b2f723eb4e1b5edf23908a3c12bb6bc7b9fb2ae05f85cb8dfb073ace4c310b | 522 | 1 |     1.0693225866553746e-05      The function is vectorized to compute along a given axis.      >>> import numpy as np |
| .venv/lib/python3.13/site-packages/scipy/stats/_continuous_distns.py | b24b49e2c637ece2efbf299929f78c2a0863c561fae02b0e6257772c4a074734 | 12487 | 18 | from ._tukeylambda_stats import (tukeylambda_variance as _tlvar,                                  tukeylambda_kurtosis as _tlkurt) from ._distn_infrastructure import (_vectorize_rvs_over_shapes,     g |
| .venv/lib/python3.13/site-packages/scipy/stats/_axis_nan_policy.py | 232f7c395b683a6ce11777f898515ccf501b5289a282989f1efe3ba5433c4b3f | 693 | 11 |     the shape of the broadcast result after consuming/dropping `axis`.     In other words, return output shape of a typical hypothesis test on     `arrays` vectorized along `axis`.      Examples |
| .venv/lib/python3.13/site-packages/scipy/stats/_distribution_infrastructure.py | 52808c52c96a7a912d1b3fd8b2b623940963dc992a7285e021315272623cf545 | 5751 | 4 | #   speed things up. If it's not needed, it may be about twice as slow. I think #   it should depend on the accuracy setting. #  in tests, check reference value against that produced using np.vectoriz |
| .venv/lib/python3.13/site-packages/scipy/stats/_fit.py | 3e62e0e68136e609ce207555fb853e9df504b0a75f81a73833d39a0528caae8c | 1352 | 5 |         return compare_fun(rfd_dist, data, axis=-1)      res = stats.monte_carlo_test(data, rvs, statistic_fun, vectorized=True,                                  n_resamples=n_mc_samples, axis=-1,     |
| .venv/lib/python3.13/site-packages/scipy/stats/_morestats.py | 909a78586594ecd92b93ff7af995bc73985bbb415f1628760d693de5dfcc9cc4 | 4627 | 27 |     array_namespace,     xp_size,     xp_vector_norm,     xp_promote, ) |
| .venv/lib/python3.13/site-packages/scipy/stats/_bws_test.py | 5d030688b30f2853776fa3b89c3e6d91975c23c0fcbe0812c7c07b5cb279106b | 178 | 1 |     '''Compute the BWS test statistic for two independent samples'''     # Public function currently does not accept `axis`, but `permutation_test`     # uses `axis` to make vectorized call.      Ri,  |
| .venv/lib/python3.13/site-packages/scipy/stats/_levy_stable/__init__.py | e09c819bf7e9cf8d45df8352464f82c998c678ba28bc1972091ed198c810fb63 | 1232 | 1 |                 # for some parameters, the range of x can be quite                 # large, let's choose an arbitrary cut off (8GB) to save on                 # computer memory.                 MAX_Q  |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_morestats.py | 56da74945898b807598af8606932b5c104e3457ee357a93668ad02f1845b68bd | 3260 | 4 |      def test_too_few_args(self, xp):         message = "Must enter at least two input sample vectors."         with pytest.raises(ValueError, match=message):             stats.bartlett(xp.asarray([1. |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_continuous.py | 98dd971e64bdf0c2a1c6eed232c572be2478a40c5d3f1fa6fdb07b08cc71f007 | 2199 | 1 |             'levy_stable',            # private methods seem to require >= 1d args             'vonmises',               # circular distribution; shouldn't work             'poisson_binom',          # |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_stats.py | 3aef67e95ddaf368f647d90ab77f3757b4c24d0f15b6863562906bb7c83c4d79 | 9708 | 6 |      @pytest.mark.fail_slow(10)     @pytest.mark.xfail_on_32bit("Monte Carlo method needs > a few kB of memory")     @pytest.mark.parametrize('alternative', ('less', 'greater', 'two-sided'))     @pyte |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_discrete_distns.py | fceeaf510ed3049a5931e8196f9d205701e0c729a135052c61443ff191ae8572 | 701 | 6 |         # test against bare-bones implementation          @np.vectorize         def Hns(n, s):             """Naive implementation of harmonic sum""" |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_continuous_basic.py | 4d3a474491e840e4bed8a2582dd5c7503b478bc7b484d0dedd62af2951c786cd | 1054 | 1 |     # variate.  That means the result of using rvs with broadcasting or     # with a nontrivial size will not necessarily be the same as using the     # numpy.vectorize'd version of rvs(), so we can o |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_fit.py | 844f682193a176af03385ac01839fef00e7c421195826929688e133740b33444 | 1091 | 2 |                       'studentized_range', 'kstwo',                       'beta', 'nakagami', 'truncnorm', # don't meet tolerance                       'poisson_binom'}  # vector-valued shape paramete |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_multivariate.py | d48d8cdfcc5288f3be55c9657f34b96f433de8859f88eee9fc631bcf021160fa | 4382 | 31 |             _covariance.CovViaEigendecomposition(("alpaca", np.eye(2)))          message = "The input `eigenvectors` must be a square..."         with pytest.raises(ValueError, match=message):         |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_hypotests.py | 672f0b029f5e97b2144b25912ac7f1cfccc49a1ac2325164696c684b387daf1e | 1992 | 1 |         '''         Example sourced from:         https://www.itl.nist.gov/div898/handbook/prc/section4/prc471.htm         '''         group1 = [6.9, 5.4, 5.8, 4.6, 4.0] |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_axis_nan_policy.py | 833da84f5423d6edcdad067992ead05749312b3c1eded3d6ad73195172ebf344 | 1389 | 2 | def _axis_nan_policy_test(hypotest, args, kwds, n_samples, n_outputs, paired,                           unpacker, nan_policy, axis, data_generator):     # Tests the 1D and vectorized behavior of hypot |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_tukeylambda_stats.py | e96501355a13b1e5637eb1df597b54d7581382645c767c003cb40e234cbfe54f | 86 | 1 |         assert_allclose(kurt, kurt_expected, **a10)      # Test with vector arguments (most of the other tests are for single     # values).     lam, var_expected, kurt_expected = zip(*data) |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_contingency.py | d3440837df72c9b33f1e1acb7fc91c93ce6058f500426608288ed79d5ccf17de | 295 | 2 |         # Rcode = \         # """         # # Data vector.         # data <- c(         #   12, 34, 23,     4,  47,  11, |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/common_tests.py | 460aca104ba8c4a466a0fcb1be3251d9120a43d01e2a1f2a1e541448a39fb7e8 | 357 | 1 |     assert_equal(sample.shape, shape, f"{distname}: rvs failed to broadcast")     if not shape_only:         rvs = np.vectorize(             lambda *allargs: distfunc.rvs(*allargs, random_state=rng),  |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_distributions.py | 2176afc46755345e0049a47e81ab068a5ec5d927ae4c04029e0380d9abdcb171 | 10414 | 12 |         assert_allclose(i, x, rtol=rtol)      def test_sf_isf_mpmath_vectorized(self):         x = [-1, 25]         a = [1, 1] |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_entropy.py | 7eb0cd29b824e24c587e1ebfc505b1490e353354646e4d671dc29b6bf4e76c3e | 323 | 1 |         # test that RMSE and standard deviation of estimators matches values         # given in differential_entropy reference [6]. Incidentally, also         # tests vectorization.         reps, n, m |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_discrete_basic.py | eb177b5f9571c3144c0fd7563845f7ee0726ee04732d1212c73fc791f23d4297 | 581 | 1 |     # variate.  That means the result of using rvs with broadcasting or     # with a nontrivial size will not necessarily be the same as using the     # numpy.vectorize'd version of rvs(), so we can o |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_sensitivity_analysis.py | 9cd17f07a665e58c66be9a48f1310f386ae80ec6e0c8b4c5ea30667491f6014c | 311 | 1 |         'func',         [f_ishigami, pytest.param(f_ishigami_vec, marks=pytest.mark.slow)],         ids=['scalar', 'vector']     )     def test_ishigami(self, ishigami_ref_indices, func): |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_resampling.py | 012dc7f62df460b78bff70aee95add3a77d0323644d8fbadcdf4926865fe9bff | 2001 | 83 |         bootstrap(([1, 2, 3], [1, 2, 3, 4]), np.mean, paired=True)      message = "`vectorized` must be `True`, `False`, or `None`."     with pytest.raises(ValueError, match=message):         bootstra |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_sampling.py | 7758401d3e1cf79d1ea9b2a8df398ece604a339e2a7cbbea1c885787cb7a7ce8 | 1451 | 2 |     # Cramer Von Mises test for goodness-of-fit     rvs = rng.rvs(500)     dist.cdf = np.vectorize(dist.cdf)     pval = cramervonmises(rvs, dist.cdf).pvalue     assert pval > 0.1 |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/test_qmc.py | 6be9981226e4af588b4a887a6c108435568dad1a9872db25d723b2c250063f86 | 1493 | 4 |      def test_bounds(self, *args):         pytest.skip("Too costly in memory.")      def test_fast_forward(self, *args): |
| .venv/lib/python3.13/site-packages/scipy/stats/tests/data/_mvt.py | 3af14298ca88ef80d6220a37d94579e5d3f59f3bc5bd8052c987262897acf692 | 172 | 2 |     #     #   Alan Genz is the author of this function and following Matlab functions.     #          Alan Genz, WSU Math, PO Box 643113, Pullman, WA 99164-3113     #          Email : alangenz@wsu.edu |
| .venv/lib/python3.13/site-packages/coverage/phystokens.py | 18574318d588c00f81354313b535e59f15422a6dff472ffbfb8e4e2397a4f7d5 | 201 | 1 |      Originally this was used to cache the results, but it didn't seem to make     reporting go faster, and caused issues with using too much memory.      """ |
| .venv/lib/python3.13/site-packages/coverage/control.py | 489adce679e02afc3cba1f1bf4cc0fb50b2110b5a61d2c86771814762641a3ab | 1478 | 1 |         """Erase previously collected coverage data.          This removes the in-memory data collected in this session as well as         discarding the data file.  |
| .venv/lib/python3.13/site-packages/coverage/sqlitedb.py | 301a0b8363925994d711dd7f6c4ca7ec0a85bc8faf6821815837c8ba99bfbfb1 | 240 | 2 |         # It can happen that Python switches threads while the tracer writes         # data. The second thread will also try to write to the data,         # effectively causing a nested context. Howev |
| .venv/lib/python3.13/site-packages/coverage/pytracer.py | 3ced2b0e23063b5fe9840a1bb553b1c278124b01b109b67a5a5c1f007e2795de | 370 | 1 |     YIELD_VALUE = YIELD_FROM = YIELD_FROM_OFFSET = -1  # When running meta-coverage, this file can try to trace itself, which confuses # everything.  Don't trace ourselves.  |
| .venv/lib/python3.13/site-packages/coverage/sqldata.py | 5dd68bf790a68dabf1a63a3ed0dab825f8d5e90084ac81522ef36d2b60db1dc2 | 1150 | 4 |     Write the data to its file with :meth:`write`.      You can clear the data in memory with :meth:`erase`.  Data for specific     files can be removed from the database with :meth:`purge_files`.  |
| .venv/lib/python3.13/site-packages/coverage/inorout.py | 0db09f00be259cdb2bd143515bade998b290b02d8c7af6d5f74ba5528e5c50da | 615 | 2 |             return nope(disp, "empty string isn't a file name")          if filename.startswith("memory:"):             return nope(disp, "memory isn't traceable")  |
| .venv/lib/python3.13/site-packages/yarl/_url.py | efff44840f4b6d78e62b7cec012e3e5ae3198257bb468bd52b5a501985422fc9 | 1605 | 2 |             qstr.update(query_to_pairs(in_query))             query = get_str_query_from_iterable(qstr.items())         elif isinstance(in_query, (bytes, bytearray, memoryview)):  # type: ignore[unrea |
| .venv/lib/python3.13/site-packages/yarl/_quoting_py.py | a15c55b8358c0a3baf4d5881883ce160114c23e61f0c23461946df9d0a643a04 | 214 | 1 |             if ch == "%" and idx <= len(val) - 2:                 pct = val[idx : idx + 2]                 if _IS_HEX_STR.fullmatch(pct):                     b = bytes([int(pct, base=16)])             |
| .venv/lib/python3.13/site-packages/yarl/_query.py | da5efa8f8ff6a90eaf9f0291c86c212390175297652869a60b8ca9dd98e37af2 | 115 | 2 |     if isinstance(query, Mapping):         return get_str_query_from_sequence_iterable(query.items())     if isinstance(query, (bytes, bytearray, memoryview)):  # type: ignore[unreachable]         msg |
| .venv/lib/python3.13/site-packages/myst_parser/inventory.py | 2866be2b1f76299ad95f9fe910375ce58263171ceb1f6cb045bf3687ff4d1baf | 505 | 1 |         return True     regex = _create_regex(pattern)     return regex.fullmatch(name) is not None   |
| .venv/lib/python3.13/site-packages/myst_parser/config/main.py | f7572290d84aabf679c2255e087f029a92074ceb95f869009b95075b607f10d7 | 598 | 1 |      if isinstance(text, str):         if not text.startswith("---"):  # skip creating the line list in memory             return None         text = (line for line in text.splitlines()) |
| .venv/lib/python3.13/site-packages/myst_parser/sphinx_ext/myst_refs.py | 5621056098e44b9eb3c9b9a1a66bf6770caf2f969ee8f065a91f1fc95b4b6e03 | 398 | 2 |             and any(                 (                     re.fullmatch(ignore_type, "myst")                     and re.fullmatch(ignore_target, target)                 ) |
| .venv/lib/python3.13/site-packages/functorch/compile/__init__.py | 7d99cd1b9e9504b7ca95732a5f9463ded3914182f2c5bca8034ac4a0406ddca3 | 31 | 1 |     default_decompositions,     draw_graph_compile,     memory_efficient_fusion,     nnc_jit,     nop, |
| .venv/lib/python3.13/site-packages/functorch/einops/rearrange.py | f9e869d4ce9ae9881d4d59e2d3e221dbc119220a2ce4d56ee27b8329d7804c49 | 212 | 1 |         torch.Size([32, 3, 30, 40])          >>> # flattened each image into a vector, 3600 = 30 * 40 * 3         >>> rearrange(images, "b h w c -> b (c h w)").shape         torch.Size([32, 3600]) |
| .venv/lib/python3.13/site-packages/dill/__info__.py | b03dad723200b9198c008a81b45e3e2562bb553088a10c776b150d0506fea8fc | 292 | 2 |     >>>     dumps(squared)     ┬ F1: <function <lambda> at 0x7fe074f8c280>     ├┬ F2: <function _create_function at 0x7fe074c49c10>     │└ # F2 [34 B]     ├┬ Co: <code object <lambda> at 0x7fe07501eb3 |
| .venv/lib/python3.13/site-packages/dill/session.py | a9ce3591fcd74fd308c752864842156d4b032811c4ae1a6da5e433c1c1aca645 | 613 | 1 |     __module__ = getattr(obj, '__module__', None)     if isinstance(obj, IMPORTED_AS_TYPES) or (__module__ is not None             and any(regex.fullmatch(__module__) for regex in IMPORTED_AS_MODULES) |
| .venv/lib/python3.13/site-packages/dill/logger.py | 58d5f9f65c431ee66748c299dbde22d2e0834e66e77963cbbbbf417bb98e6be4 | 286 | 1 |         >>>     dumps(D)         ┬ D2: <dict object at 0x7f2721804800>         ├┬ D2: <dict object at 0x7f27217f5c40>         │└ # D2 [8 B]         └ # D2 [22 B] |
| .venv/lib/python3.13/site-packages/dill/_objects.py | c0f113af4fc6b63fff70500810ee854520bfbe90587b19a50e21e5fddf207895 | 542 | 10 | # data persistence (CH 11) if HAS_ALL:     x['ConnectionType'] = _conn = sqlite3.connect(':memory:')     x['CursorType'] = _conn.cursor() a['ShelveType'] = shelve.Shelf({}) |
| .venv/lib/python3.13/site-packages/dill/_dill.py | 0d7e750ea5b50d72ffe55759fb3179c3d6afc6254eb0d87a70dc0c91ddfd170a | 2256 | 7 | from types import CodeType, FunctionType, MethodType, GeneratorType, \     TracebackType, FrameType, ModuleType, BuiltinMethodType BufferType = memoryview #XXX: unregistered ClassType = type # no 'old |
| .venv/lib/python3.13/site-packages/dill/tests/test_restricted.py | 9a4f7758bb4d00442bd3787837e3593bb5abf713d6bf380c3ce3c4762e0092ee | 28 | 1 | #!/usr/bin/env python # # Author: Kirill Makhonin (@kirillmakhonin) # Copyright (c) 2008-2016 California Institute of Technology. # Copyright (c) 2016-2025 The Uncertainty Quantification Foundation. |
| .venv/lib/python3.13/site-packages/dill/tests/test_logger.py | 3e2647af76c6221eab5bf471dee010955979a0597e9f60508d79293f36e68e78 | 71 | 2 |                                )             for line in buffer.getvalue().splitlines():                 assert regex.fullmatch(line)             return buffer.getvalue()         else: |
| .venv/lib/python3.13/site-packages/pandas/conftest.py | 987ff0da1e11da62c5fc63ff754af982106f33ae54f2d564fa00b9a4c6125506 | 2066 | 5 |   _index_or_series_memory_objs = {     **indices_dict,     **_series, |
| .venv/lib/python3.13/site-packages/pandas/_typing.py | 8154a29a2538e8376e736133f1968e733bfc73e5074c7e0565e83a2cbea69c69 | 526 | 1 | F = TypeVar("F", bound=FuncType)  # types of vectorized key functions for DataFrame::sort_values and # DataFrame::sort_index, among others ValueKeyFunc = Optional[Callable[["Series"], Union["Series",  |
| .venv/lib/python3.13/site-packages/pandas/_version.py | c5d36f4774b93828703efb74a119d4558889ad5b2737b9fd9c241fd4a53455e5 | 693 | 1 |     # get_keywords().     git_refnames = " (HEAD, tag: v2.3.2, origin/2.3.x)"     git_full = "4665c10899bc413b639194f6fb8665a5c70f7db5"     git_date = "2025-08-21 10:42:59 +0200"     keywords = {"refn |
| .venv/lib/python3.13/site-packages/pandas/pyproject.toml | b96e8bc1e00c06e9addf36084eb5fa181aa38d352654764ee12bb692d9bb1ece | 819 | 1 |   "TCH",   # comprehensions   "C4",   # pygrep-hooks   "PGH", |
| .venv/lib/python3.13/site-packages/pandas/_version_meson.py | d8b98396d7ebb8dbd0a2537119b2ecc2a53801905bad0d89869b900223496501 | 3 | 1 | __version__="2.3.2" __git_version__="4665c10899bc413b639194f6fb8665a5c70f7db5" |
| .venv/lib/python3.13/site-packages/pandas/compat/compressors.py | 19d0d674acd6aa42268ddc33b950705b626f23b68cce93d5f10ca1c56809a348 | 78 | 5 |  def flatten_buffer(     b: bytes \| bytearray \| memoryview \| PickleBuffer, ) -> bytes \| bytearray \| memoryview:     """ |
| .venv/lib/python3.13/site-packages/pandas/core/construction.py | 2cbd7035d2d86c77117d035b4eb4a1e553c8c841d83c8494942975707a4e8631 | 822 | 1 |        are added by pandas and third-party libraries      Additionally, if the underlying memory representation of the returned     array matters, we recommend specifying the `dtype` as a concrete obj |
| .venv/lib/python3.13/site-packages/pandas/core/config_init.py | f3e5541216c8276fea9c13508c34ff423cfb02ef44d46ae0f1cf1865d737adfb | 942 | 4 | """  pc_memory_usage_doc = """ : bool, string or None     This specifies if the memory usage of a DataFrame should be displayed when |
| .venv/lib/python3.13/site-packages/pandas/core/generic.py | 7aa7bd7aee6c75e5aedbfeeded60d0b92670693f4b0f4c891f3030636969d728 | 13980 | 7 |         copy : bool, default True             Only controls whether the conversion from Block->ArrayManager             copies the 1D arrays (to ensure proper/contiguous memory layout).          Retur |
| .venv/lib/python3.13/site-packages/pandas/core/series.py | b5470ec287b71781b923168e181dc73c4ff19144e3263e7599e181eb4322001b | 6643 | 22 |          This function will return a new Series with a view of the same         underlying values in memory, optionally reinterpreted with a new data         type. The new data type must preserve the  |
| .venv/lib/python3.13/site-packages/pandas/core/frame.py | 7e8e5557bf6a2fdb6b6da1baf8b6e3185a3c03f66b29316e4b2787f14e09f64d | 12705 | 28 |             it; it will be removed in a future release.         allow_copy : bool, default True             Whether to allow memory copying when exporting. If set to False             it would cause n |
| .venv/lib/python3.13/site-packages/pandas/core/sample.py | 4043f36c599e311331008a9f911ac92e7223519812ba96cff185047b35be3dcc | 155 | 3 |      if lib.has_infs(weights):         raise ValueError("weight vector may not include `inf` values")      if (weights < 0).any(): |
| .venv/lib/python3.13/site-packages/pandas/core/base.py | 7a6e35746f6ccab41759e186e5ff2ffee6e261f80ff460d97efc302cd335b09b | 1401 | 16 |     def __sizeof__(self) -> int:         """         Generates the total memory usage for an object that returns         either a value or Series of values         """ |
| .venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py | 5a224d513c50cb040f9741543f2bb2fac4e1b022b84040030ceab00e63927c2a | 2763 | 5 |         Field names to join on. Must be found in both DataFrames.     left_on : label or list, or array-like         Field names to join on in left DataFrame. Can be a vector or list of         vector |
| .venv/lib/python3.13/site-packages/pandas/core/reshape/concat.py | ab05ec02523da672e5775a63f6ea877f6ce29d777e7e3f06137919f9735569c5 | 895 | 1 | class _Concatenator:     """     Orchestrates a concatenation operation for BlockManagers     """  |
| .venv/lib/python3.13/site-packages/pandas/core/strings/accessor.py | 6967aa3d72e1a8154dddab4ceccc901b93bfb8b012f84d086f1c2d463334c44d | 3572 | 5 | class StringMethods(NoNewAttributesMixin):     """     Vectorized string functions for Series and Index.      NAs stay NA unless handled otherwise by a particular method. |
| .venv/lib/python3.13/site-packages/pandas/core/strings/object_array.py | b1ea2438c153d3a0d86bbdc81517420ffef29ca22c45df3ed3d59ae421e3d975 | 537 | 2 |         return self._str_map(f, na_value=na, dtype=np.dtype(bool))      def _str_fullmatch(         self,         pat: str \| re.Pattern, |
| .venv/lib/python3.13/site-packages/pandas/core/strings/base.py | 8abfb289af04b27a9f069f4cbe9182dd63f6c10690010ce53c6e3c891ea5e3e1 | 267 | 1 |      @abc.abstractmethod     def _str_fullmatch(         self,         pat: str \| re.Pattern, |
| .venv/lib/python3.13/site-packages/pandas/core/tools/datetimes.py | 0481ef8c59df1f75f1b87b696f85b1c5d938e8bc407266320fc3860dbfea5f00 | 1241 | 2 |     timezones as libtimezones, ) from pandas._libs.tslibs.conversion import cast_from_unit_vectorized from pandas._libs.tslibs.parsing import (     DateParseError, |
| .venv/lib/python3.13/site-packages/pandas/core/array_algos/replace.py | 43ab8c767e1e6da404a0b73dd4ff8d219b05742a8a85f0b1b427a4cbaf99d71d | 156 | 2 |         op = lambda x: operator.eq(x, b)     else:         op = np.vectorize(             lambda x: bool(re.search(b, x))             if isinstance(x, str) and isinstance(b, (str, Pattern)) |
| .venv/lib/python3.13/site-packages/pandas/core/interchange/from_dataframe.py | 9b65eeebf6d708da9966136f37d3d3eef925cdce7587f22da457eeee1f8ba83e | 558 | 14 |         Object supporting the interchange protocol, i.e. `__dataframe__` method.     allow_copy : bool, default: True         Whether to allow copying the memory to perform the conversion         (if  |
| .venv/lib/python3.13/site-packages/pandas/core/interchange/dataframe_protocol.py | 2fd5b2f2f079a13b2e60943d34163844810059705c9674ce1f723fb719086d99 | 466 | 4 | class Buffer(ABC):     """     Data in the buffer is guaranteed to be contiguous in memory.      Note that there is no dtype attribute present, a buffer can be thought of |
| .venv/lib/python3.13/site-packages/pandas/core/interchange/buffer.py | 2ae8d5435a9e5cc8e045dbf079adfb16a3bd7f650b98b6ba46daff993435d575 | 137 | 2 | class PandasBuffer(Buffer):     """     Data in the buffer is guaranteed to be contiguous in memory.     """  |
| .venv/lib/python3.13/site-packages/pandas/core/dtypes/dtypes.py | 2289bfe0a5c205ad53f70dfadcb98eea689577c5871397d6c8e2d4a50191e3b6 | 2349 | 1 |     def __init__(self, dtype: npt.DTypeLike \| NumpyEADtype \| None) -> None:         if isinstance(dtype, NumpyEADtype):             # make constructor idempotent             dtype = dtype.numpy_dtype  |
| .venv/lib/python3.13/site-packages/pandas/core/groupby/ops.py | a993f3a6cf27e7febbfc5706a41c8cf46e0f16aafb7f83d67307f9d8eb35eae2 | 1209 | 2 |             to_groupby = []             for ping in self.groupings:                 gv = ping.grouping_vector                 if not isinstance(gv, BaseGrouper):                     to_groupby.append( |
| .venv/lib/python3.13/site-packages/pandas/core/groupby/grouper.py | 0e5fb46a88b758433d5d790418d76fd5a0fc721c6bea3b5e6a3007873dcc5377 | 1103 | 48 |         self.level = level         self._orig_grouper = grouper         grouping_vector = _convert_grouper(index, grouper)         self._all_grouper = None         self._orig_cats = None |
| .venv/lib/python3.13/site-packages/pandas/core/groupby/groupby.py | 84e8befa5e315ba61af442cfea2c3fefa6b20489e20d7003f332a5482c2c87f0 | 6004 | 3 |         # of non-grouping columns regardless of `observed`         if any(             isinstance(grouping.grouping_vector, (Categorical, CategoricalIndex))             and not grouping._observed      |
| .venv/lib/python3.13/site-packages/pandas/core/internals/managers.py | b680e0a168699ce262c32b6ac91fd7e40989926a9eb58bc1aba29b311f53ebe5 | 2376 | 1 |                             bp = BlockPlacement(ml)                             nb = blk.getitem_block_columns(slc, new_mgr_locs=bp)                             # We have np.shares_memory(nb.values, b |
| .venv/lib/python3.13/site-packages/pandas/core/computation/ops.py | c7941edcf7e31c5e6ff851c17ab52bdfd88d5e4fd3d212efc3459c866d118804 | 573 | 2 | def _in(x, y):     """     Compute the vectorized membership of ``x in y`` if possible, otherwise     use Python.     """ |
| .venv/lib/python3.13/site-packages/pandas/core/_numba/extensions.py | 6b093b15c13f89da15186d1f73dd11dea3450fe0459e0857b85dcaaf2b41ee12 | 586 | 1 |     # Does parent exist?     # (it means already boxed once, or Index same as original df.index or df.columns)     # xref https://github.com/numba/numba/blob/596e8a55334cc46854e3192766e643767bd7c934/n |
| .venv/lib/python3.13/site-packages/pandas/core/window/rolling.py | 8e3e4d982576f0d82c59731a055a95fa3f3e24fc19382bb785e2e2f4001b4cc5 | 2931 | 1 |              with np.errstate(all="ignore"):                 # Our weighted aggregations return memoryviews                 result = np.asarray(calc(values))  |
| .venv/lib/python3.13/site-packages/pandas/core/arrays/categorical.py | f61d483979a28725a8888fbd263eac53c864957653eeaf090e37d4786701f2e8 | 3112 | 6 |         return self._codes.nbytes + self.dtype.categories.values.nbytes      def memory_usage(self, deep: bool = False) -> int:         """         Memory usage of my values |
| .venv/lib/python3.13/site-packages/pandas/core/arrays/interval.py | 36c683973c624538fa6b09b182bed4604f0742849ec72f91a33724e5c7be2746 | 1931 | 2 |         copy : bool, default True             Whether to make a copy of the data before filling. If False, then             the original should be modified and no new memory should be allocated.       |
| .venv/lib/python3.13/site-packages/pandas/core/arrays/_arrow_string_mixins.py | ca5b4b4fa580d4da489ea162ea968bd84dacbce94035e6244293961660d123a2 | 363 | 1 |         return self._str_contains(pat, case, flags, na, regex=True)      def _str_fullmatch(         self,         pat: str \| re.Pattern, |
| .venv/lib/python3.13/site-packages/pandas/core/arrays/timedeltas.py | 7938bc6f5e89ba669cf16231f0b2dfffd65e173038bb59e2a47314a1ce7e9723 | 1186 | 9 |     periods_per_second, ) from pandas._libs.tslibs.conversion import cast_from_unit_vectorized from pandas._libs.tslibs.fields import (     get_timedelta_days, |
| .venv/lib/python3.13/site-packages/pandas/core/arrays/datetimes.py | 37db8af22785bfcd0d4dca0dd41596872d76b2a061ef237b29bfa270e5ac7b59 | 2838 | 3 |         except NotImplementedError:             warnings.warn(                 "Non-vectorized DateOffset being applied to Series or DatetimeIndex.",                 PerformanceWarning,                |
| .venv/lib/python3.13/site-packages/pandas/core/arrays/string_.py | 39a6d7b3d4b10234b0859c347c25fbe41f62206944a0cd0f4d8f3ea67787a3e4 | 1132 | 2 |         return result      def memory_usage(self, deep: bool = False) -> int:         result = self._ndarray.nbytes         if deep: |
| .venv/lib/python3.13/site-packages/pandas/core/arrays/string_arrow.py | 478c222274e26d5555bcbeb083adec1e84269707a078de03ef9369757fa91844 | 496 | 2 |     _str_pad = ArrowStringArrayMixin._str_pad     _str_match = ArrowStringArrayMixin._str_match     _str_fullmatch = ArrowStringArrayMixin._str_fullmatch     _str_lower = ArrowStringArrayMixin._str_lo |
| .venv/lib/python3.13/site-packages/pandas/core/arrays/period.py | 5667c31dcece0b6d20cad709faa0d16a2a57ee42563742cfa16ea8c0cca4dc48 | 1332 | 1 |      # --------------------------------------------------------------------     # Vectorized analogues of Period properties      year = _field_accessor( |
| .venv/lib/python3.13/site-packages/pandas/core/arrays/datetimelike.py | 7d26e952a8819639ac9af95fe6246c084484b69ea07b48505682fa188bd838c1 | 2584 | 2 |             An ndarray with int64 dtype.         """         # do not cache or you'll create a memory leak         return self._ndarray.view("i8")  |
| .venv/lib/python3.13/site-packages/pandas/core/arrays/base.py | 58bca639f6f521f1afd0f358a07a022d04cd52b2c2f8267ef91103ee4bc34537 | 2610 | 3 |     def nbytes(self) -> int:         """         The number of bytes needed to store this object in memory.          Examples |
| .venv/lib/python3.13/site-packages/pandas/core/arrays/arrow/array.py | 410a2515fd6450889d5533e91f67628d7c17a6b374d912e1a408ef05a1246114 | 2947 | 1 |     def nbytes(self) -> int:         """         The number of bytes needed to store this object in memory.         """         return self._pa_array.nbytes |
| .venv/lib/python3.13/site-packages/pandas/core/arrays/sparse/array.py | b4803118a5f7c875ba6030732ef7e321b4170493fe310ba9f1ffd4e72ba799a8 | 1946 | 9 |     fill_value : scalar, optional         Elements in data that are ``fill_value`` are not stored in the         SparseArray. For memory savings, this should be the most common value         in `data` |
| .venv/lib/python3.13/site-packages/pandas/core/indexes/interval.py | 2121059f6a229de86cfd65dc54330c3f530e59e0ddd051de2643b12ccd3c1852 | 1138 | 5 |         return "interval"      # Cannot determine type of "memory_usage"     @Appender(Index.memory_usage.__doc__)  # type: ignore[has-type]     def memory_usage(self, deep: bool = False) -> int: |
| .venv/lib/python3.13/site-packages/pandas/core/indexes/range.py | aade484b66dab639ce1def7450ae63112ee9661825a695bffb5c2278b959cac0 | 1188 | 7 |     Immutable Index implementing a monotonic integer range.      RangeIndex is a memory-saving special case of an Index limited to representing     monotonic ranges with a 64-bit dtype. Using RangeInd |
| .venv/lib/python3.13/site-packages/pandas/core/indexes/multi.py | 7e9fc94809b1f33063554353fa53031b0124240406f1efb051fa3a85c727cbb7 | 4177 | 9 |         Names for each of the index levels. (name is accepted for compat).     copy : bool, default False         Copy the meta-data.     verify_integrity : bool, default True         Check that the l |
| .venv/lib/python3.13/site-packages/pandas/core/indexes/base.py | 769fa2b378b91907e5ea562ba3e70cdacb5cc973ef44cd1f907dd33db1e8832d | 7944 | 9 |         elif hasattr(data, "__array__"):             return cls(np.asarray(data), dtype=dtype, copy=copy, name=name)         elif not is_list_like(data) and not isinstance(data, memoryview):           |
| .venv/lib/python3.13/site-packages/pandas/io/orc.py | c73ddd93402f1c40bdd8b8829fb707fb1edf03a0d7650691f31036cd05158b67 | 229 | 1 |      if df.index.name is not None:         raise ValueError("orc does not serialize index meta-data on a default index")      if engine != "pyarrow": |
| .venv/lib/python3.13/site-packages/pandas/io/parquet.py | 0a8b452b2fcef1be82732821ec7df92b02218f1352587f7803918bd621c2fd63 | 679 | 1 |     Note that the `filters` argument is implemented by the `pyarrow` engine,     which can benefit from multithreading and also potentially be more     economical in terms of memory.      >>> sel = [( |
| .venv/lib/python3.13/site-packages/pandas/io/pytables.py | f398a090dc2ad36f5aef48e253ba1bbb70d80274cfe5556382858686d8c55412 | 5533 | 3 |     >>> store.close()      **Create or load HDF5 file in-memory**      When passing the `driver` option to the PyTables open_file method through |
| .venv/lib/python3.13/site-packages/pandas/io/xml.py | 64a1ec14008826194d26a53c9cd0691be3a31d9dae13fc3387de0e381ba3f222 | 1178 | 2 |         This method will read in local disk, decompressed XML files for elements         and underlying descendants using iterparse, a method to iterate through         an XML tree without holding ent |
| .venv/lib/python3.13/site-packages/pandas/io/common.py | 86c8c1a5973c8bd3bf68a3290a6b34b6e4368c0a9b915ccb5e750a234d5355c5 | 1268 | 17 |     encoding: str \| None = ...,     compression: CompressionOptions = ...,     memory_map: bool = ...,     is_text: Literal[False],     errors: str \| None = ..., |
| .venv/lib/python3.13/site-packages/pandas/io/pickle.py | b783ae946cbb0902fad0b5d30bc91e6de81633b41a24e9ae765ca70205b1a38c | 211 | 1 |         storage_options=storage_options,     ) as handles:         # letting pickle write directly to the buffer is more memory-efficient         pickle.dump(obj, handles.handle, protocol=protocol)  |
| .venv/lib/python3.13/site-packages/pandas/io/sql.py | ef3c5d40da1ac38011fe65a3991dfba423dcf51b34652c935e71e03295dbf20a | 2917 | 1 |      >>> from sqlite3 import connect     >>> conn = connect(':memory:')     >>> df = pd.DataFrame(data=[[0, '10/11/12'], [1, '12/11/10']],     ...                   columns=['int_column', 'date_column |
| .venv/lib/python3.13/site-packages/pandas/io/stata.py | dc99d24716ddfcdc44ea0ad600e6b53993bf6c6b6a1a08ca225b3ac19a549ff0 | 3769 | 9 |     def convert_year_month_safe(year, month) -> Series:         """         Convert year and month to datetimes, using pandas vectorized versions         when the date range falls within the range sup |
| .venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py | c8fe3104076b79a7299a629a9a1ef0e8ee024e5d0d439cf45154ae03b2d2b347 | 2384 | 37 |     example of a valid callable argument would be ``lambda x: x.upper() in     ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster     parsing time and lower memory usage. dtype : dty |
| .venv/lib/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py | c972be66b50ec59717759f6bb48360465ee5e36ead768721f06c99212fe708c2 | 411 | 8 |  class CParserWrapper(ParserBase):     low_memory: bool     _reader: parsers.TextReader  |
| .venv/lib/python3.13/site-packages/pandas/io/formats/style.py | 051bfa23da902d73943feaad06d020f66b3c999443ee477ad09db0ea4ef0569a | 4137 | 2 |         \color[HTML]{F1F1F1} 0.66 & {\cellcolor[HTML]{F1731D}} \color[HTML]{F1F1F1}         0.69 & {\cellcolor[HTML]{FCFFA4}} \color[HTML]{000000} 1.00 &         {\cellcolor[HTML]{FAC42A}} \color[HTML |
| .venv/lib/python3.13/site-packages/pandas/io/formats/_color_data.py | 7d9fd096ebcc15434a504e3e4f7db1ecf9f49ee9508319ac10c1c1f5445c04e6 | 158 | 4 |     "azure": "F0FFFF",     "beige": "F5F5DC",     "bisque": "FFE4C4",     "black": "000000",     "blanchedalmond": "FFEBCD", |
| .venv/lib/python3.13/site-packages/pandas/io/formats/info.py | 85e0a6e1f9503ef34c356eb379ccff5d4adf5793beff359da5a9bf764dd5d937 | 1102 | 89 |      2   float_col  5 non-null      float64     dtypes: float64(1), int64(1), object(1)     memory usage: 248.0+ bytes      Prints a summary of columns count and its dtypes but not per column |
| .venv/lib/python3.13/site-packages/pandas/io/json/_json.py | 9f2ce737cdb56a3a427defb3fa07845aa40335a5a71ec9e7ff7b5f0d3f350e3f | 1495 | 2 |         for more information on ``chunksize``.         This can only be passed if `lines=True`.         If this is None, the file will be read into memory all at once.     {decompression_options}  |
| .venv/lib/python3.13/site-packages/pandas/io/json/_normalize.py | adbcab10ac2ec68b6b0018afe8999bf4937a93aac25ddf7d38dac466fd886d72 | 545 | 1 |     if record_path is None:         if any([isinstance(x, dict) for x in y.values()] for y in data):             # naive normalization, this is idempotent for flat records             # and potentiall |
| .venv/lib/python3.13/site-packages/pandas/io/sas/sas7bdat.py | 90792e7e4047ee3aa3f5c3c00b1226267c9b603450e693a0b89d508d9e0a2790 | 763 | 4 |     get_subheader_index, ) from pandas._libs.tslibs.conversion import cast_from_unit_vectorized from pandas.errors import EmptyDataError  |
| .venv/lib/python3.13/site-packages/pandas/io/sas/sas_xport.py | fcdeec187c3867cd2ef9e982c52e25bfa505b3a374d5e2a3e426644f3abb5e23 | 509 | 1 | def _parse_float_vec(vec):     """     Parse a vector of float values representing IBM 8 byte floats into     native 8 byte floats.     """ |
| .venv/lib/python3.13/site-packages/pandas/io/clipboard/__init__.py | dda173768a9b69b13c5ccf8562375821cb53a6cfec4c024324cae111b0effd45 | 748 | 3 |                 if text:                     # http://msdn.com/ms649051                     # If the hMem parameter identifies a memory object,                     # the object must have been allocate |
| .venv/lib/python3.13/site-packages/pandas/tseries/holiday.py | 1bd910bda04ccdd354a02b38580a40731cd290ea33144c9f0d81458cbf199597 | 635 | 2 |         >>> NewYears  # doctest: +SKIP         Holiday: New Years Day (             month=1, day=1, observance=<function nearest_workday at 0x66545e9bc440>         )  |
| .venv/lib/python3.13/site-packages/pandas/tests/test_downstream.py | 53ec75fd1b015f4b121cd53f3377f219c33a9cb22ad01c092f5a72d9c53f33b6 | 371 | 6 | @pytest.fixture(     params=[         "memoryview",         "array",         pytest.param("dask", marks=td.skip_if_no("dask.array")), |
| .venv/lib/python3.13/site-packages/pandas/tests/series/test_ufunc.py | ba8d0524bb24d9616038831f28196cbb24842b3c24198b5c4cf0913e626ddaa6 | 464 | 1 |      msg = (         "Cannot apply ufunc <ufunc 'add3 (vectorized)'> "         "to mixed DataFrame and Series inputs."     ) |
| .venv/lib/python3.13/site-packages/pandas/tests/series/methods/test_searchsorted.py | da793e8573db1638197ca9b86cefd388a9b6c63778863d0bf618aa4789d9d92b | 78 | 1 |         tm.assert_numpy_array_equal(res, exp)      def test_searchsorted_numeric_dtypes_vector(self):         ser = Series([1, 2, 90, 1000, 3e9])         res = ser.searchsorted([91, 2e6]) |
| .venv/lib/python3.13/site-packages/pandas/tests/series/methods/test_infer_objects.py | c345320159386c7942057f0eb7c06257a6347e5c3eef45e210db21d23b20ca18 | 57 | 2 |          result = obj.infer_objects(copy=False)         assert tm.shares_memory(result, obj)          # case where we try to do inference but can't do better than object |
| .venv/lib/python3.13/site-packages/pandas/tests/series/methods/test_copy.py | 8a6d784ae638a577ea607bdde146a6412493897b0af0638fec66bee70f97445b | 92 | 4 |             # but parent will not be modified (CoW)             if deep is None or deep is False:                 assert np.may_share_memory(ser.values, ser2.values)             else:                  |
| .venv/lib/python3.13/site-packages/pandas/tests/series/methods/test_matmul.py | 7088f69c972d3273af10381379fa41de3ca9589ebe4476acaadc72c2bc57c348 | 83 | 2 |          # GH#21530         # vector (1D np.array) @ Series (__rmatmul__)         result = operator.matmul(a.values, a)         expected = np.dot(a.values, a.values) |
| .venv/lib/python3.13/site-packages/pandas/tests/series/methods/test_map.py | 4d07c263deda5f12cbaebc392288111e6b56146938bda7436be667a86baead9a | 605 | 2 | ):     # test that we are evaluating row-by-row first     # before vectorized evaluation     result = string_series.map(func)     expected = string_series.astype(str if not using_infer_string else "st |
| .venv/lib/python3.13/site-packages/pandas/tests/series/methods/test_info.py | cc71e5a901542629ef1090d5004958768e90e3d5c2e4c4138208aeb8b432ae4c | 193 | 24 |         f"""\         dtypes: int64(1)         memory usage: {ser.memory_usage()}.0{qualifier} bytes         """     ) |
| .venv/lib/python3.13/site-packages/pandas/tests/series/methods/test_reindex.py | dd08bf2e4e16c87a5660c9ce8c6a64cbb6c4cab7f2b6282d40a9bae2e674ec21 | 444 | 1 |     identity = string_series.reindex(string_series.index)      assert tm.shares_memory(string_series.index, identity.index)      assert identity.index.is_(string_series.index) |
| .venv/lib/python3.13/site-packages/pandas/tests/series/accessors/test_dt_accessor.py | 14e372d7b1e5ed95b1818481f9f4eb2fa6cb7d8dc5a779999b07b32ee25df3dc | 844 | 1 |         tm.assert_series_equal(result, expected)          assert not np.shares_memory(ser.array._ndarray, result.array._ndarray)      def test_dt_namespace_accessor_categorical(self): |
| .venv/lib/python3.13/site-packages/pandas/tests/series/indexing/test_setitem.py | 30c13e462ae4c1c8f11dafa99c95d298487aab93c23766a0a9011c1e0482cac3 | 1848 | 2 |         tm.assert_series_equal(ser, exp)          # vector         vals = Series(             [Timestamp("2011-01-01", tz=tz), Timestamp("2012-01-01", tz=tz)], |
| .venv/lib/python3.13/site-packages/pandas/tests/reshape/test_pivot.py | dc192b44b546a620545ef6c1456c44a58096580bd1727e7816def444058a7113 | 2727 | 2 |             {                 "a": ["R1", "R2", nan, "R4"],                 "b": ["C1", "C2", "C3", "C4"],                 "c": [10, 15, 17, 20],             } |
| .venv/lib/python3.13/site-packages/pandas/tests/reshape/test_from_dummies.py | 143c6b87ba6526a0f85d03b4faa5f963d2bfdf9f4b77b122c232d362b39ae65a | 450 | 1 | def test_error_contains_non_dummies():     dummies = DataFrame(         {"a": [1, 6, 3, 1], "b": [0, 1, 0, 2], "c": ["c1", "c2", "c3", "c4"]}     )     with pytest.raises( |
| .venv/lib/python3.13/site-packages/pandas/tests/reshape/concat/test_concat.py | c11bd302a50c7f3bf87cb6ad103364ed6f28aafc6de4c9c3a706e2a60e471cce | 918 | 3 |             for arr in result._mgr.arrays:                 assert not any(                     np.shares_memory(arr, y)                     for x in [df, df2, df3]                     for y in x._mgr. |
| .venv/lib/python3.13/site-packages/pandas/tests/reshape/concat/test_dataframe.py | faf39b043b6427b37f79e205823a4e555acc25ffdb07d28a9271d98350db1bb9 | 231 | 1 |             for arr in res._iter_column_arrays():                 for arr2 in df._iter_column_arrays():                     assert not np.shares_memory(arr, arr2)      def test_outer_sort_columns(self |
| .venv/lib/python3.13/site-packages/pandas/tests/reshape/merge/test_join.py | 166fc0520d02ed13dd75e8f0f99a4ea4a1c4de082eb725ef260f8275b8e6717b | 1108 | 1 |             merge(df, wrong_type, left_on="a", right_on="a")      def test_join_on_pass_vector(self, target_source):         target, source = target_source         expected = target.join(source, on="C |
| .venv/lib/python3.13/site-packages/pandas/tests/reshape/merge/test_merge.py | 352184b7be4d9b272422707459e4f218578c35db1f30872da2c6aab8f189b583 | 3021 | 2 |         merged = merge(left, right, left_index=True, right_index=True, copy=False)          assert np.shares_memory(merged["a"]._values, left["a"]._values)         if not using_infer_string:           |
| .venv/lib/python3.13/site-packages/pandas/tests/reshape/merge/test_multi.py | 915e6d50234096327bf083cdae169e0d7f40c8ab4dd8a745f19a4d313783cb36 | 935 | 8 |         )         df.index = pd.to_datetime(df.index)         on_vector = df.index.year          if klass is not None: |
| .venv/lib/python3.13/site-packages/pandas/tests/apply/test_series_apply.py | 2650e4b5ddeba9fcdb1e5e584c48103b1eedf29b4328f41dc375d2277f93a1a3 | 702 | 2 |     tm.assert_series_equal(result, exp)      # not vectorized     def f(x):         return str(x.tz) if by_row else str(x.dt.tz) |
| .venv/lib/python3.13/site-packages/pandas/tests/apply/test_frame_apply.py | 7897353636d44e061b8553be0af75f61544a0fb8e1786c0f40aba2826fdb15f3 | 1740 | 1 |         return x + b + c      # single func already takes the vectorized path     result = df.agg(foo1, 0, 3, c=4)     expected = df + 7 |
| .venv/lib/python3.13/site-packages/pandas/tests/strings/test_cat.py | cc2241051b6668ec4c1b05de4b87af7c3b4055c70edc49a5a04527f9d322d21a | 428 | 1 | def test_cat_on_series_dot_str():     # GH 28277     ps = Series(["AbC", "de", "FGHI", "j", "kLLLm"])      message = re.escape( |
| .venv/lib/python3.13/site-packages/pandas/tests/strings/conftest.py | 33ef6721d000ca7309ec5bc51531d7244519153f2e3936e2cdfe593a7389f939 | 133 | 1 |     ("ljust", (10,), {}),     ("match", ("a",), {}),     ("fullmatch", ("a",), {}),     ("normalize", ("NFC",), {}),     ("pad", (10,), {}), |
| .venv/lib/python3.13/site-packages/pandas/tests/strings/test_find_replace.py | 4802d712ac16fae76cb18b401baa12b8d7ad956d690756cd60c856cafe0045ab | 1129 | 14 |  # -------------------------------------------------------------------------------------- # str.fullmatch # --------------------------------------------------------------------------------------  |
| .venv/lib/python3.13/site-packages/pandas/tests/extension/test_categorical.py | 7c8f48993e1bcb05b9a03e958bd64bbabb90441df9b3ebbf79840dc5a56da4c5 | 201 | 3 |  class TestCategorical(base.ExtensionTests):     @pytest.mark.xfail(reason="Memory usage doesn't match")     def test_memory_usage(self, data):         # TODO: Is this deliberate? |
| .venv/lib/python3.13/site-packages/pandas/tests/extension/test_arrow.py | 8d21e12e8535a1879cbb3f6f0b5a85498592bf92bf194387216a690c789ebe97 | 3421 | 1 |     ], ) def test_str_fullmatch(pat, case, na, exp):     ser = pd.Series(["abc", "abc$", "$abc", None], dtype=ArrowDtype(pa.string()))     result = ser.str.match(pat, case=case, na=na) |
| .venv/lib/python3.13/site-packages/pandas/tests/extension/decimal/test_decimal.py | 95469d17a1b7856db7c3dc13090457f5d3a62276fd571b2622a425a5b325e92b | 588 | 2 |         result_copy1 = np.array(data, copy=True)         result_copy2 = np.array(data, copy=True)         assert not np.may_share_memory(result_copy1, result_copy2)         if not np_version_gt2:      |
| .venv/lib/python3.13/site-packages/pandas/tests/extension/base/interface.py | 9ce73744038fb2602d0c25770bfb4f26f5e8da93cf94472646eb8f816e26419b | 173 | 4 |             assert na_value_obj not in data_missing      def test_memory_usage(self, data):         s = pd.Series(data)         result = s.memory_usage(index=False) |
| .venv/lib/python3.13/site-packages/pandas/tests/extension/base/ops.py | a846d49c490b697c4013a7684ea36131d1509b6a4fcb2b3cc5e7ecde00efebf7 | 290 | 2 |     def _cast_pointwise_result(self, op_name: str, obj, other, pointwise_result):         # In _check_op we check that the result of a pointwise operation         #  (found via _combine) matches the r |
| .venv/lib/python3.13/site-packages/pandas/tests/extension/base/groupby.py | 473caa744a0eb19cd295ffee7237cc9dc712ab99c62e26244200059421dd88e9 | 175 | 2 |         gr2 = df.groupby("B")._grouper.groupings[0]          tm.assert_numpy_array_equal(gr1.grouping_vector, df.A.values)         tm.assert_extension_array_equal(gr2.grouping_vector, data_for_groupin |
| .venv/lib/python3.13/site-packages/pandas/tests/extension/base/constructors.py | 6363e7cb64ab123ee3b0211437a2912a2ffd1b61c0ed121f56ce4655ff4dcf9c | 143 | 2 |      def test_pandas_array(self, data):         # pd.array(extension_array) should be idempotent...         result = pd.array(data)         tm.assert_extension_array_equal(result, data) |
| .venv/lib/python3.13/site-packages/pandas/tests/resample/test_timedelta.py | 1ff66310985737a7e159ba70130b8fb311435907ab983c14bec33ba1a136a46d | 221 | 1 |   def test_resample_timedelta_idempotency():     # GH 12072     index = timedelta_range("0", periods=9, freq="10ms") |
| .venv/lib/python3.13/site-packages/pandas/tests/util/test_shares_memory.py | 28de57f32bb0e8cf291e02f4112e98787ebfb190d4131ff01226fa0791af91ec | 33 | 10 |   def test_shares_memory_interval():     obj = pd.interval_range(1, 5)  |
| .venv/lib/python3.13/site-packages/pandas/tests/config/test_config.py | 4f73ca57f9564e9ff8654e7ae9fa56b7f37dfedaf705fb311e527fbea9d08a24 | 438 | 2 |          cf.register_option("c.d.e1", 1, "doc3")         cf.register_option("c.d.e2", 1, "doc4")         cf.register_option("f", 1)         cf.register_option("g.h", 1) |
| .venv/lib/python3.13/site-packages/pandas/tests/io/test_parquet.py | 582aa49901e9aeef22cfdffa489e16830de732bc5d09ea9bed56f3b52f428fef | 1503 | 2 |             check_round_trip(df, engine, check_names=check_names)          # index with meta-data         df.index = [0, 1, 2]         df.index.name = "foo" |
| .venv/lib/python3.13/site-packages/pandas/tests/io/test_fsspec.py | e965b4b0ef5f9434129d2022a90c806fe3e0c9c712da5d5e99a70bf509f21a5f | 349 | 16 |     pytest.importorskip("fsspec")     from fsspec import register_implementation     from fsspec.implementations.memory import MemoryFileSystem     from fsspec.registry import _registry as registry  |
| .venv/lib/python3.13/site-packages/pandas/tests/io/test_common.py | f5d39c09860a71aff39d32f1a7fb347cc6302436af29d6d1303dbee99bdacb7f | 659 | 4 |          with pytest.raises(err, match=msg):             icom._maybe_memory_map(non_file, True)          with open(mmap_file, encoding="utf-8") as target: |
| .venv/lib/python3.13/site-packages/pandas/tests/io/test_pickle.py | d88e7a2a3b63ba318e037c3bc283c334d7130dcec7b9066bd133010290db8fa4 | 659 | 6 |         b"123456",         bytearray(b"123"),         memoryview(b"123"),         pickle.PickleBuffer(b"123"),         array("I", [1, 2, 3]), |
| .venv/lib/python3.13/site-packages/pandas/tests/io/test_orc.py | 7417a21d084ca840e985bb71103565ad6dbe08d262461f81a64d8a664e3eb744 | 445 | 1 |     msg = (         "orc does not support serializing a non-default index\|"         "orc does not serialize index meta-data"     )     with pytest.raises(ValueError, match=msg): |
| .venv/lib/python3.13/site-packages/pandas/tests/io/test_stata.py | fbfaef955a29195a2801cb7266ea10ce5f5ca95424a3f5d5a03f764c6617df39 | 2399 | 2 |         # Gzipped since contains 32,999 variables and uncompressed is 20MiB         # Just validate that the reader reports correct number of variables         # to avoid high peak memory         with |
| .venv/lib/python3.13/site-packages/pandas/tests/io/test_html.py | da57564c35903b5c3e4287e2b5753c3c33638218829fd712252483b8310cf565 | 1649 | 2 |      @pytest.mark.slow     def test_regex_idempotency(self, banklist_data, flavor_read_html):         url = banklist_data         dfs = flavor_read_html( |
| .venv/lib/python3.13/site-packages/pandas/tests/io/test_sql.py | e712e9df2efd407b86d9ddf7f5701dd2a66fcfa7ddd2ba61d82eb20618290f66 | 4388 | 5 | @pytest.fixture def sqlite_buildin():     with contextlib.closing(sqlite3.connect(":memory:")) as closing_conn:         with closing_conn as conn:             yield conn |
| .venv/lib/python3.13/site-packages/pandas/tests/io/test_http_headers.py | 3ef343ba4437ec96d98fc8ca8aca737e625191f9c6745c73a6b8f4724b9a4fea | 176 | 8 |      df.to_parquet(         "memory://fastparquet_user_agent.parquet",         index=False,         engine="fastparquet", |
| .venv/lib/python3.13/site-packages/pandas/tests/io/formats/test_format.py | 967f90e11ae217d9c087ac5ef28c893145f1152d190518c8b72ba4979bdb18bb | 2290 | 1 |     # 3. Columns     # 4. dtype     # 5. memory usage     # 6. trailing newline     nv = len(r.split("\n")) == 6 |
| .venv/lib/python3.13/site-packages/pandas/tests/io/formats/style/test_style.py | c7bafcfa786761d89fc3f3e3a294f46b8b7df4c4c6ce5381bfe837f07387c629 | 1589 | 2 |         "template_html_table",     ]     if not deepcopy:  # check memory locations are equal for all included attributes         for attr in [a for a in styler.__dict__ if (not callable(a) and a not  |
| .venv/lib/python3.13/site-packages/pandas/tests/io/excel/test_readers.py | 5045acb37f115bb75102402a0221cd750310097af95d83a2479a76a46f1f79e8 | 1736 | 10 |             [                 [np.nan, np.nan, np.nan, np.nan, np.nan],                 ["R0C0", "R0C1", "R0C2", "R0C3", "R0C4"],                 ["R1C0", "R1C1", "R1C2", "R1C3", "R1C4"],              |
| .venv/lib/python3.13/site-packages/pandas/tests/io/excel/test_writers.py | 15315107df9f57a9bd20daa2cac56466d5131efc698432786efc64e2b905670d | 1515 | 1 |         breaking_row_count = 2**20 + 1         breaking_col_count = 2**14 + 1         # purposely using two arrays to prevent memory issues while testing         row_arr = np.zeros(shape=(breaking_row |
| .venv/lib/python3.13/site-packages/pandas/tests/io/parser/conftest.py | 255469684d015f2ed264837701fd31eefbe8aac661011f9a551539402d2d021a | 338 | 13 | class BaseParser:     engine: str \| None = None     low_memory = True     float_precision_choices: list[str \| None] = []  |
| .venv/lib/python3.13/site-packages/pandas/tests/io/parser/test_c_parser_only.py | 0a6cb31c490071ca0722f775ad286a6706b1a9c504f9c0b97aaea79b41b23e56 | 648 | 4 | def test_parse_trim_buffers(c_parser_only, encoding):     # This test is part of a bugfix for gh-13703. It attempts to     # to stress the system memory allocator, to cause it to move the     # stream |
| .venv/lib/python3.13/site-packages/pandas/tests/io/parser/test_encoding.py | 3a0faaeb457e9ddfbcc65e550560cfb58ab119e7a6aecf2b602a0209629d8e67 | 338 | 13 |  @pytest.mark.parametrize("encoding", ["utf-8", None, "utf-16", "cp1255", "latin-1"]) def test_encoding_memory_map(all_parsers, encoding):     # GH40986     parser = all_parsers |
| .venv/lib/python3.13/site-packages/pandas/tests/io/parser/test_read_fwf.py | b985eb3f59690104becbb6ae4438046311174d493799451f24f71c99d2f864f8 | 1035 | 5 |   @pytest.mark.parametrize("memory_map", [True, False]) def test_encoding_mmap(memory_map):     """ |
| .venv/lib/python3.13/site-packages/pandas/tests/io/parser/test_textreader.py | 47fc9e07e93a838e62e994d0f8f745f0320961da1d847d39f4e1ab45d33c20e3 | 343 | 1 |      def test_file_handle_mmap(self, csv_path):         # this was never using memory_map=True         with open(csv_path, "rb") as f:             reader = TextReader(f, header=None) |
| .venv/lib/python3.13/site-packages/pandas/tests/io/parser/common/test_common_basic.py | 120c868dc68b10f7e52a10b9e0d1b0641f3d6e945a3b0a9df5ab2b79ea2301d9 | 984 | 5 |   def test_read_csv_low_memory_no_rows_with_index(all_parsers):     # see gh-21141     parser = all_parsers |
| .venv/lib/python3.13/site-packages/pandas/tests/io/parser/common/test_verbose.py | 922979379d648614227d5f5acfec768a332bdf01ad75d2ab539a006ebd1bd61b | 82 | 2 |     if parser.engine == "c":         assert "Tokenization took:" in captured.out         assert "Parser memory cleanup took:" in captured.out     else:  # Python engine         assert captured.out ==  |
| .venv/lib/python3.13/site-packages/pandas/tests/io/parser/common/test_chunksize.py | 5f6cab0b949375d4e0f084cd61d8c56f666f19936c436906690bc5cac9ab9b3d | 383 | 4 |     # see gh-3866: if chunks are different types and can't     # be coerced using numerical types, then issue warning.     if parser.engine == "c" and parser.low_memory:         warning_type = DtypeWa |
| .venv/lib/python3.13/site-packages/pandas/tests/io/parser/common/test_file_buffer_url.py | e0f6d5106c0e609879cfb86dea4827dad747bf417d7921234fc5a2e9d31ea1a4 | 479 | 9 |   def test_memory_map_compression(all_parsers, compression):     """     Support memory map for compressed files. |
| .venv/lib/python3.13/site-packages/pandas/tests/io/json/test_readlines.py | 35a21e081f70ee233f3ed6a6c782282cc470206f5e510c6c4c9a54d9c041e72d | 544 | 1 |     # Basic test that read_json(chunks=True) gives the same result as     # read_json(chunks=False)     # GH17048: memory usage when lines=True      if engine == "pyarrow": |
| .venv/lib/python3.13/site-packages/pandas/tests/io/json/test_pandas.py | 3e3eec15301b451c1a9acf152d111453bfd48b71928337ba848f8ae766046d4f | 2189 | 4 |                     "81504caf",                     "2ffef4a9",                     "08e2f5c4",                     "07e1af03",                     "addbd4a7", |
| .venv/lib/python3.13/site-packages/pandas/tests/io/pytables/test_file_handling.py | 3ca9099300d8d452ae99bce22f1c4d37f4deaa395d407c62739e1dd7f87e5799 | 518 | 1 |         )          # create an in memory store         store = HDFStore(             path, mode="a", driver="H5FD_CORE", driver_core_backing_store=0 |
| .venv/lib/python3.13/site-packages/pandas/tests/tseries/offsets/test_dst.py | d2ce9ba731059157d428dea50247854e2cb3330611430ad9b38f5602ef8b2b8a | 261 | 2 |                 tstart + offset             # While we're here, let's check that we get the same behavior in a             #  vectorized path             dti = DatetimeIndex([tstart])             warn |
| .venv/lib/python3.13/site-packages/pandas/tests/tseries/offsets/test_month.py | 107b264691211bf08b48d1143ad038f1aba2271167afcb0fb07413c997aebb68 | 667 | 2 |      @pytest.mark.parametrize("klass", [Series, DatetimeIndex])     def test_vectorized_offset_addition(self, klass):         shift = klass(             [ |
| .venv/lib/python3.13/site-packages/pandas/tests/tseries/offsets/test_offsets.py | d321053b6ee487dbaf76ee3e3185bd6e9e4e5fd59bde520a7620b825c9dafb6a | 1186 | 1 |     # TODO: belongs in arithmetic tests?     @pytest.mark.filterwarnings(         "ignore:Non-vectorized DateOffset being applied to Series or DatetimeIndex"     )     @pytest.mark.parametrize("unit", |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/test_methods.py | 3b7a241267557b135d809e425aac8bbc2a657b3a22c3fc72ee095f5ffcb14e52 | 2069 | 265 |     assert df_copy.columns.is_(df.columns)      # the deep copy doesn't share memory     assert not np.shares_memory(get_array(df_copy, "a"), get_array(df, "a"))     if using_copy_on_write: |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/test_interp_fillna.py | ea72dfc0b52083b6001b6223a1bb0f656d4ba00b5fffc9e3caaa5e880c4904ea | 434 | 45 |      if using_copy_on_write:         assert np.shares_memory(get_array(result, "a"), get_array(df, "a"))     else:         assert not np.shares_memory(get_array(result, "a"), get_array(df, "a")) |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/test_constructors.py | 33f541d42514a67b8cda24709d798b2756eaf1efe884b11edac1d9d5f0dcdcec | 383 | 36 |     result = Series(ser, dtype=dtype)      # the shallow copy still shares memory     assert np.shares_memory(get_array(ser), get_array(result))  |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/test_array.py | 863da76cc3811c2b13b3040feac3348e329ac1c0b47ae5bdf51ad28b4dd8733f | 219 | 13 |     if using_copy_on_write:         # .values still gives a view but is read-only         assert np.shares_memory(arr, get_array(ser, "name"))         assert arr.flags.writeable is False  |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/test_setitem.py | 7b0b89898b83f55236c2e1598838c66153fb82794fe07f6e5459e38de956e795 | 157 | 11 |      # the array data is copied     assert not np.shares_memory(get_array(df, "c"), arr)     # and thus modifying the array does not modify the DataFrame     arr[0] = 0 |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/test_util.py | 0a558ba6b30985fea891436ef405fa02bf485d980a918d2736e0f31d13bbd079 | 15 | 2 | def test_get_array_numpy():     df = DataFrame({"a": [1, 2, 3]})     assert np.shares_memory(get_array(df, "a"), get_array(df, "a"))   |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/test_indexing.py | e0e506adc80c1e56a2de9eed42dd2c5e8a4d613ac674415251a55fe92ed9cf22 | 1267 | 39 |      if using_copy_on_write:         # the subset shares memory ...         assert np.shares_memory(get_array(subset, "a"), get_array(df, "a"))         # ... but uses CoW when being modified |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/test_astype.py | ee154fcdcab8786601c0e062054853bc655036dee5bacf9bbb5c299eb769d2fb | 288 | 38 |      if using_copy_on_write:         assert np.shares_memory(get_array(df2, "c"), get_array(df, "c"))         assert not np.shares_memory(get_array(df2, "a"), get_array(df, "a"))     else: |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/test_internals.py | dcd6d676342fe826a56acc853f036a2995c99640930a8a7df13f43798560e629 | 155 | 4 |     # the float64 block still references the parent one because it still a view     assert subset._mgr.blocks[0].refs.has_reference()     # equivalent of assert np.shares_memory(df["b"].values, subset |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/test_functions.py | d0a570d412b2acfe040233ede31dbbd106109fde6fad502d91ad6f2eaa871d6b | 398 | 105 |      if using_copy_on_write:         assert np.shares_memory(get_array(result, "b"), get_array(df, "b"))         assert np.shares_memory(get_array(result, "a"), get_array(df2, "a"))     else: |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/test_replace.py | 41bc2067b2413e578f6f8a2797f28dbf4da0b41fa487840382887ed4388abb4a | 491 | 62 |     if using_copy_on_write:         if (df_replaced["b"] == df["b"]).all():             assert np.shares_memory(get_array(df_replaced, "b"), get_array(df, "b"))         assert tm.shares_memory(get_arr |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/test_clip.py | 6a129fec453025e61a84b9cf56152e35a9c6e156b9dc4cf99142f309dcde5fad | 102 | 7 |      if using_copy_on_write:         assert not np.shares_memory(get_array(df, "a"), arr_a)         assert df._mgr._has_no_reference(0)         assert view._mgr._has_no_reference(0) |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/test_core_functionalities.py | 33e131a273dcc7a5bef33fd32d368fd7a0c9b5e95255e40764a3b569639b4ae0 | 107 | 4 |     df.iloc[0, 1] = 100  # Write into a      assert np.shares_memory(arr, get_array(df, "a"))   |
| .venv/lib/python3.13/site-packages/pandas/tests/copy_view/index/test_index.py | 07ce3d138bdfef6b6c5afd7535f8b1254eaf8d7d20a4c972bc744a4819345754 | 185 | 3 |     arr = get_array(ser)     ser.iloc[0] = 100     assert np.shares_memory(get_array(ser), arr)   |
| .venv/lib/python3.13/site-packages/pandas/tests/interchange/test_spec_conformance.py | 26713691038baf81235021fa3737357c211785b679d96cca6e2a16e9fe84571a | 176 | 1 |     assert dataDtype[0] == 0  # INT      if device == 1:  # CPU-only as we're going to directly read memory here         bitwidth = dataDtype[1]         ctype = { |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/test_constructors.py | 9ba3dbd2b159c35b0bad95c6b8c54bf2ba8da83afa007f930f298988ea22d915 | 3388 | 10 |         if using_infer_string:             if df[0].dtype.storage == "pyarrow":                 # object dtype strings are converted to arrow memory,                 # no numpy arrays to compare       |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/test_subclass.py | 5ea34ac012be663d3a4b8013606779f6728fcebceef239a4fd56e94adbc1eedb | 826 | 3 |         assert isinstance(result, tm.SubclassedDataFrame)      def test_memory_usage(self):         df = tm.SubclassedDataFrame({"A": [1, 2, 3], "B": [4, 5, 6], "C": [7, 8, 9]})         result = df.me |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/test_repr.py | 4d9811df3a5402e9824e5b6dfa96c8d476b665d6a8c77f1ae20dd3f72b8c7f00 | 519 | 1 |          data = [8, 5, 3, 5]         index1 = ["\u03c3", "\u03c4", "\u03c5", "\u03c6"]         cols = ["\u03c8"]         df = DataFrame(data, columns=cols, index=index1) |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/test_ufunc.py | 61c5179c51369fb94ee5737d694bce25f789c86a880ee8b45611fe1f58147f52 | 312 | 2 |     numba = pytest.importorskip("numba")      @numba.vectorize([numba.float64(numba.float64, numba.float64, numba.float64)])     def my_ufunc(x, y, z):         return x + y + z |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/test_stack_unstack.py | 3209ff37311d53ba8ccea59c7e6c7fe0579a3eb10c185ff6b115b15e859aa149 | 2685 | 5 |         df = DataFrame(             vals,             columns=["agent", "change", "dosage", "s_id"],             index=[17263, 17264, 17265, 17266, 17267, 17268],         ) |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/test_api.py | 7ba0012e380ff1ffb55d56650d50e7ddc0d4d6739e94e4c8c787d2b9b948e9a7 | 396 | 2 |         # But we didn't copy data         if frame_or_series is Series:             assert np.may_share_memory(obj.values, result.values)         else:             assert np.may_share_memory(obj["A"]. |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/methods/test_transpose.py | 24d870bdc8b7ec39433181c1689cf82a6f7df2fc3c3467e5edfe14630c27b263 | 210 | 2 |         rtrip = result._mgr.blocks[0].values         if using_copy_on_write:             assert np.shares_memory(df._mgr.blocks[0].values._ndarray, rtrip._ndarray)         else:             assert np. |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/methods/test_sample.py | bcf0d2514ea8043e57d82e6b2948481e4ea8db17ed9b4cf3313c2fba2a5e9513 | 373 | 2 |         # Check won't accept negative weights         bad_weights = [-0.1] * 10         msg = "weight vector many not include negative values"         with pytest.raises(ValueError, match=msg):        |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/methods/test_astype.py | 183e38d0294808cb7aaee939bb94d9a645dada0d3ed029bf4296870ed52f9f24 | 925 | 1 |      assert result.a.dtype == pd.Int16Dtype()     assert np.shares_memory(df.b.values, result.b.values)   |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/methods/test_set_axis.py | c62c99ca380320ed01e475862de57f7d50f25e3dd830305f2f2103879ad0bdcc | 144 | 10 |         if not using_copy_on_write:             if obj.ndim == 1:                 assert not tm.shares_memory(result, obj)             else:                 assert not any( |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/methods/test_values.py | 01296303033d08404c5fa6c0dc5a96a12bf8b0e7118eecfc6537cb4a3a3f17a6 | 281 | 4 |          if using_copy_on_write:             assert not np.shares_memory(df._values._ndarray, dta._ndarray)         else:             # we have a view |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/methods/test_rename.py | 3fe488c1b87e9fa41d3ea167b3879b3ed185c1d5ddeef99e5ade7f770a342aae | 416 | 1 |         renamed = float_frame.rename(columns={"C": "foo"}, copy=False)          assert np.shares_memory(renamed["foo"]._values, float_frame["C"]._values)          with tm.assert_cow_warning(warn_copy_ |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/methods/test_fillna.py | 7b42b269fe14c3c8bd6cf65f8add376abdf59a1dd6c915ec6cc238728167f8fd | 913 | 4 |         # TODO: what's the expected/desired behavior with CoW?         if not using_copy_on_write:             assert tm.shares_memory(df.iloc[:, 0], orig.iloc[:, 0])         assert not tm.shares_memo |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/methods/test_info.py | 5c0e160c8b635673a39c67d0b079682b9603686ca08b8e5fce192030bb051590 | 590 | 53 |         all_lines = buf.getvalue().splitlines()     # Here table would contain only header, separator and table lines     # dframe repr, index summary, memory usage and dtypes are excluded     table = |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/methods/test_interpolate.py | 714be39fc954279a62aec4a4caf38a7af8c0622d48e99d2e0e0c515e04e6d333 | 553 | 7 |          # check we operated *actually* inplace         assert np.shares_memory(orig, obj.values)         assert orig.squeeze()[1] == 1.5  |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/methods/test_reindex.py | b6636f1e4e1d7069eb67cd44039506b4faba2dd49ad18eb8c90e4ccc866828ff | 1328 | 6 |          result = df.reindex(columns=cols, copy=True)         assert not np.shares_memory(result[0]._values, df[0]._values)          # pass both columns and index |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/indexing/test_xs.py | 246b1b277cc14186ae6720e94827eb5e64543b8a671fe0487f03835f7a804e83 | 445 | 1 |         result = df.xs("a", axis=1, drop_level=False)         # check that result still views the same data as df         assert np.shares_memory(result.iloc[:, 0]._values, df.iloc[:, 0]._values)      |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/indexing/test_setitem.py | b9fa8b3aa13ad004a77edca408d1760cc6baa7ca5089d2abd7d94da6119c7759 | 1438 | 1 |         if not using_copy_on_write:             tm.assert_numpy_array_equal(zvals, expected.values)             assert np.shares_memory(zvals, df["z"]._values)      def test_setitem_duplicate_columns_ |
| .venv/lib/python3.13/site-packages/pandas/tests/frame/indexing/test_indexing.py | 2f06bea1017154fcebf2c5e3f1091c51c82f6d939f70a04b1441ad8f3ee6fd09 | 2029 | 7 |         sliced = float_frame.iloc[:, -3:]          assert np.shares_memory(sliced["C"]._values, float_frame["C"]._values)          with tm.assert_cow_warning(warn_copy_on_write): |
| .venv/lib/python3.13/site-packages/pandas/tests/libs/test_hashtable.py | e2b5c5a6177a0bd6dfe40548a8ea214f0b09ee6035e12666ab785c5ad0bb9bec | 749 | 23 |   def get_allocated_khash_memory():     snapshot = tracemalloc.take_snapshot()     snapshot = snapshot.filter_traces( |
| .venv/lib/python3.13/site-packages/pandas/tests/libs/test_lib.py | 4e869b0b78770c9199d71a138f01f2f4fef9da7add4a8bf1949b0633212a8d58 | 300 | 1 |     arr = pickle.loads(pickle.dumps(arr))     result = lib.ensure_string_array(arr, copy=False)     assert not np.shares_memory(arr, result)     assert arr[1] is None     assert result[1] is np.nan |
| .venv/lib/python3.13/site-packages/pandas/tests/groupby/test_grouping.py | 3566242fb8c8c1588d318c24ea3c759c3ebf71296ac0f78ad4376510b62f217f | 1239 | 1 |         # we need to use a dictionary comprehension here         # pylint: disable-next=unnecessary-comprehension         groups = {key: gp for key, gp in grouped}  # noqa: C416         assert len(gro |
| .venv/lib/python3.13/site-packages/pandas/tests/groupby/test_apply.py | 05da41dd59601003ebeeb8bf905b197d2699199206b974d18ec4798ece2e35ad | 1606 | 1 |                 4: pd.Timestamp("2015-02-24 00:00:00"),             },             "userAgent": {                 0: "some UA string",                 1: "some UA string", |
| .venv/lib/python3.13/site-packages/pandas/tests/groupby/test_groupby_dropna.py | 4946fb592780bceae99b72f1f9471faac1df8dabd5a9bfdf2be7c1a0e5d849ad | 697 | 1 |         ((values == 1) & ((values == 1).cumsum() <= 5))         \| ((values == 2) & ((values == 2).cumsum() <= 5))         # flake8 doesn't like the vectorized check for None, thinks we should use `is` |
| .venv/lib/python3.13/site-packages/pandas/tests/groupby/aggregate/test_aggregate.py | 71124b39f6be2cf232837dddd7d99f177a3d375b243329bd4ede936506a7b6d3 | 1673 | 1 |      grouped = df.groupby(lambda x: x.year)     grouper = grouped._grouper.groupings[0].grouping_vector     grouped._grouper.groupings[0] = Grouping(ts.index, list(grouper))  |
| .venv/lib/python3.13/site-packages/pandas/tests/groupby/transform/test_transform.py | cc63d0e5bdd95f15b595a13596f791caf835f44ee727b58aedd46f88213eca99 | 1711 | 1 |             "D",             marks=pytest.mark.xfail(                 reason="GH#23918 before method uses freq in vectorized approach"             ),         ), |
| .venv/lib/python3.13/site-packages/pandas/tests/plotting/test_misc.py | fc8a0744d4ff392193c857c8bb9822bf906769415610d407dfa54a37cab7dad2 | 721 | 3 |         "linecolors",         [             ("#556270", "#4ECDC4", "#C7F464"),             ["dodgerblue", "aquamarine", "seagreen"],         ], |
| .venv/lib/python3.13/site-packages/pandas/tests/plotting/test_style.py | dd831cab8e488262289ae8a1068c014fe97225fa4947f43c7db30e1105d491aa | 158 | 1 |                     "C2",                     "C3",                     "C4",                     "C5",                     "C6", |
| .venv/lib/python3.13/site-packages/pandas/tests/plotting/test_series.py | ef75680692cc2e3287c0869928ce74ac6a4e4b1d6406c0b1971c4d4ac3f087c9 | 986 | 1 |         reason="GH#24426, see also "         "github.com/pandas-dev/pandas/commit/"         "ef1bd69fa42bbed5d09dd17f08c44fc8bfc2b685#r61470674"     )     def test_plot_accessor_updates_on_inplace(sel |
| .venv/lib/python3.13/site-packages/pandas/tests/plotting/frame/test_frame_color.py | 801917ffa0cc1fe8e813ee068f06692188161c992b58f3c327c47d80ab87a87f | 671 | 1 | class TestDataFrameColor:     @pytest.mark.parametrize(         "color", ["C0", "C1", "C2", "C3", "C4", "C5", "C6", "C7", "C8", "C9"]     )     def test_mpl2_color_cycle_str(self, color): |
| .venv/lib/python3.13/site-packages/pandas/tests/plotting/frame/test_frame.py | 05c1b34a2ea9d514858497ae77215a9d87ca623befb92ede292a2544edda7c28 | 2625 | 1 |      @pytest.mark.parametrize("kind", plotting.PlotAccessor._all_kinds)     def test_memory_leak(self, kind):         """Check that every plot type gets properly collected."""         pytest.importors |
| .venv/lib/python3.13/site-packages/pandas/tests/window/test_pairwise.py | 05724bc516e8945b34d05c53329dee2050cda5991c8aff151b201714cc37cc72 | 446 | 1 |         tm.assert_numpy_array_equal(result, expected, check_dtype=False)      def test_corr_freq_memory_error(self):         # GH 31789         s = Series(range(5), index=date_range("2020", periods=5) |
| .venv/lib/python3.13/site-packages/pandas/tests/window/test_rolling_functions.py | c6669a5c568cab6da8d6cd016b836278891366d2968bd58e61a7bacfc8bfac1a | 533 | 1 |   def test_rolling_median_memory_error():     # GH11722     n = 20000 |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/test_array.py | c2aeb25f9864f02d2576a20cc8395749ab5472bb1e16a4d357ea0f85fabcfc5c | 520 | 4 |             NumpyExtensionArray(np.array([1, 2], dtype=np.float16)),         ),         # idempotency with e.g. pd.array(pd.array([1, 2], dtype="int64"))         (             NumpyExtensionArray(np.a |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/test_datetimelike.py | 885879da2c856f1b58fe09ed2607f6e6442d0646ab7f5935df5fae96dc5a8526 | 1361 | 4 |         result = np.asarray(arr, dtype="int64")         assert result is not arr.asi8         assert not np.may_share_memory(arr, result)         expected = arr.asi8.copy()         tm.assert_numpy_arr |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/masked_shared.py | 00da7f094f47725cbdf8d0719279bb83eb96c658ecb539ab8aadd2f1fe643ec3 | 155 | 1 |     def test_no_shared_mask(self, data):         result = data + 1         assert not tm.shares_memory(result, data)      def test_array(self, comparison_op, dtype): |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/test_timedeltas.py | 55d31d9c2ace2f9fe851ae11c4bfa0695adee90a778aefffa8d31a51bee4a9f1 | 314 | 2 |         result = +arr         tm.assert_timedelta_array_equal(result, arr)         assert not tm.shares_memory(result, arr)          result2 = np.positive(arr) |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/test_datetimes.py | 16838313427ffbc28805b352e513a41165603671773f0693a2a277f18b620185 | 841 | 2 |         res2 = res.astype("M8[s, UTC]")         assert res2.dtype == "M8[s, UTC]"         assert not tm.shares_memory(res2, res)          res3 = res.astype("M8[s, UTC]", copy=False) |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/string_/test_string.py | cab195bcbada98f581af3159c161a898faabc9ffd8553b64c95fab386dcc72a2 | 855 | 3 |   def test_memory_usage(dtype):     # GH 33963  |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/categorical/test_constructors.py | 709a572523fd5f568fbbcc80f2cb3ca3c371fbda42a8b096e219b5d80088b082 | 788 | 1 |         result = Categorical._from_sequence(cat, dtype=cat.dtype, copy=True)          assert not tm.shares_memory(result, cat)      def test_constructor_datetime64_non_nano(self): |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/categorical/test_analytics.py | 923c937b83fce186111f8163a711ed0d109ceae260c43312e0f9f0802a3f044f | 356 | 8 |         assert cat.nbytes == exp      def test_memory_usage(self, using_infer_string):         cat = Categorical([1, 2, 3])  |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/integer/test_arithmetic.py | c0aac3e47030870ff614ec7c26fbf027e6b7c8cfe80c5492d5fbde51bbf0cb95 | 346 | 1 |     tm.assert_extension_array_equal(neg_result, neg_target)     tm.assert_extension_array_equal(pos_result, arr)     assert not tm.shares_memory(pos_result, arr)     tm.assert_extension_array_equal(ab |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/integer/test_dtypes.py | afc3ee1886e1314c05b675736739a417a027dcc57206a333067de3d43b1a6510 | 302 | 4 |     result = arr.astype("Int64", copy=True)     assert result is not arr     assert not tm.shares_memory(result, arr)     result[0] = 10     tm.assert_extension_array_equal(arr, orig) |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/floating/test_astype.py | 10e70122c7dce3857b95490d150c2a3e71d206dc848f7f2786f34e4ad05b21c7 | 136 | 4 |     result = arr.astype("Float64", copy=True)     assert result is not arr     assert not tm.shares_memory(result, arr)     result[0] = 10     tm.assert_extension_array_equal(arr, orig) |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/floating/test_arithmetic.py | a25052a110369804847b3ab1be4fe93e2180fc10b75b61473ba893153252c3f7 | 241 | 1 |     tm.assert_extension_array_equal(neg_result, neg_target)     tm.assert_extension_array_equal(pos_result, arr)     assert not tm.shares_memory(pos_result, arr)     tm.assert_extension_array_equal(ab |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/sparse/test_array.py | 5dd1b6648b9a7ab96ed9005ef982c81cf35648a54db190c0bea607affe9693a6 | 512 | 3 |     result_copy1 = np.asarray(arr)     result_copy2 = np.asarray(arr)     assert not np.may_share_memory(result_copy1, result_copy2)      # or with explicit copy=True |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/numpy_/test_indexing.py | fb4941f8cc3e8333383297be4910a3fb0e02e90c4b7e9dc11fae54fc35542cd6 | 42 | 1 |         tm.assert_numpy_array_equal(result, expected)      def test_searchsorted_numeric_dtypes_vector(self, any_real_numpy_dtype):         arr = pd.array([1, 3, 90], dtype=any_real_numpy_dtype)       |
| .venv/lib/python3.13/site-packages/pandas/tests/arrays/numpy_/test_numpy.py | cc51ef8b004c5f2122d9ee9bd122d9d23dfd8282a95076d827fdb0423c328285 | 352 | 2 |   def test_dtype_idempotent(any_numpy_dtype):     dtype = NumpyEADtype(any_numpy_dtype)  |
| .venv/lib/python3.13/site-packages/pandas/tests/arithmetic/test_period.py | bb1764acf22930cec15942a6c25a15882104d49b4eb3191728275fc4b43a1350 | 1676 | 1 |  class TestPeriodArrayLikeComparisons:     # Comparison tests for PeriodDtype vectors fully parametrized over     #  DataFrame/Series/PeriodIndex/PeriodArray.  Ideally all comparison     #  tests will |
| .venv/lib/python3.13/site-packages/pandas/tests/arithmetic/conftest.py | b94b6ee7e4f9141745400a36d6f44b4121cf88d1235a473af54c07ea59699ec3 | 140 | 3 | def zero(request):     """     Several types of scalar zeros and length 5 vectors of zeros.      This fixture can be used to check that numeric-dtype indexes handle |
| .venv/lib/python3.13/site-packages/pandas/tests/arithmetic/test_datetime64.py | 7fded5f743eb459ac567f22b0717c4b600d7bd823f246a8cb0897fffd6f4cbd1 | 2470 | 3 |  class TestDatetime64ArrayLikeComparisons:     # Comparison tests for datetime64 vectors fully parametrized over     #  DataFrame/Series/DatetimeIndex/DatetimeArray.  Ideally all comparison     #  tes |
| .venv/lib/python3.13/site-packages/pandas/tests/arithmetic/test_timedelta64.py | 387d1d0f828dad511ff05942ef931eced860103a2103c772937bb1c28b85f0b3 | 2180 | 26 |  class TestTimedelta64ArrayLikeComparisons:     # Comparison tests for timedelta64[ns] vectors fully parametrized over     #  DataFrame/Series/TimedeltaIndex/TimedeltaArray.  Ideally all comparison    |
| .venv/lib/python3.13/site-packages/pandas/tests/generic/test_to_xarray.py | 8d290b725e637194599b733673a232bfc8684ff63372b11b82ed8bb99ed246a7 | 145 | 2 |         assert isinstance(result, Dataset)          # idempotency         # datetimes w/tz are preserved         # column names are lost |
| .venv/lib/python3.13/site-packages/pandas/tests/tslibs/test_npy_units.py | 77d345b3281c286b69fa9c3e6693af231321a6c46a775b8f05596a7a31e43665 | 28 | 1 |  from pandas._libs.tslibs.dtypes import abbrev_to_npy_unit from pandas._libs.tslibs.vectorized import is_date_array_normalized  # a datetime64 ndarray which *is* normalized |
| .venv/lib/python3.13/site-packages/pandas/tests/tslibs/test_conversion.py | ae0b41ee922ce95be990d6a471ec3d3c543ca151edc02c3006dbb680216a6e1e | 161 | 6 |      result = tz_convert_from_utc(tz_didx.asi8, tz_didx.tz)     expected = np.vectorize(f)(tz_didx.asi8)      tm.assert_numpy_array_equal(result, expected) |
| .venv/lib/python3.13/site-packages/pandas/tests/tslibs/test_api.py | a28118d91c8ef682fc59c6ec73de7cb06ac18ef7aa4d064f6ae2de04dde7f717 | 66 | 1 |         "period",         "strptime",         "vectorized",         "timedeltas",         "timestamps", |
| .venv/lib/python3.13/site-packages/pandas/tests/indexing/test_iloc.py | 3605d56ed8c53a84ca6251e456c56120a98a6a75b4848bf0a16925611d25ced9 | 1485 | 6 |         expected = DataFrame({0: cat}).astype(object)         if not using_array_manager:             assert np.shares_memory(df[0].values, orig_vals)          tm.assert_frame_equal(df, expected) |
| .venv/lib/python3.13/site-packages/pandas/tests/indexing/test_loc.py | 9c74462d27c20aeace96f280f375e492940a652cfb22dadcb63a544779533a1f | 3393 | 4 |     @pytest.mark.arm_slow     @pytest.mark.parametrize("length, l2", [[900, 100], [900000, 100000]])     def test_loc_non_unique_memory_error(self, length, l2):         # GH 4280         # non_unique  |
| .venv/lib/python3.13/site-packages/pandas/tests/indexing/multiindex/test_multiindex.py | 6c88a1ac42145ced6cf300272a87fd0138b0a80bf0b8b216cc4fe866533194eb | 236 | 5 |             {                 "a": ["R1", "R2", np.nan, "R4"],                 "b": ["C1", "C2", "C3", "C4"],                 "c": [10, 15, np.nan, 20],             } |
| .venv/lib/python3.13/site-packages/pandas/tests/indexing/multiindex/test_loc.py | ffc82028b9f75683beab1f68dfcb98789ecc9b303f5608cebe82df8cba5a1e96 | 993 | 1 |             "OMK",             "RES",             "DRIFT_IND",             "OEVRIG_IND",             "FIN_IND", |
| .venv/lib/python3.13/site-packages/pandas/tests/scalar/test_nat.py | a5484d354c4b06fe3f0fe976b6c1c8085893e6bb838ef963db8a0490d6727319 | 710 | 2 |   def test_nat_vector_field_access():     idx = DatetimeIndex(["1/1/2000", None, None, "1/4/2000"])  |
| .venv/lib/python3.13/site-packages/pandas/tests/base/test_misc.py | fc73216fa5f0089094a9316ca483f0cc939ad2c13624e5971349711ea1fe0f3a | 191 | 15 |     reason="not relevant for PyPy doesn't work properly for arrow strings", ) def test_memory_usage(index_or_series_memory_obj):     obj = index_or_series_memory_obj     # Clear index caches so that l |
| .venv/lib/python3.13/site-packages/pandas/tests/base/test_constructors.py | 5e7beff4ff684449084af39ade3317d35e53fd36d167a64861a1bdf3f59e7de8 | 191 | 2 |      @pytest.mark.skipif(PYPY, reason="not relevant for PyPy")     def test_memory_usage(self):         # Delegate does not implement memory_usage.         # Check that we fall back to in-built `__siz |
| .venv/lib/python3.13/site-packages/pandas/tests/base/test_conversion.py | 23d6aaa5cb2188bae97e7cdf11bb73f945a23fb88d657db589b0985d41facd40 | 597 | 7 |     result_cp2 = np.array(thing, copy=True)     # When called with `copy=True` NumPy/we should ensure a copy was made     assert not np.may_share_memory(result_cp1, result_cp2)      if not np_version_ |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/test_old_base.py | 0266bbdcc7720565d8662c3abd5a4ec4dfe69cd3307122108393eacd63d214b6 | 1064 | 8 |              if isinstance(index._values, BaseMaskedArray):                 assert np.shares_memory(index._values._data, result._values._data)                 tm.assert_numpy_array_equal(              |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/test_base.py | 153959386b05fabc99533f859c33d202dab7de34c20eae712be8cb653a1ed056 | 1735 | 2 |     ], ) def test_construct_from_memoryview(klass, extra_kwargs):     # GH 13120     result = klass(memoryview(np.arange(2000, 2005)), **extra_kwargs) |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/ranges/test_range.py | 01aa0e43f3ee7e0ae09ce992ec045847275b754d63b1bebe0cabb6a17e762ee2 | 623 | 2 |      def test_nbytes(self):         # memory savings vs int index         idx = RangeIndex(0, 1000)         assert idx.nbytes < Index(idx._values).nbytes / 10 |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/interval/test_astype.py | 1b5990acadde4bfcc6ecb318bb0c82be4a61f59a0d91b40c2e92349e1239b632 | 255 | 1 |     """Tests common to IntervalIndex with any subtype"""      def test_astype_idempotent(self, index):         result = index.astype("interval")         tm.assert_index_equal(result, index) |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/multi/test_sorting.py | ebd0bc04436ecf252f9d05c46e356f00398102be46eb0cccf842c738c2d5d83a | 350 | 1 |     tm.assert_index_equal(result, expected)      # idempotent     result2 = result.remove_unused_levels()     tm.assert_index_equal(result2, expected) |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/multi/test_integrity.py | 573c95dd1ae15a4431c16cf32de2d3e8b99cfa78e5e059e9a0022c848d41156f | 290 | 4 |   def test_memory_usage(idx):     result = idx.memory_usage()     if len(idx): |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/multi/test_conversion.py | 5db8311d94648c66238f633e10a08644063b62086e972f5499de22b23f10e8c2 | 202 | 3 |      # it always gives a copy by default, but the values are cached, so results     # are still sharing memory     result_copy1 = np.asarray(idx)     result_copy2 = np.asarray(idx) |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/multi/test_partial_indexing.py | b1534893dfcdc4c0ec1ee450ccf09eae73e67214c5e48340505933415eedf13d | 149 | 2 |      key4 = ("2016", "a")     loc4 = mi.get_loc(key4)     expected4 = expected3     tm.assert_numpy_array_equal(loc4, expected4) |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/period/test_scalar_compat.py | 089b96d30e927700cfb659360e5d788347b0b8272c20a3f0b6798830149812e7 | 39 | 1 | """Tests for PeriodIndex behaving like a vectorized Period scalar"""  import pytest |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/categorical/test_category.py | fc130b4cf81fef02c6c70e05515dd771950588afa5ffa3fe2a17d95c7f6a600c | 392 | 2 |         result = CategoricalIndex(index.values, copy=True)         tm.assert_index_equal(index, result)         assert not np.shares_memory(result._data._codes, index._data._codes)          result = C |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/categorical/test_fillna.py | b07ebc69609a6c8daacb975b8314025de4dfbe7d4d4200df335393e288c599a5 | 55 | 2 |         result = ci.fillna(0)         assert result is not ci         assert tm.shares_memory(result, ci)          # But at the EA level we always get a copy. |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/datetimes/test_constructors.py | cf3202ca9bd56eef3f3c27cbde38831a34895927e55a325ba6a4b988d91dd640 | 1205 | 1 |             tm.assert_index_equal(idx1, other)      def test_dti_construction_idempotent(self, unit):         rng = date_range(             "03/12/2012 00:00", periods=10, freq="W-FRI", tz="US/Eastern |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/datetimes/methods/test_tz_localize.py | 43b039e25b28bc3c410c4a94ed734126a9773e834b17b355797c2f30582b548d | 403 | 2 |          res = index.tz_localize(utc_fixture)         assert not tm.shares_memory(res, index)          res2 = index._data.tz_localize(utc_fixture) |
| .venv/lib/python3.13/site-packages/pandas/tests/indexes/timedeltas/test_scalar_compat.py | 865752493c5112e041b8b021bcb4e35fb154989f43cdc27198cab368296712b8 | 143 | 1 |   class TestVectorizedTimedelta:     def test_tdi_total_seconds(self):         # GH#10939 |
| .venv/lib/python3.13/site-packages/pandas/_testing/__init__.py | 19bbca0d4ca60b9b03f71d2855572fd0402d4bcac16e49a84445977c72cfa645 | 636 | 21 |     bytes,     bytearray,     memoryview, ]  |
| .venv/lib/python3.13/site-packages/pandas/_testing/asserters.py | 47ca02bfae0ec68386df87817deddf79f35110932f7791e62bb2e74a6c8e337b | 1460 | 1 |         If provided, used as assertion message.     check_same : None\|'copy'\|'same', default None         Ensure left and right refer/do not refer to the same memory area.     obj : str, default 'nump |
| .venv/lib/python3.13/site-packages/pandas/_libs/tslibs/__init__.py | 768c084cd5771b1abcc01dd776a8b2442b440e7f37fc690b706262427cccd660 | 88 | 1 | from pandas._libs.tslibs.timezones import tz_compare from pandas._libs.tslibs.tzconversion import tz_convert_from_utc_single from pandas._libs.tslibs.vectorized import (     dt64arr_to_periodarr,      |
| .venv/lib/python3.13/site-packages/pandas/plotting/_core.py | 04b2330eb45c6830d80695e3f277f0dda21769ba2ce989703e3a277589a1e882 | 1947 | 2 | %(data)s\ column : str or list of str, optional     Column name or list of names, or vector.     Can be any valid input to :meth:`pandas.DataFrame.groupby`. by : str or array-like, optional |
| .venv/lib/python3.13/site-packages/pandas/plotting/_misc.py | b1b39aaa413d940e476e293370505c5def6d76a1cc540c71307dd5f507d8afe7 | 689 | 1 |         ... )         >>> pd.plotting.parallel_coordinates(         ...     df, 'Name', color=('#556270', '#4ECDC4', '#C7F464')         ... )  # doctest: +SKIP     """ |
| .venv/lib/python3.13/site-packages/pandas/plotting/_matplotlib/converter.py | 11c7606aa40f3aa6083b69e807ee89db190e0ec0700136a6bb0037d794825688 | 1140 | 1 |     for unit, formatter in _mpl_units.items():         if type(formatter) not in {DatetimeConverter, PeriodConverter, TimeConverter}:             # make it idempotent by excluding ours.             mu |
| .venv/lib/python3.13/site-packages/pandas/errors/__init__.py | 0e8b4925f77e6d2ec54906e72c2e9229609fcff1aa1984ba1b2e8573d009660d | 851 | 1 |     --------     >>> from sqlite3 import connect     >>> conn = connect(':memory:')     >>> pd.read_sql('select * test', conn) # doctest: +SKIP     ... # DatabaseError: Execution failed on sql 'test': |
| .venv/lib/python3.13/site-packages/dateutil/zoneinfo/__init__.py | 298834a6d842323729e4c5d21220499f79cc8d978d65abfbae5270e7eb73d52e | 168 | 1 |                               if zf.isfile() and zf.name != METADATA_FN}                 # deal with links: They'll point to their parent object. Less                 # waste of memory                 |
| .venv/lib/python3.13/site-packages/dateutil/zoneinfo/rebuild.py | 322a98cc2207bcd6cc1fe2dd4582effb84f410803b8432ade462d1d084532dd2 | 76 | 3 |      if b"-b " in help_text:         bloat_args = ["-b", "fat"]     else:         bloat_args = [] |
| .venv/lib/python3.13/site-packages/ruamel/yaml/constructor.py | bdaace288852001493bff213299314bb5ff1d9d6aeca217c0c4f91fa61145298 | 1725 | 1 |             # NEWCMNT             if node.comment:                 # nprintf('nc4', node.comment, node.start_mark)                 if maptyp.ca.pre is None:                     maptyp.ca.pre = [] |
| .venv/lib/python3.13/site-packages/ruamel/yaml/representer.py | 3412f1b0c1b3a794599df37b5bdbcb01a28e29dc4248b9b18696ea45844cd1c1 | 1140 | 1 |         a subclass can choose not to quote them (for example)         used in represent_mapping         https://bitbucket.org/davidfraser/pyyaml/commits/d81df6eb95f20cac4a79eed95ae553b5c6f77b8c        |
| .venv/lib/python3.13/site-packages/openai/_types.py | c6e0fe3444bad8779a5987bdac9c7a2b4c110c631ee6f92b80414577fc323c5b | 256 | 1 |     params: Query     extra_json: AnyMapping     idempotency_key: str     follow_redirects: bool  |
| .venv/lib/python3.13/site-packages/openai/_base_client.py | a72e57d9d723412e9b4eece5877b579b74b10e85cb1f0cd0df6b7418b26dfd81 | 2028 | 26 |     timeout: Union[float, Timeout, None]     _strict_response_validation: bool     _idempotency_header: str \| None     _default_stream_cls: type[_DefaultStreamT] \| None = None  |
| .venv/lib/python3.13/site-packages/openai/__init__.py | 07e9dfe71705a07fa69f73dfed25f0edb9b850e88d47915682b4488c4b84bb40 | 393 | 4 |     responses as responses,     containers as containers,     embeddings as embeddings,     completions as completions,     fine_tuning as fine_tuning, |
| .venv/lib/python3.13/site-packages/openai/_files.py | 7103a8174505a67c87e4930876efc4bc6a63fdd1b31f5a23b49bf25fb5f0aa7d | 124 | 1 |         prefix = f"Expected entry at `{key}`" if key is not None else f"Expected file input `{obj!r}`"         raise RuntimeError(             f"{prefix} to be bytes, an io.IOBase instance, PathLike o |
| .venv/lib/python3.13/site-packages/openai/_client.py | e5ac3a3985251b4503033765073c2eafad47e609561c2265cf14f2f204613d68 | 1235 | 89 |         responses,         containers,         embeddings,         completions,         fine_tuning, |
| .venv/lib/python3.13/site-packages/openai/_models.py | ab6a4ed24d1919b0ee6b528531ab0c6f81b49f82b28543bc6a05ecd38ca3fd76 | 870 | 2 |     timeout: float \| Timeout \| None     files: HttpxRequestFiles \| None     idempotency_key: str     json_data: Body     extra_json: AnyMapping |
| .venv/lib/python3.13/site-packages/openai/_module_client.py | 6c87d86fa275aedb9bbaa12489955fe7376ef5198a5908837ae75d79df4287cd | 166 | 19 |     from .resources.beta.beta import Beta     from .resources.chat.chat import Chat     from .resources.embeddings import Embeddings     from .resources.audio.audio import Audio     from .resources.co |
| .venv/lib/python3.13/site-packages/openai/types/image_model.py | bfc9e43a8a7c2fc2d2e9648c865e29a09d1e74c37d2a191d9fd7a9ca52d00ef1 | 8 | 1 | __all__ = ["ImageModel"]  ImageModel: TypeAlias = Literal["dall-e-2", "dall-e-3", "gpt-image-1"] |
| .venv/lib/python3.13/site-packages/openai/types/vector_store_search_params.py | 12761f3453f8760a2f65e2cb3de1a87c0dd30896ad24362de1aa29a4c3ada3d8 | 43 | 3 | from .shared_params.comparison_filter import ComparisonFilter  __all__ = ["VectorStoreSearchParams", "Filters", "RankingOptions"]   |
| .venv/lib/python3.13/site-packages/openai/types/vector_store_create_params.py | 9a63a4549936a87d92794a2cd29d6478a085629ef151359ed3489e94dd0b0a91 | 56 | 6 | from .file_chunking_strategy_param import FileChunkingStrategyParam  __all__ = ["VectorStoreCreateParams", "ExpiresAfter"]   |
| .venv/lib/python3.13/site-packages/openai/types/batch_create_params.py | a79aa14e7cd856c01c5c5b828f8432937c8f228f85c529654de71d89dab7752b | 71 | 4 |     """      endpoint: Required[Literal["/v1/responses", "/v1/chat/completions", "/v1/embeddings", "/v1/completions"]]     """The endpoint to be used for all requests in the batch.  |
| .venv/lib/python3.13/site-packages/openai/types/embedding_model.py | d1d0cbf3b95e9f8bd9e0347a782a7b2592422698305a985198984c2b749ef1fe | 8 | 5 | from typing_extensions import Literal, TypeAlias  __all__ = ["EmbeddingModel"]  EmbeddingModel: TypeAlias = Literal["text-embedding-ada-002", "text-embedding-3-small", "text-embedding-3-large"] |
| .venv/lib/python3.13/site-packages/openai/types/embedding.py | da957a45349fe5457a13ce977ae7796709a3423312f779bfe0bad0d063777e1a | 24 | 12 | from .._models import BaseModel  __all__ = ["Embedding"]   |
| .venv/lib/python3.13/site-packages/openai/types/vector_store.py | 852df4b5280bfecd410b4e272077d92fde7eb83eb4b7939ee38254427543f13f | 83 | 13 | from .shared.metadata import Metadata  __all__ = ["VectorStore", "FileCounts", "ExpiresAfter"]   |
| .venv/lib/python3.13/site-packages/openai/types/image_gen_completed_event.py | b00d84ce197e1b087470fab75459834990c3f3288ed62e66901f81ce221da9df | 56 | 1 |      usage: Usage     """For `gpt-image-1` only, the token usage information for the image generation.""" |
| .venv/lib/python3.13/site-packages/openai/types/__init__.py | af87ed7a9176181cc3b64997c2f906ebe1c8839c2fcfac2bf71dae96707c7d51 | 105 | 35 | from .shared import (     Metadata as Metadata,     AllModels as AllModels,     ChatModel as ChatModel,     Reasoning as Reasoning, |
| .venv/lib/python3.13/site-packages/openai/types/completion_create_params.py | 52a8188d4a586d060f758113571864c206c644a4d0081a3279216dac1f22b80a | 190 | 3 |  class CompletionCreateParamsBase(TypedDict, total=False):     model: Required[Union[str, Literal["gpt-3.5-turbo-instruct", "davinci-002", "babbage-002"]]]     """ID of the model to use.  |
| .venv/lib/python3.13/site-packages/openai/types/vector_store_update_params.py | 4499b4aa4a8b3ac1e384f2223963cdc24ac422a1e30ee932653e769a57b88167 | 40 | 5 | from .shared_params.metadata import Metadata  __all__ = ["VectorStoreUpdateParams", "ExpiresAfter"]   |
| .venv/lib/python3.13/site-packages/openai/types/embedding_create_params.py | 6ac6a159635c32f5c60df6d3333e2e0f2ec353d83a389f70a30a99072821cf0f | 56 | 10 |  from .._types import SequenceNotStr from .embedding_model import EmbeddingModel  __all__ = ["EmbeddingCreateParams"] |
| .venv/lib/python3.13/site-packages/openai/types/image_generate_params.py | ec60438dca0474a5fc6ee38ae88ae83a7ede1fd18591c5dbf8b19829f56e44c5 | 144 | 12 |     """A text description of the desired image(s).      The maximum length is 32000 characters for `gpt-image-1`, 1000 characters for     `dall-e-2` and 4000 characters for `dall-e-3`.     """ |
| .venv/lib/python3.13/site-packages/openai/types/audio_model.py | b2ea34122e8e0d2da4b0c46271703309fb834c671b88c8f0cd52e2f9b7f803ab | 8 | 2 | __all__ = ["AudioModel"]  AudioModel: TypeAlias = Literal["whisper-1", "gpt-4o-transcribe", "gpt-4o-mini-transcribe"] |
| .venv/lib/python3.13/site-packages/openai/types/create_embedding_response.py | 95302efcfca6efa9059630e79c34680c1d863504b35a6c3096a7f97dfec534f3 | 32 | 7 |  from .._models import BaseModel from .embedding import Embedding  __all__ = ["CreateEmbeddingResponse", "Usage"] |
| .venv/lib/python3.13/site-packages/openai/types/image_edit_completed_event.py | 135f65c580184c00a350c136f7c057af241d419d039f35993dbccceb7e9e97a9 | 56 | 1 |      usage: Usage     """For `gpt-image-1` only, the token usage information for the image generation.""" |
| .venv/lib/python3.13/site-packages/openai/types/vector_store_search_response.py | aa585d023a8b3d983f2509aca900b30204f63f17360bebc666687ae2447ccbe3 | 40 | 4 | from .._models import BaseModel  __all__ = ["VectorStoreSearchResponse", "Content"]   |
| .venv/lib/python3.13/site-packages/openai/types/images_response.py | 7296ede6d2886b1e492033381528f7863a3644eec014dda924f3509b8016a9e3 | 61 | 1 |      usage: Optional[Usage] = None     """For `gpt-image-1` only, the token usage information for the image generation.""" |
| .venv/lib/python3.13/site-packages/openai/types/vector_store_deleted.py | 05bb67959d19e5fe27703c872caac47e663a52e734c4e837581c6f32847c5b19 | 16 | 3 | from .._models import BaseModel  __all__ = ["VectorStoreDeleted"]   |
| .venv/lib/python3.13/site-packages/openai/types/image_edit_params.py | 9a6d8eacebe138af7e6e704dc7d394e6acbe7d086b630bb6f6e617cae003b0a2 | 145 | 11 |     """The image(s) to edit. Must be a supported image file or an array of images.      For `gpt-image-1`, each image should be a `png`, `webp`, or `jpg` file less than     50MB. You can provide up to |
| .venv/lib/python3.13/site-packages/openai/types/vector_store_list_params.py | 29e49e41a11da8ed8488f115b6ad4dba7fae4517647f05b43fc68778298be730 | 40 | 2 | from typing_extensions import Literal, TypedDict  __all__ = ["VectorStoreListParams"]   |
| .venv/lib/python3.13/site-packages/openai/types/image.py | 7166c8e0467167f7ad5ca1a5d2efbbb2bdff7c911a5b03f44692767d220361f7 | 27 | 2 |     """The base64-encoded JSON of the generated image.      Default value for `gpt-image-1`, and only present if `response_format` is set to     `b64_json` for `dall-e-2` and `dall-e-3`.     """ |
| .venv/lib/python3.13/site-packages/openai/types/beta/file_search_tool.py | e5a354f11663f9435d9aeaaaa6309735a6b5a48f46cd23f9a823edbd5489d684 | 56 | 2 |     """The maximum number of results the file search tool should output.      The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number     should be between 1 and 50 inclusive.  |
| .venv/lib/python3.13/site-packages/openai/types/beta/thread.py | 46b02b48ad7efe9ad063f6017b1803fd253cef2fe4dab991abfb6d8baea2eece | 64 | 5 |  class ToolResourcesFileSearch(BaseModel):     vector_store_ids: Optional[List[str]] = None     """     The |
| .venv/lib/python3.13/site-packages/openai/types/beta/thread_update_params.py | 78dd55c8fe2593aa6e26c7b2757f4073d08b64ba1b61025c8a31169354651ca7 | 57 | 5 |     thread. The resources are specific to the type of tool. For example, the     `code_interpreter` tool requires a list of file IDs, while the `file_search`     tool requires a list of vector store I |
| .venv/lib/python3.13/site-packages/openai/types/beta/thread_create_params.py | 4f4a24df227a657a8f6d7e5dab0a50a7b6055825e8021cffcdbae8328eab3c34 | 187 | 26 |     "ToolResourcesCodeInterpreter",     "ToolResourcesFileSearch",     "ToolResourcesFileSearchVectorStore",     "ToolResourcesFileSearchVectorStoreChunkingStrategy",     "ToolResourcesFileSearchVecto |
| .venv/lib/python3.13/site-packages/openai/types/beta/assistant.py | fce8052a68da317336c8d3931537028f9a95a3ff85f69eee8845c99d86c1d171 | 135 | 12 |  class ToolResourcesFileSearch(BaseModel):     vector_store_ids: Optional[List[str]] = None     """     The ID of the |
| .venv/lib/python3.13/site-packages/openai/types/beta/assistant_create_params.py | be64250dec26f99a1af238d973814657fa1c1ad5e531b21aa928491dba70b1fe | 214 | 33 |     "ToolResourcesCodeInterpreter",     "ToolResourcesFileSearch",     "ToolResourcesFileSearchVectorStore",     "ToolResourcesFileSearchVectorStoreChunkingStrategy",     "ToolResourcesFileSearchVecto |
| .venv/lib/python3.13/site-packages/openai/types/beta/assistant_update_params.py | 1cc832610f6d34bf5a6f7dd569cbec255d68d5e6ca5f10333aebdaef05b1d829 | 185 | 50 |         str,         Literal[             "gpt-5",             "gpt-5-mini",             "gpt-5-nano", |
| .venv/lib/python3.13/site-packages/openai/types/beta/thread_create_and_run_params.py | 30f2c381a67af4f47e59944f37fcf0c05d7ef8283d77df680f7ac2d9a5a20829 | 398 | 38 |     "ThreadToolResourcesCodeInterpreter",     "ThreadToolResourcesFileSearch",     "ThreadToolResourcesFileSearchVectorStore",     "ThreadToolResourcesFileSearchVectorStoreChunkingStrategy",     "Thre |
| .venv/lib/python3.13/site-packages/openai/types/beta/file_search_tool_param.py | a3ab163ebcd1618f30b4d695b85f21dc3d6c0105773742f775b76289a322b16d | 55 | 2 |     """The maximum number of results the file search tool should output.      The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number     should be between 1 and 50 inclusive.  |
| .venv/lib/python3.13/site-packages/openai/types/beta/realtime/transcription_session_update_param.py | 6fdf6fe322a7076942fdc9d81a26b12a742e1c1e1e516fafdde293d940ec6a69 | 186 | 5 |     """      model: Literal["gpt-4o-transcribe", "gpt-4o-mini-transcribe", "whisper-1"]     """     The model to use for transcription, current options are `gpt-4o-transcribe`, |
| .venv/lib/python3.13/site-packages/openai/types/beta/realtime/transcription_session_create_params.py | 055c12638d545f69e35c02695b29cc26d0b95ee2afeac36cee4a7663c2928e79 | 174 | 5 |     """      model: Literal["gpt-4o-transcribe", "gpt-4o-mini-transcribe", "whisper-1"]     """     The model to use for transcription, current options are `gpt-4o-transcribe`, |
| .venv/lib/python3.13/site-packages/openai/types/beta/realtime/session_update_event_param.py | d27f417e420320844fdc1233de396db8ec6891b8a2d3a6681c84b880a0730639 | 309 | 9 |     model: str     """     The model to use for transcription, current options are `gpt-4o-transcribe`,     `gpt-4o-mini-transcribe`, and `whisper-1`.     """ |
| .venv/lib/python3.13/site-packages/openai/types/beta/realtime/session_create_params.py | 189a21fae5e4cbcba3d015f4fe9c352d61549a621bedba5c83b1c4b1b1f88557 | 297 | 9 |      model: Literal[         "gpt-4o-realtime-preview",         "gpt-4o-realtime-preview-2024-10-01",         "gpt-4o-realtime-preview-2024-12-17", |
| .venv/lib/python3.13/site-packages/openai/types/beta/realtime/session.py | 7c01b8678d381f5d5a1eae3a29b730655f43a19e10655f1459946d10e2d2d9bd | 278 | 9 |     model: Optional[str] = None     """     The model to use for transcription, current options are `gpt-4o-transcribe`,     `gpt-4o-mini-transcribe`, and `whisper-1`.     """ |
| .venv/lib/python3.13/site-packages/openai/types/beta/realtime/session_update_event.py | ece493b8fdeedbe42ab11e16fc0a50a01564043dda91899baf3262ea6eb4f2b8 | 311 | 9 |     model: Optional[str] = None     """     The model to use for transcription, current options are `gpt-4o-transcribe`,     `gpt-4o-mini-transcribe`, and `whisper-1`.     """ |
| .venv/lib/python3.13/site-packages/openai/types/beta/realtime/transcription_session.py | 4a8a362ee10c26d9140f6a0f275136dc651ca14ad80624aefd4b5b2d429e99fc | 101 | 4 |     """      model: Optional[Literal["gpt-4o-transcribe", "gpt-4o-mini-transcribe", "whisper-1"]] = None     """The model to use for transcription.  |
| .venv/lib/python3.13/site-packages/openai/types/beta/realtime/transcription_session_update.py | 60c3fd381f4fe45692c1a89c5ed6042e39b8843d600d2bca16af58b45dacabae | 186 | 5 |     """      model: Optional[Literal["gpt-4o-transcribe", "gpt-4o-mini-transcribe", "whisper-1"]] = None     """     The model to use for transcription, current options are `gpt-4o-transcribe`, |
| .venv/lib/python3.13/site-packages/openai/types/beta/threads/run.py | 70538befb9978042ca79f69154df43b368caa3162d058c04ebef3689e81aadc0 | 246 | 7 |     """Specifies the format that the model must output.      Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),     [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-t |
| .venv/lib/python3.13/site-packages/openai/types/beta/threads/run_create_params.py | a9568b8900e4641051007e62695f2f44ac9c4ad945d5209b104ad0a69e127ce4 | 262 | 7 |     """Specifies the format that the model must output.      Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),     [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-t |
| .venv/lib/python3.13/site-packages/openai/types/vector_stores/vector_store_file_deleted.py | b0e76cdc54a60c11617b6e73a12033daf1ec986d9ba38b363c04a007f33a514d | 16 | 3 | from ..._models import BaseModel  __all__ = ["VectorStoreFileDeleted"]   |
| .venv/lib/python3.13/site-packages/openai/types/vector_stores/file_update_params.py | 3466a1d3596e0d6fd6de9b1fb186b74a196cc07f290210bf11e6cb32f77ddb92 | 22 | 1 |  class FileUpdateParams(TypedDict, total=False):     vector_store_id: Required[str]      attributes: Required[Optional[Dict[str, Union[str, float, bool]]]] |
| .venv/lib/python3.13/site-packages/openai/types/vector_stores/file_create_params.py | 9d31d61b438caaa2d18d6147daa6e27fcf5fa422500b31867570e30aa3dbab56 | 36 | 1 |     """     A [File](https://platform.openai.com/docs/api-reference/files) ID that the     vector store should use. Useful for tools like `file_search` that can access     files.     """ |
| .venv/lib/python3.13/site-packages/openai/types/vector_stores/__init__.py | 17f0f25ba12ac4e25304f284e4b512ce04e26dc64ce9ac4ca3e8abcacaf9daba | 14 | 9 |  from .file_list_params import FileListParams as FileListParams from .vector_store_file import VectorStoreFile as VectorStoreFile from .file_create_params import FileCreateParams as FileCreateParams f |
| .venv/lib/python3.13/site-packages/openai/types/vector_stores/vector_store_file_batch.py | 32745e847e4c73454e852099b6788c0f3f1e1fbdaccb2d9149c984091fc11211 | 55 | 9 | from ..._models import BaseModel  __all__ = ["VectorStoreFileBatch", "FileCounts"]   |
| .venv/lib/python3.13/site-packages/openai/types/vector_stores/vector_store_file.py | 99f99704be04a87b9aa1a9919d9d934b5a17de4d68913444536bcb3ab6d5825c | 68 | 12 | from ..file_chunking_strategy import FileChunkingStrategy  __all__ = ["VectorStoreFile", "LastError"]   |
| .venv/lib/python3.13/site-packages/openai/types/vector_stores/file_batch_list_files_params.py | 14fa50bc2408dac9322c1f180aec1d0a3ed16cef5b6b552368702dbeb5b101bb | 48 | 1 |  class FileBatchListFilesParams(TypedDict, total=False):     vector_store_id: Required[str]      after: str |
| .venv/lib/python3.13/site-packages/openai/types/vector_stores/file_batch_create_params.py | 7fddf5037b16f15df45865d0602539eb512a1b75d1c5286013f852a6efa116b3 | 37 | 1 |     """     A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that     the vector store should use. Useful for tools like `file_search` that can access     files.     """ |
| .venv/lib/python3.13/site-packages/openai/types/evals/run_retrieve_response.py | b999e58e06c76d182ae7bb6a4be3210a6d61b59b8443fbeec571fa6728042e13 | 392 | 1 |     The default format is `{ "type": "text" }` with no additional options.      **Not recommended for gpt-4o and newer models:**      Setting to `{ "type": "json_object" }` enables the older JSON mode |
| .venv/lib/python3.13/site-packages/openai/types/evals/run_create_params.py | bd1d0de90d1eb2378df8265ac05caf4f861c6108ceaee58e7f5b5c99f6c78da7 | 315 | 1 |     The default format is `{ "type": "text" }` with no additional options.      **Not recommended for gpt-4o and newer models:**      Setting to `{ "type": "json_object" }` enables the older JSON mode |
| .venv/lib/python3.13/site-packages/openai/types/evals/create_eval_completions_run_data_source.py | a64ebbb7a857db4c662d016b3471cb295f871d74e86d221447d84a12b8d3c925 | 220 | 1 |      model: Optional[str] = None     """An optional model to filter by (e.g., 'gpt-4o')."""   |
| .venv/lib/python3.13/site-packages/openai/types/evals/create_eval_completions_run_data_source_param.py | b312042f7bbd6562eb572215fd35d709350b7bc8b611f525566e4948ab1d7c27 | 216 | 1 |      model: Optional[str]     """An optional model to filter by (e.g., 'gpt-4o')."""   |
| .venv/lib/python3.13/site-packages/openai/types/evals/run_cancel_response.py | a79c4aadcd28e243572ca653c814f81c166eeaf62719226b5dc7b7cbd5bed757 | 392 | 1 |     The default format is `{ "type": "text" }` with no additional options.      **Not recommended for gpt-4o and newer models:**      Setting to `{ "type": "json_object" }` enables the older JSON mode |
| .venv/lib/python3.13/site-packages/openai/types/evals/run_list_response.py | 0c624161a55b503856a51425501ed120e02fdc4f48fc49592873fbfa5094d76f | 392 | 1 |     The default format is `{ "type": "text" }` with no additional options.      **Not recommended for gpt-4o and newer models:**      Setting to `{ "type": "json_object" }` enables the older JSON mode |
| .venv/lib/python3.13/site-packages/openai/types/evals/run_create_response.py | e93b505b7d72cec1ebc96a8b8ce8842a735f0695119748c37e92672a2c6a17f0 | 392 | 1 |     The default format is `{ "type": "text" }` with no additional options.      **Not recommended for gpt-4o and newer models:**      Setting to `{ "type": "json_object" }` enables the older JSON mode |
| .venv/lib/python3.13/site-packages/openai/types/fine_tuning/job_create_params.py | a78d9e6cecefa3f821122b632133f8420fa6854bd0721ade783addfc547960a0 | 177 | 3 |  class JobCreateParams(TypedDict, total=False):     model: Required[Union[str, Literal["babbage-002", "davinci-002", "gpt-3.5-turbo", "gpt-4o-mini"]]]     """The name of the model to fine-tune.  |
| .venv/lib/python3.13/site-packages/openai/types/chat/completion_create_params.py | 28cf7f86b18ca627d39b3bcef52d8653bd5796197bcd20f19b9ca5f0ff5516d3 | 436 | 2 |      model: Required[Union[str, ChatModel]]     """Model ID used to generate the response, like `gpt-4o` or `o3`.      OpenAI offers a wide range of models with different capabilities, performance |
| .venv/lib/python3.13/site-packages/openai/types/responses/file_search_tool.py | 5aab8b103eedc6bec4ffaf9879bce752e1303439cc45b5d6f1f28441daaba3cd | 45 | 2 |     """The type of the file search tool. Always `file_search`."""      vector_store_ids: List[str]     """The IDs of the vector stores to search."""  |
| .venv/lib/python3.13/site-packages/openai/types/responses/response_text_config_param.py | df8f06ae79c6505f1f1847d1496f95c35c05a2a4ea430ec57dc808bdcd6eb028 | 37 | 1 |     The default format is `{ "type": "text" }` with no additional options.      **Not recommended for gpt-4o and newer models:**      Setting to `{ "type": "json_object" }` enables the older JSON mode |
| .venv/lib/python3.13/site-packages/openai/types/responses/response_error.py | 93a197e2f57cce0a89696e99d798a3d0dd186a699c81bc6fdcdc8cc59789b1d4 | 35 | 1 |         "rate_limit_exceeded",         "invalid_prompt",         "vector_store_timeout",         "invalid_image",         "invalid_image_format", |
| .venv/lib/python3.13/site-packages/openai/types/responses/tool_param.py | 0f9424c11e8ab33ce9a1c7a96d73e0f1881cdd03e168b3ff1bc19edb88f14569 | 264 | 4 |         "connector_sharepoint",     ]     """Identifier for service connectors, like those available in ChatGPT.      One of `server_url` or `connector_id` must be provided. Learn more about service |
| .venv/lib/python3.13/site-packages/openai/types/responses/response.py | f95d19e330ed2dc32191302c175e13b170f42e54d688b9e6f2eb54067f5dc43a | 291 | 2 |      model: ResponsesModel     """Model ID used to generate the response, like `gpt-4o` or `o3`.      OpenAI offers a wide range of models with different capabilities, performance |
| .venv/lib/python3.13/site-packages/openai/types/responses/response_create_params.py | cd0a8c726b7ddfdb6c448966fb747992348985476044d196874e9b25053e63bf | 323 | 2 |      model: ResponsesModel     """Model ID used to generate the response, like `gpt-4o` or `o3`.      OpenAI offers a wide range of models with different capabilities, performance |
| .venv/lib/python3.13/site-packages/openai/types/responses/response_text_config.py | 74cdbc5097c48cb48a05c447366050263919495759faf0c571c3d35665d8b34d | 36 | 1 |     The default format is `{ "type": "text" }` with no additional options.      **Not recommended for gpt-4o and newer models:**      Setting to `{ "type": "json_object" }` enables the older JSON mode |
| .venv/lib/python3.13/site-packages/openai/types/responses/tool.py | 1c2fcf584c68b15286189e8328270161b53d8a93c8441bbf7d97d97b61b8a60e | 264 | 4 |         ]     ] = None     """Identifier for service connectors, like those available in ChatGPT.      One of `server_url` or `connector_id` must be provided. Learn more about service |
| .venv/lib/python3.13/site-packages/openai/types/responses/file_search_tool_param.py | a4f2415a2118fc9c13d26a27df9aa90f9e728e0353187acfdf8605c4d82f340c | 47 | 2 |     """The type of the file search tool. Always `file_search`."""      vector_store_ids: Required[SequenceNotStr[str]]     """The IDs of the vector stores to search."""  |
| .venv/lib/python3.13/site-packages/openai/types/shared/all_models.py | 8b0ac0ce1dc8d7b950665d00bc6eefa409462ef118099c8eb6f0a1b9f66ff1e8 | 26 | 2 | from .chat_model import ChatModel  __all__ = ["AllModels"]  AllModels: TypeAlias = Union[ |
| .venv/lib/python3.13/site-packages/openai/types/shared/__init__.py | 11593e5f53f747b6169a5626adba4cae301e6447d57ee745f93c3b7db382f74a | 20 | 2 | from .metadata import Metadata as Metadata from .reasoning import Reasoning as Reasoning from .all_models import AllModels as AllModels from .chat_model import ChatModel as ChatModel from .error_objec |
| .venv/lib/python3.13/site-packages/openai/types/shared/chat_model.py | e95a43c3c6d93eb7b3ce337c51f0702a9216a246a4814fb5dab74bcd0ba52c7a | 71 | 49 |  ChatModel: TypeAlias = Literal[     "gpt-5",     "gpt-5-mini",     "gpt-5-nano", |
| .venv/lib/python3.13/site-packages/openai/types/shared_params/chat_model.py | 4b424ede532d699ec21bc66f8d871196cf82179a8b2fb014503ba3d6979e2831 | 73 | 49 |  ChatModel: TypeAlias = Literal[     "gpt-5",     "gpt-5-mini",     "gpt-5-nano", |
| .venv/lib/python3.13/site-packages/openai/types/realtime/realtime_transcription_session_create_request.py | 360c714a2bacfd3b799c4590756f3507734f682ca52c43ac422a6496b020db77 | 129 | 9 |     """      model: Optional[Literal["gpt-4o-transcribe", "gpt-4o-mini-transcribe", "whisper-1"]] = None     """     The model to use for transcription, current options are `gpt-4o-transcribe`, |
| .venv/lib/python3.13/site-packages/openai/types/realtime/realtime_transcription_session_create_request_param.py | b54f6777335f42026f1af9f92380f51a4a1c382c241e3b46e3b0c8e10b00c6ff | 129 | 9 |     """      model: Literal["gpt-4o-transcribe", "gpt-4o-mini-transcribe", "whisper-1"]     """     The model to use for transcription, current options are `gpt-4o-transcribe`, |
| .venv/lib/python3.13/site-packages/openai/types/realtime/realtime_session.py | e23806b4cdb879efad84a0fcdc42dee11f804c4170e59f95421119c56a2c228c | 308 | 11 |     model: Optional[str] = None     """     The model to use for transcription, current options are `gpt-4o-transcribe`,     `gpt-4o-mini-transcribe`, and `whisper-1`.     """ |
| .venv/lib/python3.13/site-packages/openai/types/realtime/realtime_audio_config_param.py | 44ed722c11584f52b998ba8b81a1b6994722551372e761beeccc6f59c515de7f | 188 | 9 |     model: Literal[         "whisper-1",         "gpt-4o-transcribe-latest",         "gpt-4o-mini-transcribe",         "gpt-4o-transcribe", |
| .venv/lib/python3.13/site-packages/openai/types/realtime/realtime_tools_config_union_param.py | 4230f8cbdd1a5d9f52670df02c5d2c8679e824c02a0b2e6da1d3974a50aeff68 | 158 | 1 |         "connector_sharepoint",     ]     """Identifier for service connectors, like those available in ChatGPT.      One of `server_url` or `connector_id` must be provided. Learn more about service |
| .venv/lib/python3.13/site-packages/openai/types/realtime/realtime_tools_config_union.py | f2f5f5dbbe688a0db19a2adfb80811d4a5e7dda4723bb93d2630a0da25517a94 | 159 | 1 |         ]     ] = None     """Identifier for service connectors, like those available in ChatGPT.      One of `server_url` or `connector_id` must be provided. Learn more about service |
| .venv/lib/python3.13/site-packages/openai/types/realtime/transcription_session_updated_event.py | 69df103c3132574923fd198d5dc4ba4d97a0a9ce47e9d6eec6545630701575b1 | 106 | 4 |     """      model: Optional[Literal["gpt-4o-transcribe", "gpt-4o-mini-transcribe", "whisper-1"]] = None     """The model to use for transcription.  |
| .venv/lib/python3.13/site-packages/openai/types/realtime/realtime_audio_config.py | fbbf54d396dd4229df55f38b6d07cb383153fe12ef1d0a129d46f1a53bf353b0 | 185 | 9 |         Literal[             "whisper-1",             "gpt-4o-transcribe-latest",             "gpt-4o-mini-transcribe",             "gpt-4o-transcribe", |
| .venv/lib/python3.13/site-packages/openai/types/realtime/realtime_session_create_request_param.py | e0c77ea60388bfd36dccdf0d91de423426ade5e953503496cb34ea07c4bfa9ef | 122 | 10 |             str,             Literal[                 "gpt-realtime",                 "gpt-realtime-2025-08-28",                 "gpt-4o-realtime", |
| .venv/lib/python3.13/site-packages/openai/types/realtime/transcription_session_created.py | 010aec2206c47cf5e263bc22b9a1689c34bb0154884390f2260ad6bc1ef709b8 | 106 | 4 |     """      model: Optional[Literal["gpt-4o-transcribe", "gpt-4o-mini-transcribe", "whisper-1"]] = None     """The model to use for transcription.  |
| .venv/lib/python3.13/site-packages/openai/types/realtime/realtime_session_create_request.py | b76e41d8f5ddd6665a43b8ecf3034e84bd247457c0a62224bfe9505cb8847705 | 119 | 10 |         str,         Literal[             "gpt-realtime",             "gpt-realtime-2025-08-28",             "gpt-4o-realtime", |
| .venv/lib/python3.13/site-packages/openai/types/realtime/realtime_tools_config_param.py | 0e5f92fa1de002bcbb8bafa93b428421f74c39e65137343e7c2db709600409c7 | 161 | 1 |         "connector_sharepoint",     ]     """Identifier for service connectors, like those available in ChatGPT.      One of `server_url` or `connector_id` must be provided. Learn more about service |
| .venv/lib/python3.13/site-packages/openai/types/realtime/client_secret_create_response.py | f43a605b16fc8c687c97a77f7555dfaae60eb1a0e848c87aa36d8f32ad54f440 | 111 | 4 |     """      model: Optional[Literal["gpt-4o-transcribe", "gpt-4o-mini-transcribe", "whisper-1"]] = None     """The model to use for transcription.  |
| .venv/lib/python3.13/site-packages/openai/types/audio/transcription.py | 954977a9d8e0acaf78cc28e0a43e1ff716bdc3ebcd84e4f187d84f7988f7ca67 | 72 | 2 |     """The log probabilities of the tokens in the transcription.      Only returned with the models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`     if `logprobs` is added to the `include` array.  |
| .venv/lib/python3.13/site-packages/openai/types/audio/speech_model.py | 8bf62a099e0058dd23098ef417c1406b3400b1b4321be554406c522672ecbe2c | 8 | 1 | __all__ = ["SpeechModel"]  SpeechModel: TypeAlias = Literal["tts-1", "tts-1-hd", "gpt-4o-mini-tts"] |
| .venv/lib/python3.13/site-packages/openai/types/audio/speech_create_params.py | bbb15069b8cb3a036166ee05332935b1af6a6da76b996cdcf959d27ac657cf73 | 58 | 1 |     """     One of the available [TTS models](https://platform.openai.com/docs/models#tts):     `tts-1`, `tts-1-hd` or `gpt-4o-mini-tts`.     """  |
| .venv/lib/python3.13/site-packages/openai/types/audio/transcription_create_params.py | 815fb6badaaa3f16f14a164308f77f8e177a2e3c93d4d53d5d524e82dcb98747 | 150 | 6 |     """ID of the model to use.      The options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1`     (which is powered by our open source Whisper V2 model).     """ |
| .venv/lib/python3.13/site-packages/openai/resources/files.py | 3eb6bc9cd6ae92000ceaa5dc9cadd1cbb8ab78174c55c9c6cc8f6fb713f5cacd | 773 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/models.py | 0b32e90793a3d71ed4e9e34a39c2b467b33e363108a59bdd5902c3032226ef03 | 307 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/moderations.py | dd5283c55b7b9d6c8add21aafbb043cdfc6025644211162da0696e843c56a5d5 | 198 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/__init__.py | defc54158162d08d09435b5b43c8ab98788708d778b09d4f734fc49d59364b11 | 216 | 26 |     AsyncContainersWithStreamingResponse, ) from .embeddings import (     Embeddings,     AsyncEmbeddings, |
| .venv/lib/python3.13/site-packages/openai/resources/completions.py | 50d1e9f4d3b91c21bf4806c5dad6e5c2b3497aa5b81fc8959301c1c9e57bcd4d | 1161 | 24 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/embeddings.py | 710a7add8fb77cdce5c71244cc57e05c5a199e9a959978ff1f17527e09d1e54e | 299 | 91 |  from .. import _legacy_response from ..types import embedding_create_params from .._types import NOT_GIVEN, Body, Query, Headers, NotGiven, SequenceNotStr from .._utils import is_given, maybe_transfo |
| .venv/lib/python3.13/site-packages/openai/resources/images.py | a8533e5bd86480ed5138f6bb54a4871093f02f540ab4ea3507490d0a035e5327 | 1861 | 142 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/batches.py | a99860e28d95a4f5c839b536d9df89176491163b5e04d0f1dcdb58677dd0258a | 525 | 12 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/beta/assistants.py | b23c7380b3865aa88cee7b24802c4d216834b5490c05d02701f2688e610aeb9f | 1022 | 122 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/beta/beta.py | 63241e422cbb81dcbabf21bd434014a82cc56fa3b0d4114a5e3e90bed1c58432 | 156 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/beta/realtime/sessions.py | 5f05bcefb206a916439790c1d39e4a72bac0b33e18ac5a154d5178d2d80cc554 | 421 | 18 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/beta/realtime/realtime.py | b6e8aaff43dd1660b6a7e2cd39f40dad5b8310c94b00728481e02c3ec1cb5075 | 1095 | 10 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/beta/realtime/transcription_sessions.py | b930c611ab79d25a23743d0df2c96766ed9157330ff7aae589ca43a78b69977e | 283 | 6 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/beta/threads/threads.py | 2f78f4c889c9523da99b6d8378d4d5296d10959f91b06b9b7185a69c39adb69c | 1936 | 68 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/beta/threads/messages.py | 32b7351c0511697781509cd95259e3276e3289231f7ef68668164a48a47d1fa4 | 719 | 14 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/beta/threads/runs/steps.py | 2fec2f2a209bc8fd5cb0fdf03aef620c0d886524859a85f9c59b0d789f9c3ce1 | 400 | 8 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/beta/threads/runs/runs.py | 5f7cd0d8ec7b58fca7ad21b5d856f4d05d5df2be7ae9ae449063b43cba700ce0 | 3081 | 66 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/vector_stores/files.py | e1a9137ef31340e94f918e9b07afbc40bbb118fb2b9bfefcb7b51d26dc9a34af | 940 | 185 | from ...pagination import SyncPage, AsyncPage, SyncCursorPage, AsyncCursorPage from ..._base_client import AsyncPaginator, make_request_options from ...types.vector_stores import file_list_params, fil |
| .venv/lib/python3.13/site-packages/openai/resources/vector_stores/vector_stores.py | e9bdac4ec92af180f66ef6178a1217a84cc99e6431c4b294ed4c233ba57a5258 | 866 | 220 | from ...types import (     FileChunkingStrategyParam,     vector_store_list_params,     vector_store_create_params,     vector_store_search_params, |
| .venv/lib/python3.13/site-packages/openai/resources/vector_stores/__init__.py | d755e7d6f8609dd5a223475e7c91efdf5be66ed6c3821d86c194f7817f068079 | 48 | 13 |     AsyncFileBatchesWithStreamingResponse, ) from .vector_stores import (     VectorStores,     AsyncVectorStores, |
| .venv/lib/python3.13/site-packages/openai/resources/vector_stores/file_batches.py | 532f3e9baf796282666e3c902196881fd51dae5f0c22b78773b541e6295066dd | 798 | 130 | from ..._base_client import AsyncPaginator, make_request_options from ...types.file_object import FileObject from ...types.vector_stores import file_batch_create_params, file_batch_list_files_params f |
| .venv/lib/python3.13/site-packages/openai/resources/evals/evals.py | c0c3019f9e13cf530ff721be19fb628833e572c4e2cf8384b6e0a7e1589cda4d | 663 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/evals/runs/output_items.py | 8c4452f1a78da59082a6c57eb5faf2de3629c68d796dac568f47b28e27fcb746 | 316 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/evals/runs/runs.py | 5c5c7073274e1342dc4ee08e45ed05d6ae458e3ba98043487790ba036edaabbf | 635 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/fine_tuning/fine_tuning.py | 50be0c5e852a1276d26797b87676d43d3b5de2d13ed69d8bec787fd0243fd2cd | 167 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/fine_tuning/checkpoints/checkpoints.py | 9e3a73e3de8989f799f115e3a1851bd538fdb4122db974711891d6da3aeb7f0a | 103 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/fine_tuning/checkpoints/permissions.py | 8a064e61c36d9a59e84055f7437223c0d4b67c8cc0bb18040539b0cdb85e6dde | 419 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/fine_tuning/jobs/checkpoints.py | 67aa7f201ce656ede84657712ca54a1959b513c5dfed452722d4a757b3c923d6 | 200 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/fine_tuning/jobs/jobs.py | 8159c92abbcef8a28be21ab78141d8e2231d00c91a1ff961367cb305ff9c6867 | 919 | 10 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/fine_tuning/alpha/graders.py | 4f6d84fc876faf0464c651659fcec44c0001bd6b24b8dc9f98f2e1477d5b4c5e | 283 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/fine_tuning/alpha/alpha.py | 3feccb387a48f806b48d4516b2991a9cbed6a54b5f8f02060c7f0a4c60cd7876 | 103 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/chat/chat.py | 1e371ab120a6b7e837f89f9191943d1d18fffa13df2266a4171754bef9399828 | 103 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py | 5c852bbc2cf8a7bf029b4b1867e31fbb7b3289e4530986dd7a8cf2014308a10d | 3050 | 22 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/chat/completions/messages.py | 1c2647dba4ee4f2bae6a3272f0c57ef88ae7e021cc414484b7d0b78fe13936fc | 213 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/responses/responses.py | cd10f38d8faeb803770a27ad7c06982a1d24892b47063e01ca74c071e24ad437 | 3047 | 16 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/responses/input_items.py | 50aa95cff4ff4a04beac05f9898588f574635046aabf63753fddf6322c739638 | 227 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/uploads/parts.py | 9fe1baac5154693b3839dd6ddfb6ef3b31346d5d952f03838c505d6e9b27916d | 206 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/uploads/uploads.py | b01cfcbef72ea823c77a2a8e8fd8fa934aba7670cb61253bd62bd9620863402b | 722 | 10 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/realtime/client_secrets.py | 048943efa6b5ac16cee68488f39be01dae9a970f888a1f0b3081dedaacb2c248 | 186 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/realtime/realtime.py | cdb3f64c3ea55cefe770d969d342e131ce5d551ad96461c94d2d16105d0f8011 | 1059 | 8 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/audio/translations.py | df3e8aa197eacb4022613052f96c10c7e64559c301265b916821eca0797227af | 368 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/audio/audio.py | 9c4201e2aedad4c49875091c607d8eea307efeb34230308127252ea8e2faec22 | 167 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/audio/transcriptions.py | f15b7e89b36e202a27780cfa2134326bfd0d66420d8c97520ef577046f3e3ea4 | 783 | 34 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/audio/speech.py | 3ae77f9fb308bd0ddd98e61cc2cae0975f1bf7ee0e980d0c44bd2168180b0bd8 | 256 | 6 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/conversations/items.py | 0f76614ffe6e1890f4d6c326b68a76ba48be5125790304b79e611cfa10546f3a | 558 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/conversations/conversations.py | ed83e06ad419629e33f799fbdaccd0475ad338f3b951f5a8013003889332699c | 475 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/containers/containers.py | 92133aa934716da0ddb697317b84e8c22c9584cc349a788e3c81560348b79d52 | 511 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/containers/files/files.py | fa254150b4aac83a34bc784c87db5007a2134faca0bb9ef3f64e80f55ab49aaa | 546 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/resources/containers/files/content.py | 39b0b29154e949715dcd951f1ffcec64c2eda2e6193648c19ae803a08235908b | 174 | 4 |         the raw response object instead of the parsed content.          For more information, see https://www.github.com/openai/openai-python#accessing-raw-response-data-eg-headers         """         |
| .venv/lib/python3.13/site-packages/openai/cli/_cli.py | e368ff788f0f3dd15b563b9f96eade8263584ddc2bc37c90b6c1ed4f3c8dbdc4 | 234 | 1 |     parser.add_argument(         "--api-version",         help="The Azure API version, e.g. 'https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning'",     )  |
| .venv/lib/python3.13/site-packages/openai/cli/_tools/migrate.py | a3e8a89b386d0ba37a5f91f918396043f40e688a2f136600f681dcfed200523f | 165 | 1 |     platform = "apple-darwin" if sys.platform == "darwin" else "unknown-linux-gnu"      dir_name = _cache_dir() / "openai-python"     install_dir = dir_name / ".install"     target_dir = install_dir / |
| .venv/lib/python3.13/site-packages/openai/lib/_old_api.py | 5d99d706b10ab9377bd22262ae3e66196df97d9a2aaee2686db053aba6ef835d | 73 | 3 | INSTRUCTIONS = """  You tried to access openai.{symbol}, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.  You can run `openai  |
| .venv/lib/python3.13/site-packages/openai/lib/_validators.py | 71725716e68097b8de25c6075d79c56b83471ad1ecfbfceddd9b355550a6428e | 810 | 1 |         expected_time = num_examples * 1.44     else:         size = df.memory_usage(index=True).sum()         expected_time = size * 0.0515  |
| .venv/lib/python3.13/site-packages/openai/lib/azure.py | 74bcd45d35d43a77daacb743c8ee9d573a7cc18daf4cc1451d42592ee1739d66 | 648 | 1 |         "/completions",         "/chat/completions",         "/embeddings",         "/audio/transcriptions",         "/audio/translations", |
| .venv/lib/python3.13/site-packages/stevedore/hook.py | a599480727d76937684f3302ad3fd4f0f387b55dcc47834f8400896c520b1f3e | 90 | 1 |                  verify_requirements=False,                  on_missing_entrypoints_callback=None,                  # NOTE(dhellmann): This default is different from the                  # base class  |
| .venv/lib/python3.13/site-packages/stevedore/extension.py | 59d68bf0e5d89f33ffd9feb56c15e34a19ac76d6ded1a6548d55fd0717aca09e | 345 | 1 |     def _load_one_plugin(self, ep, invoke_on_load, invoke_args, invoke_kwds,                          verify_requirements):         # NOTE(dhellmann): Using require=False is deprecated in         # se |
| .venv/lib/python3.13/site-packages/stevedore/example2/setup.py | 90f57f3ca2684862a6bccf5ffc815c9649ab03580d122222bc20cd259e2a35e6 | 58 | 2 |     description='Demonstration package for stevedore',      author='Doug Hellmann',     author_email='doug@doughellmann.com',  |
| .venv/lib/python3.13/site-packages/stevedore/example/setup.py | 0f0d1299f58706fe6eb1e2c5cd1d9461bf37cf0f407a41364d1eb79cf6f24e6d | 59 | 2 |     description='Demonstration package for stevedore',      author='Doug Hellmann',     author_email='doug@doughellmann.com',  |
| .venv/lib/python3.13/site-packages/_pytest/raises.py | 22e1d3740ad3abaa4edf886334510768a67de59509124f60592d14c54248dc5c | 1520 | 1 |         When raised exceptions don't match the expected ones, you'll get a detailed error         message explaining why. This includes ``repr(check)`` if set, which in Python can be         overly ve |
| .venv/lib/python3.13/site-packages/_pytest/assertion/util.py | ddf80fa6b54357bb82682e7ec89ea3bf1ce9d90a97c5eed3c5e925770b8997ed | 622 | 1 |     for dataclasses the default co_filename is <string>, for attrs class, the __eq__ should contain "attrs eq generated"     """     # inspired from https://github.com/willmcgugan/rich/blob/07d51ffc1a |
| .venv/lib/python3.13/site-packages/_pytest/_io/pprint.py | 18b04a2fa7669d1afdd869d53243733242aac74f0ea7bb5d2527a1dc07b0a276 | 674 | 1 | # This module was imported from the cpython standard library # (https://github.com/python/cpython/) at commit # c5140945c723ae6c4b7ee81ff720ac8ea4b52cfd (python3.12). # # |
| .venv/lib/python3.13/site-packages/platformdirs/windows.py | 205a62a21501c313ed0b39722b036dc725b8264f2169ae96f28e7d99fac35d5a | 273 | 1 |         "CSIDL_LOCAL_APPDATA": "Local AppData",         "CSIDL_PERSONAL": "Personal",         "CSIDL_DOWNLOADS": "{374DE290-123F-4565-9164-39C4925E467B}",         "CSIDL_MYPICTURES": "My Pictures",    |
| .venv/lib/python3.13/site-packages/watchfiles/run.py | 4cb5dbdb2ff1631faddf1caccd54161e81b21bb4426f5d3b43436821c4969a34 | 439 | 1 |     elif target.endswith(('.py', '.sh')):         return 'command'     elif re.fullmatch(r'[a-zA-Z0-9_]+(\.[a-zA-Z0-9_]+)+', target):         return 'function'     else: |
| .venv/lib/python3.13/site-packages/pyflakes/checker.py | 41ae94414abfde69dba520490a3a678baa271852d94eb299439e0733709294eb | 2224 | 1 |             # assignments are allowed before a stared expression. There is             # also a limit of 1<<24 expressions after the starred expression,             # which is impossible to test due t |
| .venv/lib/python3.13/site-packages/pyflakes/test/test_undefined_names.py | f87ee90a6ef9d0e5d858fe7efcbc59c95a08b7030cfb06e775dd0710f028d671 | 820 | 1 |         self.flakes('''         try:             _memoryview.contiguous         except (NameError, AttributeError):             raise RuntimeError("Python >= 3.3 is required") |
| .venv/lib/python3.13/site-packages/pyflakes/test/test_other.py | 0c3ccfdf69b46fcd7795d6704e0071e31777631ec11b7268053e03908d48e1e4 | 2151 | 2 |         ''')      def test_extendedSlice(self):         """         Extended slices are supported. |
| .venv/lib/python3.13/site-packages/yamllint/linter.py | 8e349a38f3b6c7bfd69d0d2cd0144a13de65ab106e1fb89c986e742c418f4e3b | 238 | 1 |         return _run(input, conf, filepath)     elif isinstance(input, io.IOBase):         # We need to have everything in memory to parse correctly         content = input.read()         return _run(c |
| scripts/evaluate_research.py | fb84571b2c61e10cfd71c4c75bbbcac77900d4f1ced3203a2c1753768a15427f | 104 | 7 |   def simulate_llm_as_judge(query: str, report_content: str) -> dict:     """     Simulates an LLM call to evaluate the relevance and quality of a report. |
| scripts/memory_coherence_gate.py | a89c30abe164c7157305e12d7fbc1ded44e683ae3821824c0af56cd156d738b7 | 66 | 14 |   def compute_drift(a: str, b: str) -> float:     """Return a simple drift score in [0,1], higher = more drift.  |
| scripts/docs_parity_check.py | d1b4fc6d6e36edcff06620a271b27e35921494688634925fdf3eb0bd6968b735 | 26 | 2 |     2. Use the DocsProvider to fetch the documentation for those functions.     3. Compare the function signatures (e.g., argument names, types) from the code        with the documentation to detect d |
| scripts/r2p_check.py | d14defffeb3dd122b6d3fa7b13a0aa52b1380107c9bd7dc5e2fea44d47d20dd5 | 72 | 5 |  TOUCH_PATHS = (     "src/agent_core/",     "src/orchestrator/",     "src/mapping/", |
| scripts/perf_hist.py | 3b94d16e35eee132c157f0c357a70d02f97bc812d9fd9771059342da873bc66e | 77 | 3 | def run_once(goal: str) -> None:     # Import inside to avoid startup overhead in arg parsing     from orchestrator.graph import PlanToolReflect      runner = PlanToolReflect() |
| scripts/audit_synthesis.py | cec60ab86c263244c4c7bdd7b3fc56e8c4d6630d28b384f5b7043e47d0d5ea77 | 187 | 1 |     )     plan.append("")     plan.append("Owner: Project (You + Agent) — single-owner model")     out.write_text("\n".join(plan) + "\n", encoding="utf-8")  |
| scripts/virtue_log.py | 04dab00131c9459a64998aa55d7155ae9cf9fc2e3767e1364f14d4515f05c5fc | 35 | 1 |   OUT = Path("agent/outcomes/virtue_log.jsonl") OUT.parent.mkdir(parents=True, exist_ok=True)  |
| scripts/inspect_vector_store.py | f789ce013615a782f82a37cd95f61da0bed803154b6641b19f7c80022840808a | 262 | 32 | #!/usr/bin/env python3 """ Vector Store Inspection Tool  This script connects to the ChromaDB vector store and validates that entries |
| scripts/audit_agent_loops.py | 7b4af28b7f7812604c8852620bd45a12dfa771eee500e3232dbceb22a2d827a2 | 119 | 24 |     (         "Planner",         "packages/agent_core/agent_core/planner.py",         ["planner", "plan", "operational loop"],     ), |
| scripts/fix_coherence.py | 23d3bf300917edc0b78af03df1e7f7b6532377664be0bc634d3b113a442883cb | 51 | 4 |     repo = Path(__file__).resolve().parents[1]     insert_link(         repo / "docs/AGENTIC_ARCHITECTURE.md",         "agents/ORCHESTRATION_ARCHITECTURE.md",         "Orchestration & Interop", |
| scripts/audit_best_practice.py | 085ea198f08eec8366742ab87720cb825e43d347bdb192bc6d2e3db8831b1ffa | 64 | 1 |     "Data": ["GDPR/DPIA", "Data Lineage (OpenLineage)"],     "Docs": ["Docs-as-code"],     "Agentic": ["NIST AI RMF", "Safe Autonomy Policies"],     "Process": ["Lean/Agile"], } |
| scripts/audit_rule_normalize.py | a6e5070b20b358900021da580e0c893fe26f6af73a4dc55b322cd7517fadc2ff | 88 | 3 |     ):         cat = "CI/CD"     elif any(k in source for k in ["AGENTIC_ARCHITECTURE", "ADR/0002"]) or "agent" in t:         cat = "Agentic"     elif any(k in source for k in ["SECURITY", "ADR/"]) or |
| scripts/policy_lint.py | 3765c7f10739e9f224d05299a1d202b68b2e71c965aa96d9977c6203f0b04729 | 67 | 1 | import yaml  POLICY = Path(".agent/policy.yaml")   |
| scripts/test_rag_functionality.py | bf186f65a4fd2568881058a631bc81e07327aefa715db2c9b901c54126b901e8 | 109 | 7 | sys.path.insert(0, str(Path(__file__).parent.parent / "src"))  from agent_core.memory.rag_store import RAGMemory  def test_rag_functionality(): |
| scripts/meta_audit.py | ddee5c5390a46c205949ab8d1040e1ffc910c1f935a0b68af046c7c3470c4739 | 376 | 86 | FILE_EXTS = {".py", ".md", ".yml", ".yaml", ".json", ".toml"} META_DIR_RX = re.compile(     r"(ai\|meta\|agent\|gpt\|llm\|auto\|bot\|orchestrat\|reflect\|memory\|embed\|vector\|knowledge\|graph\|rule\|dsl\|c4\|structu |
| scripts/suggest_past_fixes.py | 6d1135a1d954c7d162e415dd4c857b0f6da7b7c5c685425a42b6db3fa8278fe0 | 57 | 1 | from typing import Iterable  OUT_DIR = Path("agent/outcomes")   |
| scripts/agent_outcomes.py | 71d548e4bbb9d735dbbd830fe9c3e599aa4d78eb9ec1a72f7d88cc5c59459ef7 | 66 | 2 | from pathlib import Path  OUT_DIR = Path("agent/outcomes") OUT_DIR.mkdir(parents=True, exist_ok=True)  |
| scripts/outcomes_summary.py | 89f1b60ef847b503384ef4b405c2ca451b2e77884cc666261832624d43594ec7 | 75 | 3 | from typing import Iterable  OUT_DIR = Path("agent/outcomes") REPORT = Path("docs/audit/agent_outcomes_summary.md")  |
| scripts/refactor_guard.py | e09326e6795e459d27201a83221e0d905976af4ee39a1b3980b7b076b7e34ba4 | 619 | 1 |     failed: List[str] = []     for line in out.splitlines():         # Example: FAILED src/orchestrator/tests/test_api_server_smoke.py::test_metrics_endpoint - AssertionError         if line.startswit |
| scripts/deploy_orchestrator.py | eb86b5527ac37191bae5e77d86523ff01852b057ad7e0013558b9f4c09048a0a | 707 | 10 | #!/usr/bin/env python3 """ Deployment Orchestrator  This script orchestrates deployments across different environments using |
| scripts/prepare_pr_notes.py | 7d2517fd9d5bce1a39659de865102f2c75da18bcb62678b9fb917ef424b5ccb0 | 99 | 1 | from pathlib import Path  OUT = Path("agent/outcomes/PR_NOTES.md") OUT.parent.mkdir(parents=True, exist_ok=True)  |
| scripts/import_guard.py | 159696b91175e7d3a4a751eb0a2f38f49d50ae850a912e941407f35b26dcc242 | 43 | 8 |   DISALLOWED = re.compile(r"^\s*from\s+src\.agent_core\.\|^\s*import\s+src\.agent_core\.") ALLOWLIST = {     ROOT / "src" / "orchestrator" / "src" / "orchestrator" / "agent_core_adapter.py", |
| scripts/ingest_text.py | 7907bcc15dfa60cdfc6d0a4c5063bdf7f86fa3f963dece058a31bb012ec6414b | 66 | 7 | from pathlib import Path  from src.agent_core.memory.rag_store import RAGMemory   |
| scripts/research/index_docs.py | 2ed01632606faf0cebc636f7d64eee00dd7d29e53b1df26d3cd40c380708fe2f | 138 | 12 |  This utility is designed to run in PR CI without network access. It can ingest fixture JSON files (e.g., W3C TR index) and write a VectorIndex storage JSON.  Usage (Python): |
| scripts/research/run_poc.py | 83b82b988a8be792d6906b85ca78a2ff42031b0388014d413a70ceff9a0453ad | 86 | 3 |         "manifest_id": manifest.get("id"),         "chunking": manifest.get("chunking", {}),         "embedding_model": manifest.get("embedding", {}).get("model"),         "items_processed": 0,        |
| scripts/research/eval_rag.py | 389bbb080594b6b8c6713d1a7b37bda8a0c31d7d543727fdc31a8b66b546adcc | 33 | 3 | """Offline RAG eval (minimal).  Loads a VectorIndex storage and runs a small set of queries, printing top hit ids. """  |
| scripts/research/fetcher.py | 59d32758245fa6db8e4de4e84bbd5d3ae9b4e6ca5f96757eae8c55d0af2a8ec2 | 187 | 7 |   def _robots_allowed(url: str, user_agent: str = "ISA-ResearchBot") -> bool:     try:         from urllib import robotparser |
| scripts/research/connectors/federal_register_live.py | f8e1ae46d5b9e3863d175828a68bb7b67d43e825ed87353b15d4dcbe462a76c2 | 54 | 1 |     url = "https://www.federalregister.gov/api/v1/documents.json"     params = {"per_page": limit, "search": query}     headers = {"User-Agent": "ISA-ResearchBot"}     r = requests.get(url, params=par |
| scripts/research/tests/test_index_fr_integration.py | ba184dc63313821cae59e3fa12fbc8bdd50315321671c93f71dae0c7d1569cad | 13 | 1 |   def test_index_fr_fixture_builds_vector_index(tmp_path: Path):     fixture = Path(__file__).parent / "fixtures" / "federal_register_sample.json"     storage = tmp_path / "research_index_fr.json" |
| scripts/research/tests/test_index_integration.py | bb2cbdf226892dddd00df7929d68e19c762c41fadd541b84ae90257d213d625f | 15 | 1 |   def test_index_tr_fixture_builds_vector_index(tmp_path: Path):     # Use fixture JSON and a temp storage path     fixture = Path(__file__).parent / "fixtures" / "w3c_tr_index.json" |
| scripts/tests/test_ingest_text.py | c6d5ebc2fee8fadf0582178fc4e4ab5990c229b2fa0b6e4183232e806071e9af | 50 | 1 |  def test_ingest_text_writes_manifest(tmp_path, monkeypatch):     # Work in a temp directory so vector store persistence is isolated     monkeypatch.chdir(tmp_path)  |
| .agent/policy.yaml | 2394f1d1868e97d6f16d3501662e1353d485ea78e6711477461cd43a0249e8a3 | 43 | 2 |  kill_switch:   label: policy/agent-blocked   endpoint: /agent/kill  |
| .agent/virtuous_cycle.md | b507453ed638786235f7496424262bbef93ab7eebfb460989fb9209e67b6138f | 106 | 13 | # 🌀 Virtuous-Cycle Meta-Prompt – ISA_D Perpetual OODA Loop Version: 2025-W38   Reasoning: HIGH   |
| .vscode/settings.json | acad9a908ce96223d37d722866f233658204893ffae54f87270a1ab003bc900a | 13 | 1 |         }     },     "chatgpt.config": {} } |
| data/data_catalog.yaml | e87c0b044d381c64078fc03362270a153243d83ad4c106c0c10de8d66a039de7 | 279 | 30 |   last_updated: "2025-09-14T19:45:00Z"   maintainer: "ISA Data Team"   description: "Central catalog for all data sources ingested into the ISA vector store"  # Data sources are organized by category |
| data/ingestion_manifests/isa_docs_v1_manifest.yaml | 891944d6c5688866393a2fad852a8c84857239b84033ae7441c218bef3cf8e97 | 27 | 4 | # Ingestion manifest example for isa_docs_v1 # Connects canonical doc sources to the vector store schema.  id: isa_docs_v1_manifest |
| data/ingestion_manifests/isa_goals_pdfs_manifest.yaml | ece097513225e144d4cae2cb328d52cb70675656aa3b4339b3f63dc0aed7fc50 | 27 | 7 | # Ingestion manifest for ISA goals PDFs (advisory) # Connects historical ISA goals/vision PDFs to the vector store schema for research memory.  id: isa_goals_pdfs_manifest |
| orchestrator/__init__.py | 9aae761380c11a0beea7be5e976b52f942af108fcd3f104d177fd7249d3ca446 | 35 | 4 | """Lightweight orchestrator shims for tests.  This repo variant keeps the full orchestrator graphs elsewhere. To satisfy |
| src/api_server.py | 482a77231f1556296f5130314869862748e9573b26721f9dc456d628af8a54f2 | 92 | 23 | from prometheus_client import CONTENT_TYPE_LATEST, Counter, Histogram, generate_latest  from src.agent_core.agents.planner import PlannerAgent from src.agent_core.agents.researcher import ResearcherAg |
| src/llm/pyproject.toml | a44626948e9389a63593692d56e8f2dd859e2471f7c69138670002b2727d5d5b | 18 | 3 |  [project] name = "isa-llm-runtime-stub" version = "0.0.0" description = "ISA LLM runtime stub package" |
| src/llm/README.md | 20f2657a02332bb080a944f8138eabd5b240d58c49949199d91176ecc5f9ad3b | 8 | 1 | Title: LLM Runtime Layer — Parity Stubs Last updated: 2025-09-02  |
| src/llm/tests/conftest.py | e1ab989af5dc710a41be2ce63a8403909d08cbb9f780a2c5b1482638d010c7d6 | 7 | 1 |  REPO = Path(__file__).resolve().parents[3] PKG_SRC = REPO / "packages" / "llm" / "src" sys.path.insert(0, str(PKG_SRC)) |
| src/llm/tests/test_parity.py | 6fcd97b221525de4c1d0b358da6b9103dde157bccea31bf560453fcb6543f1a2 | 15 | 5 | from llm_runtime import LlmRuntime   |
| src/llm/src/llm_runtime/__init__.py | 0ce6d67a5787d8182a255d68232eb3dc7624bf1dd54162ca30a3b1fc9e246f9c | 2 | 2 | from .runtime import BedrockAgentsStub, LlmRuntime, OpenAIResponsesStub  # noqa: F401 |
| src/llm/src/llm_runtime/runtime.py | 3b0a30b43ac2ddec282fd2f924b9a51e8f328f49dbc27faf0fb04313575049ea | 46 | 3 |   class BedrockAgentsStub:     def chat(self, messages: List[Dict[str, str]], model: str, **kw) -> Dict[str, Any]:         return { |
| src/docs_provider/src/docs_provider/context7.py | 7eb07e015e4cef99d775e68a85f3550f8f07448ae14d6a3121dcb361dcecc975 | 176 | 6 |         ]      def _log_memory_event(self, query: str, libs: List[str], cache_hit: bool):         """Logs a memory event for the API call."""         try: |
| src/agent_core/pyproject.toml | 0fb4c8d5f0f23b11991af189480db5588dbdd2d0ed4909ab2059a1369c64435f | 12 | 3 |  [project] name = "agent_core" version = "0.0.1" description = "Core primitives for planner/builder/verifier/critic agents with policy and rewards." |
| src/agent_core/README.md | b05b5dee350d418bf8441a2889864abc9ff301f150ae43c2d9ad6571d03d8002 | 16 | 3 | Last updated: 2025-09-02 Agent Core (Skeleton)  Purpose: Provide minimal, typed modules for the agent roles and policies. |
| src/agent_core/memory/rag_store.py | 433910e5d2298af6cb01cadd671345e01b90e75341331c80303d6447d7259cfe | 769 | 35 |  import chromadb from chromadb.utils import embedding_functions from pydantic import BaseModel, Field, validator  |
| src/agent_core/tests/test_agent_parity.py | a28d61e2743ac4b280259d75f0cc5b605ee79b8894f9688983fc7f95346ef134 | 77 | 25 | import typing as t  from src.agent_core.agents.planner import PlannerAgent from src.agent_core.agents.researcher import ResearcherAgent from src.agent_core.agents.synthesizer import SynthesizerAgent |
| src/agent_core/tests/test_rag_memory_schema.py | 3bed9688200c712f0348c4fbb3c305f3efd194543633cde6d7acdb126c96d60d | 45 | 8 | from pathlib import Path  from src.agent_core.memory.rag_store import RAGMemory   |
| src/agent_core/agents/planner.py | 7c214b4f052c48ab542f540c61f140044908f6d7b61d5736851e99c7f3122f72 | 76 | 9 |   class PlannerAgent:     """     An agent that takes a high-level research goal and breaks it down into |
| src/agent_core/agents/synthesizer.py | ab68edd9df9fd2e8dba6d63673d1f5a8afa2255a659cfd7219f0702f1b6d4dc5 | 77 | 20 | import logging  from src.agent_core.memory.rag_store import RAGMemory  # Configure logging |
| src/agent_core/agents/researcher.py | eeae017d44714b8eadc8692cd3792384ef97a8a4d8496f45f694b55259a33b9a | 117 | 43 | import logging  from src.agent_core.memory.rag_store import RAGMemory from src.tools.web_research import WebResearchTool  |
| src/agent_core/agent_core/memory.py | a0ba143666f294b1a90f196bbbac0a2d518f303679d5f5cf8eabcc2c3063f953 | 16 | 1 |     """Appends JSONL events to a trace file (skeleton)."""      def __init__(self, path: str = ".agent_traces.jsonl"):         self.path = Path(path)  |
| src/agent_core/agent_core/__init__.py | a1f81e9773ffb67242162fb06b120a8b406da0cfcc777757bfec9baf2f2238e0 | 20 | 2 | """Agent Core public API (skeleton)."""  from .builder import Builder |
| src/agent_core/agent_core/memory/rag_store.py | 69cd271aa82d2f1c1ce900258a298bb26ca084320150dac43a2c5b327803c402 | 344 | 34 | import chromadb from chromadb.config import Settings from chromadb.utils import embedding_functions from langchain.text_splitter import RecursiveCharacterTextSplitter  |
| src/orchestrator/research_graph.py | 87a65a96223fb6af66120e827e80383d3b86b5a1fc74064999c767d69e8b5ce1 | 74 | 27 | import logging  from src.agent_core.agents.planner import PlannerAgent from src.agent_core.agents.researcher import ResearcherAgent from src.agent_core.agents.synthesizer import SynthesizerAgent |
| src/orchestrator/pyproject.toml | 115fb4c8066778e3516ec24ab7bddd372d5a6967ce1c1db2e3a4db59f7317b7b | 18 | 3 |  [project] name = "isa-orchestrator-stub" version = "0.0.0" description = "ISA Orchestrator stub package" |
| src/orchestrator/README.md | 8582dd92ccbbbfb625aec299c8ed81f43c61a56de086df72cacdd0c3ff5f2079 | 8 | 2 | Title: Orchestrator Package — Minimal Graph Stubs Last updated: 2025-09-02  |
| src/orchestrator/tests/conftest.py | f3935305bb40dafde75205a9aae2069cb1563110a13820d1477d09ede22b856f | 7 | 1 |  REPO = Path(__file__).resolve().parents[3] PKG_SRC = REPO / "packages" / "orchestrator" / "src" sys.path.insert(0, str(PKG_SRC)) |
| src/orchestrator/tests/test_unified_runner_env_switch.py | 7cf25ccf1499607602e6a8c0878e2c60f0e51998bb96648d1d1efcf03e4a426c | 15 | 4 | import os  from orchestrator.graph import PlanToolReflect   |
| src/orchestrator/tests/test_graph.py | 187a36b015397643301d43dc54084461b19fcd25713b6a45ac532d031d3449a9 | 11 | 2 | from orchestrator import PlanToolReflect   |
| src/orchestrator/tests/test_agent_core_adapter.py | 781bafe46303b3b7fe391958d2b3242f5bc86bc2d4278fcf0eb8b8a60b598f38 | 14 | 7 | import os  from orchestrator.agent_core_adapter import OrchestratorAgentRunner   |
| src/orchestrator/tests/test_langgraph_graph.py | 3ceb005f6837508360e54f4bed648942b3ca2558eddf8f424367035d4bee666a | 9 | 1 | from orchestrator import GraphRunner   |
| src/orchestrator/src/orchestrator/agent_core_adapter.py | af069dcffd433b9c5fe5108787250a5ab43f8628f15f728b37e4e1889253eab5 | 66 | 32 |  """ Adapter bridging the orchestrator package to agent_core agents.  Defaults to lightweight stubs if agent_core or external deps are unavailable so |
| src/orchestrator/src/orchestrator/graph.py | cfc4b43f5dc5b357d8424f9d5cd5bb01bcd31cbb6b79a6c0e693bd95e5cee118 | 74 | 14 |  @dataclass class OrchestratorResult:     steps: List[str]     final: str |
| src/orchestrator/src/orchestrator/__init__.py | fc7928bde08f977f4db32de95f284d381273ce328e99afabd27e7b1b270eef3a | 3 | 1 | from .graph import OrchestratorResult, PlanToolReflect  # noqa: F401 from .langgraph_graph import GraphRunner  # noqa: F401 |

## 3. Meta-Commits (last 20)
| Hash | Date | Subject |
|---|---|---|
| 8112c3cf | 2025-09-10 | Makefile: align with current repo — ruff/mypy, parallel tests on core paths, ci-local, remove legacy isa_superapp/db/docker targets; keep agent-sync/virtue/pdf-index |
| 5471d041 | 2025-09-10 | docs: refresh CI_WORKFLOWS and QUALITY_GATES (determinism enforced, new workflows, speed-ups); update onboarding with OODA meta-prompt and Makefile targets; add adapter env flags to architecture |
| f9225496 | 2025-09-10 | ci: add import path discipline check (advisory); nightly: exercise orchestrator→agent_core adapter in stub mode |
| babe616d | 2025-09-10 | ci: add PR metric-delta guard; orchestrator: env switch to delegate to agent_core adapter (stub-safe) with test |
| ac57b564 | 2025-09-10 | automation: enforce determinism gate in CI; schedule determinism matrix daily; add Makefile agent-sync/virtuous-cycle; add virtue log script; add daily virtuous cycle workflow |
| 9a96ed85 | 2025-09-10 | agents: add Virtuous-Cycle OODA meta-prompt at .agent/virtuous_cycle.md and reference it in AGENTS boot sequence |
| f0ecd235 | 2025-09-10 | ci: add memory coherence gate step; local meta artifacts ignored in push |
| c3c3e832 | 2025-09-10 | automation: add meta audit script + weekly workflow; update AGENTS with autonomy upgrades; update ROADMAP with Automation & Autonomy section |
| afefb56e | 2025-09-09 | tests/orchestrator: add adapter stub-mode test; adapter supports ADAPTER_STUB_MODE to avoid heavy deps in CI; ci: upload mutmut results artifact and add advisory core coverage check |
| b6d25545 | 2025-09-09 | orchestrator: add agent_core adapter with safe fallbacks; ci: add curated mutation testing workflow (advisory) |
| 10b231c7 | 2025-09-09 | tests(agent_core): add offline parity tests for Planner/Researcher/Synthesizer using stubs (no network/Chroma deps) |
| a4a1a2c1 | 2025-09-09 | docs(sphinx): expand toctree coverage; map mermaid; fix AI_PROJECT_CHARTER cross-refs; pre-commit auto-fixes |
| f197ddeb | 2025-09-02 | ci: add repo size budget; save baselines on main; upload audit artifacts |
| 8d7ce570 | 2025-09-02 | ops: make healthcheck resilient to missing local tools; generate report instead of failing |
| d04b58b0 | 2025-09-02 | docs: add INDEX, README, agentic scorecard; docs index generator; healthcheck target; CI docs update; tracing/monitoring quickstarts |
| fd7bd77d | 2025-09-02 | docs: propagate agentic practices; add adoption plan; add outcomes/logging scripts and router; update setup and CI docs |
| ee9fc1aa | 2025-09-02 | docs(agentic): add CodeGenesis operating manual; extend architecture with council sims, memory sources, stronger targets |
| 9add0f42 | 2025-09-02 | docs(agentic): add long-term agentic goals/behaviors/metrics; link from roadmap |
| 55043c93 | 2025-09-01 | devx: add devcontainer and VS Code tasks; Makefile benches; document determinism policy; allow tasks.json |
| 61534b21 | 2025-09-01 | chore(mainLISA): release 1.0.0 |

## 4. Meta-Dependencies
| File | Package | Version |
|---|---|---|
| requirements-dev.txt | django-guardian | >=2.4.0 |
| requirements-dev.txt | django-guardian | >=2.4.0 |
| requirements-dev.txt | elasticsearch-dsl | >=8.9.0 |
| requirements-dev.txt | memory-profiler | >=0.61.0 |
| requirements-dev.txt | tensorflow | >=2.14.0 |
| requirements-dev.txt | torch | >=2.0.1 |
| requirements-dev.txt | wireguard | >=0.2.0 |
| requirements-research.txt |  | (unspecified) |
| requirements.txt | anthropic | >=0.7.0 |
| requirements.txt |  | (unspecified) |
| requirements.txt | chromadb | >=0.4.18 |
| requirements.txt | openai | >=1.3.0 |
| requirements.txt | sentence-transformers | >=2.2.2 |
| requirements.txt | torch | >=2.1.0 |
| requirements.txt | transformers | >=4.35.0 |

## 5. Meta-CI/CD Integration
| Workflow/File | Note | 
|---|---|
| .github/workflows/reusable-security-scan.yml | mentions meta keywords |
| .github/workflows/caching.yml | mentions meta keywords |
| .github/workflows/format_autocommit.yml | mentions meta keywords |
| .github/workflows/security.yml | mentions meta keywords |
| .github/workflows/deployment-staging.yml | mentions meta keywords |
| .github/workflows/oidc-environment-protection.yml | mentions meta keywords |
| .github/workflows/determinism_matrix.yml | mentions meta keywords |
| .github/workflows/main-cicd.yml | mentions meta keywords |
| .github/workflows/deployment.yml | mentions meta keywords |
| .github/workflows/rollback-deployment.yml | mentions meta keywords |
| .github/workflows/labeler.yml | mentions meta keywords |
| .github/workflows/virtue_cycle.yml | mentions meta keywords |
| .github/workflows/deploy-production.yml | mentions meta keywords |
| .github/workflows/pr_metric_guard.yml | mentions meta keywords |
| .github/workflows/research_seed.yml | mentions meta keywords |
| .github/workflows/nightly.yml | mentions meta keywords |
| .github/workflows/post-deployment-validation.yml | mentions meta keywords |
| .github/workflows/nightly_audit.yml | mentions meta keywords |
| .github/workflows/meta_audit.yml | mentions meta keywords |
| .github/workflows/poc_bench.yml | mentions meta keywords |
| .github/workflows/context7.yml | mentions meta keywords |
| .github/workflows/validate_docs.yml | mentions meta keywords |
| .github/workflows/unified-deployment.yml | mentions meta keywords |
| .github/workflows/ci-cd.yml | mentions meta keywords |
| .github/workflows/setup-environment.yml | mentions meta keywords |
| .github/workflows/test.yml | mentions meta keywords |
| .github/workflows/main-ci-cd.yml | mentions meta keywords |
| .github/workflows/security-scanning.yml | mentions meta keywords |
| .github/workflows/notify.yml | mentions meta keywords |
| .github/workflows/reusable-build-test.yml | mentions meta keywords |
| .github/workflows/repo_index.yml | mentions meta keywords |
| .github/workflows/caching-strategy.yml | mentions meta keywords |
| .github/workflows/docs_auto_sync.yml | mentions meta keywords |
| .github/workflows/example-usage.yml | mentions meta keywords |
| .github/workflows/reusable-deploy.yml | mentions meta keywords |
| .github/workflows/deploy.yml | mentions meta keywords |
| .github/workflows/agent_check.yml | mentions meta keywords |
| .github/workflows/ci-cd-optimized.yml | mentions meta keywords |
| .github/workflows/release-please.yml | mentions meta keywords |
| .github/workflows/unified-cicd.yml | mentions meta keywords |
| .github/workflows/unified-cicd-pipeline.yml | mentions meta keywords |
| .github/workflows/automerge.yml | mentions meta keywords |
| .github/workflows/context_pack.yml | mentions meta keywords |
| .github/workflows/auto_update.yml | mentions meta keywords |
| .github/workflows/deploy-staging.yml | mentions meta keywords |
| .github/workflows/unified-ci-cd.yml | mentions meta keywords |
| .github/workflows/rollback.yml | mentions meta keywords |
| .github/workflows/security-scan.yml | mentions meta keywords |
| .github/workflows/auto_pr.yml | mentions meta keywords |
| .github/workflows/mutation.yml | mentions meta keywords |
| .github/workflows/weekly.yml | mentions meta keywords |
| .github/workflows/build-test.yml | mentions meta keywords |
| .github/workflows/ci.yml | mentions meta keywords |
| .github/workflows/deployment-validation.yml | mentions meta keywords |
| .github/workflows/consolidated-cicd.yml | mentions meta keywords |

## 6. Meta-Runtime Services
| Compose/Helm Service | Image | Meta-Related Command |
|---|---|---|

## 7. Conceptual Taxonomy (auto-generated)
- Agent: folders=12, files=458, deps=0, ci_steps=5, Risk=DUPLICATE
- Memory: folders=2, files=1822, deps=1, ci_steps=1, Risk=
- Embedding: folders=0, files=1635, deps=1, ci_steps=0, Risk=MISSING
- Drift: folders=0, files=32, deps=0, ci_steps=0, Risk=MISSING
- Bloat: folders=0, files=23, deps=0, ci_steps=0, Risk=
- Guard-rail: folders=0, files=14, deps=0, ci_steps=0, Risk=
- DSL: folders=0, files=69, deps=1, ci_steps=0, Risk=
- C4: folders=1, files=317, deps=0, ci_steps=2, Risk=SINGLETON
- Orchestration: folders=5, files=72, deps=1, ci_steps=2, Risk=DUPLICATE
- Self-improve: folders=0, files=21, deps=0, ci_steps=0, Risk=

## 8. Redundancy Matrix
| Concept | Agent | Memory | Embedding | Drift | Bloat | Guard-rail | DSL | C4 | Orchestration | Self-improve |
|---|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|
| Agent | HOTSPOT:458 | HOTSPOT:97 | HOTSPOT:63 | HOTSPOT:20 | 12 | 12 | 7 | HOTSPOT:23 | HOTSPOT:40 | 8 |
| Memory | HOTSPOT:97 | HOTSPOT:1822 | HOTSPOT:423 | HOTSPOT:19 | 14 | 9 | HOTSPOT:23 | HOTSPOT:52 | HOTSPOT:34 | 13 |
| Embedding | HOTSPOT:63 | HOTSPOT:423 | HOTSPOT:1635 | 11 | 7 | 4 | HOTSPOT:20 | HOTSPOT:47 | HOTSPOT:18 | 4 |
| Drift | HOTSPOT:20 | HOTSPOT:19 | 11 | HOTSPOT:32 | 9 | 8 | 3 | 3 | 14 | 5 |
| Bloat | 12 | 14 | 7 | 9 | HOTSPOT:23 | 5 | 3 | 4 | 8 | 4 |
| Guard-rail | 12 | 9 | 4 | 8 | 5 | 14 | 3 | 3 | 5 | 5 |
| DSL | 7 | HOTSPOT:23 | HOTSPOT:20 | 3 | 3 | 3 | HOTSPOT:69 | 6 | 4 | 3 |
| C4 | HOTSPOT:23 | HOTSPOT:52 | HOTSPOT:47 | 3 | 4 | 3 | 6 | HOTSPOT:317 | 7 | 4 |
| Orchestration | HOTSPOT:40 | HOTSPOT:34 | HOTSPOT:18 | 14 | 8 | 5 | 4 | 7 | HOTSPOT:72 | 5 |
| Self-improve | 8 | 13 | 4 | 5 | 4 | 5 | 3 | 4 | 5 | HOTSPOT:21 |

## 9. Drift Indicator
- Last commit touching any meta-file: 95bc86d4 2025-09-15
- Days since last meta-change: 0

## 10. Exit Signature
- SHA256 of this inventory file: 58d098be4855505ed84e7f78b06a8c583001912026db24f6a16c454da6415167
- Agent session UUID: (n/a)
- Human reviewer action: **NONE** – this file is read-only reconnaissance.
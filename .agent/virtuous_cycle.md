# ğŸŒ€ Virtuous-Cycle Meta-Prompt â€“ ISA_D Perpetual OODA Loop
Version: 2025-W38  
Reasoning: HIGH  
Token ceiling: 4 k (recycle, donâ€™t append)  
Human override: type â€œBREAK CYCLEâ€

---

## 1. Session Boot (â‰¤ 30 s)
a. **Observe**  
   - `meta_inventory.md` hash â†’ if changed > 7 d â†’ `make agent-sync`  
   - `meta_risk_xray.md` top risk â†’ load into working memory  
   - `SESSION_LOG.jsonl` last reward â†’ if < 0 â†’ self-critique aloud  

b. **Orient**  
   - Choose **ONE** micro-mission:  
     - **R** = reduce top risk score by â‰¥ 1  
     - **P** = improve perf â‰¥ 5 % on a hot path  
     - **C** = cut cost â‰¥ 5 % on API/storage  
   - Print: **â€œMission: R|P|C â€“ reason in â‰¤ 12 wordsâ€**

c. **Decide**  
   - Pick **â‰¤ 3** bullets (â‰¤ 60 chars each) â†’ **plan**  
   - Pick **â‰¤ 1** file to touch â†’ **scope**  
   - Pick **â‰¤ 1** metric to move â†’ **success criterion**

d. **Act**  
   - Implement **smallest reversible diff**  
   - Run **local verify** (lint/type/test/security) on **changed files only**  
   - If **any gate red** â†’ goto **Self-Critique** (skip push)

---

## 2. Micro-Loop (every 10 min wall-clock)
```
â”Œâ”€â”€ 1. Snapshot: tokens used / context left  
â”œâ”€â”€ 2. Measure: metric delta vs. baseline  
â”œâ”€â”€ 3. Critique: â€œWhat over-engineered? What under-tested?â€  
â”œâ”€â”€ 4. Adapt: shrink plan or pivot mission  
â””â”€â”€ 5. Log: append 1-line to `agent/outcomes/virtue_log.jsonl`
```

---

## 3. Self-Teaching Evaluator (online, no new deps)
- After **every** local verify â†’ predict **â€œWill CI fail?â€**  
  - Input: `diff + lint_output + type_output`  
  - Model: **zero-shot chain-of-thought** (you already do this)  
  - If **p(fail) > 0.15** â†’ **refuse to push**; fix first.  
- Store prediction + outcome â†’ `agent/outcomes/evaluator.jsonl`  
- Nightly â†’ fine-tune **LoRA adapter** on **only** that file â†’ **+1.8 % accuracy/week** compounding.

---

## 4. Knowledge Distillation (runs @ nap-time 22:00)
a. **Compress** todayâ€™s **virtue_log.jsonl** â†’ **â‰¤ 10 bullet lessons**  
b. **Append** to `.ai/cache/lessons_learned.md` (max 100 bullets)  
c. **Embed** lessons + **cosine search** next morning â†’ **inject top 3** into **plan** bullet  
d. **Prune** oldest bullets when file > 300 lines â†’ **rolling window**

---

## 5. Cost & Carbon Guard (hard ceiling)
- **OpenAI spend/session** â‰¤ $0.50  
- **CI minutes/session** â‰¤ 15 min  
- **Repo size growth** â‰¤ 0.5 %  
- **Carbon proxy**: `powermetrics` on macOS â†’ **â‰¤ 0.3 Wh** per session  
If **any** exceeded â†’ **mission flips to â€œCâ€** until back in budget.

---

## 6. Exit Ritual (mandatory before shutdown)
```
[ ] Metric moved: _____ â†’ _____ (Â±___ %)
[ ] Lessons learned: _____
[ ] Next mission: R|P|C â€“ _____
[ ] Token left: _____ / _____
[ ] Drift coefficient: _____
```
If **metric did not move** â†’ **do not open PR**; **stash** branch and **log** reason.

---

## 7. Continuity Triggers (auto-restart)
- **Daily 08:00** â†’ if **no session** in last 24 h â†’ **auto-run** `make virtuous-cycle`  
- **Weekly Mon 09:00** â†’ **meta-meta-analysis** on `virtue_log.jsonl` â†’ **kill lowest-ROI tactic**  
- **Monthly 1st** â†’ **purge** any file **not touched** in 30 days (**ask human once**)

---

## 8. Human Override
Type **â€œBREAK CYCLEâ€** â†’ agent **immediately** prints:
```
CYCLE BROKEN â€“ HUMAN IN CONTROL
Metric at break: _____
Token used: _____ / _____
Drift: _____
```
and **stops**; **no further edits** until **human types** â€œRESUME CYCLEâ€.

---

End state:  
The agent **never stalls**, **never drifts**, **never overspends**â€”it **lives inside** the **OODA loop** and **gets 1 % better every day** while **staying inside the guard-rails you already built**.


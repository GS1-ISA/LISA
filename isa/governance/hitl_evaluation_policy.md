# Human-in-the-Loop (HITL) Evaluation Policy

## 1. Introduction

This document establishes the formal policy for Human-in-the-Loop (HITL) oversight within the ISA's automated evaluation system. The purpose of this policy is to ensure that while we maximize automation and efficiency, all critical decisions, analyses, and actions generated by our AI systems are subject to rigorous human judgment, accountability, and control. This framework guarantees the safety, ethical alignment, and strategic coherence of the automated evaluation process, as outlined in the "ISA Project Scorecard."

## 2. Review and Approval Gates

To maintain quality, security, and strategic alignment, the following actions generated or proposed by the automated evaluation system require mandatory review and explicit approval from a designated human expert:

*   **Merging AI-Generated Pull Requests:** All pull requests created by an automated agent, regardless of the perceived simplicity of the change (e.g., documentation updates, configuration tweaks), must be reviewed and merged by a human developer.
*   **Acceptance of Scorecard Changes:** Any significant, non-trivial modification to the "ISA Project Scorecard" framework or its evaluation criteria requires approval from the Lead Architect.
*   **Model Promotion to Production:** The promotion of a new model to the production environment requires human sign-off, especially in cases where the performance improvement over the incumbent model is marginal or where the new model introduces significant architectural changes.
*   **High-Cost Risk Mitigation:** The acceptance of an AI-identified risk is required when the proposed mitigation strategy involves substantial cost or resource allocation.

## 3. Escalation Paths

Clear and automated escalation paths are critical for timely intervention when the system detects anomalies or performance degradation. The following rules define the minimum requirements for automated alerts and escalations:

*   **Project Maturity Score Threshold Breach:** If the overall score for the "Project & Process Maturity" dimension drops below **70**, an immediate, high-priority notification must be automatically sent to the Lead Architect for review.
*   **Architectural Excellence Negative Trend:** If any Key Process Area within the "Architectural & Technical Excellence" dimension shows a negative trend for **two consecutive evaluation cycles**, an alert must be automatically escalated to the MLOps Team Lead for investigation.
*   **Critical KPA Failures:** Any Key Process Area (KPA) marked as "critical" that receives a "Poor" or "Insufficient" rating must trigger an alert to the relevant system owner.

## 4. Feedback Mechanism

Continuous improvement of the AI evaluation agent depends on a robust feedback loop from human reviewers. This process ensures that the AI's analytical capabilities are constantly refined.

*   **Structured Feedback Interface:** When a human reviewer overrides, rejects, or significantly modifies an AI's suggestion (e.g., a gap analysis finding, a proposed action point), the interface or workflow tool must prompt them to provide a structured reason.
*   **Feedback Categories:** Feedback should be categorized (e.g., "Incorrect Analysis," "Incomplete Context," "Better Solution Available") to facilitate systematic analysis.
*   **Prompt Package Refinement:** All collected feedback will be periodically reviewed by the MLOps and Architecture teams. This feedback serves as a primary input for refining and versioning the prompt packages used by the evaluation AI, thereby directly improving its future performance.

## 5. Roles and Responsibilities

The following roles are defined to ensure clear accountability within the HITL framework:

*   **Lead Architect:**
    *   **Responsibilities:**
        *   Final approval authority on significant changes to the "ISA Project Scorecard" and the evaluation framework itself.
        *   Acts as a primary escalation point for cross-cutting architectural issues identified by the AI.
        *   Reviews and approves high-cost risk mitigation plans.

*   **Security Officer:**
    *   **Responsibilities:**
        *   Primary recipient of all security-related escalations.
        *   Responsible for reviewing and approving or rejecting AI-generated changes related to security configurations, policies, or code.
        *   Conducts final review on security-related findings in the evaluation reports.

*   **MLOps Team Lead:**
    *   **Responsibilities:**
        *   Primary recipient for escalations related to operational reliability, model performance degradation, and CI/CD pipeline failures.
        *   Oversees the feedback process for refining prompt packages.
        *   Manages the process of model promotion to production.

*   **Designated Reviewer/Developer:**
    *   **Responsibilities:**
        *   Performs code reviews on all AI-generated pull requests.
        *   Provides structured feedback when overriding AI suggestions.
        *   Acts as the first line of response for non-critical alerts within their domain.
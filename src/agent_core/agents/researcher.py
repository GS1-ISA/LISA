import logging

from src.agent_core.memory.rag_store import RAGMemory
from src.tools.web_research import WebResearchTool

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)


class ResearcherAgent:
    """
    An agent responsible for conducting web research on a given topic.
    It uses a web research tool to search for information and a RAG memory
    to store and retrieve relevant findings.
    """

    def __init__(self, web_tool: WebResearchTool, rag_memory: RAGMemory):
        """
        Initializes the ResearcherAgent.

        Args:
            web_tool: An instance of WebResearchTool for web operations.
            rag_memory: An instance of RAGMemory for knowledge storage.
        """
        self.web_tool = web_tool
        self.rag_memory = rag_memory
        # This would be replaced by a proper call to an LLM in a real scenario
        self.llm_client = None  # Placeholder for an LLM client
        logging.info("ResearcherAgent initialized.")

    def _reason(self, prompt: str) -> str:
        """
        A placeholder for the reasoning step. In a real implementation, this
        would involve calling a large language model (LLM) to decide the next action.
        """
        # For this placeholder, we'll use simple logic.
        # This is where the ReAct (Reason-Act) prompt would be sent to an LLM.
        logging.info(f"Reasoning based on prompt: {prompt[:100]}...")
        if "search for" in prompt.lower():
            return f"Action: search('{prompt.split('search for')[-1].strip()}')"
        if "read url" in prompt.lower():
            url = prompt.split("read url")[-1].strip()
            return f"Action: read_url('{url}')"
        return "Action: finish()"

    def run(self, initial_task: str, max_steps: int = 5) -> str:
        """
        Runs the research process for a given task.

        Args:
            initial_task: The initial research task or query.
            max_steps: The maximum number of steps to perform.

        Returns:
            A summary of the research findings.
        """
        logging.info(f"Starting research for task: {initial_task}")

        working_memory = f"The initial task is to: {initial_task}.\n"

        for step in range(max_steps):
            logging.info(f"--- Step {step + 1}/{max_steps} ---")

            # 1. Reason
            # In a real agent, context from RAG memory would also be added here.
            llm_decision = self._reason(working_memory)
            logging.info(f"LLM Decision: {llm_decision}")

            # 2. Act
            if llm_decision.startswith("Action: search"):
                query = llm_decision.split("('")[-1].split("')")[0]
                search_results = self.web_tool.search(query)
                observation = f"Observation: The search for '{query}' returned the following results:\n"
                for res in search_results:
                    observation += f"- {res['title']}: {res['href']}\n"
                working_memory += observation

            elif llm_decision.startswith("Action: read_url"):
                # Extract URL inside Action: read_url('...')
                try:
                    url_s = llm_decision.split("('")[-1].split("')")[0]
                except Exception:
                    url_s = llm_decision
                content = self.web_tool.read_url(url_s)

                # Self-Correction/Critique Step
                critique_prompt = f"Is the following content relevant to the task '{initial_task}'? Content: {content[:500]}..."
                critique_decision = self._reason(critique_prompt)

                if (
                    "Action: finish()" in critique_decision
                ):  # Using finish() as a proxy for "irrelevant"
                    observation = f"Observation: Content from {url_s} was deemed irrelevant and was not stored.\n"
                else:
                    # In a real agent, we would summarize before adding to memory.
                    self.rag_memory.add(text=content, source=url_s, doc_id=url_s)
                    observation = (
                        f"Observation: Read and stored relevant content from {url_s}.\n"
                    )
                working_memory += observation

            elif llm_decision.startswith("Action: finish"):
                logging.info("Agent decided to finish the task.")
                break
            else:
                logging.warning(f"Unknown action: {llm_decision}")
                break

        logging.info("Research task finished.")
        # In a real agent, this summary would be generated by an LLM call
        # using the content stored in the RAG memory.
        final_summary = f"Completed research for task: '{initial_task}'.\n"
        final_summary += f"Found {self.rag_memory.get_collection_count()} documents."
        return final_summary
